[
  {
    "objectID": "practice.html",
    "href": "practice.html",
    "title": "Practice1-Climate-change",
    "section": "",
    "text": "Practice1-Climate-change\n\n\n%pip install pandas matplotlib numpy lets_plot\n\nRequirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.2.2)\nRequirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.9.2)\nRequirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.26.4)\nCollecting lets_plot\n  Using cached lets_plot-4.5.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\nRequirement already satisfied: contourpy&gt;=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: packaging&gt;=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\nRequirement already satisfied: pillow&gt;=8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\nCollecting pypng (from lets_plot)\n  Using cached pypng-0.20220715.0-py3-none-any.whl.metadata (13 kB)\nCollecting palettable (from lets_plot)\n  Using cached palettable-3.3.3-py2.py3-none-any.whl.metadata (3.3 kB)\nRequirement already satisfied: six&gt;=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)\nUsing cached lets_plot-4.5.1-cp312-cp312-win_amd64.whl (3.1 MB)\nUsing cached palettable-3.3.3-py2.py3-none-any.whl (332 kB)\nUsing cached pypng-0.20220715.0-py3-none-any.whl (58 kB)\nInstalling collected packages: pypng, palettable, lets_plot\nSuccessfully installed lets_plot-4.5.1 palettable-3.3.3 pypng-0.20220715.0\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\n\nfrom lets_plot import *\nLetsPlot.setup_html(no_js=True)\nplt.style.use(\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\n\n\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\n\n\n1.Why have researchers chosen this particular measure over other measures (such as absolute temperature)?\n\nTemperature anomalies indicate how much warmer or colder it is than normal for a particular place and time. For the GISS analysis, normal always means the average over the 30-year period 1951-1980 for that place and time of year. This base period is specific to GISS, not universal. But note that trends do not depend on the choice of the base period: If the absolute temperature at a specific location is 2 degrees higher than a year ago, so is the corresponding temperature anomaly, no matter what base period is selected, since the normal temperature used as base point (which is subtracted from the absolute temperature to get the anomaly) is the same for both years.\nNote that regional mean anomalies (in particular global anomalies) are not computed from the current absolute mean and the 1951-80 mean for that region, but from station temperature anomalies. Finding absolute regional means encounters significant difficulties that create large uncertainties. This is why the GISS analysis deals with anomalies rather than absolute temperatures. For a more detailed discussion of that topic, please see “The Elusive Absolute Temperature”.\n\ndf.head()\n\n\n\n\n\n\n\n\nYear\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\n\n\n0\n1880\n-0.39\n-0.54\n-0.24\n-0.31\n-0.06\n-0.18\n-0.22\n-0.26\n-0.25\n-0.31\n-0.44\n-0.43\n-0.30\nNaN\nNaN\n-0.20\n-0.22\n-0.33\n\n\n1\n1881\n-0.31\n-0.25\n-0.06\n-0.02\n0.05\n-0.34\n0.09\n-0.06\n-0.29\n-0.45\n-0.37\n-0.23\n-0.19\n-0.20\n-0.33\n-0.01\n-0.10\n-0.37\n\n\n2\n1882\n0.26\n0.21\n0.02\n-0.30\n-0.23\n-0.29\n-0.28\n-0.15\n-0.25\n-0.52\n-0.34\n-0.69\n-0.21\n-0.18\n0.08\n-0.17\n-0.24\n-0.37\n\n\n3\n1883\n-0.58\n-0.66\n-0.15\n-0.30\n-0.26\n-0.12\n-0.06\n-0.23\n-0.34\n-0.17\n-0.45\n-0.15\n-0.29\n-0.33\n-0.64\n-0.24\n-0.14\n-0.32\n\n\n4\n1884\n-0.16\n-0.11\n-0.64\n-0.59\n-0.36\n-0.42\n-0.41\n-0.52\n-0.45\n-0.45\n-0.58\n-0.47\n-0.43\n-0.40\n-0.14\n-0.53\n-0.45\n-0.50\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 145 entries, 0 to 144\nData columns (total 19 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Year    145 non-null    int64  \n 1   Jan     145 non-null    float64\n 2   Feb     145 non-null    float64\n 3   Mar     145 non-null    float64\n 4   Apr     145 non-null    float64\n 5   May     145 non-null    float64\n 6   Jun     145 non-null    float64\n 7   Jul     145 non-null    float64\n 8   Aug     145 non-null    float64\n 9   Sep     145 non-null    float64\n 10  Oct     144 non-null    float64\n 11  Nov     144 non-null    float64\n 12  Dec     144 non-null    float64\n 13  J-D     144 non-null    float64\n 14  D-N     143 non-null    float64\n 15  DJF     144 non-null    float64\n 16  MAM     145 non-null    float64\n 17  JJA     145 non-null    float64\n 18  SON     144 non-null    float64\ndtypes: float64(18), int64(1)\nmemory usage: 21.7 KB\n\n\n\ndf = df.set_index(\"Year\")\ndf.head()\n\n\n\n\n\n\n\n\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\nYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1880\n-0.39\n-0.54\n-0.24\n-0.31\n-0.06\n-0.18\n-0.22\n-0.26\n-0.25\n-0.31\n-0.44\n-0.43\n-0.30\nNaN\nNaN\n-0.20\n-0.22\n-0.33\n\n\n1881\n-0.31\n-0.25\n-0.06\n-0.02\n0.05\n-0.34\n0.09\n-0.06\n-0.29\n-0.45\n-0.37\n-0.23\n-0.19\n-0.20\n-0.33\n-0.01\n-0.10\n-0.37\n\n\n1882\n0.26\n0.21\n0.02\n-0.30\n-0.23\n-0.29\n-0.28\n-0.15\n-0.25\n-0.52\n-0.34\n-0.69\n-0.21\n-0.18\n0.08\n-0.17\n-0.24\n-0.37\n\n\n1883\n-0.58\n-0.66\n-0.15\n-0.30\n-0.26\n-0.12\n-0.06\n-0.23\n-0.34\n-0.17\n-0.45\n-0.15\n-0.29\n-0.33\n-0.64\n-0.24\n-0.14\n-0.32\n\n\n1884\n-0.16\n-0.11\n-0.64\n-0.59\n-0.36\n-0.42\n-0.41\n-0.52\n-0.45\n-0.45\n-0.58\n-0.47\n-0.43\n-0.40\n-0.14\n-0.53\n-0.45\n-0.50\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\nYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2020\n1.58\n1.69\n1.66\n1.39\n1.26\n1.14\n1.10\n1.12\n1.19\n1.20\n1.58\n1.18\n1.34\n1.36\n1.56\n1.44\n1.12\n1.32\n\n\n2021\n1.25\n0.95\n1.20\n1.12\n1.04\n1.20\n1.07\n1.02\n1.04\n1.29\n1.29\n1.16\n1.14\n1.14\n1.13\n1.12\n1.10\n1.21\n\n\n2022\n1.24\n1.16\n1.41\n1.08\n1.02\n1.12\n1.06\n1.16\n1.14\n1.31\n1.09\n1.06\n1.15\n1.16\n1.19\n1.17\n1.11\n1.18\n\n\n2023\n1.29\n1.29\n1.63\n1.01\n1.12\n1.19\n1.44\n1.57\n1.67\n1.88\n1.97\n1.85\n1.49\n1.43\n1.21\n1.26\n1.40\n1.84\n\n\n2024\n1.66\n1.93\n1.77\n1.79\n1.44\n1.54\n1.42\n1.42\n1.57\nNaN\nNaN\nNaN\nNaN\nNaN\n1.81\n1.67\n1.46\nNaN\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\ndf[\"Jan\"].plot(ax=ax)\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\nax.plot(df.index, df[\"Jan\"])\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\n\n\n\n\n\n\n\n\n\nmonth = \"Jan\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.66, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average temperature anomaly in {month} \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n\n\n\n\n\n\n\n\n\nmonth = \"J-D\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.68, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average annual temperature anomaly in \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n\n\n\n\n\n\n\n\n\ndf[\"Period\"] = pd.cut(\n    df.index,\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\ndf[\"Period\"].tail(20)\n\nYear\n2005    1981—2010\n2006    1981—2010\n2007    1981—2010\n2008    1981—2010\n2009    1981—2010\n2010    1981—2010\n2011          NaN\n2012          NaN\n2013          NaN\n2014          NaN\n2015          NaN\n2016          NaN\n2017          NaN\n2018          NaN\n2019          NaN\n2020          NaN\n2021          NaN\n2022          NaN\n2023          NaN\n2024          NaN\nName: Period, dtype: category\nCategories (3, object): ['1921—1950' &lt; '1951—1980' &lt; '1981—2010']\n\n\n\nlist_of_months = [\"Jun\", \"Jul\", \"Aug\"]\ndf[list_of_months].stack().head()\n\nYear     \n1880  Jun   -0.18\n      Jul   -0.22\n      Aug   -0.26\n1881  Jun   -0.34\n      Jul    0.09\ndtype: float64\n\n\n\nfig, axes = plt.subplots(ncols=3, figsize=(9, 4), sharex=True, sharey=True)\nfor ax, period in zip(axes, df[\"Period\"].dropna().unique()):\n    df.loc[df[\"Period\"] == period, list_of_months].stack().hist(ax=ax)\n    ax.set_title(period)\nplt.suptitle(\"Histogram of temperature anomalies\")\naxes[1].set_xlabel(\"Summer temperature distribution\")\nplt.tight_layout();\n\n\n\n\n\n\n\n\n\n# Create a variable that has years 1951 to 1980, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1951) & (df.index &lt;= 1980), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at this data:\ntemp_all_months\n\n\n\n\n\n\n\n\nYear\nmonth\nvalues\n\n\n\n\n0\n1951\nJan\n-0.36\n\n\n1\n1951\nFeb\n-0.51\n\n\n2\n1951\nMar\n-0.19\n\n\n3\n1951\nApr\n0.07\n\n\n4\n1951\nMay\n0.17\n\n\n...\n...\n...\n...\n\n\n355\n1980\nAug\n0.09\n\n\n356\n1980\nSep\n0.10\n\n\n357\n1980\nOct\n0.12\n\n\n358\n1980\nNov\n0.20\n\n\n359\n1980\nDec\n0.09\n\n\n\n\n360 rows × 3 columns\n\n\n\n\nquantiles = [0.3, 0.7]\nlist_of_percentiles = np.quantile(temp_all_months[\"values\"], q=quantiles)\n\nprint(f\"The cold threshold of {quantiles[0]*100}% is {list_of_percentiles[0]}\")\nprint(f\"The hot threshold of {quantiles[1]*100}% is {list_of_percentiles[1]}\")\n\nThe cold threshold of 30.0% is -0.1\nThe hot threshold of 70.0% is 0.1\n\n\n\n# Create a variable that has years 1981 to 2010, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1981) & (df.index &lt;= 2010), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at the start of this data data:\ntemp_all_months.head()\n\n\n\n\n\n\n\n\nYear\nmonth\nvalues\n\n\n\n\n0\n1981\nJan\n0.79\n\n\n1\n1981\nFeb\n0.62\n\n\n2\n1981\nMar\n0.68\n\n\n3\n1981\nApr\n0.39\n\n\n4\n1981\nMay\n0.18\n\n\n\n\n\n\n\n\nentries_less_than_q30 = temp_all_months[\"values\"] &lt; list_of_percentiles[0]\nproportion_under_q30 = entries_less_than_q30.mean()\nprint(\n    f\"The proportion under {list_of_percentiles[0]} is {proportion_under_q30*100:.2f}%\"\n)\n\nThe proportion under -0.1 is 1.94%\n\n\n\nproportion_over_q70 = (temp_all_months[\"values\"] &gt; list_of_percentiles[1]).mean()\nprint(f\"The proportion over {list_of_percentiles[1]} is {proportion_over_q70*100:.2f}%\")\n\nThe proportion over 0.1 is 84.72%\n\n\n\ntemp_all_months = (\n    df.loc[:, \"DJF\":\"SON\"]\n    .stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"Season\", 0: \"Values\"})\n)\ntemp_all_months[\"Period\"] = pd.cut(\n    temp_all_months[\"Year\"],\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n# Take a look at a cut of the data using `.iloc`, which provides position\ntemp_all_months.iloc[-135:-125]\n\n\n\n\n\n\n\n\nYear\nSeason\nValues\nPeriod\n\n\n\n\n443\n1991\nDJF\n0.51\n1981—2010\n\n\n444\n1991\nMAM\n0.45\n1981—2010\n\n\n445\n1991\nJJA\n0.42\n1981—2010\n\n\n446\n1991\nSON\n0.32\n1981—2010\n\n\n447\n1992\nDJF\n0.43\n1981—2010\n\n\n448\n1992\nMAM\n0.30\n1981—2010\n\n\n449\n1992\nJJA\n-0.04\n1981—2010\n\n\n450\n1992\nSON\n-0.15\n1981—2010\n\n\n451\n1993\nDJF\n0.37\n1981—2010\n\n\n452\n1993\nMAM\n0.31\n1981—2010\n\n\n\n\n\n\n\n\ngrp_mean_var = temp_all_months.groupby([\"Season\", \"Period\"])[\"Values\"].agg(\n    [np.mean, np.var]\n)\ngrp_mean_var\n\n\n\n\n\n\n\n\n\nmean\nvar\n\n\nSeason\nPeriod\n\n\n\n\n\n\nDJF\n1921—1950\n-0.027931\n0.057703\n\n\n1951—1980\n-0.003333\n0.050375\n\n\n1981—2010\n0.522000\n0.078644\n\n\nJJA\n1921—1950\n-0.054483\n0.021611\n\n\n1951—1980\n0.001333\n0.014640\n\n\n1981—2010\n0.399000\n0.067775\n\n\nMAM\n1921—1950\n-0.041724\n0.031136\n\n\n1951—1980\n0.000333\n0.025272\n\n\n1981—2010\n0.507667\n0.075812\n\n\nSON\n1921—1950\n0.081379\n0.027798\n\n\n1951—1980\n-0.001333\n0.026384\n\n\n1981—2010\n0.427000\n0.110739\n\n\n\n\n\n\n\n\nmin_year = 1880\n(\n    ggplot(temp_all_months, aes(x=\"Year\", y=\"Values\", color=\"Season\"))\n    + geom_abline(slope=0, color=\"black\", size=1)\n    + geom_line(size=1)\n    + labs(\n        title=f\"Average annual temperature anomaly in \\n in the northern hemisphere ({min_year}—{temp_all_months['Year'].max()})\",\n        y=\"Annual temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n    + geom_text(\n        x=min_year, y=0.1, label=\"1951—1980 average\", hjust=\"left\", color=\"black\"\n    )\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n      \n        \n          \n            \n              \n              \n            \n            \n              \n                \n                \n              \n              \n                \n                \n              \n              \n                \n                \n              \n              \n                \n                \n              \n            \n            \n              \n                \n                  \n                    1951—1980 average\n                  \n                \n              \n            \n          \n        \n        \n          \n            \n            \n          \n        \n        \n          \n            \n            \n          \n        \n        \n          \n            \n            \n          \n        \n      \n      \n        \n          \n            \n            \n            \n              \n                1880\n              \n            \n          \n          \n            \n            \n            \n              \n                1900\n              \n            \n          \n          \n            \n            \n            \n              \n                1920\n              \n            \n          \n          \n            \n            \n            \n              \n                1940\n              \n            \n          \n          \n            \n            \n            \n              \n                1960\n              \n            \n          \n          \n            \n            \n            \n              \n                1980\n              \n            \n          \n          \n            \n            \n            \n              \n                2000\n              \n            \n          \n          \n            \n            \n            \n              \n                2020\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                -1.0\n              \n            \n          \n          \n            \n              \n                -0.5\n              \n            \n          \n          \n            \n              \n                0.0\n              \n            \n          \n          \n            \n              \n                0.5\n              \n            \n          \n          \n            \n              \n                1.0\n              \n            \n          \n          \n            \n              \n                1.5\n              \n            \n          \n        \n      \n    \n    \n      \n        Average annual temperature anomaly in \n      \n      \n         in the northern hemisphere (1880—2024)\n      \n    \n    \n      \n        Annual temperature anomalies\n      \n    \n    \n      \n        Year\n      \n    \n    \n      \n      \n      \n        \n          \n            Season\n          \n        \n        \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                MAM\n              \n            \n          \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                JJA\n              \n            \n          \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                SON\n              \n            \n          \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                DJF\n              \n            \n          \n        \n      \n    \n    \n    \n  \n  \n  \n\n\n\n\ndf_co2 = pd.read_csv(\"D:\\Yang Fan\\data\\data2(1).csv\")\ndf_co2.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nMonthly average\nInterpolated\nTrend\n\n\n\n\n0\n1958\n3\n315.71\n315.71\n314.62\n\n\n1\n1958\n4\n317.45\n317.45\n315.29\n\n\n2\n1958\n5\n317.50\n317.50\n314.71\n\n\n3\n1958\n6\n-99.99\n317.10\n314.85\n\n\n4\n1958\n7\n315.86\n315.86\n314.98\n\n\n\n\n\n\n\n\ndf_co2_june = df_co2.loc[df_co2[\"Month\"] == 6]\ndf_co2_june.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nMonthly average\nInterpolated\nTrend\n\n\n\n\n3\n1958\n6\n-99.99\n317.10\n314.85\n\n\n15\n1959\n6\n318.15\n318.15\n315.92\n\n\n27\n1960\n6\n319.59\n319.59\n317.36\n\n\n39\n1961\n6\n319.77\n319.77\n317.48\n\n\n51\n1962\n6\n320.55\n320.55\n318.27\n\n\n\n\n\n\n\n\ndf_temp_co2 = pd.merge(df_co2_june, df, on=\"Year\")\ndf_temp_co2[[\"Year\", \"Jun\", \"Trend\"]].head()\n\n\n\n\n\n\n\n\nYear\nJun\nTrend\n\n\n\n\n0\n1958\n0.05\n314.85\n\n\n1\n1959\n0.14\n315.92\n\n\n2\n1960\n0.18\n317.36\n\n\n3\n1961\n0.18\n317.48\n\n\n4\n1962\n-0.13\n318.27\n\n\n\n\n\n\n\n\n(\n    ggplot(df_temp_co2, aes(x=\"Jun\", y=\"Trend\"))\n    + geom_point(color=\"black\", size=3)\n    + labs(\n        title=\"Scatterplot of temperature anomalies vs carbon dioxide emissions\",\n        y=\"Carbon dioxide levels (trend, mole fraction)\",\n        x=\"Temperature anomaly (degrees Celsius)\",\n    )\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n      \n        \n          \n            \n              \n                \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                \n              \n            \n          \n        \n        \n          \n            \n            \n          \n        \n      \n      \n        \n          \n            \n            \n            \n              \n                -0.2\n              \n            \n          \n          \n            \n            \n            \n              \n                0.0\n              \n            \n          \n          \n            \n            \n            \n              \n                0.2\n              \n            \n          \n          \n            \n            \n            \n              \n                0.4\n              \n            \n          \n          \n            \n            \n            \n              \n                0.6\n              \n            \n          \n          \n            \n            \n            \n              \n                0.8\n              \n            \n          \n          \n            \n            \n            \n              \n                1.0\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                320\n              \n            \n          \n          \n            \n              \n                340\n              \n            \n          \n          \n            \n              \n                360\n              \n            \n          \n          \n            \n              \n                380\n              \n            \n          \n          \n            \n              \n                400\n              \n            \n          \n        \n      \n    \n    \n      \n        Scatterplot of temperature anomalies vs carbon dioxide emissions\n      \n    \n    \n      \n        Carbon dioxide levels (trend, mole fraction)\n      \n    \n    \n      \n        Temperature anomaly (degrees Celsius)\n      \n    \n    \n    \n  \n  \n  \n\n\n\n\ndf_temp_co2[[\"Jun\", \"Trend\"]].corr(method=\"pearson\")\n\n\n\n\n\n\n\n\nJun\nTrend\n\n\n\n\nJun\n1.000000\n0.914371\n\n\nTrend\n0.914371\n1.000000\n\n\n\n\n\n\n\n\n(\n    ggplot(df_temp_co2, aes(x=\"Year\", y=\"Jun\"))\n    + geom_line(size=1)\n    + labs(\n        title=\"June temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n      \n        \n          \n            \n              \n                \n                \n              \n            \n          \n        \n        \n          \n            \n            \n          \n        \n      \n      \n        \n          \n            \n            \n            \n              \n                1960\n              \n            \n          \n          \n            \n            \n            \n              \n                1970\n              \n            \n          \n          \n            \n            \n            \n              \n                1980\n              \n            \n          \n          \n            \n            \n            \n              \n                1990\n              \n            \n          \n          \n            \n            \n            \n              \n                2000\n              \n            \n          \n          \n            \n            \n            \n              \n                2010\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                -0.2\n              \n            \n          \n          \n            \n              \n                0.0\n              \n            \n          \n          \n            \n              \n                0.2\n              \n            \n          \n          \n            \n              \n                0.4\n              \n            \n          \n          \n            \n              \n                0.6\n              \n            \n          \n          \n            \n              \n                0.8\n              \n            \n          \n          \n            \n              \n                1.0\n              \n            \n          \n        \n      \n    \n    \n      \n        June temperature anomalies\n      \n    \n    \n      \n        Jun\n      \n    \n    \n      \n        Year\n      \n    \n    \n    \n  \n  \n  \n\n\n\n\nbase_plot = ggplot(df_temp_co2) + scale_x_continuous(format=\"d\")\nplot_p = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Jun\"), size=1)\n    + labs(title=\"June temperature anomalies\")\n)\nplot_q = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Trend\"), size=1)\n    + labs(title=\"Carbon dioxide emissions\")\n)\ngggrid([plot_p, plot_q], ncol=2)\n\n\n  \n    \n    \n  \n  \n    \n    \n      \n      \n      \n        \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n        \n        \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n          \n          \n            \n              \n              \n            \n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  1960\n                \n              \n            \n            \n              \n              \n              \n                \n                  1970\n                \n              \n            \n            \n              \n              \n              \n                \n                  1980\n                \n              \n            \n            \n              \n              \n              \n                \n                  1990\n                \n              \n            \n            \n              \n              \n              \n                \n                  2000\n                \n              \n            \n            \n              \n              \n              \n                \n                  2010\n                \n              \n            \n            \n            \n          \n          \n            \n              \n                \n                  -0.2\n                \n              \n            \n            \n              \n                \n                  0.0\n                \n              \n            \n            \n              \n                \n                  0.2\n                \n              \n            \n            \n              \n                \n                  0.4\n                \n              \n            \n            \n              \n                \n                  0.6\n                \n              \n            \n            \n              \n                \n                  0.8\n                \n              \n            \n            \n              \n                \n                  1.0\n                \n              \n            \n          \n        \n      \n      \n        \n          June temperature anomalies\n        \n      \n      \n        \n          Jun\n        \n      \n      \n        \n          Year\n        \n      \n      \n      \n    \n    \n    \n  \n  \n    \n    \n      \n      \n      \n        \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n        \n        \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n          \n          \n            \n              \n              \n            \n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  1960\n                \n              \n            \n            \n              \n              \n              \n                \n                  1970\n                \n              \n            \n            \n              \n              \n              \n                \n                  1980\n                \n              \n            \n            \n              \n              \n              \n                \n                  1990\n                \n              \n            \n            \n              \n              \n              \n                \n                  2000\n                \n              \n            \n            \n              \n              \n              \n                \n                  2010\n                \n              \n            \n            \n            \n          \n          \n            \n              \n                \n                  320\n                \n              \n            \n            \n              \n                \n                  340\n                \n              \n            \n            \n              \n                \n                  360\n                \n              \n            \n            \n              \n                \n                  380\n                \n              \n            \n            \n              \n                \n                  400\n                \n              \n            \n          \n        \n      \n      \n        \n          Carbon dioxide emissions\n        \n      \n      \n        \n          Trend\n        \n      \n      \n        \n          Year\n        \n      \n      \n      \n    \n    \n    \n  \n\n\n\nSource: Create a variable that has years 1951 to 1980, and months Jan to Dec (inclusive)\n\n\nPractice2-Collecting-and-analysing-data-from-experiments\n\n\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nfrom lets_plot import *\n\n\nLetsPlot.setup_html(no_js=True)\n\n\nplt.style.use(\n\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\n\n\ndata_np = pd.read_excel(\n    \"data/doing-economics-datafile-working-in-excel-project-2.xlsx\",\n    usecols=\"A:Q\",\n    header=1,\n    index_col=\"Period\",\n)\ndata_n = data_np.iloc[:10, :].copy()\ndata_p = data_np.iloc[14:24, :].copy()\n\n\ntest_data = {\n    \"City A\": [14.1, 14.1, 13.7],\n    \"City B\": [11.0, 12.6, 12.1],\n}\n\n\n# Original dataframe\ntest_df = pd.DataFrame.from_dict(test_data)\n# A copy of the dataframe\ntest_copy = test_df.copy()\n# A pointer to the dataframe\ntest_pointer = test_df\n\n\ntest_pointer.iloc[1, 1] = 99\n\n\nprint(\"test_df=\")\nprint(f\"{test_df}\\n\")\nprint(\"test_copy=\")\nprint(f\"{test_copy}\\n\")\n\ntest_df=\n   City A  City B\n0    14.1    11.0\n1    14.1    99.0\n2    13.7    12.1\n\ntest_copy=\n   City A  City B\n0    14.1    11.0\n1    14.1    12.6\n2    13.7    12.1\n\n\n\n\ndata_n.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 10 entries, 1 to 10\nData columns (total 16 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   Copenhagen       10 non-null     object\n 1   Dnipropetrovs’k  10 non-null     object\n 2   Minsk            10 non-null     object\n 3   St. Gallen       10 non-null     object\n 4   Muscat           10 non-null     object\n 5   Samara           10 non-null     object\n 6   Zurich           10 non-null     object\n 7   Boston           10 non-null     object\n 8   Bonn             10 non-null     object\n 9   Chengdu          10 non-null     object\n 10  Seoul            10 non-null     object\n 11  Riyadh           10 non-null     object\n 12  Nottingham       10 non-null     object\n 13  Athens           10 non-null     object\n 14  Istanbul         10 non-null     object\n 15  Melbourne        10 non-null     object\ndtypes: object(16)\nmemory usage: 1.3+ KB\n\n\n\ndata_n = data_n.astype(\"double\")\ndata_p = data_p.astype(\"double\")\n\n\nmean_n_c = data_n.mean(axis=1)\nmean_p_c = data_p.agg(np.mean, axis=1)\n\n\nfig, ax = plt.subplots()\nmean_n_c.plot(ax=ax, label=\"Without punishment\")\nmean_p_c.plot(ax=ax, label=\"With punishment\")\nax.set_title(\"Average contributions to the public goods game\")\nax.set_ylabel(\"Average contribution\")\nax.legend();\n\n\n\n\n\n\n\n\n\npartial_names_list = [\"F. Kennedy\", \"Lennon\", \"Maynard Keynes\", \"Wayne\"]\n[\"John \" + name for name in partial_names_list]\n\n['John F. Kennedy', 'John Lennon', 'John Maynard Keynes', 'John Wayne']\n\n\n\n# Create new dataframe with bars in\ncompare_grps = pd.DataFrame(\n    [mean_n_c.loc[[1, 10]], mean_p_c.loc[[1, 10]]],\n    index=[\"Without punishment\", \"With punishment\"],\n)\n# Rename columns to have 'round' in them\ncompare_grps.columns = [\"Round \" + str(i) for i in compare_grps.columns]\n# Swap the column and index variables around with the transpose function, ready for plotting (.T is transpose)\ncompare_grps = compare_grps.T\n# Make a bar chart\ncompare_grps.plot.bar(rot=0);\n\n\n\n\n\n\n\n\n\nn_c = data_n.agg([\"std\", \"var\", \"mean\"], 1)\nn_c\n\n\n\n\n\n\n\n\nstd\nvar\nmean\n\n\nPeriod\n\n\n\n\n\n\n\n1\n2.020724\n4.083325\n10.578313\n\n\n2\n2.238129\n5.009220\n10.628398\n\n\n3\n2.329569\n5.426891\n10.407079\n\n\n4\n2.068213\n4.277504\n9.813033\n\n\n5\n2.108329\n4.445049\n9.305433\n\n\n6\n2.240881\n5.021549\n8.454844\n\n\n7\n2.136614\n4.565117\n7.837568\n\n\n8\n2.349442\n5.519880\n7.376388\n\n\n9\n2.413845\n5.826645\n6.392985\n\n\n10\n2.187126\n4.783520\n4.383769\n\n\n\n\n\n\n\n\np_c = data_p.agg([\"std\", \"var\", \"mean\"], 1)\n\n\nfig, ax = plt.subplots()\nn_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 standard deviations\n(n_c[\"mean\"] + 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 standard deviations\n(n_c[\"mean\"] - 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_n.columns)):\n    ax.scatter(x=data_n.index, y=data_n.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game without punishment\")\nplt.show();\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\np_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 sd\n(p_c[\"mean\"] + 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 sd\n(p_c[\"mean\"] - 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_p.columns)):\n    ax.scatter(x=data_p.index, y=data_p.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game with punishment\")\nplt.show();\n\n\n\n\n\n\n\n\n\ndata_p.apply(lambda x: x.max() - x.min(), axis=1)\n\nPeriod\n1     10.199675\n2     12.185065\n3     12.689935\n4     12.625000\n5     12.140375\n6     12.827541\n7     13.098931\n8     13.482621\n9     13.496754\n10    11.307360\ndtype: float64\n\n\n\n# A lambda function accepting three inputs, a, b, and c, and calculating the sum of the squares\ntest_function = lambda a, b, c: a**2 + b**2 + c**2\n\n\n# Now we apply the function by handing over (in parenthesis) the following inputs: a=3, b=4 and c=5\ntest_function(3, 4, 5)\n\n50\n\n\n\nrange_function = lambda x: x.max() - x.min()\nrange_p = data_p.apply(range_function, axis=1)\nrange_n = data_n.apply(range_function, axis=1)\n\n\nfig, ax = plt.subplots()\nrange_p.plot(ax=ax, label=\"With punishment\")\nrange_n.plot(ax=ax, label=\"Without punishment\")\nax.set_ylim(0, None)\nax.legend()\nax.set_title(\"Range of contributions to the public goods game\")\nplt.show();\n\n\n\n\n\n\n\n\n\nfuncs_to_apply = [range_function, \"max\", \"min\", \"std\", \"mean\"]\nsumm_p = data_p.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\nsumm_n = data_n.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\n\n\nsumm_n.loc[[1, 10], :].round(2)\n\n\n\n\n\n\n\n\nrange\nmax\nmin\nstd\nmean\n\n\nPeriod\n\n\n\n\n\n\n\n\n\n1\n6.14\n14.10\n7.96\n2.02\n10.58\n\n\n10\n7.38\n8.68\n1.30\n2.19\n4.38\n\n\n\n\n\n\n\n\nsumm_p.loc[[1, 10], :].round(2)\n\n\n\n\n\n\n\n\nrange\nmax\nmin\nstd\nmean\n\n\nPeriod\n\n\n\n\n\n\n\n\n\n1\n10.20\n16.02\n5.82\n3.21\n10.64\n\n\n10\n11.31\n17.51\n6.20\n3.90\n12.87\n\n\n\n\n\n\n\n\n%pip install pingouin\n\nCollecting pingouin\n  Downloading pingouin-0.5.5-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (3.9.2)\nRequirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (1.26.4)\nRequirement already satisfied: pandas&gt;=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (2.2.2)\nCollecting pandas-flavor (from pingouin)\n  Downloading pandas_flavor-0.6.0-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: scikit-learn&gt;=1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (1.5.1)\nRequirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (1.13.1)\nRequirement already satisfied: seaborn in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (0.13.2)\nRequirement already satisfied: statsmodels in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (0.14.2)\nRequirement already satisfied: tabulate in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (0.9.0)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas&gt;=1.5-&gt;pingouin) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas&gt;=1.5-&gt;pingouin) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas&gt;=1.5-&gt;pingouin) (2023.3)\nRequirement already satisfied: joblib&gt;=1.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn&gt;=1.2-&gt;pingouin) (1.4.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn&gt;=1.2-&gt;pingouin) (3.5.0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib-&gt;pingouin) (1.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib-&gt;pingouin) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib-&gt;pingouin) (4.51.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib-&gt;pingouin) (1.4.4)\nRequirement already satisfied: packaging&gt;=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib-&gt;pingouin) (24.1)\nRequirement already satisfied: pillow&gt;=8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib-&gt;pingouin) (10.4.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib-&gt;pingouin) (3.1.2)\nRequirement already satisfied: xarray in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas-flavor-&gt;pingouin) (2023.6.0)\nRequirement already satisfied: patsy&gt;=0.5.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from statsmodels-&gt;pingouin) (0.5.6)\nRequirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from patsy&gt;=0.5.6-&gt;statsmodels-&gt;pingouin) (1.16.0)\nDownloading pingouin-0.5.5-py3-none-any.whl (204 kB)\nDownloading pandas_flavor-0.6.0-py3-none-any.whl (7.2 kB)\nInstalling collected packages: pandas-flavor, pingouin\nSuccessfully installed pandas-flavor-0.6.0 pingouin-0.5.5\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport pingouin as pg\n\n\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :])\n\n\n\n\n\n\n\n\nT\ndof\nalternative\np-val\nCI95%\ncohen-d\nBF10\npower\n\n\n\n\nT-test\n-0.063782\n30\ntwo-sided\n0.949567\n[-2.0, 1.87]\n0.02255\n0.337\n0.050437\n\n\n\n\n\n\n\n\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :], paired=True)\n\n\n\n\n\n\n\n\nT\ndof\nalternative\np-val\nCI95%\ncohen-d\nBF10\npower\n\n\n\n\nT-test\n-0.149959\n15\ntwo-sided\n0.882795\n[-0.92, 0.8]\n0.02255\n0.258\n0.05082\n\n\n\n\n\n\n\nSource: Original dataframe\n\n\nPractice2-Recreate-the-matplotlib-plots-using-letsplot-library\n\n\n%pip install lets-plot\n\nRequirement already satisfied: lets-plot in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.5.1)\nRequirement already satisfied: pypng in c:\\users\\hp\\anaconda3\\lib\\site-packages (from lets-plot) (0.20220715.0)\nRequirement already satisfied: palettable in c:\\users\\hp\\anaconda3\\lib\\site-packages (from lets-plot) (3.3.3)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nfrom lets_plot import *\n\n\nLetsPlot.setup_html()\n\n\n            \n            \n            \n\n\n\nimport matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [2, 4, 1, 3, 5]\nplt.plot(x, y)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pandas as pd\nfrom lets_plot import *\n\ndata = {\n    'x': [1, 2, 3, 4, 5],\n    'y': [2, 4, 1, 3, 5]\n}\ndf = pd.DataFrame(data)\n\nggplot(df, aes(x='x', y='y')) + geom_line()\n\n   \n   \n\n\n\nimport matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [2, 4, 1, 3, 5]\nplt.scatter(x, y)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pandas as pd\nfrom lets_plot import *\n\ndata = {\n    'x': [1, 2, 3, 4, 5],\n    'y': [2, 4, 1, 3, 5]\n}\ndf = pd.DataFrame(data)\n\nggplot(df, aes(x='x', y='y')) + geom_bar(stat='identity')\n\n   \n   \n\n\n\nimport matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [2, 4, 1, 3, 5]\nplt.bar(x, y)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\nplt.hist(x, bins=5)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\nplt.boxplot(x)\nplt.show()\n\n\n\n\n\n\n\n\nSource: Practice2-Recreate-the-matplotlib-plots-using-letsplot-library.ipynb\n\n\nPractice3-DouBan-top250-visualizations\n\n\n%pip install requests beautifulsoup4\n\nRequirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.32.3)\nRequirement already satisfied: beautifulsoup4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.12.3)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (3.7)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\nRequirement already satisfied: soupsieve&gt;1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport requests\n \n# 定义请求的 URL 和 headers\nurl = \"https://movie.douban.com/top250\"\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n}\n \n# 发送 GET 请求\nresponse = requests.get(url, headers=headers)\nresponse.encoding = 'utf-8'  # 设置编码方式\nhtml_content = response.text  # 获取网页的 HTML 内容\nprint(\"网页内容加载成功！\")\n\n网页内容加载成功！\n\n\n\nfrom bs4 import BeautifulSoup\n \n# 使用 Beautiful Soup 解析 HTML\nsoup = BeautifulSoup(html_content, 'html.parser')\n \n# 提取电影名称、描述、评分和评价人数\nmovies = []\nfor item in soup.find_all('div', class_='item'):\n    title = item.find('span', class_='title').get_text()  # 电影名称\n    description = item.find('span', class_='inq')  # 电影描述\n    rating = item.find('span', class_='rating_num').get_text()  # 评分\n    votes = item.find('div', class_='star').find_all('span')[3].get_text()  # 评价人数\n    \n    # 如果没有描述，将其置为空字符串\n    if description:\n        description = description.get_text()\n    else:\n        description = ''\n    \n    movie = {\n        \"title\": title,\n        \"description\": description,\n        \"rating\": rating,\n        \"votes\": votes.replace('人评价', '').strip()\n    }\n    movies.append(movie)\n \nprint(\"数据提取成功！\")\n\n数据提取成功！\n\n\n\nimport csv\n \n# 将数据保存到 CSV 文件\nwith open('douban_top250.csv', 'w', newline='', encoding='utf-8') as csvfile:\n    fieldnames = ['title', 'description', 'rating', 'votes']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n \n    writer.writeheader()  # 写入表头\n    for movie in movies:\n        writer.writerow(movie)  # 写入每一行数据\n \nprint(\"数据已成功保存到 douban_top250.csv\")\n\n数据已成功保存到 douban_top250.csv\n\n\nSource: 定义请求的 URL 和 headers\n\n\nPractice3-Extracting-data\n\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport textwrap\n\n\npd.read_csv(\n    \"https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/storms.csv\", nrows=10\n)\n\n\n\n\n\n\n\n\nrownames\nname\nyear\nmonth\nday\nhour\nlat\nlong\nstatus\ncategory\nwind\npressure\ntropicalstorm_force_diameter\nhurricane_force_diameter\n\n\n\n\n0\n1\nAmy\n1975\n6\n27\n0\n27.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n1\n2\nAmy\n1975\n6\n27\n6\n28.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n2\n3\nAmy\n1975\n6\n27\n12\n29.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n3\n4\nAmy\n1975\n6\n27\n18\n30.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n4\n5\nAmy\n1975\n6\n28\n0\n31.5\n-78.8\ntropical depression\nNaN\n25\n1012\nNaN\nNaN\n\n\n5\n6\nAmy\n1975\n6\n28\n6\n32.4\n-78.7\ntropical depression\nNaN\n25\n1012\nNaN\nNaN\n\n\n6\n7\nAmy\n1975\n6\n28\n12\n33.3\n-78.0\ntropical depression\nNaN\n25\n1011\nNaN\nNaN\n\n\n7\n8\nAmy\n1975\n6\n28\n18\n34.0\n-77.0\ntropical depression\nNaN\n30\n1006\nNaN\nNaN\n\n\n8\n9\nAmy\n1975\n6\n29\n0\n34.4\n-75.8\ntropical storm\nNaN\n35\n1004\nNaN\nNaN\n\n\n9\n10\nAmy\n1975\n6\n29\n6\n34.0\n-74.8\ntropical storm\nNaN\n40\n1002\nNaN\nNaN\n\n\n\n\n\n\n\n\nimport requests\n\nurl = \"https://api.ons.gov.uk/timeseries/JP9Z/dataset/UNEM/data\"\n\n# Get the data from the ONS API:\njson_data = requests.get(url).json()\n\n# Prep the data for a quick plot\ntitle = json_data[\"description\"][\"title\"]\ndf = (\n    pd.DataFrame(pd.json_normalize(json_data[\"months\"]))\n    .assign(\n        date=lambda x: pd.to_datetime(x[\"date\"]),\n        value=lambda x: pd.to_numeric(x[\"value\"]),\n    )\n    .set_index(\"date\")\n)\n\ndf[\"value\"].plot(title=title, ylim=(0, df[\"value\"].max() * 1.2), lw=3.0);\n\n\n---------------------------------------------------------------------------\nJSONDecodeError                           Traceback (most recent call last)\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\requests\\models.py:974, in Response.json(self, **kwargs)\n    973 try:\n--&gt; 974     return complexjson.loads(self.text, **kwargs)\n    975 except JSONDecodeError as e:\n    976     # Catch JSON-related errors and raise as requests.JSONDecodeError\n    977     # This aliases json.JSONDecodeError and simplejson.JSONDecodeError\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\json\\__init__.py:346, in loads(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\n    343 if (cls is None and object_hook is None and\n    344         parse_int is None and parse_float is None and\n    345         parse_constant is None and object_pairs_hook is None and not kw):\n--&gt; 346     return _default_decoder.decode(s)\n    347 if cls is None:\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\json\\decoder.py:337, in JSONDecoder.decode(self, s, _w)\n    333 \"\"\"Return the Python representation of ``s`` (a ``str`` instance\n    334 containing a JSON document).\n    335 \n    336 \"\"\"\n--&gt; 337 obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n    338 end = _w(s, end).end()\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\json\\decoder.py:355, in JSONDecoder.raw_decode(self, s, idx)\n    354 except StopIteration as err:\n--&gt; 355     raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n    356 return obj, end\n\nJSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nJSONDecodeError                           Traceback (most recent call last)\nCell In[3], line 6\n      3 url = \"https://api.ons.gov.uk/timeseries/JP9Z/dataset/UNEM/data\"\n      5 # Get the data from the ONS API:\n----&gt; 6 json_data = requests.get(url).json()\n      8 # Prep the data for a quick plot\n      9 title = json_data[\"description\"][\"title\"]\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\requests\\models.py:978, in Response.json(self, **kwargs)\n    974     return complexjson.loads(self.text, **kwargs)\n    975 except JSONDecodeError as e:\n    976     # Catch JSON-related errors and raise as requests.JSONDecodeError\n    977     # This aliases json.JSONDecodeError and simplejson.JSONDecodeError\n--&gt; 978     raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n\nJSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\n\n\n\nurl = \"http://aeturrell.com/research\"\npage = requests.get(url)\npage.text[:300]\n\n'&lt;!DOCTYPE html&gt;\\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\"&gt;&lt;head&gt;\\n\\n&lt;meta charset=\"utf-8\"&gt;\\n&lt;meta name=\"generator\" content=\"quarto-1.5.56\"&gt;\\n\\n&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\"&gt;\\n\\n&lt;meta name=\"author\" content=\"Arthur Turrell\"&gt;\\n'\n\n\n\nsoup = BeautifulSoup(page.text, \"html.parser\")\nprint(soup.prettify()[60000:60500])\n\n       &lt;/div&gt;\n          &lt;div class=\"project-category\"&gt;\n           &lt;a href=\"#category=gender pay gap\"&gt;\n            gender pay gap\n           &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;div class=\"project-category\"&gt;\n           &lt;a href=\"#category=labour\"&gt;\n            labour\n           &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;div class=\"project-category\"&gt;\n           &lt;a href=\"#category=text analysis\"&gt;\n            text analysis\n           &lt;/a&gt;\n          &lt;/div&gt;\n         &lt;/div&gt;\n         &lt;div class=\"project-details-listing\n\n\n\n# Get all paragraphs\nall_paras = soup.find_all(\"p\")\n# Just show one of the paras\nall_paras[1]\n\n&lt;p&gt;Botta, Federico, Robin Lovelace, Laura Gilbert, and Arthur Turrell. \"Packaging code and data for reproducible research: A case study of journey time statistics.\" &lt;i&gt;Environment and Planning B: Urban Analytics and City Science&lt;/i&gt; (2024): 23998083241267331. doi: &lt;a href=\"https://doi.org/10.1177/23998083241267331\"&gt;&lt;code&gt;10.1177/23998083241267331&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n\n\nall_paras[1].text\n\n'Botta, Federico, Robin Lovelace, Laura Gilbert, and Arthur Turrell. \"Packaging code and data for reproducible research: A case study of journey time statistics.\" Environment and Planning B: Urban Analytics and City Science (2024): 23998083241267331. doi: 10.1177/23998083241267331'\n\n\n\nprojects = soup.find_all(\"div\", class_=\"project-content listing-pub-info\")\nprojects = [x.text.strip() for x in projects]\nprojects[:4]\n\n['Botta, Federico, Robin Lovelace, Laura Gilbert, and Arthur Turrell. \"Packaging code and data for reproducible research: A case study of journey time statistics.\" Environment and Planning B: Urban Analytics and City Science (2024): 23998083241267331. doi: 10.1177/23998083241267331',\n 'Kalamara, Eleni, Arthur Turrell, Chris Redl, George Kapetanios, and Sujit Kapadia. \"Making text count: economic forecasting using newspaper text.\" Journal of Applied Econometrics 37, no. 5 (2022): 896-919. doi: 10.1002/jae.2907',\n 'Turrell, A., Speigner, B., Copple, D., Djumalieva, J. and Thurgood, J., 2021. Is the UK’s productivity puzzle mostly driven by occupational mismatch? An analysis using big data on job vacancies. Labour Economics, 71, p.102013. doi: 10.1016/j.labeco.2021.102013',\n 'Haldane, Andrew G., and Arthur E. Turrell. \"Drawing on different disciplines: macroeconomic agent-based models.\" Journal of Evolutionary Economics 29 (2019): 39-66. doi: 10.1007/s00191-018-0557-5']\n\n\n\nstart, stop = 0, 50\nroot_url = \"www.codingforeconomists.com/page=\"\ninfo_on_pages = [scraper(root_url + str(i)) for i in range(start, stop)]\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[17], line 3\n      1 start, stop = 0, 50\n      2 root_url = \"www.codingforeconomists.com/page=\"\n----&gt; 3 info_on_pages = [scraper(root_url + str(i)) for i in range(start, stop)]\n\nNameError: name 'scraper' is not defined\n\n\n\n\ndf_list = pd.read_html(\n    \"https://simple.wikipedia.org/wiki/FIFA_World_Cup\", match=\"Sweden\"\n)\n# Retrieve first and only entry from list of dataframes\ndf = df_list[0]\ndf.head()\n\n\n\n\n\n\n\n\nYears\nHosts\nWinners\nScore\nRunner's-up\nThird place\nScore.1\nFourth place\n\n\n\n\n0\n1930 Details\nUruguay\nUruguay\n4 - 2\nArgentina\nUnited States\n[note 1]\nYugoslavia\n\n\n1\n1934 Details\nItaly\nItaly\n2 - 1\nCzechoslovakia\nGermany\n3 - 2\nAustria\n\n\n2\n1938 Details\nFrance\nItaly\n4 - 2\nHungary\nBrazil\n4 - 2\nSweden\n\n\n3\n1950 Details\nBrazil\nUruguay\n2 - 1\nBrazil\nSweden\n[note 2]\nSpain\n\n\n4\n1954 Details\nSwitzerland\nWest Germany\n3 - 2\nHungary\nAustria\n3 - 1\nUruguay\n\n\n\n\n\n\n\n\nimport pdftotext\nfrom pathlib import Path\n\n# Download the pdf_with_table.pdf file from\n# https://github.com/aeturrell/coding-for-economists/blob/main/data/pdf_with_table.pdf\n# and put it in a subfolder called data before running the next line\n\n# Load the PDF\nwith open(Path(\"data/pdf_with_table.pdf\"), \"rb\") as f:\n    pdf = pdftotext.PDF(f)\n\n# Read all the text into one string; print a chunk of the string\nprint(\"\\n\\n\".join(pdf)[:220])\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[19], line 1\n----&gt; 1 import pdftotext\n      2 from pathlib import Path\n      4 # Download the pdf_with_table.pdf file from\n      5 # https://github.com/aeturrell/coding-for-economists/blob/main/data/pdf_with_table.pdf\n      6 # and put it in a subfolder called data before running the next line\n      7 \n      8 # Load the PDF\n\nModuleNotFoundError: No module named 'pdftotext'\n\n\n\n\n%pip install pdftotext\n\nCollecting pdftotextNote: you may need to restart the kernel to use updated packages.\n\n  Downloading pdftotext-2.2.2.tar.gz (113 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nBuilding wheels for collected packages: pdftotext\n  Building wheel for pdftotext (setup.py): started\n  Building wheel for pdftotext (setup.py): finished with status 'error'\n  Running setup.py clean for pdftotext\nFailed to build pdftotext\n\n\nSource: Get the data from the ONS API:\n\n\nPractice3-scrape-imdb-movie-rating-and-details\n\n\nfrom bs4 import BeautifulSoup\nimport requests\nimport re\nimport pandas as pd\n\n\n# Downloading imdb top 250 movie's data\nurl = 'http://www.imdb.com/chart/top'\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.text, \"html.parser\")\n\n\nmovies = soup.select('td.titleColumn')\ncrew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\nratings = [b.attrs.get('data-value')\n        for b in soup.select('td.posterColumn span[name=ir]')]\n\n\n# create a empty list for storing\n# movie information\nlist = []\n\n# Iterating over movies to extract\n# each movie's details\nfor index in range(0, len(movies)):\n    \n    # Separating movie into: 'place',\n    # 'title', 'year'\n    movie_string = movies[index].get_text()\n    movie = (' '.join(movie_string.split()).replace('.', ''))\n    movie_title = movie[len(str(index))+1:-7]\n    year = re.search('\\((.*?)\\)', movie_string).group(1)\n    place = movie[:len(str(index))-(len(movie))]\n    data = {\"place\": place,\n            \"movie_title\": movie_title,\n            \"rating\": ratings[index],\n            \"year\": year,\n            \"star_cast\": crew[index],\n            }\n    list.append(data)\n\n\nfor movie in list:\n    print(movie['place'], '-', movie['movie_title'], '('+movie['year'] +\n        ') -', 'Starring:', movie['star_cast'], movie['rating'])\n\n\n#saving the list as dataframe\n#then converting into .csv file\ndf = pd.DataFrame(list)\ndf.to_csv('imdb_top_250_movies.csv',index=False)\n\n\nfrom bs4 import BeautifulSoup\nimport requests\nimport re\nimport pandas as pd\n\n\n# Downloading imdb top 250 movie's data\nurl = 'http://www.imdb.com/chart/top'\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.text, \"html.parser\")\nmovies = soup.select('td.titleColumn')\ncrew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\nratings = [b.attrs.get('data-value')\n        for b in soup.select('td.posterColumn span[name=ir]')]\n\n\n\n\n# create a empty list for storing\n# movie information\nlist = []\n\n# Iterating over movies to extract\n# each movie's details\nfor index in range(0, len(movies)):\n    \n    # Separating movie into: 'place',\n    # 'title', 'year'\n    movie_string = movies[index].get_text()\n    movie = (' '.join(movie_string.split()).replace('.', ''))\n    movie_title = movie[len(str(index))+1:-7]\n    year = re.search('\\((.*?)\\)', movie_string).group(1)\n    place = movie[:len(str(index))-(len(movie))]\n    data = {\"place\": place,\n            \"movie_title\": movie_title,\n            \"rating\": ratings[index],\n            \"year\": year,\n            \"star_cast\": crew[index],\n            }\n    list.append(data)\n\n# printing movie details with its rating.\nfor movie in list:\n    print(movie['place'], '-', movie['movie_title'], '('+movie['year'] +\n        ') -', 'Starring:', movie['star_cast'], movie['rating'])\n\n\n##.......##\ndf = pd.DataFrame(list)\ndf.to_csv('imdb_top_250_movies.csv',index=False)\n\nSource: Downloading imdb top 250 movie's data\n\n\nPractice4-IMDb-and-Douban-top-250-movie-datasets\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimdb_data = pd.read_csv('IMDB_Top250.csv')  # Replace with actual file path\ndouban_data = pd.read_csv('douban_top250.csv')  # Replace with actual file path\n\n\nfrom bs4 import BeautifulSoup\nimport re\nimport urllib.request, urllib.error  # for URL requests\nimport csv  # for saving as CSV\n\n\n# Regular expressions to extract information\nfindLink = re.compile(r'&lt;a href=\"(.*?)\"&gt;')  # detail link\nfindImgSrc = re.compile(r'&lt;img.*src=\"(.*?)\"', re.S)  # image link\nfindTitle = re.compile(r'&lt;span class=\"title\"&gt;(.*)&lt;/span&gt;')  # movie title\nfindRating = re.compile(r'&lt;span class=\"rating_num\" property=\"v:average\"&gt;(.*)&lt;/span&gt;')  # rating\nfindJudge = re.compile(r'&lt;span&gt;(\\d*)人评价&lt;/span&gt;')  # number of reviews\nfindInq = re.compile(r'&lt;span class=\"inq\"&gt;(.*)&lt;/span&gt;')  # summary\nfindBd = re.compile(r'&lt;p class=\"\"&gt;(.*?)&lt;/p&gt;', re.S)  # additional info\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load datasets\ndouban_file_path = 'douban_top250.csv'  \nimdb_file_path = 'IMDB_Top250.csv'      \n\ndouban_data = pd.read_csv(douban_file_path, encoding='utf-8', on_bad_lines='skip')\nimdb_data = pd.read_csv(imdb_file_path, encoding='utf-8', on_bad_lines='skip')\n\n# Renaming columns for clarity and merging compatibility\ndouban_data.rename(columns={\n    '影片中文名': 'Title',\n    '评分': 'Douban_Score',\n    '评价数': 'Douban_Reviews',\n    '相关信息': 'Douban_Info'\n}, inplace=True)\n\n\nimdb_data.rename(columns={\n    'Name': 'Title',\n    'Year': 'Release_Year',\n    'IMDB Ranking': 'IMDB_Score',\n    'Genre': 'IMDB_Genre',\n    'Director': 'IMDB_Director'\n}, inplace=True)\n\n\n# Calculate average scores for both platforms\ndouban_avg_score = douban_data['Douban_Score'].mean()\nimdb_avg_score = imdb_data['IMDB_Score'].mean()\n\n# Find overlapping movies by title\noverlap_movies = pd.merge(douban_data, imdb_data, on='Title')\n\n# Visualize average scores\nplt.figure(figsize=(8, 5))\nplt.bar(['Douban', 'IMDb'], [douban_avg_score, imdb_avg_score], alpha=0.7)\nplt.title('Average Scores: Douban vs IMDb')\nplt.ylabel('Average Score')\nplt.show()\n\n# Analyze release year distribution\nplt.figure(figsize=(10, 5))\ndouban_data['Douban_Info'] = douban_data['Douban_Info'].astype(str)\ndouban_years = douban_data['Douban_Info'].str.extract(r'(\\d{4})').dropna()\ndouban_years = douban_years[0].astype(int).value_counts().sort_index()\n\nimdb_years = imdb_data['Release_Year'].value_counts().sort_index()\n\ndouban_years.plot(kind='bar', alpha=0.7, label='Douban', figsize=(10, 5))\nimdb_years.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Release Year Distribution')\nplt.xlabel('Year')\nplt.ylabel('Number of Movies')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Analyze genre distribution\nimdb_genres = imdb_data['IMDB_Genre'].str.split(',').explode().str.strip().value_counts()\nplt.figure(figsize=(10, 5))\nimdb_genres.head(10).plot(kind='bar', alpha=0.7, color='orange')\nplt.title('Top 10 IMDb Genres')\nplt.xlabel('Genre')\nplt.ylabel('Count')\nplt.show()\n\n# Top directors by movie count\ndouban_directors = douban_data['Douban_Info'].str.extract(r'导演: (.+?) ').dropna()\ndouban_top_directors = douban_directors[0].value_counts().head(10)\n\nimdb_top_directors = imdb_data['IMDB_Director'].value_counts().head(10)\n\nplt.figure(figsize=(10, 5))\ndouban_top_directors.plot(kind='bar', alpha=0.7, label='Douban', color='blue')\nplt.title('Top 10 Douban Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\nplt.figure(figsize=(10, 5))\nimdb_top_directors.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Top 10 IMDb Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\n# Save overlapping movies to a CSV file\noverlap_movies.to_csv('overlap_movies.csv', index=False)\n\n# Print results\nprint(f\"豆瓣平均评分: {douban_avg_score}\")\nprint(f\"IMDb平均评分: {imdb_avg_score}\")\nprint(f\"重叠电影数量: {len(overlap_movies)}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n豆瓣平均评分: 8.9396\nIMDb平均评分: 8.254\n重叠电影数量: 0\n\n\nSource: Regular expressions to extract information"
  },
  {
    "objectID": "labs/Practice/Practice4-IMDb-and-Douban-top-250-movie-datasets.html",
    "href": "labs/Practice/Practice4-IMDb-and-Douban-top-250-movie-datasets.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimdb_data = pd.read_csv('IMDB_Top250.csv')  # Replace with actual file path\ndouban_data = pd.read_csv('douban_top250.csv')  # Replace with actual file path\n\n\nfrom bs4 import BeautifulSoup\nimport re\nimport urllib.request, urllib.error  # for URL requests\nimport csv  # for saving as CSV\n\n\n# Regular expressions to extract information\nfindLink = re.compile(r'&lt;a href=\"(.*?)\"&gt;')  # detail link\nfindImgSrc = re.compile(r'&lt;img.*src=\"(.*?)\"', re.S)  # image link\nfindTitle = re.compile(r'&lt;span class=\"title\"&gt;(.*)&lt;/span&gt;')  # movie title\nfindRating = re.compile(r'&lt;span class=\"rating_num\" property=\"v:average\"&gt;(.*)&lt;/span&gt;')  # rating\nfindJudge = re.compile(r'&lt;span&gt;(\\d*)人评价&lt;/span&gt;')  # number of reviews\nfindInq = re.compile(r'&lt;span class=\"inq\"&gt;(.*)&lt;/span&gt;')  # summary\nfindBd = re.compile(r'&lt;p class=\"\"&gt;(.*?)&lt;/p&gt;', re.S)  # additional info\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load datasets\ndouban_file_path = 'douban_top250.csv'  \nimdb_file_path = 'IMDB_Top250.csv'      \n\ndouban_data = pd.read_csv(douban_file_path, encoding='utf-8', on_bad_lines='skip')\nimdb_data = pd.read_csv(imdb_file_path, encoding='utf-8', on_bad_lines='skip')\n\n# Renaming columns for clarity and merging compatibility\ndouban_data.rename(columns={\n    '影片中文名': 'Title',\n    '评分': 'Douban_Score',\n    '评价数': 'Douban_Reviews',\n    '相关信息': 'Douban_Info'\n}, inplace=True)\n\n\nimdb_data.rename(columns={\n    'Name': 'Title',\n    'Year': 'Release_Year',\n    'IMDB Ranking': 'IMDB_Score',\n    'Genre': 'IMDB_Genre',\n    'Director': 'IMDB_Director'\n}, inplace=True)\n\n\n# Calculate average scores for both platforms\ndouban_avg_score = douban_data['Douban_Score'].mean()\nimdb_avg_score = imdb_data['IMDB_Score'].mean()\n\n# Find overlapping movies by title\noverlap_movies = pd.merge(douban_data, imdb_data, on='Title')\n\n# Visualize average scores\nplt.figure(figsize=(8, 5))\nplt.bar(['Douban', 'IMDb'], [douban_avg_score, imdb_avg_score], alpha=0.7)\nplt.title('Average Scores: Douban vs IMDb')\nplt.ylabel('Average Score')\nplt.show()\n\n# Analyze release year distribution\nplt.figure(figsize=(10, 5))\ndouban_data['Douban_Info'] = douban_data['Douban_Info'].astype(str)\ndouban_years = douban_data['Douban_Info'].str.extract(r'(\\d{4})').dropna()\ndouban_years = douban_years[0].astype(int).value_counts().sort_index()\n\nimdb_years = imdb_data['Release_Year'].value_counts().sort_index()\n\ndouban_years.plot(kind='bar', alpha=0.7, label='Douban', figsize=(10, 5))\nimdb_years.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Release Year Distribution')\nplt.xlabel('Year')\nplt.ylabel('Number of Movies')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Analyze genre distribution\nimdb_genres = imdb_data['IMDB_Genre'].str.split(',').explode().str.strip().value_counts()\nplt.figure(figsize=(10, 5))\nimdb_genres.head(10).plot(kind='bar', alpha=0.7, color='orange')\nplt.title('Top 10 IMDb Genres')\nplt.xlabel('Genre')\nplt.ylabel('Count')\nplt.show()\n\n# Top directors by movie count\ndouban_directors = douban_data['Douban_Info'].str.extract(r'导演: (.+?) ').dropna()\ndouban_top_directors = douban_directors[0].value_counts().head(10)\n\nimdb_top_directors = imdb_data['IMDB_Director'].value_counts().head(10)\n\nplt.figure(figsize=(10, 5))\ndouban_top_directors.plot(kind='bar', alpha=0.7, label='Douban', color='blue')\nplt.title('Top 10 Douban Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\nplt.figure(figsize=(10, 5))\nimdb_top_directors.plot(kind='bar', alpha=0.7, label='IMDb', color='orange')\nplt.title('Top 10 IMDb Directors')\nplt.xlabel('Director')\nplt.ylabel('Movie Count')\nplt.show()\n\n# Save overlapping movies to a CSV file\noverlap_movies.to_csv('overlap_movies.csv', index=False)\n\n# Print results\nprint(f\"豆瓣平均评分: {douban_avg_score}\")\nprint(f\"IMDb平均评分: {imdb_avg_score}\")\nprint(f\"重叠电影数量: {len(overlap_movies)}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n豆瓣平均评分: 8.9396\nIMDb平均评分: 8.254\n重叠电影数量: 0"
  },
  {
    "objectID": "labs/Practice/Practice3-Extracting-data.html",
    "href": "labs/Practice/Practice3-Extracting-data.html",
    "title": "",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport textwrap\n\n\npd.read_csv(\n    \"https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/storms.csv\", nrows=10\n)\n\n\n\n\n\n\n\n\nrownames\nname\nyear\nmonth\nday\nhour\nlat\nlong\nstatus\ncategory\nwind\npressure\ntropicalstorm_force_diameter\nhurricane_force_diameter\n\n\n\n\n0\n1\nAmy\n1975\n6\n27\n0\n27.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n1\n2\nAmy\n1975\n6\n27\n6\n28.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n2\n3\nAmy\n1975\n6\n27\n12\n29.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n3\n4\nAmy\n1975\n6\n27\n18\n30.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n4\n5\nAmy\n1975\n6\n28\n0\n31.5\n-78.8\ntropical depression\nNaN\n25\n1012\nNaN\nNaN\n\n\n5\n6\nAmy\n1975\n6\n28\n6\n32.4\n-78.7\ntropical depression\nNaN\n25\n1012\nNaN\nNaN\n\n\n6\n7\nAmy\n1975\n6\n28\n12\n33.3\n-78.0\ntropical depression\nNaN\n25\n1011\nNaN\nNaN\n\n\n7\n8\nAmy\n1975\n6\n28\n18\n34.0\n-77.0\ntropical depression\nNaN\n30\n1006\nNaN\nNaN\n\n\n8\n9\nAmy\n1975\n6\n29\n0\n34.4\n-75.8\ntropical storm\nNaN\n35\n1004\nNaN\nNaN\n\n\n9\n10\nAmy\n1975\n6\n29\n6\n34.0\n-74.8\ntropical storm\nNaN\n40\n1002\nNaN\nNaN\n\n\n\n\n\n\n\n\nimport requests\n\nurl = \"https://api.ons.gov.uk/timeseries/JP9Z/dataset/UNEM/data\"\n\n# Get the data from the ONS API:\njson_data = requests.get(url).json()\n\n# Prep the data for a quick plot\ntitle = json_data[\"description\"][\"title\"]\ndf = (\n    pd.DataFrame(pd.json_normalize(json_data[\"months\"]))\n    .assign(\n        date=lambda x: pd.to_datetime(x[\"date\"]),\n        value=lambda x: pd.to_numeric(x[\"value\"]),\n    )\n    .set_index(\"date\")\n)\n\ndf[\"value\"].plot(title=title, ylim=(0, df[\"value\"].max() * 1.2), lw=3.0);\n\n\n---------------------------------------------------------------------------\nJSONDecodeError                           Traceback (most recent call last)\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\requests\\models.py:974, in Response.json(self, **kwargs)\n    973 try:\n--&gt; 974     return complexjson.loads(self.text, **kwargs)\n    975 except JSONDecodeError as e:\n    976     # Catch JSON-related errors and raise as requests.JSONDecodeError\n    977     # This aliases json.JSONDecodeError and simplejson.JSONDecodeError\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\json\\__init__.py:346, in loads(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\n    343 if (cls is None and object_hook is None and\n    344         parse_int is None and parse_float is None and\n    345         parse_constant is None and object_pairs_hook is None and not kw):\n--&gt; 346     return _default_decoder.decode(s)\n    347 if cls is None:\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\json\\decoder.py:337, in JSONDecoder.decode(self, s, _w)\n    333 \"\"\"Return the Python representation of ``s`` (a ``str`` instance\n    334 containing a JSON document).\n    335 \n    336 \"\"\"\n--&gt; 337 obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n    338 end = _w(s, end).end()\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\json\\decoder.py:355, in JSONDecoder.raw_decode(self, s, idx)\n    354 except StopIteration as err:\n--&gt; 355     raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n    356 return obj, end\n\nJSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nJSONDecodeError                           Traceback (most recent call last)\nCell In[3], line 6\n      3 url = \"https://api.ons.gov.uk/timeseries/JP9Z/dataset/UNEM/data\"\n      5 # Get the data from the ONS API:\n----&gt; 6 json_data = requests.get(url).json()\n      8 # Prep the data for a quick plot\n      9 title = json_data[\"description\"][\"title\"]\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\requests\\models.py:978, in Response.json(self, **kwargs)\n    974     return complexjson.loads(self.text, **kwargs)\n    975 except JSONDecodeError as e:\n    976     # Catch JSON-related errors and raise as requests.JSONDecodeError\n    977     # This aliases json.JSONDecodeError and simplejson.JSONDecodeError\n--&gt; 978     raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n\nJSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\n\n\n\nurl = \"http://aeturrell.com/research\"\npage = requests.get(url)\npage.text[:300]\n\n'&lt;!DOCTYPE html&gt;\\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\"&gt;&lt;head&gt;\\n\\n&lt;meta charset=\"utf-8\"&gt;\\n&lt;meta name=\"generator\" content=\"quarto-1.5.56\"&gt;\\n\\n&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\"&gt;\\n\\n&lt;meta name=\"author\" content=\"Arthur Turrell\"&gt;\\n'\n\n\n\nsoup = BeautifulSoup(page.text, \"html.parser\")\nprint(soup.prettify()[60000:60500])\n\n       &lt;/div&gt;\n          &lt;div class=\"project-category\"&gt;\n           &lt;a href=\"#category=gender pay gap\"&gt;\n            gender pay gap\n           &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;div class=\"project-category\"&gt;\n           &lt;a href=\"#category=labour\"&gt;\n            labour\n           &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;div class=\"project-category\"&gt;\n           &lt;a href=\"#category=text analysis\"&gt;\n            text analysis\n           &lt;/a&gt;\n          &lt;/div&gt;\n         &lt;/div&gt;\n         &lt;div class=\"project-details-listing\n\n\n\n# Get all paragraphs\nall_paras = soup.find_all(\"p\")\n# Just show one of the paras\nall_paras[1]\n\n&lt;p&gt;Botta, Federico, Robin Lovelace, Laura Gilbert, and Arthur Turrell. \"Packaging code and data for reproducible research: A case study of journey time statistics.\" &lt;i&gt;Environment and Planning B: Urban Analytics and City Science&lt;/i&gt; (2024): 23998083241267331. doi: &lt;a href=\"https://doi.org/10.1177/23998083241267331\"&gt;&lt;code&gt;10.1177/23998083241267331&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n\n\nall_paras[1].text\n\n'Botta, Federico, Robin Lovelace, Laura Gilbert, and Arthur Turrell. \"Packaging code and data for reproducible research: A case study of journey time statistics.\" Environment and Planning B: Urban Analytics and City Science (2024): 23998083241267331. doi: 10.1177/23998083241267331'\n\n\n\nprojects = soup.find_all(\"div\", class_=\"project-content listing-pub-info\")\nprojects = [x.text.strip() for x in projects]\nprojects[:4]\n\n['Botta, Federico, Robin Lovelace, Laura Gilbert, and Arthur Turrell. \"Packaging code and data for reproducible research: A case study of journey time statistics.\" Environment and Planning B: Urban Analytics and City Science (2024): 23998083241267331. doi: 10.1177/23998083241267331',\n 'Kalamara, Eleni, Arthur Turrell, Chris Redl, George Kapetanios, and Sujit Kapadia. \"Making text count: economic forecasting using newspaper text.\" Journal of Applied Econometrics 37, no. 5 (2022): 896-919. doi: 10.1002/jae.2907',\n 'Turrell, A., Speigner, B., Copple, D., Djumalieva, J. and Thurgood, J., 2021. Is the UK’s productivity puzzle mostly driven by occupational mismatch? An analysis using big data on job vacancies. Labour Economics, 71, p.102013. doi: 10.1016/j.labeco.2021.102013',\n 'Haldane, Andrew G., and Arthur E. Turrell. \"Drawing on different disciplines: macroeconomic agent-based models.\" Journal of Evolutionary Economics 29 (2019): 39-66. doi: 10.1007/s00191-018-0557-5']\n\n\n\nstart, stop = 0, 50\nroot_url = \"www.codingforeconomists.com/page=\"\ninfo_on_pages = [scraper(root_url + str(i)) for i in range(start, stop)]\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[17], line 3\n      1 start, stop = 0, 50\n      2 root_url = \"www.codingforeconomists.com/page=\"\n----&gt; 3 info_on_pages = [scraper(root_url + str(i)) for i in range(start, stop)]\n\nNameError: name 'scraper' is not defined\n\n\n\n\ndf_list = pd.read_html(\n    \"https://simple.wikipedia.org/wiki/FIFA_World_Cup\", match=\"Sweden\"\n)\n# Retrieve first and only entry from list of dataframes\ndf = df_list[0]\ndf.head()\n\n\n\n\n\n\n\n\nYears\nHosts\nWinners\nScore\nRunner's-up\nThird place\nScore.1\nFourth place\n\n\n\n\n0\n1930 Details\nUruguay\nUruguay\n4 - 2\nArgentina\nUnited States\n[note 1]\nYugoslavia\n\n\n1\n1934 Details\nItaly\nItaly\n2 - 1\nCzechoslovakia\nGermany\n3 - 2\nAustria\n\n\n2\n1938 Details\nFrance\nItaly\n4 - 2\nHungary\nBrazil\n4 - 2\nSweden\n\n\n3\n1950 Details\nBrazil\nUruguay\n2 - 1\nBrazil\nSweden\n[note 2]\nSpain\n\n\n4\n1954 Details\nSwitzerland\nWest Germany\n3 - 2\nHungary\nAustria\n3 - 1\nUruguay\n\n\n\n\n\n\n\n\nimport pdftotext\nfrom pathlib import Path\n\n# Download the pdf_with_table.pdf file from\n# https://github.com/aeturrell/coding-for-economists/blob/main/data/pdf_with_table.pdf\n# and put it in a subfolder called data before running the next line\n\n# Load the PDF\nwith open(Path(\"data/pdf_with_table.pdf\"), \"rb\") as f:\n    pdf = pdftotext.PDF(f)\n\n# Read all the text into one string; print a chunk of the string\nprint(\"\\n\\n\".join(pdf)[:220])\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[19], line 1\n----&gt; 1 import pdftotext\n      2 from pathlib import Path\n      4 # Download the pdf_with_table.pdf file from\n      5 # https://github.com/aeturrell/coding-for-economists/blob/main/data/pdf_with_table.pdf\n      6 # and put it in a subfolder called data before running the next line\n      7 \n      8 # Load the PDF\n\nModuleNotFoundError: No module named 'pdftotext'\n\n\n\n\n%pip install pdftotext\n\nCollecting pdftotextNote: you may need to restart the kernel to use updated packages.\n\n  Downloading pdftotext-2.2.2.tar.gz (113 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nBuilding wheels for collected packages: pdftotext\n  Building wheel for pdftotext (setup.py): started\n  Building wheel for pdftotext (setup.py): finished with status 'error'\n  Running setup.py clean for pdftotext\nFailed to build pdftotext"
  },
  {
    "objectID": "labs/Practice/Practice2-Recreate-the-matplotlib-plots-using-letsplot-library.html",
    "href": "labs/Practice/Practice2-Recreate-the-matplotlib-plots-using-letsplot-library.html",
    "title": "",
    "section": "",
    "text": "%pip install lets-plot\n\nRequirement already satisfied: lets-plot in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.5.1)\nRequirement already satisfied: pypng in c:\\users\\hp\\anaconda3\\lib\\site-packages (from lets-plot) (0.20220715.0)\nRequirement already satisfied: palettable in c:\\users\\hp\\anaconda3\\lib\\site-packages (from lets-plot) (3.3.3)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nfrom lets_plot import *\n\n\nLetsPlot.setup_html()\n\n\n            \n            \n            \n\n\n\nimport matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [2, 4, 1, 3, 5]\nplt.plot(x, y)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pandas as pd\nfrom lets_plot import *\n\ndata = {\n    'x': [1, 2, 3, 4, 5],\n    'y': [2, 4, 1, 3, 5]\n}\ndf = pd.DataFrame(data)\n\nggplot(df, aes(x='x', y='y')) + geom_line()\n\n   \n   \n\n\n\nimport matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [2, 4, 1, 3, 5]\nplt.scatter(x, y)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pandas as pd\nfrom lets_plot import *\n\ndata = {\n    'x': [1, 2, 3, 4, 5],\n    'y': [2, 4, 1, 3, 5]\n}\ndf = pd.DataFrame(data)\n\nggplot(df, aes(x='x', y='y')) + geom_bar(stat='identity')\n\n   \n   \n\n\n\nimport matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [2, 4, 1, 3, 5]\nplt.bar(x, y)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\nplt.hist(x, bins=5)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\nplt.boxplot(x)\nplt.show()"
  },
  {
    "objectID": "labs/Practice/Practice1-Climate-change.html",
    "href": "labs/Practice/Practice1-Climate-change.html",
    "title": "",
    "section": "",
    "text": "%pip install pandas matplotlib numpy lets_plot\n\nRequirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.2.2)\nRequirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.9.2)\nRequirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.26.4)\nCollecting lets_plot\n  Using cached lets_plot-4.5.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\nRequirement already satisfied: contourpy&gt;=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: packaging&gt;=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\nRequirement already satisfied: pillow&gt;=8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\nCollecting pypng (from lets_plot)\n  Using cached pypng-0.20220715.0-py3-none-any.whl.metadata (13 kB)\nCollecting palettable (from lets_plot)\n  Using cached palettable-3.3.3-py2.py3-none-any.whl.metadata (3.3 kB)\nRequirement already satisfied: six&gt;=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)\nUsing cached lets_plot-4.5.1-cp312-cp312-win_amd64.whl (3.1 MB)\nUsing cached palettable-3.3.3-py2.py3-none-any.whl (332 kB)\nUsing cached pypng-0.20220715.0-py3-none-any.whl (58 kB)\nInstalling collected packages: pypng, palettable, lets_plot\nSuccessfully installed lets_plot-4.5.1 palettable-3.3.3 pypng-0.20220715.0\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\n\nfrom lets_plot import *\nLetsPlot.setup_html(no_js=True)\nplt.style.use(\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\n\n\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\n\n\n1.Why have researchers chosen this particular measure over other measures (such as absolute temperature)?\n\nTemperature anomalies indicate how much warmer or colder it is than normal for a particular place and time. For the GISS analysis, normal always means the average over the 30-year period 1951-1980 for that place and time of year. This base period is specific to GISS, not universal. But note that trends do not depend on the choice of the base period: If the absolute temperature at a specific location is 2 degrees higher than a year ago, so is the corresponding temperature anomaly, no matter what base period is selected, since the normal temperature used as base point (which is subtracted from the absolute temperature to get the anomaly) is the same for both years.\nNote that regional mean anomalies (in particular global anomalies) are not computed from the current absolute mean and the 1951-80 mean for that region, but from station temperature anomalies. Finding absolute regional means encounters significant difficulties that create large uncertainties. This is why the GISS analysis deals with anomalies rather than absolute temperatures. For a more detailed discussion of that topic, please see “The Elusive Absolute Temperature”.\n\ndf.head()\n\n\n\n\n\n\n\n\nYear\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\n\n\n0\n1880\n-0.39\n-0.54\n-0.24\n-0.31\n-0.06\n-0.18\n-0.22\n-0.26\n-0.25\n-0.31\n-0.44\n-0.43\n-0.30\nNaN\nNaN\n-0.20\n-0.22\n-0.33\n\n\n1\n1881\n-0.31\n-0.25\n-0.06\n-0.02\n0.05\n-0.34\n0.09\n-0.06\n-0.29\n-0.45\n-0.37\n-0.23\n-0.19\n-0.20\n-0.33\n-0.01\n-0.10\n-0.37\n\n\n2\n1882\n0.26\n0.21\n0.02\n-0.30\n-0.23\n-0.29\n-0.28\n-0.15\n-0.25\n-0.52\n-0.34\n-0.69\n-0.21\n-0.18\n0.08\n-0.17\n-0.24\n-0.37\n\n\n3\n1883\n-0.58\n-0.66\n-0.15\n-0.30\n-0.26\n-0.12\n-0.06\n-0.23\n-0.34\n-0.17\n-0.45\n-0.15\n-0.29\n-0.33\n-0.64\n-0.24\n-0.14\n-0.32\n\n\n4\n1884\n-0.16\n-0.11\n-0.64\n-0.59\n-0.36\n-0.42\n-0.41\n-0.52\n-0.45\n-0.45\n-0.58\n-0.47\n-0.43\n-0.40\n-0.14\n-0.53\n-0.45\n-0.50\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 145 entries, 0 to 144\nData columns (total 19 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Year    145 non-null    int64  \n 1   Jan     145 non-null    float64\n 2   Feb     145 non-null    float64\n 3   Mar     145 non-null    float64\n 4   Apr     145 non-null    float64\n 5   May     145 non-null    float64\n 6   Jun     145 non-null    float64\n 7   Jul     145 non-null    float64\n 8   Aug     145 non-null    float64\n 9   Sep     145 non-null    float64\n 10  Oct     144 non-null    float64\n 11  Nov     144 non-null    float64\n 12  Dec     144 non-null    float64\n 13  J-D     144 non-null    float64\n 14  D-N     143 non-null    float64\n 15  DJF     144 non-null    float64\n 16  MAM     145 non-null    float64\n 17  JJA     145 non-null    float64\n 18  SON     144 non-null    float64\ndtypes: float64(18), int64(1)\nmemory usage: 21.7 KB\n\n\n\ndf = df.set_index(\"Year\")\ndf.head()\n\n\n\n\n\n\n\n\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\nYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1880\n-0.39\n-0.54\n-0.24\n-0.31\n-0.06\n-0.18\n-0.22\n-0.26\n-0.25\n-0.31\n-0.44\n-0.43\n-0.30\nNaN\nNaN\n-0.20\n-0.22\n-0.33\n\n\n1881\n-0.31\n-0.25\n-0.06\n-0.02\n0.05\n-0.34\n0.09\n-0.06\n-0.29\n-0.45\n-0.37\n-0.23\n-0.19\n-0.20\n-0.33\n-0.01\n-0.10\n-0.37\n\n\n1882\n0.26\n0.21\n0.02\n-0.30\n-0.23\n-0.29\n-0.28\n-0.15\n-0.25\n-0.52\n-0.34\n-0.69\n-0.21\n-0.18\n0.08\n-0.17\n-0.24\n-0.37\n\n\n1883\n-0.58\n-0.66\n-0.15\n-0.30\n-0.26\n-0.12\n-0.06\n-0.23\n-0.34\n-0.17\n-0.45\n-0.15\n-0.29\n-0.33\n-0.64\n-0.24\n-0.14\n-0.32\n\n\n1884\n-0.16\n-0.11\n-0.64\n-0.59\n-0.36\n-0.42\n-0.41\n-0.52\n-0.45\n-0.45\n-0.58\n-0.47\n-0.43\n-0.40\n-0.14\n-0.53\n-0.45\n-0.50\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\nYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2020\n1.58\n1.69\n1.66\n1.39\n1.26\n1.14\n1.10\n1.12\n1.19\n1.20\n1.58\n1.18\n1.34\n1.36\n1.56\n1.44\n1.12\n1.32\n\n\n2021\n1.25\n0.95\n1.20\n1.12\n1.04\n1.20\n1.07\n1.02\n1.04\n1.29\n1.29\n1.16\n1.14\n1.14\n1.13\n1.12\n1.10\n1.21\n\n\n2022\n1.24\n1.16\n1.41\n1.08\n1.02\n1.12\n1.06\n1.16\n1.14\n1.31\n1.09\n1.06\n1.15\n1.16\n1.19\n1.17\n1.11\n1.18\n\n\n2023\n1.29\n1.29\n1.63\n1.01\n1.12\n1.19\n1.44\n1.57\n1.67\n1.88\n1.97\n1.85\n1.49\n1.43\n1.21\n1.26\n1.40\n1.84\n\n\n2024\n1.66\n1.93\n1.77\n1.79\n1.44\n1.54\n1.42\n1.42\n1.57\nNaN\nNaN\nNaN\nNaN\nNaN\n1.81\n1.67\n1.46\nNaN\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\ndf[\"Jan\"].plot(ax=ax)\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\nax.plot(df.index, df[\"Jan\"])\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\n\n\n\n\n\n\n\n\n\nmonth = \"Jan\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.66, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average temperature anomaly in {month} \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n\n\n\n\n\n\n\n\n\nmonth = \"J-D\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.68, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average annual temperature anomaly in \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n\n\n\n\n\n\n\n\n\ndf[\"Period\"] = pd.cut(\n    df.index,\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\ndf[\"Period\"].tail(20)\n\nYear\n2005    1981—2010\n2006    1981—2010\n2007    1981—2010\n2008    1981—2010\n2009    1981—2010\n2010    1981—2010\n2011          NaN\n2012          NaN\n2013          NaN\n2014          NaN\n2015          NaN\n2016          NaN\n2017          NaN\n2018          NaN\n2019          NaN\n2020          NaN\n2021          NaN\n2022          NaN\n2023          NaN\n2024          NaN\nName: Period, dtype: category\nCategories (3, object): ['1921—1950' &lt; '1951—1980' &lt; '1981—2010']\n\n\n\nlist_of_months = [\"Jun\", \"Jul\", \"Aug\"]\ndf[list_of_months].stack().head()\n\nYear     \n1880  Jun   -0.18\n      Jul   -0.22\n      Aug   -0.26\n1881  Jun   -0.34\n      Jul    0.09\ndtype: float64\n\n\n\nfig, axes = plt.subplots(ncols=3, figsize=(9, 4), sharex=True, sharey=True)\nfor ax, period in zip(axes, df[\"Period\"].dropna().unique()):\n    df.loc[df[\"Period\"] == period, list_of_months].stack().hist(ax=ax)\n    ax.set_title(period)\nplt.suptitle(\"Histogram of temperature anomalies\")\naxes[1].set_xlabel(\"Summer temperature distribution\")\nplt.tight_layout();\n\n\n\n\n\n\n\n\n\n# Create a variable that has years 1951 to 1980, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1951) & (df.index &lt;= 1980), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at this data:\ntemp_all_months\n\n\n\n\n\n\n\n\nYear\nmonth\nvalues\n\n\n\n\n0\n1951\nJan\n-0.36\n\n\n1\n1951\nFeb\n-0.51\n\n\n2\n1951\nMar\n-0.19\n\n\n3\n1951\nApr\n0.07\n\n\n4\n1951\nMay\n0.17\n\n\n...\n...\n...\n...\n\n\n355\n1980\nAug\n0.09\n\n\n356\n1980\nSep\n0.10\n\n\n357\n1980\nOct\n0.12\n\n\n358\n1980\nNov\n0.20\n\n\n359\n1980\nDec\n0.09\n\n\n\n\n360 rows × 3 columns\n\n\n\n\nquantiles = [0.3, 0.7]\nlist_of_percentiles = np.quantile(temp_all_months[\"values\"], q=quantiles)\n\nprint(f\"The cold threshold of {quantiles[0]*100}% is {list_of_percentiles[0]}\")\nprint(f\"The hot threshold of {quantiles[1]*100}% is {list_of_percentiles[1]}\")\n\nThe cold threshold of 30.0% is -0.1\nThe hot threshold of 70.0% is 0.1\n\n\n\n# Create a variable that has years 1981 to 2010, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1981) & (df.index &lt;= 2010), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at the start of this data data:\ntemp_all_months.head()\n\n\n\n\n\n\n\n\nYear\nmonth\nvalues\n\n\n\n\n0\n1981\nJan\n0.79\n\n\n1\n1981\nFeb\n0.62\n\n\n2\n1981\nMar\n0.68\n\n\n3\n1981\nApr\n0.39\n\n\n4\n1981\nMay\n0.18\n\n\n\n\n\n\n\n\nentries_less_than_q30 = temp_all_months[\"values\"] &lt; list_of_percentiles[0]\nproportion_under_q30 = entries_less_than_q30.mean()\nprint(\n    f\"The proportion under {list_of_percentiles[0]} is {proportion_under_q30*100:.2f}%\"\n)\n\nThe proportion under -0.1 is 1.94%\n\n\n\nproportion_over_q70 = (temp_all_months[\"values\"] &gt; list_of_percentiles[1]).mean()\nprint(f\"The proportion over {list_of_percentiles[1]} is {proportion_over_q70*100:.2f}%\")\n\nThe proportion over 0.1 is 84.72%\n\n\n\ntemp_all_months = (\n    df.loc[:, \"DJF\":\"SON\"]\n    .stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"Season\", 0: \"Values\"})\n)\ntemp_all_months[\"Period\"] = pd.cut(\n    temp_all_months[\"Year\"],\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n# Take a look at a cut of the data using `.iloc`, which provides position\ntemp_all_months.iloc[-135:-125]\n\n\n\n\n\n\n\n\nYear\nSeason\nValues\nPeriod\n\n\n\n\n443\n1991\nDJF\n0.51\n1981—2010\n\n\n444\n1991\nMAM\n0.45\n1981—2010\n\n\n445\n1991\nJJA\n0.42\n1981—2010\n\n\n446\n1991\nSON\n0.32\n1981—2010\n\n\n447\n1992\nDJF\n0.43\n1981—2010\n\n\n448\n1992\nMAM\n0.30\n1981—2010\n\n\n449\n1992\nJJA\n-0.04\n1981—2010\n\n\n450\n1992\nSON\n-0.15\n1981—2010\n\n\n451\n1993\nDJF\n0.37\n1981—2010\n\n\n452\n1993\nMAM\n0.31\n1981—2010\n\n\n\n\n\n\n\n\ngrp_mean_var = temp_all_months.groupby([\"Season\", \"Period\"])[\"Values\"].agg(\n    [np.mean, np.var]\n)\ngrp_mean_var\n\n\n\n\n\n\n\n\n\nmean\nvar\n\n\nSeason\nPeriod\n\n\n\n\n\n\nDJF\n1921—1950\n-0.027931\n0.057703\n\n\n1951—1980\n-0.003333\n0.050375\n\n\n1981—2010\n0.522000\n0.078644\n\n\nJJA\n1921—1950\n-0.054483\n0.021611\n\n\n1951—1980\n0.001333\n0.014640\n\n\n1981—2010\n0.399000\n0.067775\n\n\nMAM\n1921—1950\n-0.041724\n0.031136\n\n\n1951—1980\n0.000333\n0.025272\n\n\n1981—2010\n0.507667\n0.075812\n\n\nSON\n1921—1950\n0.081379\n0.027798\n\n\n1951—1980\n-0.001333\n0.026384\n\n\n1981—2010\n0.427000\n0.110739\n\n\n\n\n\n\n\n\nmin_year = 1880\n(\n    ggplot(temp_all_months, aes(x=\"Year\", y=\"Values\", color=\"Season\"))\n    + geom_abline(slope=0, color=\"black\", size=1)\n    + geom_line(size=1)\n    + labs(\n        title=f\"Average annual temperature anomaly in \\n in the northern hemisphere ({min_year}—{temp_all_months['Year'].max()})\",\n        y=\"Annual temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n    + geom_text(\n        x=min_year, y=0.1, label=\"1951—1980 average\", hjust=\"left\", color=\"black\"\n    )\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n      \n        \n          \n            \n              \n              \n            \n            \n              \n                \n                \n              \n              \n                \n                \n              \n              \n                \n                \n              \n              \n                \n                \n              \n            \n            \n              \n                \n                  \n                    1951—1980 average\n                  \n                \n              \n            \n          \n        \n        \n          \n            \n            \n          \n        \n        \n          \n            \n            \n          \n        \n        \n          \n            \n            \n          \n        \n      \n      \n        \n          \n            \n            \n            \n              \n                1880\n              \n            \n          \n          \n            \n            \n            \n              \n                1900\n              \n            \n          \n          \n            \n            \n            \n              \n                1920\n              \n            \n          \n          \n            \n            \n            \n              \n                1940\n              \n            \n          \n          \n            \n            \n            \n              \n                1960\n              \n            \n          \n          \n            \n            \n            \n              \n                1980\n              \n            \n          \n          \n            \n            \n            \n              \n                2000\n              \n            \n          \n          \n            \n            \n            \n              \n                2020\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                -1.0\n              \n            \n          \n          \n            \n              \n                -0.5\n              \n            \n          \n          \n            \n              \n                0.0\n              \n            \n          \n          \n            \n              \n                0.5\n              \n            \n          \n          \n            \n              \n                1.0\n              \n            \n          \n          \n            \n              \n                1.5\n              \n            \n          \n        \n      \n    \n    \n      \n        Average annual temperature anomaly in \n      \n      \n         in the northern hemisphere (1880—2024)\n      \n    \n    \n      \n        Annual temperature anomalies\n      \n    \n    \n      \n        Year\n      \n    \n    \n      \n      \n      \n        \n          \n            Season\n          \n        \n        \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                MAM\n              \n            \n          \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                JJA\n              \n            \n          \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                SON\n              \n            \n          \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n            \n              \n                DJF\n              \n            \n          \n        \n      \n    \n    \n    \n  \n  \n  \n\n\n\n\ndf_co2 = pd.read_csv(\"D:\\Yang Fan\\data\\data2(1).csv\")\ndf_co2.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nMonthly average\nInterpolated\nTrend\n\n\n\n\n0\n1958\n3\n315.71\n315.71\n314.62\n\n\n1\n1958\n4\n317.45\n317.45\n315.29\n\n\n2\n1958\n5\n317.50\n317.50\n314.71\n\n\n3\n1958\n6\n-99.99\n317.10\n314.85\n\n\n4\n1958\n7\n315.86\n315.86\n314.98\n\n\n\n\n\n\n\n\ndf_co2_june = df_co2.loc[df_co2[\"Month\"] == 6]\ndf_co2_june.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nMonthly average\nInterpolated\nTrend\n\n\n\n\n3\n1958\n6\n-99.99\n317.10\n314.85\n\n\n15\n1959\n6\n318.15\n318.15\n315.92\n\n\n27\n1960\n6\n319.59\n319.59\n317.36\n\n\n39\n1961\n6\n319.77\n319.77\n317.48\n\n\n51\n1962\n6\n320.55\n320.55\n318.27\n\n\n\n\n\n\n\n\ndf_temp_co2 = pd.merge(df_co2_june, df, on=\"Year\")\ndf_temp_co2[[\"Year\", \"Jun\", \"Trend\"]].head()\n\n\n\n\n\n\n\n\nYear\nJun\nTrend\n\n\n\n\n0\n1958\n0.05\n314.85\n\n\n1\n1959\n0.14\n315.92\n\n\n2\n1960\n0.18\n317.36\n\n\n3\n1961\n0.18\n317.48\n\n\n4\n1962\n-0.13\n318.27\n\n\n\n\n\n\n\n\n(\n    ggplot(df_temp_co2, aes(x=\"Jun\", y=\"Trend\"))\n    + geom_point(color=\"black\", size=3)\n    + labs(\n        title=\"Scatterplot of temperature anomalies vs carbon dioxide emissions\",\n        y=\"Carbon dioxide levels (trend, mole fraction)\",\n        x=\"Temperature anomaly (degrees Celsius)\",\n    )\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n      \n        \n          \n            \n              \n                \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                \n              \n            \n          \n        \n        \n          \n            \n            \n          \n        \n      \n      \n        \n          \n            \n            \n            \n              \n                -0.2\n              \n            \n          \n          \n            \n            \n            \n              \n                0.0\n              \n            \n          \n          \n            \n            \n            \n              \n                0.2\n              \n            \n          \n          \n            \n            \n            \n              \n                0.4\n              \n            \n          \n          \n            \n            \n            \n              \n                0.6\n              \n            \n          \n          \n            \n            \n            \n              \n                0.8\n              \n            \n          \n          \n            \n            \n            \n              \n                1.0\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                320\n              \n            \n          \n          \n            \n              \n                340\n              \n            \n          \n          \n            \n              \n                360\n              \n            \n          \n          \n            \n              \n                380\n              \n            \n          \n          \n            \n              \n                400\n              \n            \n          \n        \n      \n    \n    \n      \n        Scatterplot of temperature anomalies vs carbon dioxide emissions\n      \n    \n    \n      \n        Carbon dioxide levels (trend, mole fraction)\n      \n    \n    \n      \n        Temperature anomaly (degrees Celsius)\n      \n    \n    \n    \n  \n  \n  \n\n\n\n\ndf_temp_co2[[\"Jun\", \"Trend\"]].corr(method=\"pearson\")\n\n\n\n\n\n\n\n\nJun\nTrend\n\n\n\n\nJun\n1.000000\n0.914371\n\n\nTrend\n0.914371\n1.000000\n\n\n\n\n\n\n\n\n(\n    ggplot(df_temp_co2, aes(x=\"Year\", y=\"Jun\"))\n    + geom_line(size=1)\n    + labs(\n        title=\"June temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n      \n        \n          \n            \n              \n                \n                \n              \n            \n          \n        \n        \n          \n            \n            \n          \n        \n      \n      \n        \n          \n            \n            \n            \n              \n                1960\n              \n            \n          \n          \n            \n            \n            \n              \n                1970\n              \n            \n          \n          \n            \n            \n            \n              \n                1980\n              \n            \n          \n          \n            \n            \n            \n              \n                1990\n              \n            \n          \n          \n            \n            \n            \n              \n                2000\n              \n            \n          \n          \n            \n            \n            \n              \n                2010\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                -0.2\n              \n            \n          \n          \n            \n              \n                0.0\n              \n            \n          \n          \n            \n              \n                0.2\n              \n            \n          \n          \n            \n              \n                0.4\n              \n            \n          \n          \n            \n              \n                0.6\n              \n            \n          \n          \n            \n              \n                0.8\n              \n            \n          \n          \n            \n              \n                1.0\n              \n            \n          \n        \n      \n    \n    \n      \n        June temperature anomalies\n      \n    \n    \n      \n        Jun\n      \n    \n    \n      \n        Year\n      \n    \n    \n    \n  \n  \n  \n\n\n\n\nbase_plot = ggplot(df_temp_co2) + scale_x_continuous(format=\"d\")\nplot_p = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Jun\"), size=1)\n    + labs(title=\"June temperature anomalies\")\n)\nplot_q = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Trend\"), size=1)\n    + labs(title=\"Carbon dioxide emissions\")\n)\ngggrid([plot_p, plot_q], ncol=2)\n\n\n  \n    \n    \n  \n  \n    \n    \n      \n      \n      \n        \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n        \n        \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n          \n          \n            \n              \n              \n            \n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  1960\n                \n              \n            \n            \n              \n              \n              \n                \n                  1970\n                \n              \n            \n            \n              \n              \n              \n                \n                  1980\n                \n              \n            \n            \n              \n              \n              \n                \n                  1990\n                \n              \n            \n            \n              \n              \n              \n                \n                  2000\n                \n              \n            \n            \n              \n              \n              \n                \n                  2010\n                \n              \n            \n            \n            \n          \n          \n            \n              \n                \n                  -0.2\n                \n              \n            \n            \n              \n                \n                  0.0\n                \n              \n            \n            \n              \n                \n                  0.2\n                \n              \n            \n            \n              \n                \n                  0.4\n                \n              \n            \n            \n              \n                \n                  0.6\n                \n              \n            \n            \n              \n                \n                  0.8\n                \n              \n            \n            \n              \n                \n                  1.0\n                \n              \n            \n          \n        \n      \n      \n        \n          June temperature anomalies\n        \n      \n      \n        \n          Jun\n        \n      \n      \n        \n          Year\n        \n      \n      \n      \n    \n    \n    \n  \n  \n    \n    \n      \n      \n      \n        \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n          \n            \n              \n              \n              \n              \n              \n              \n              \n              \n              \n              \n            \n          \n        \n        \n          \n            \n              \n                \n                  \n                  \n                \n              \n            \n          \n          \n            \n              \n              \n            \n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  1960\n                \n              \n            \n            \n              \n              \n              \n                \n                  1970\n                \n              \n            \n            \n              \n              \n              \n                \n                  1980\n                \n              \n            \n            \n              \n              \n              \n                \n                  1990\n                \n              \n            \n            \n              \n              \n              \n                \n                  2000\n                \n              \n            \n            \n              \n              \n              \n                \n                  2010\n                \n              \n            \n            \n            \n          \n          \n            \n              \n                \n                  320\n                \n              \n            \n            \n              \n                \n                  340\n                \n              \n            \n            \n              \n                \n                  360\n                \n              \n            \n            \n              \n                \n                  380\n                \n              \n            \n            \n              \n                \n                  400\n                \n              \n            \n          \n        \n      \n      \n        \n          Carbon dioxide emissions\n        \n      \n      \n        \n          Trend\n        \n      \n      \n        \n          Year"
  },
  {
    "objectID": "labs/Labexercises/03Chipotle-Exercises-with-solutions(1).html",
    "href": "labs/Labexercises/03Chipotle-Exercises-with-solutions(1).html",
    "title": "Visualizing Chipotle’s Data",
    "section": "",
    "text": "This time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n# set this so the graphs open internally\n%matplotlib inline\n\n\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called chipo.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n    \nchipo = pd.read_csv(url, sep = '\\t')\n\n\n\nStep 4. See the first 10 entries\n\nchipo.head(10)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n0\n1\n1\nChips and Fresh Tomato Salsa\nNaN\n$2.39\n\n\n1\n1\n1\nIzze\n[Clementine]\n$3.39\n\n\n2\n1\n1\nNantucket Nectar\n[Apple]\n$3.39\n\n\n3\n1\n1\nChips and Tomatillo-Green Chili Salsa\nNaN\n$2.39\n\n\n4\n2\n2\nChicken Bowl\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98\n\n\n5\n3\n1\nChicken Bowl\n[Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...\n$10.98\n\n\n6\n3\n1\nSide of Chips\nNaN\n$1.69\n\n\n7\n4\n1\nSteak Burrito\n[Tomatillo Red Chili Salsa, [Fajita Vegetables...\n$11.75\n\n\n8\n4\n1\nSteak Soft Tacos\n[Tomatillo Green Chili Salsa, [Pinto Beans, Ch...\n$9.25\n\n\n9\n5\n1\nSteak Burrito\n[Fresh Tomato Salsa, [Rice, Black Beans, Pinto...\n$9.25\n\n\n\n\n\n\n\n\n\nStep 5. Create a histogram of the top 5 items bought\n\n# get the Series of the names\nx = chipo.item_name\n\n# use the Counter class from collections to create a dictionary with keys(text) and frequency\nletter_counts = Counter(x)\n\n# convert the dictionary to a DataFrame\ndf = pd.DataFrame.from_dict(letter_counts, orient='index')\n\n# sort the values from the top to the least value and slice the first 5 items\ndf = df[0].sort_values(ascending = True)[45:50]\n\n# create the plot\ndf.plot(kind='bar')\n\n# Set the title and labels\nplt.xlabel('Items')\nplt.ylabel('Number of Times Ordered')\nplt.title('Most ordered Chipotle\\'s Items')\n\n# show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\nStep 6. Create a scatterplot with the number of items orderered per order price\n\nHint: Price should be in the X-axis and Items ordered in the Y-axis\n\n# create a list of prices\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price] # strip the dollar sign and trailing space\n\n# then groupby the orders and sum\norders = chipo.groupby('order_id').sum()\n\n# creates the scatterplot\n# plt.scatter(orders.quantity, orders.item_price, s = 50, c = 'green')\nplt.scatter(x = orders.item_price, y = orders.quantity, s = 50, c = 'green')\n\n# Set the title and labels\nplt.xlabel('Order Price')\nplt.ylabel('Items ordered')\nplt.title('Number of items ordered per order price')\nplt.ylim(0)\n\n(0.0, 36.7)\n\n\n\n\n\nStep 7. BONUS: Create a question and a graph to answer your own question."
  },
  {
    "objectID": "labs/Labexercises/02Chipotle-Exercises-with-solutions.html",
    "href": "labs/Labexercises/02Chipotle-Exercises-with-solutions.html",
    "title": "Ex1 - Filtering and Sorting Data",
    "section": "",
    "text": "This time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called chipo.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep = '\\t')\n\n\n\nStep 4. How many products cost more than $10.00?\n\n\nprices = [float(value[1 : -1]) for value in chipo.item_price]\n\nchipo.item_price = prices\n\nchipo_filtered = chipo.drop_duplicates(['item_name','quantity','choice_description'])\n\nchipo_one_prod = chipo_filtered[chipo_filtered.quantity == 1]\nchipo_one_prod\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n0\n1\n1\nChips and Fresh Tomato Salsa\nNaN\n2.39\n\n\n1\n1\n1\nIzze\n[Clementine]\n3.39\n\n\n2\n1\n1\nNantucket Nectar\n[Apple]\n3.39\n\n\n3\n1\n1\nChips and Tomatillo-Green Chili Salsa\nNaN\n2.39\n\n\n5\n3\n1\nChicken Bowl\n[Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...\n10.98\n\n\n...\n...\n...\n...\n...\n...\n\n\n4602\n1827\n1\nBarbacoa Burrito\n[Tomatillo Green Chili Salsa]\n9.25\n\n\n4607\n1829\n1\nSteak Burrito\n[Tomatillo Green Chili Salsa, [Rice, Cheese, S...\n11.75\n\n\n4610\n1830\n1\nSteak Burrito\n[Fresh Tomato Salsa, [Rice, Sour Cream, Cheese...\n11.75\n\n\n4611\n1830\n1\nVeggie Burrito\n[Tomatillo Green Chili Salsa, [Rice, Fajita Ve...\n11.25\n\n\n4612\n1831\n1\nCarnitas Bowl\n[Fresh Tomato Salsa, [Fajita Vegetables, Rice,...\n9.25\n\n\n\n\n1806 rows × 5 columns\n\n\n\n\nchipo.query('item_price &gt; 10').item_name.nunique()\n\n31\n\n\n\n\nStep 5. What is the price of each item?\n\nprint a data frame with only two columns item_name and item_price\n\n\nchipo_filtered = chipo.drop_duplicates(['item_name','quantity'])\n\nchipo[(chipo['item_name'] == 'Chicken Bowl') & (chipo['quantity'] == 1)]\n\nchipo_one_prod = chipo_filtered[chipo_filtered.quantity == 1]\n\nprice_per_item = chipo_one_prod[['item_name', 'item_price']]\n\nprice_per_item.sort_values(by = \"item_price\", ascending = False).head(20)\n\n\n\n\n\n\n\n\nitem_name\nitem_price\n\n\n\n\n606\nSteak Salad Bowl\n11.89\n\n\n1229\nBarbacoa Salad Bowl\n11.89\n\n\n1132\nCarnitas Salad Bowl\n11.89\n\n\n7\nSteak Burrito\n11.75\n\n\n168\nBarbacoa Crispy Tacos\n11.75\n\n\n39\nBarbacoa Bowl\n11.75\n\n\n738\nVeggie Soft Tacos\n11.25\n\n\n186\nVeggie Salad Bowl\n11.25\n\n\n62\nVeggie Bowl\n11.25\n\n\n57\nVeggie Burrito\n11.25\n\n\n250\nChicken Salad\n10.98\n\n\n5\nChicken Bowl\n10.98\n\n\n8\nSteak Soft Tacos\n9.25\n\n\n554\nCarnitas Crispy Tacos\n9.25\n\n\n237\nCarnitas Soft Tacos\n9.25\n\n\n56\nBarbacoa Soft Tacos\n9.25\n\n\n92\nSteak Crispy Tacos\n9.25\n\n\n664\nSteak Salad\n8.99\n\n\n54\nSteak Bowl\n8.99\n\n\n3750\nCarnitas Salad\n8.99\n\n\n\n\n\n\n\n\n\n\nStep 6. Sort by the name of the item\n\nchipo.item_name.sort_values()\n\n# OR\n\nchipo.sort_values(by = \"item_name\")\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n3389\n1360\n2\n6 Pack Soft Drink\n[Diet Coke]\n12.98\n\n\n341\n148\n1\n6 Pack Soft Drink\n[Diet Coke]\n6.49\n\n\n1849\n749\n1\n6 Pack Soft Drink\n[Coke]\n6.49\n\n\n1860\n754\n1\n6 Pack Soft Drink\n[Diet Coke]\n6.49\n\n\n2713\n1076\n1\n6 Pack Soft Drink\n[Coke]\n6.49\n\n\n...\n...\n...\n...\n...\n...\n\n\n2384\n948\n1\nVeggie Soft Tacos\n[Roasted Chili Corn Salsa, [Fajita Vegetables,...\n8.75\n\n\n781\n322\n1\nVeggie Soft Tacos\n[Fresh Tomato Salsa, [Black Beans, Cheese, Sou...\n8.75\n\n\n2851\n1132\n1\nVeggie Soft Tacos\n[Roasted Chili Corn Salsa (Medium), [Black Bea...\n8.49\n\n\n1699\n688\n1\nVeggie Soft Tacos\n[Fresh Tomato Salsa, [Fajita Vegetables, Rice,...\n11.25\n\n\n1395\n567\n1\nVeggie Soft Tacos\n[Fresh Tomato Salsa (Mild), [Pinto Beans, Rice...\n8.49\n\n\n\n\n4622 rows × 5 columns\n\n\n\n\n\nStep 7. What was the quantity of the most expensive item ordered?\n\nchipo.sort_values(by = \"item_price\", ascending = False).head(1)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n3598\n1443\n15\nChips and Fresh Tomato Salsa\nNaN\n44.25\n\n\n\n\n\n\n\n\n\nStep 8. How many times was a Veggie Salad Bowl ordered?\n\nchipo_salad = chipo[chipo.item_name == \"Veggie Salad Bowl\"]\n# chipo_salad = chipo.query('item_name == \"Veggie Salad Bowl\"')\n\nlen(chipo_salad)\n\n18\n\n\n\n\nStep 9. How many times did someone order more than one Canned Soda?\n\nchipo_drink_steak_bowl = chipo[(chipo.item_name == \"Canned Soda\") & (chipo.quantity &gt; 1)]\n# chipo_drink_steak_bowl = chipo.query('item_name == \"Canned Soda\" & quantity &gt; 1')\n\nlen(chipo_drink_steak_bowl)\n\n20"
  },
  {
    "objectID": "labs/Labexercises/01Occupation-Exercises-with-solutions.html",
    "href": "labs/Labexercises/01Occupation-Exercises-with-solutions.html",
    "title": "Ex3 - Getting and Knowing your Data",
    "section": "",
    "text": "This time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport numpy as np\n\n\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called users and use the ‘user_id’ as index\n\nusers = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user', \n                      sep='|', index_col='user_id')\n\n\n\nStep 4. See the first 25 entries\n\nusers.head(25)\n\n\n\n\n\n\n\n\nage\ngender\noccupation\nzip_code\n\n\nuser_id\n\n\n\n\n\n\n\n\n1\n24\nM\ntechnician\n85711\n\n\n2\n53\nF\nother\n94043\n\n\n3\n23\nM\nwriter\n32067\n\n\n4\n24\nM\ntechnician\n43537\n\n\n5\n33\nF\nother\n15213\n\n\n6\n42\nM\nexecutive\n98101\n\n\n7\n57\nM\nadministrator\n91344\n\n\n8\n36\nM\nadministrator\n05201\n\n\n9\n29\nM\nstudent\n01002\n\n\n10\n53\nM\nlawyer\n90703\n\n\n11\n39\nF\nother\n30329\n\n\n12\n28\nF\nother\n06405\n\n\n13\n47\nM\neducator\n29206\n\n\n14\n45\nM\nscientist\n55106\n\n\n15\n49\nF\neducator\n97301\n\n\n16\n21\nM\nentertainment\n10309\n\n\n17\n30\nM\nprogrammer\n06355\n\n\n18\n35\nF\nother\n37212\n\n\n19\n40\nM\nlibrarian\n02138\n\n\n20\n42\nF\nhomemaker\n95660\n\n\n21\n26\nM\nwriter\n30068\n\n\n22\n25\nM\nwriter\n40206\n\n\n23\n30\nF\nartist\n48197\n\n\n24\n21\nF\nartist\n94533\n\n\n25\n39\nM\nengineer\n55107\n\n\n\n\n\n\n\n\n\nStep 5. See the last 10 entries\n\nusers.tail(10)\n\n\n\n\n\n\n\n\nage\ngender\noccupation\nzip_code\n\n\nuser_id\n\n\n\n\n\n\n\n\n934\n61\nM\nengineer\n22902\n\n\n935\n42\nM\ndoctor\n66221\n\n\n936\n24\nM\nother\n32789\n\n\n937\n48\nM\neducator\n98072\n\n\n938\n38\nF\ntechnician\n55038\n\n\n939\n26\nF\nstudent\n33319\n\n\n940\n32\nM\nadministrator\n02215\n\n\n941\n20\nM\nstudent\n97229\n\n\n942\n48\nF\nlibrarian\n78209\n\n\n943\n22\nM\nstudent\n77841\n\n\n\n\n\n\n\n\n\nStep 6. What is the number of observations in the dataset?\n\nusers.shape[0]\n\n943\n\n\n\n\nStep 7. What is the number of columns in the dataset?\n\nusers.shape[1]\n\n4\n\n\n\n\nStep 8. Print the name of all the columns.\n\nusers.columns\n\nIndex(['age', 'gender', 'occupation', 'zip_code'], dtype='object')\n\n\n\n\nStep 9. How is the dataset indexed?\n\nusers.index\n\nIndex([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       934, 935, 936, 937, 938, 939, 940, 941, 942, 943],\n      dtype='int64', name='user_id', length=943)\n\n\n\n\nStep 10. What is the data type of each column?\n\nusers.dtypes\n\nage            int64\ngender        object\noccupation    object\nzip_code      object\ndtype: object\n\n\n\n\nStep 11. Print only the occupation column\n\nusers.occupation\n\n#or\n\nusers['occupation']\n\nuser_id\n1         technician\n2              other\n3             writer\n4         technician\n5              other\n           ...      \n939          student\n940    administrator\n941          student\n942        librarian\n943          student\nName: occupation, Length: 943, dtype: object\n\n\n\n\nStep 12. How many different occupations are in this dataset?\n\nusers.occupation.nunique()\n\n21\n\n\n\n\nStep 13. What is the most frequent occupation?\n\nusers.occupation.value_counts().head(1).index[0]\n\n'student'\n\n\n\n\nStep 14. Summarize the DataFrame.\n\nusers.describe() \n\n\n\n\n\n\n\n\nage\n\n\n\n\ncount\n943.000000\n\n\nmean\n34.051962\n\n\nstd\n12.192740\n\n\nmin\n7.000000\n\n\n25%\n25.000000\n\n\n50%\n31.000000\n\n\n75%\n43.000000\n\n\nmax\n73.000000\n\n\n\n\n\n\n\n\n\nStep 15. Summarize all the columns\n\nusers.describe(include = \"all\")\n\n\n\n\n\n\n\n\nage\ngender\noccupation\nzip_code\n\n\n\n\ncount\n943.000000\n943\n943\n943\n\n\nunique\nNaN\n2\n21\n795\n\n\ntop\nNaN\nM\nstudent\n55414\n\n\nfreq\nNaN\n670\n196\n9\n\n\nmean\n34.051962\nNaN\nNaN\nNaN\n\n\nstd\n12.192740\nNaN\nNaN\nNaN\n\n\nmin\n7.000000\nNaN\nNaN\nNaN\n\n\n25%\n25.000000\nNaN\nNaN\nNaN\n\n\n50%\n31.000000\nNaN\nNaN\nNaN\n\n\n75%\n43.000000\nNaN\nNaN\nNaN\n\n\nmax\n73.000000\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nStep 16. Summarize only the occupation column\n\nusers.occupation.describe()\n\ncount         943\nunique         21\ntop       student\nfreq          196\nName: occupation, dtype: object\n\n\n\n\nStep 17. What is the mean age of users?\n\nround(users.age.mean())\n\n34\n\n\n\n\nStep 18. What is the age with least occurrence?\n\nusers.age.value_counts().tail()\n\nage\n7     1\n66    1\n11    1\n10    1\n73    1\nName: count, dtype: int64"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yang Fan’s website and data analysis portfolio",
    "section": "",
    "text": "Hello, and thanks for visiting!\nWelcome to my website and data analysis portfolio.\nHere, I’ll feature my projects for the Fall 2024 Informational technologies in Business class.\nPlease use the Menu Bar above to look around."
  },
  {
    "objectID": "homework/Lecture4-homework-YangFan.html",
    "href": "homework/Lecture4-homework-YangFan.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\ndf = pd.read_csv('all-ages.csv')\n\n\ndf\n\n\n\n\n\n\n\n\nMajor_code\nMajor\nMajor_category\nTotal\nEmployed\nEmployed_full_time_year_round\nUnemployed\nUnemployment_rate\nMedian\nP25th\nP75th\n\n\n\n\n0\n1100\nGENERAL AGRICULTURE\nAgriculture & Natural Resources\n128148\n90245\n74078\n2423\n0.026147\n50000\n34000\n80000.0\n\n\n1\n1101\nAGRICULTURE PRODUCTION AND MANAGEMENT\nAgriculture & Natural Resources\n95326\n76865\n64240\n2266\n0.028636\n54000\n36000\n80000.0\n\n\n2\n1102\nAGRICULTURAL ECONOMICS\nAgriculture & Natural Resources\n33955\n26321\n22810\n821\n0.030248\n63000\n40000\n98000.0\n\n\n3\n1103\nANIMAL SCIENCES\nAgriculture & Natural Resources\n103549\n81177\n64937\n3619\n0.042679\n46000\n30000\n72000.0\n\n\n4\n1104\nFOOD SCIENCE\nAgriculture & Natural Resources\n24280\n17281\n12722\n894\n0.049188\n62000\n38500\n90000.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n168\n6211\nHOSPITALITY MANAGEMENT\nBusiness\n200854\n163393\n122499\n8862\n0.051447\n49000\n33000\n70000.0\n\n\n169\n6212\nMANAGEMENT INFORMATION SYSTEMS AND STATISTICS\nBusiness\n156673\n134478\n118249\n6186\n0.043977\n72000\n50000\n100000.0\n\n\n170\n6299\nMISCELLANEOUS BUSINESS & MEDICAL ADMINISTRATION\nBusiness\n102753\n77471\n61603\n4308\n0.052679\n53000\n36000\n83000.0\n\n\n171\n6402\nHISTORY\nHumanities & Liberal Arts\n712509\n478416\n354163\n33725\n0.065851\n50000\n35000\n80000.0\n\n\n172\n6403\nUNITED STATES HISTORY\nHumanities & Liberal Arts\n17746\n11887\n8204\n943\n0.073500\n50000\n39000\n81000.0\n\n\n\n\n173 rows × 11 columns\n\n\n\n\n# 按照专业分组，并把失业率从低到高升序排列\nresult = df.groupby([\"Major\"]).sum().sort_values([\"Unemployment_rate\"])\nprint(result)\n\n                                            Major_code  \\\nMajor                                                    \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING            2411   \nEDUCATIONAL ADMINISTRATION AND SUPERVISION        2301   \nPHARMACOLOGY                                      3607   \nMATERIALS SCIENCE                                 5008   \nMATHEMATICS AND COMPUTER SCIENCE                  4005   \n...                                                ...   \nLIBRARY SCIENCE                                   3501   \nSCHOOL STUDENT COUNSELING                         2303   \nMILITARY TECHNOLOGIES                             3801   \nCLINICAL PSYCHOLOGY                               5202   \nMISCELLANEOUS FINE ARTS                           6099   \n\n                                                                 Major_category  \\\nMajor                                                                             \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING                              Engineering   \nEDUCATIONAL ADMINISTRATION AND SUPERVISION                            Education   \nPHARMACOLOGY                                             Biology & Life Science   \nMATERIALS SCIENCE                                                   Engineering   \nMATHEMATICS AND COMPUTER SCIENCE                        Computers & Mathematics   \n...                                                                         ...   \nLIBRARY SCIENCE                                                       Education   \nSCHOOL STUDENT COUNSELING                                             Education   \nMILITARY TECHNOLOGIES                       Industrial Arts & Consumer Services   \nCLINICAL PSYCHOLOGY                                    Psychology & Social Work   \nMISCELLANEOUS FINE ARTS                                                    Arts   \n\n                                            Total  Employed  \\\nMajor                                                         \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING       6264      4120   \nEDUCATIONAL ADMINISTRATION AND SUPERVISION   4037      3113   \nPHARMACOLOGY                                 5015      3481   \nMATERIALS SCIENCE                            7208      5866   \nMATHEMATICS AND COMPUTER SCIENCE             7184      5874   \n...                                           ...       ...   \nLIBRARY SCIENCE                             16193      7091   \nSCHOOL STUDENT COUNSELING                    2396      1492   \nMILITARY TECHNOLOGIES                        4315      1650   \nCLINICAL PSYCHOLOGY                          7638      5128   \nMISCELLANEOUS FINE ARTS                      8511      6431   \n\n                                            Employed_full_time_year_round  \\\nMajor                                                                       \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING                               3350   \nEDUCATIONAL ADMINISTRATION AND SUPERVISION                           2468   \nPHARMACOLOGY                                                         2579   \nMATERIALS SCIENCE                                                    4505   \nMATHEMATICS AND COMPUTER SCIENCE                                     5039   \n...                                                                   ...   \nLIBRARY SCIENCE                                                      4330   \nSCHOOL STUDENT COUNSELING                                            1093   \nMILITARY TECHNOLOGIES                                                1708   \nCLINICAL PSYCHOLOGY                                                  3297   \nMISCELLANEOUS FINE ARTS                                              3802   \n\n                                            Unemployed  Unemployment_rate  \\\nMajor                                                                       \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING               0           0.000000   \nEDUCATIONAL ADMINISTRATION AND SUPERVISION           0           0.000000   \nPHARMACOLOGY                                        57           0.016111   \nMATERIALS SCIENCE                                  134           0.022333   \nMATHEMATICS AND COMPUTER SCIENCE                   150           0.024900   \n...                                                ...                ...   \nLIBRARY SCIENCE                                    743           0.094843   \nSCHOOL STUDENT COUNSELING                          169           0.101746   \nMILITARY TECHNOLOGIES                              187           0.101796   \nCLINICAL PSYCHOLOGY                                587           0.102712   \nMISCELLANEOUS FINE ARTS                           1190           0.156147   \n\n                                            Median  P25th     P75th  \nMajor                                                                \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING       85000  55000  125000.0  \nEDUCATIONAL ADMINISTRATION AND SUPERVISION   58000  44750   79000.0  \nPHARMACOLOGY                                 60000  35000  105000.0  \nMATERIALS SCIENCE                            75000  60000  100000.0  \nMATHEMATICS AND COMPUTER SCIENCE             92000  53000  136000.0  \n...                                            ...    ...       ...  \nLIBRARY SCIENCE                              40000  30000   55000.0  \nSCHOOL STUDENT COUNSELING                    41000  33200   50000.0  \nMILITARY TECHNOLOGIES                        64000  39750   90000.0  \nCLINICAL PSYCHOLOGY                          45000  26100   62000.0  \nMISCELLANEOUS FINE ARTS                      45000  30000   60000.0  \n\n[173 rows x 10 columns]\n\n\n\nimport pandas as pd\ndf = pd.read_csv('recent-grads.csv')\ndf\n\n\n\n\n\n\n\n\nRank\nMajor_code\nMajor\nTotal\nMen\nWomen\nMajor_category\nShareWomen\nSample_size\nEmployed\n...\nPart_time\nFull_time_year_round\nUnemployed\nUnemployment_rate\nMedian\nP25th\nP75th\nCollege_jobs\nNon_college_jobs\nLow_wage_jobs\n\n\n\n\n0\n1\n2419\nPETROLEUM ENGINEERING\n2339.0\n2057.0\n282.0\nEngineering\n0.120564\n36\n1976\n...\n270\n1207\n37\n0.018381\n110000\n95000\n125000\n1534\n364\n193\n\n\n1\n2\n2416\nMINING AND MINERAL ENGINEERING\n756.0\n679.0\n77.0\nEngineering\n0.101852\n7\n640\n...\n170\n388\n85\n0.117241\n75000\n55000\n90000\n350\n257\n50\n\n\n2\n3\n2415\nMETALLURGICAL ENGINEERING\n856.0\n725.0\n131.0\nEngineering\n0.153037\n3\n648\n...\n133\n340\n16\n0.024096\n73000\n50000\n105000\n456\n176\n0\n\n\n3\n4\n2417\nNAVAL ARCHITECTURE AND MARINE ENGINEERING\n1258.0\n1123.0\n135.0\nEngineering\n0.107313\n16\n758\n...\n150\n692\n40\n0.050125\n70000\n43000\n80000\n529\n102\n0\n\n\n4\n5\n2405\nCHEMICAL ENGINEERING\n32260.0\n21239.0\n11021.0\nEngineering\n0.341631\n289\n25694\n...\n5180\n16697\n1672\n0.061098\n65000\n50000\n75000\n18314\n4440\n972\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n168\n169\n3609\nZOOLOGY\n8409.0\n3050.0\n5359.0\nBiology & Life Science\n0.637293\n47\n6259\n...\n2190\n3602\n304\n0.046320\n26000\n20000\n39000\n2771\n2947\n743\n\n\n169\n170\n5201\nEDUCATIONAL PSYCHOLOGY\n2854.0\n522.0\n2332.0\nPsychology & Social Work\n0.817099\n7\n2125\n...\n572\n1211\n148\n0.065112\n25000\n24000\n34000\n1488\n615\n82\n\n\n170\n171\n5202\nCLINICAL PSYCHOLOGY\n2838.0\n568.0\n2270.0\nPsychology & Social Work\n0.799859\n13\n2101\n...\n648\n1293\n368\n0.149048\n25000\n25000\n40000\n986\n870\n622\n\n\n171\n172\n5203\nCOUNSELING PSYCHOLOGY\n4626.0\n931.0\n3695.0\nPsychology & Social Work\n0.798746\n21\n3777\n...\n965\n2738\n214\n0.053621\n23400\n19200\n26000\n2403\n1245\n308\n\n\n172\n173\n3501\nLIBRARY SCIENCE\n1098.0\n134.0\n964.0\nEducation\n0.877960\n2\n742\n...\n237\n410\n87\n0.104946\n22000\n20000\n22000\n288\n338\n192\n\n\n\n\n173 rows × 21 columns\n\n\n\n\n# 按照专业分组，将女生占比从高到低降序排列\nresult = df.groupby([\"Major\"]).sum().sort_values([\"ShareWomen\"],ascending=False)\nprint(result)\n\n                                               Rank  Major_code     Total  \\\nMajor                                                                       \nEARLY CHILDHOOD EDUCATION                       165        2307   37589.0   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES   164        6102   38279.0   \nMEDICAL ASSISTING SERVICES                       52        6104   11123.0   \nELEMENTARY EDUCATION                            139        2304  170862.0   \nFAMILY AND CONSUMER SCIENCES                    151        2901   58001.0   \n...                                             ...         ...       ...   \nMINING AND MINERAL ENGINEERING                    2        2416     756.0   \nCONSTRUCTION SERVICES                            27        5601   18498.0   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES      67        2504    4790.0   \nMILITARY TECHNOLOGIES                            74        3801     124.0   \nFOOD SCIENCE                                     22        1104       0.0   \n\n                                                   Men     Women  \\\nMajor                                                              \nEARLY CHILDHOOD EDUCATION                       1167.0   36422.0   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES   1225.0   37054.0   \nMEDICAL ASSISTING SERVICES                       803.0   10320.0   \nELEMENTARY EDUCATION                           13029.0  157833.0   \nFAMILY AND CONSUMER SCIENCES                    5166.0   52835.0   \n...                                                ...       ...   \nMINING AND MINERAL ENGINEERING                   679.0      77.0   \nCONSTRUCTION SERVICES                          16820.0    1678.0   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES     4419.0     371.0   \nMILITARY TECHNOLOGIES                            124.0       0.0   \nFOOD SCIENCE                                       0.0       0.0   \n\n                                                                    Major_category  \\\nMajor                                                                                \nEARLY CHILDHOOD EDUCATION                                                Education   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES                               Health   \nMEDICAL ASSISTING SERVICES                                                  Health   \nELEMENTARY EDUCATION                                                     Education   \nFAMILY AND CONSUMER SCIENCES                   Industrial Arts & Consumer Services   \n...                                                                            ...   \nMINING AND MINERAL ENGINEERING                                         Engineering   \nCONSTRUCTION SERVICES                          Industrial Arts & Consumer Services   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES                            Engineering   \nMILITARY TECHNOLOGIES                          Industrial Arts & Consumer Services   \nFOOD SCIENCE                                       Agriculture & Natural Resources   \n\n                                               ShareWomen  Sample_size  \\\nMajor                                                                    \nEARLY CHILDHOOD EDUCATION                        0.968954          342   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES    0.967998           95   \nMEDICAL ASSISTING SERVICES                       0.927807           67   \nELEMENTARY EDUCATION                             0.923745         1629   \nFAMILY AND CONSUMER SCIENCES                     0.910933          518   \n...                                                   ...          ...   \nMINING AND MINERAL ENGINEERING                   0.101852            7   \nCONSTRUCTION SERVICES                            0.090713          295   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES      0.077453           71   \nMILITARY TECHNOLOGIES                            0.000000            4   \nFOOD SCIENCE                                     0.000000           36   \n\n                                               Employed  Full_time  Part_time  \\\nMajor                                                                           \nEARLY CHILDHOOD EDUCATION                         32551      27569       7001   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES     29763      19975      13862   \nMEDICAL ASSISTING SERVICES                         9168       5643       4107   \nELEMENTARY EDUCATION                             149339     123177      37965   \nFAMILY AND CONSUMER SCIENCES                      46624      36747      15872   \n...                                                 ...        ...        ...   \nMINING AND MINERAL ENGINEERING                      640        556        170   \nCONSTRUCTION SERVICES                             16318      15690       1751   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES        4186       4175        247   \nMILITARY TECHNOLOGIES                                 0        111          0   \nFOOD SCIENCE                                       3149       2558       1121   \n\n                                               Full_time_year_round  \\\nMajor                                                                 \nEARLY CHILDHOOD EDUCATION                                     20748   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES                 14460   \nMEDICAL ASSISTING SERVICES                                     4290   \nELEMENTARY EDUCATION                                          86540   \nFAMILY AND CONSUMER SCIENCES                                  26906   \n...                                                             ...   \nMINING AND MINERAL ENGINEERING                                  388   \nCONSTRUCTION SERVICES                                         12313   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES                    3607   \nMILITARY TECHNOLOGIES                                           111   \nFOOD SCIENCE                                                   1735   \n\n                                               Unemployed  Unemployment_rate  \\\nMajor                                                                          \nEARLY CHILDHOOD EDUCATION                            1360           0.040105   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES        1487           0.047584   \nMEDICAL ASSISTING SERVICES                            407           0.042507   \nELEMENTARY EDUCATION                                 7297           0.046586   \nFAMILY AND CONSUMER SCIENCES                         3355           0.067128   \n...                                                   ...                ...   \nMINING AND MINERAL ENGINEERING                         85           0.117241   \nCONSTRUCTION SERVICES                                1042           0.060023   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES           250           0.056357   \nMILITARY TECHNOLOGIES                                   0           0.000000   \nFOOD SCIENCE                                          338           0.096931   \n\n                                               Median  P25th  P75th  \\\nMajor                                                                 \nEARLY CHILDHOOD EDUCATION                       28000  21000  35000   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES   28000  20000  40000   \nMEDICAL ASSISTING SERVICES                      42000  30000  65000   \nELEMENTARY EDUCATION                            32000  23400  38000   \nFAMILY AND CONSUMER SCIENCES                    30000  22900  40000   \n...                                               ...    ...    ...   \nMINING AND MINERAL ENGINEERING                  75000  55000  90000   \nCONSTRUCTION SERVICES                           50000  36000  60000   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES     40000  27000  52000   \nMILITARY TECHNOLOGIES                           40000  40000  40000   \nFOOD SCIENCE                                    53000  32000  70000   \n\n                                               College_jobs  Non_college_jobs  \\\nMajor                                                                           \nEARLY CHILDHOOD EDUCATION                             23515              7705   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES         19957              9404   \nMEDICAL ASSISTING SERVICES                             2091              6948   \nELEMENTARY EDUCATION                                 108085             36972   \nFAMILY AND CONSUMER SCIENCES                          20985             20133   \n...                                                     ...               ...   \nMINING AND MINERAL ENGINEERING                          350               257   \nCONSTRUCTION SERVICES                                  3275              5351   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES            1861              2121   \nMILITARY TECHNOLOGIES                                     0                 0   \nFOOD SCIENCE                                           1183              1274   \n\n                                               Low_wage_jobs  \nMajor                                                         \nEARLY CHILDHOOD EDUCATION                               2868  \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES           5125  \nMEDICAL ASSISTING SERVICES                              1270  \nELEMENTARY EDUCATION                                   11502  \nFAMILY AND CONSUMER SCIENCES                            5248  \n...                                                      ...  \nMINING AND MINERAL ENGINEERING                            50  \nCONSTRUCTION SERVICES                                    703  \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES              406  \nMILITARY TECHNOLOGIES                                      0  \nFOOD SCIENCE                                             485  \n\n[173 rows x 20 columns]\n\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\na=df['Median'].groupby(df['Major_category']).sum()\na.plot.bar()\nplt.show()"
  },
  {
    "objectID": "homework/Lecture3-homework1-YangFan.html",
    "href": "homework/Lecture3-homework1-YangFan.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nurl ='https://raw.githubusercontent.com/tidyverse/datascience-box/refs/heads/main/course-materials/lab-instructions/lab-03/data/nobel.csv'\ndf = pd.read_csv(url)\nprint(df.head())\n\n   id       firstname    surname  year category  \\\n0   1  Wilhelm Conrad    Röntgen  1901  Physics   \n1   2      Hendrik A.    Lorentz  1902  Physics   \n2   3          Pieter     Zeeman  1902  Physics   \n3   4           Henri  Becquerel  1903  Physics   \n4   5          Pierre      Curie  1903  Physics   \n\n                                         affiliation       city      country  \\\n0                                  Munich University     Munich      Germany   \n1                                  Leiden University     Leiden  Netherlands   \n2                               Amsterdam University  Amsterdam  Netherlands   \n3                                École Polytechnique      Paris       France   \n4  École municipale de physique et de chimie indu...      Paris       France   \n\n    born_date   died_date  ... died_country_code overall_motivation share  \\\n0  1845-03-27  1923-02-10  ...                DE                NaN     1   \n1  1853-07-18  1928-02-04  ...                NL                NaN     2   \n2  1865-05-25  1943-10-09  ...                NL                NaN     2   \n3  1852-12-15  1908-08-25  ...                FR                NaN     2   \n4  1859-05-15  1906-04-19  ...                FR                NaN     4   \n\n                                          motivation  born_country_original  \\\n0  \"in recognition of the extraordinary services ...  Prussia (now Germany)   \n1  \"in recognition of the extraordinary service t...        the Netherlands   \n2  \"in recognition of the extraordinary service t...        the Netherlands   \n3  \"in recognition of the extraordinary services ...                 France   \n4  \"in recognition of the extraordinary services ...                 France   \n\n       born_city_original died_country_original died_city_original  \\\n0  Lennep (now Remscheid)               Germany             Munich   \n1                  Arnhem       the Netherlands                NaN   \n2              Zonnemaire       the Netherlands          Amsterdam   \n3                   Paris                France                NaN   \n4                   Paris                France              Paris   \n\n   city_original country_original  \n0         Munich          Germany  \n1         Leiden  the Netherlands  \n2      Amsterdam  the Netherlands  \n3          Paris           France  \n4          Paris           France  \n\n[5 rows x 26 columns]\n\n\n\ndf\n\n\n\n\n\n\n\n\nid\nfirstname\nsurname\nyear\ncategory\naffiliation\ncity\ncountry\nborn_date\ndied_date\n...\ndied_country_code\noverall_motivation\nshare\nmotivation\nborn_country_original\nborn_city_original\ndied_country_original\ndied_city_original\ncity_original\ncountry_original\n\n\n\n\n0\n1\nWilhelm Conrad\nRöntgen\n1901\nPhysics\nMunich University\nMunich\nGermany\n1845-03-27\n1923-02-10\n...\nDE\nNaN\n1\n\"in recognition of the extraordinary services ...\nPrussia (now Germany)\nLennep (now Remscheid)\nGermany\nMunich\nMunich\nGermany\n\n\n1\n2\nHendrik A.\nLorentz\n1902\nPhysics\nLeiden University\nLeiden\nNetherlands\n1853-07-18\n1928-02-04\n...\nNL\nNaN\n2\n\"in recognition of the extraordinary service t...\nthe Netherlands\nArnhem\nthe Netherlands\nNaN\nLeiden\nthe Netherlands\n\n\n2\n3\nPieter\nZeeman\n1902\nPhysics\nAmsterdam University\nAmsterdam\nNetherlands\n1865-05-25\n1943-10-09\n...\nNL\nNaN\n2\n\"in recognition of the extraordinary service t...\nthe Netherlands\nZonnemaire\nthe Netherlands\nAmsterdam\nAmsterdam\nthe Netherlands\n\n\n3\n4\nHenri\nBecquerel\n1903\nPhysics\nÉcole Polytechnique\nParis\nFrance\n1852-12-15\n1908-08-25\n...\nFR\nNaN\n2\n\"in recognition of the extraordinary services ...\nFrance\nParis\nFrance\nNaN\nParis\nFrance\n\n\n4\n5\nPierre\nCurie\n1903\nPhysics\nÉcole municipale de physique et de chimie indu...\nParis\nFrance\n1859-05-15\n1906-04-19\n...\nFR\nNaN\n4\n\"in recognition of the extraordinary services ...\nFrance\nParis\nFrance\nParis\nParis\nFrance\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n930\n965\nSir Gregory P.\nWinter\n2018\nChemistry\nMRC Laboratory of Molecular Biology\nCambridge\nUnited Kingdom\n1951-04-14\nNaN\n...\nNaN\nNaN\n4\n\"for the phage display of peptides and antibod...\nUnited Kingdom\nLeicester\nNaN\nNaN\nCambridge\nUnited Kingdom\n\n\n931\n966\nDenis\nMukwege\n2018\nPeace\nNaN\nNaN\nNaN\n1955-03-01\nNaN\n...\nNaN\nNaN\n2\n\"for their efforts to end the use of sexual vi...\nBelgian Congo (now Democratic Republic of the ...\nBukavu\nNaN\nNaN\nNaN\nNaN\n\n\n932\n967\nNadia\nMurad\n2018\nPeace\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\n2\n\"for their efforts to end the use of sexual vi...\nIraq\nKojo\nNaN\nNaN\nNaN\nNaN\n\n\n933\n968\nWilliam D.\nNordhaus\n2018\nEconomics\nYale University\nNew Haven CT\nUSA\n1941-05-31\nNaN\n...\nNaN\nNaN\n2\n\"for integrating climate change into long-run ...\nUSA\nAlbuquerque NM\nNaN\nNaN\nNew Haven CT\nUSA\n\n\n934\n969\nPaul M.\nRomer\n2018\nEconomics\nNYU Stern School of Business\nNew York NY\nUSA\nNaN\nNaN\n...\nNaN\nNaN\n2\n\"for integrating technological innovations int...\nUSA\nDenver CO\nNaN\nNaN\nNew York NY\nUSA\n\n\n\n\n935 rows × 26 columns\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 935 entries, 0 to 934\nData columns (total 26 columns):\n #   Column                 Non-Null Count  Dtype \n---  ------                 --------------  ----- \n 0   id                     935 non-null    int64 \n 1   firstname              935 non-null    object\n 2   surname                906 non-null    object\n 3   year                   935 non-null    int64 \n 4   category               935 non-null    object\n 5   affiliation            685 non-null    object\n 6   city                   680 non-null    object\n 7   country                681 non-null    object\n 8   born_date              902 non-null    object\n 9   died_date              627 non-null    object\n 10  gender                 935 non-null    object\n 11  born_city              907 non-null    object\n 12  born_country           907 non-null    object\n 13  born_country_code      907 non-null    object\n 14  died_city              608 non-null    object\n 15  died_country           614 non-null    object\n 16  died_country_code      614 non-null    object\n 17  overall_motivation     17 non-null     object\n 18  share                  935 non-null    int64 \n 19  motivation             935 non-null    object\n 20  born_country_original  907 non-null    object\n 21  born_city_original     907 non-null    object\n 22  died_country_original  614 non-null    object\n 23  died_city_original     608 non-null    object\n 24  city_original          680 non-null    object\n 25  country_original       681 non-null    object\ndtypes: int64(3), object(23)\nmemory usage: 190.1+ KB\n\n\n\ndf[(df['country'].notna())]\n\n\n\n\n\n\n\n\nid\nfirstname\nsurname\nyear\ncategory\naffiliation\ncity\ncountry\nborn_date\ndied_date\n...\ndied_country_code\noverall_motivation\nshare\nmotivation\nborn_country_original\nborn_city_original\ndied_country_original\ndied_city_original\ncity_original\ncountry_original\n\n\n\n\n0\n1\nWilhelm Conrad\nRöntgen\n1901\nPhysics\nMunich University\nMunich\nGermany\n1845-03-27\n1923-02-10\n...\nDE\nNaN\n1\n\"in recognition of the extraordinary services ...\nPrussia (now Germany)\nLennep (now Remscheid)\nGermany\nMunich\nMunich\nGermany\n\n\n1\n2\nHendrik A.\nLorentz\n1902\nPhysics\nLeiden University\nLeiden\nNetherlands\n1853-07-18\n1928-02-04\n...\nNL\nNaN\n2\n\"in recognition of the extraordinary service t...\nthe Netherlands\nArnhem\nthe Netherlands\nNaN\nLeiden\nthe Netherlands\n\n\n2\n3\nPieter\nZeeman\n1902\nPhysics\nAmsterdam University\nAmsterdam\nNetherlands\n1865-05-25\n1943-10-09\n...\nNL\nNaN\n2\n\"in recognition of the extraordinary service t...\nthe Netherlands\nZonnemaire\nthe Netherlands\nAmsterdam\nAmsterdam\nthe Netherlands\n\n\n3\n4\nHenri\nBecquerel\n1903\nPhysics\nÉcole Polytechnique\nParis\nFrance\n1852-12-15\n1908-08-25\n...\nFR\nNaN\n2\n\"in recognition of the extraordinary services ...\nFrance\nParis\nFrance\nNaN\nParis\nFrance\n\n\n4\n5\nPierre\nCurie\n1903\nPhysics\nÉcole municipale de physique et de chimie indu...\nParis\nFrance\n1859-05-15\n1906-04-19\n...\nFR\nNaN\n4\n\"in recognition of the extraordinary services ...\nFrance\nParis\nFrance\nParis\nParis\nFrance\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n928\n963\nFrances H.\nArnold\n2018\nChemistry\nCalifornia Institute of Technology (Caltech)\nPasadena CA\nUSA\n1956-07-25\nNaN\n...\nNaN\nNaN\n2\n\"for the directed evolution of enzymes\"\nUSA\nPittsburgh PA\nNaN\nNaN\nPasadena CA\nUSA\n\n\n929\n964\nGeorge P.\nSmith\n2018\nChemistry\nUniversity of Missouri\nColumbia\nUSA\n1941-03-10\nNaN\n...\nNaN\nNaN\n4\n\"for the phage display of peptides and antibod...\nUSA\nNorwalk CT\nNaN\nNaN\nColumbia\nUSA\n\n\n930\n965\nSir Gregory P.\nWinter\n2018\nChemistry\nMRC Laboratory of Molecular Biology\nCambridge\nUnited Kingdom\n1951-04-14\nNaN\n...\nNaN\nNaN\n4\n\"for the phage display of peptides and antibod...\nUnited Kingdom\nLeicester\nNaN\nNaN\nCambridge\nUnited Kingdom\n\n\n933\n968\nWilliam D.\nNordhaus\n2018\nEconomics\nYale University\nNew Haven CT\nUSA\n1941-05-31\nNaN\n...\nNaN\nNaN\n2\n\"for integrating climate change into long-run ...\nUSA\nAlbuquerque NM\nNaN\nNaN\nNew Haven CT\nUSA\n\n\n934\n969\nPaul M.\nRomer\n2018\nEconomics\nNYU Stern School of Business\nNew York NY\nUSA\nNaN\nNaN\n...\nNaN\nNaN\n2\n\"for integrating technological innovations int...\nUSA\nDenver CO\nNaN\nNaN\nNew York NY\nUSA\n\n\n\n\n681 rows × 26 columns\n\n\n\n\ndf[(df['died_date'].isna())]\n\n\n\n\n\n\n\n\nid\nfirstname\nsurname\nyear\ncategory\naffiliation\ncity\ncountry\nborn_date\ndied_date\n...\ndied_country_code\noverall_motivation\nshare\nmotivation\nborn_country_original\nborn_city_original\ndied_country_original\ndied_city_original\ncity_original\ncountry_original\n\n\n\n\n68\n68\nChen Ning\nYang\n1957\nPhysics\nInstitute for Advanced Study\nPrinceton NJ\nUSA\n1922-09-22\nNaN\n...\nNaN\nNaN\n2\n\"for their penetrating investigation of the so...\nChina\nHofei Anhwei\nNaN\nNaN\nPrinceton NJ\nUSA\n\n\n69\n69\nTsung-Dao\nLee\n1957\nPhysics\nColumbia University\nNew York NY\nUSA\n1926-11-24\nNaN\n...\nNaN\nNaN\n2\n\"for their penetrating investigation of the so...\nChina\nShanghai\nNaN\nNaN\nNew York NY\nUSA\n\n\n94\n95\nLeon N.\nCooper\n1972\nPhysics\nBrown University\nProvidence RI\nUSA\n1930-02-28\nNaN\n...\nNaN\nNaN\n3\n\"for their jointly developed theory of superco...\nUSA\nNew York NY\nNaN\nNaN\nProvidence RI\nUSA\n\n\n96\n97\nLeo\nEsaki\n1973\nPhysics\nIBM Thomas J. Watson Research Center\nYorktown Heights NY\nUSA\n1925-03-12\nNaN\n...\nNaN\nNaN\n4\n\"for their experimental discoveries regarding ...\nJapan\nOsaka\nNaN\nNaN\nYorktown Heights NY\nUSA\n\n\n97\n98\nIvar\nGiaever\n1973\nPhysics\nGeneral Electric Company\nSchenectady NY\nUSA\n1929-04-05\nNaN\n...\nNaN\nNaN\n4\n\"for their experimental discoveries regarding ...\nNorway\nBergen\nNaN\nNaN\nSchenectady NY\nUSA\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n930\n965\nSir Gregory P.\nWinter\n2018\nChemistry\nMRC Laboratory of Molecular Biology\nCambridge\nUnited Kingdom\n1951-04-14\nNaN\n...\nNaN\nNaN\n4\n\"for the phage display of peptides and antibod...\nUnited Kingdom\nLeicester\nNaN\nNaN\nCambridge\nUnited Kingdom\n\n\n931\n966\nDenis\nMukwege\n2018\nPeace\nNaN\nNaN\nNaN\n1955-03-01\nNaN\n...\nNaN\nNaN\n2\n\"for their efforts to end the use of sexual vi...\nBelgian Congo (now Democratic Republic of the ...\nBukavu\nNaN\nNaN\nNaN\nNaN\n\n\n932\n967\nNadia\nMurad\n2018\nPeace\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\n2\n\"for their efforts to end the use of sexual vi...\nIraq\nKojo\nNaN\nNaN\nNaN\nNaN\n\n\n933\n968\nWilliam D.\nNordhaus\n2018\nEconomics\nYale University\nNew Haven CT\nUSA\n1941-05-31\nNaN\n...\nNaN\nNaN\n2\n\"for integrating climate change into long-run ...\nUSA\nAlbuquerque NM\nNaN\nNaN\nNew Haven CT\nUSA\n\n\n934\n969\nPaul M.\nRomer\n2018\nEconomics\nNYU Stern School of Business\nNew York NY\nUSA\nNaN\nNaN\n...\nNaN\nNaN\n2\n\"for integrating technological innovations int...\nUSA\nDenver CO\nNaN\nNaN\nNew York NY\nUSA\n\n\n\n\n308 rows × 26 columns"
  },
  {
    "objectID": "homework/Lecture1-workflow-basics.html",
    "href": "homework/Lecture1-workflow-basics.html",
    "title": "",
    "section": "",
    "text": "(workflow-basics)= # Workflow Basics\nThis chapter will take you through some of the essential parts of a Python workflow."
  },
  {
    "objectID": "homework/Lecture1-workflow-basics.html#prerequisites",
    "href": "homework/Lecture1-workflow-basics.html#prerequisites",
    "title": "",
    "section": "Prerequisites",
    "text": "Prerequisites\nYou’ll need an installation of Python and Visual Studio Code with the Python extensions to get to grips with this chapter. If you haven’t installed those yet, head back to {ref}code-preliminaries and follow the instructions there."
  },
  {
    "objectID": "homework/Lecture1-workflow-basics.html#working-with-python-scripts-and-the-interactive-window",
    "href": "homework/Lecture1-workflow-basics.html#working-with-python-scripts-and-the-interactive-window",
    "title": "",
    "section": "Working with Python scripts and the interactive window",
    "text": "Working with Python scripts and the interactive window\nAs a reminder, the figure below shows the typical layout of Visual Studio Code.\n\n\n\nA typical user view in Visual Studio Code\n\n\nWhen you create a new script (File-&gt;New File-&gt;Save as ’your_script_name.py), it will appear in the part of the screen labelled as 3.\nTo run a script, select the code you want to run, right click, and select “Run Selection/Line in Interactive Window”. You can also hit shift + enter if you set this shortcut up; if you haven’t it’s well worth doing and you can find the instructions in {ref}code-preliminaries.\nUsing the “Run Selection/Line in Interactive Window” option or using the shortcut will cause panel 5 in the above diagram (the interactive window) to appear, where you will see the code run and the outputs of your script appear.\nIf you have an issue getting the code to run in the interactive window, first check the instructions in {ref}`code-preliminaries`. If you're still having issues, it may be that Visual Studio Code isn't sure which Python to run, or where Python is on your system. To fix the latter problem, hit the \"Select kernel\" button in the top right-hand side of the interactive window.\nWhen you are first writing a script, it’s useful to be able to move back and forth between the script and the interactive window. You might execute a line of code (put the cursor on the relevant line and hit shift and enter) in the interactive window, then manually write out some code in the interactive window’s execution box (seen at the bottom of panel 5 saying “Type code here…”), and then explore some of the variables you’ve created with the variable explorer (using the button “Variables”) at the top of the interactive window.\nBut, once you’ve honed the code in your script, it’s good to make the script a complete analytical process that you are happy running end-to-end and that—for production or ‘final’ work—you would use the “Run Current File in Interactive Window” option to run all the way through. This is good practice because what is in your script is reproducible but what you’ve entered manually in the interactive window is not. And you want the outputs from your code to be reproducible and understandable by others (including future you!), but this is hard if there are undocumented extra lines of code that you only did on the fly via the interactive window’s execution box."
  },
  {
    "objectID": "homework/Lecture1-workflow-basics.html#using-installed-packages-and-modules",
    "href": "homework/Lecture1-workflow-basics.html#using-installed-packages-and-modules",
    "title": "",
    "section": "Using installed packages and modules",
    "text": "Using installed packages and modules\nWe already saw how to install packages in {ref}code-preliminaries. If you forgot, look back at how to do this now. In short, packages are installed using the command line or, on Windows, the Anaconda prompt. With either of these open, type conda install packagename and hit enter to both search for and install the package you need.\nWhat about using a package that you’ve installed? That’s what we’ll look at now.\nLet’s see an example of using the powerful numerical library numpy. There are different ways to import packages to use within a script or notebook; you can import the entire package in one go or just import the functions you need (if you know their names). When an entire package is imported, you can give it any name you like and the convention for numpy is to import it as the shortened ‘np’. All of the functions and methods of the package can be accessed by typing np followed by . and then typing the function name. This convention of importing packages with a given name makes your code easier to read, because you know exactly which package is doing what, and avoids any conflicts when functions from different packages have the same name.\nAs well as demonstrating importing the whole package for numpy, the example below shows importing just one specific function from numpy, inv, which does matrix inversion. Note that because inv was imported separately it can be used without an np prefix.\n\nimport numpy as np\nfrom numpy.linalg import inv\n\nmatrix = np.array([[4.0, 2.0, 4.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n\nprint(\"Matrix:\")\nprint(matrix)\n\ninv_mat = inv(matrix)\nprint(\"Inverse:\")\nprint(inv_mat)\n\nMatrix:\n[[4. 2. 4.]\n [4. 5. 6.]\n [7. 8. 9.]]\nInverse:\n[[ 0.25       -1.16666667  0.66666667]\n [-0.5        -0.66666667  0.66666667]\n [ 0.25        1.5        -1.        ]]\n\n\n\nimport numpy as np\nfrom numpy.linalg import inv\n\nmatrix = np.array([[4.0, 2.0, 4.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n\nprint(\"Matrix:\")\nprint(matrix)\n\ninv_mat = inv(matrix)\nprint(\"Inverse:\")\nprint(inv_mat)\n\nMatrix:\n[[4. 2. 4.]\n [4. 5. 6.]\n [7. 8. 9.]]\nInverse:\n[[ 0.25       -1.16666667  0.66666667]\n [-0.5        -0.66666667  0.66666667]\n [ 0.25        1.5        -1.        ]]\n\n\nWe could have imported all of numpy and it used it without extension using from numpy import * but this is considered bad practice as it fills our ‘namespace’ with function names that might clash with other packages and it’s less easy to read because you don’t know which function came from which package (one of Python’s mantras is “explicit is better than implict”). However, some packages are designed to be used like this, so, for example, you will see from lets_plot import * in this book.\nIf you want to check what packages you have installed in your Python environment, run `conda list` on your computer's command line (aka the *terminal* or *command prompt*).\nSometimes you might forget what a function you have imported does! Or at least, you might not be sure what all of the optional arguments are. In Visual Studio Code, you can just hover your cursor over the name of the function and a box will come up that tells you everything you need to know about it. This box is auto-generated by doc-strings; information that is written in text just under a function’s definition (def statement).\nAn alternative way to see what a function does is to use a wonderful package called rich that does many things including providing an inspect() function. You will need to use pip to install rich by running pip install rich on the command line. Here’s an example of using rich’s inpsect method on the inv() function we imported above (methods=True reports all of the functionality of inv()):\n\nfrom rich import inspect\n\ninspect(inv, help=True)\n\n╭─────────────── &lt;function inv at 0x000002308AF6F560&gt; ────────────────╮\n│ def inv(a):                                                         │\n│                                                                     │\n│ Compute the (multiplicative) inverse of a matrix.                   │\n│                                                                     │\n│ Given a square matrix `a`, return the matrix `ainv` satisfying      │\n│ ``dot(a, ainv) = dot(ainv, a) = eye(a.shape[0])``.                  │\n│                                                                     │\n│ Parameters                                                          │\n│ ----------                                                          │\n│ a : (..., M, M) array_like                                          │\n│     Matrix to be inverted.                                          │\n│                                                                     │\n│ Returns                                                             │\n│ -------                                                             │\n│ ainv : (..., M, M) ndarray or matrix                                │\n│     (Multiplicative) inverse of the matrix `a`.                     │\n│                                                                     │\n│ Raises                                                              │\n│ ------                                                              │\n│ LinAlgError                                                         │\n│     If `a` is not square or inversion fails.                        │\n│                                                                     │\n│ See Also                                                            │\n│ --------                                                            │\n│ scipy.linalg.inv : Similar function in SciPy.                       │\n│                                                                     │\n│ Notes                                                               │\n│ -----                                                               │\n│                                                                     │\n│ .. versionadded:: 1.8.0                                             │\n│                                                                     │\n│ Broadcasting rules apply, see the `numpy.linalg` documentation for  │\n│ details.                                                            │\n│                                                                     │\n│ Examples                                                            │\n│ --------                                                            │\n│ &gt;&gt;&gt; from numpy.linalg import inv                                    │\n│ &gt;&gt;&gt; a = np.array([[1., 2.], [3., 4.]])                              │\n│ &gt;&gt;&gt; ainv = inv(a)                                                   │\n│ &gt;&gt;&gt; np.allclose(np.dot(a, ainv), np.eye(2))                         │\n│ True                                                                │\n│ &gt;&gt;&gt; np.allclose(np.dot(ainv, a), np.eye(2))                         │\n│ True                                                                │\n│                                                                     │\n│ If a is a matrix object, then the return value is a matrix as well: │\n│                                                                     │\n│ &gt;&gt;&gt; ainv = inv(np.matrix(a))                                        │\n│ &gt;&gt;&gt; ainv                                                            │\n│ matrix([[-2. ,  1. ],                                               │\n│         [ 1.5, -0.5]])                                              │\n│                                                                     │\n│ Inverses of several matrices can be computed at once:               │\n│                                                                     │\n│ &gt;&gt;&gt; a = np.array([[[1., 2.], [3., 4.]], [[1, 3], [3, 5]]])          │\n│ &gt;&gt;&gt; inv(a)                                                          │\n│ array([[[-2.  ,  1.  ],                                             │\n│         [ 1.5 , -0.5 ]],                                            │\n│        [[-1.25,  0.75],                                             │\n│         [ 0.75, -0.25]]])                                           │\n│                                                                     │\n│ 34 attribute(s) not shown. Run inspect(inspect) for options.        │\n╰─────────────────────────────────────────────────────────────────────╯\n\n\n\n\nfrom rich import inspect\n\ninspect(inv, help=True)\n\n╭─────────────── &lt;function inv at 0x000002308AF6F560&gt; ────────────────╮\n│ def inv(a):                                                         │\n│                                                                     │\n│ Compute the (multiplicative) inverse of a matrix.                   │\n│                                                                     │\n│ Given a square matrix `a`, return the matrix `ainv` satisfying      │\n│ ``dot(a, ainv) = dot(ainv, a) = eye(a.shape[0])``.                  │\n│                                                                     │\n│ Parameters                                                          │\n│ ----------                                                          │\n│ a : (..., M, M) array_like                                          │\n│     Matrix to be inverted.                                          │\n│                                                                     │\n│ Returns                                                             │\n│ -------                                                             │\n│ ainv : (..., M, M) ndarray or matrix                                │\n│     (Multiplicative) inverse of the matrix `a`.                     │\n│                                                                     │\n│ Raises                                                              │\n│ ------                                                              │\n│ LinAlgError                                                         │\n│     If `a` is not square or inversion fails.                        │\n│                                                                     │\n│ See Also                                                            │\n│ --------                                                            │\n│ scipy.linalg.inv : Similar function in SciPy.                       │\n│                                                                     │\n│ Notes                                                               │\n│ -----                                                               │\n│                                                                     │\n│ .. versionadded:: 1.8.0                                             │\n│                                                                     │\n│ Broadcasting rules apply, see the `numpy.linalg` documentation for  │\n│ details.                                                            │\n│                                                                     │\n│ Examples                                                            │\n│ --------                                                            │\n│ &gt;&gt;&gt; from numpy.linalg import inv                                    │\n│ &gt;&gt;&gt; a = np.array([[1., 2.], [3., 4.]])                              │\n│ &gt;&gt;&gt; ainv = inv(a)                                                   │\n│ &gt;&gt;&gt; np.allclose(np.dot(a, ainv), np.eye(2))                         │\n│ True                                                                │\n│ &gt;&gt;&gt; np.allclose(np.dot(ainv, a), np.eye(2))                         │\n│ True                                                                │\n│                                                                     │\n│ If a is a matrix object, then the return value is a matrix as well: │\n│                                                                     │\n│ &gt;&gt;&gt; ainv = inv(np.matrix(a))                                        │\n│ &gt;&gt;&gt; ainv                                                            │\n│ matrix([[-2. ,  1. ],                                               │\n│         [ 1.5, -0.5]])                                              │\n│                                                                     │\n│ Inverses of several matrices can be computed at once:               │\n│                                                                     │\n│ &gt;&gt;&gt; a = np.array([[[1., 2.], [3., 4.]], [[1, 3], [3, 5]]])          │\n│ &gt;&gt;&gt; inv(a)                                                          │\n│ array([[[-2.  ,  1.  ],                                             │\n│         [ 1.5 , -0.5 ]],                                            │\n│        [[-1.25,  0.75],                                             │\n│         [ 0.75, -0.25]]])                                           │\n│                                                                     │\n│ 34 attribute(s) not shown. Run inspect(inspect) for options.        │\n╰─────────────────────────────────────────────────────────────────────╯\n\n\n\nkbytaasrctaj Exercise Write a code block that imports the **numpy** function `numpy.linalg.det()` as `det()`. Run `inspect()` on it. Find the determinant of `[[4, 3], [1, 7]]`.\n\nModules\nSometimes, you will want to call in some code from a different script that you wrote (rather than from a package provided by someone else). Imagine you have several scripts with code in, a, b, and c, all of which need to use the same underlying function that you have written. What do you do? (Note that “script with code in” is just a text file that has a .py extension and contains code.)\nA central tenet of good coding is that you do not repeat yourself. Therefore, a bad solution to this problem would be to copy and paste the same code into all three of the scripts. A good solution is to write the code that’s need just once in a separate ‘utility’ script and have the other scripts import that one function. This also adheres to another important programming principle: that of writing modular code.\nThis schematic shows the kind of situation we’re talking about:\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport matplotlib_inline.backend_inline\n\n# Plot settings\nplt.style.use(\n    \"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\"\n)\nmatplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n\n\ngraph = nx.DiGraph()\ngraph.add_edges_from(\n    [\n        (\"Utility script\", \"code file a\"),\n        (\"Utility script\", \"code file b\"),\n        (\"code file a\", \"code file c\"),\n        (\"code file b\", \"code file c\"),\n        (\"Utility script\", \"code file c\"),\n    ]\n)\ncolour_node = \"#AFCBFF\"\nfixed_pos = nx.spring_layout(graph, seed=100)\nnx.draw(graph, pos=fixed_pos, with_labels=True, node_size=6000, node_color=colour_node)\nextent = 1.4\nplt.xlim(-extent, extent)\nplt.ylim(-extent, extent)\nplt.show();\n\n\n\n\n\n\n\n\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport matplotlib_inline.backend_inline\n\n# Plot settings\nplt.style.use(\n    \"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\"\n)\nmatplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n\n\ngraph = nx.DiGraph()\ngraph.add_edges_from(\n    [\n        (\"Utility script\", \"code file a\"),\n        (\"Utility script\", \"code file b\"),\n        (\"code file a\", \"code file c\"),\n        (\"code file b\", \"code file c\"),\n        (\"Utility script\", \"code file c\"),\n    ]\n)\ncolour_node = \"#AFCBFF\"\nfixed_pos = nx.spring_layout(graph, seed=100)\nnx.draw(graph, pos=fixed_pos, with_labels=True, node_size=6000, node_color=colour_node)\nextent = 1.4\nplt.xlim(-extent, extent)\nplt.ylim(-extent, extent)\nplt.show();\n\n\n\n\n\n\n\n\nHow can we give code files a, b, and c access to the functions etc in the “Utility script”? We would define a file ‘utilities.py’ that had the following function in that we would like to use in the other code files:\n# Contents of utilities.py file\ndef really_useful_func(number):\n    return number*10\nThen, in ‘code_script_a.py’, we would write:\n\nimport utilities as utils\n\nprint(utils.really_useful_func(20))\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[7], line 1\n----&gt; 1 import utilities as utils\n      3 print(utils.really_useful_func(20))\n\nModuleNotFoundError: No module named 'utilities'\n\n\n\nAn alternative is to just import the function we want, with the name we want:\n\nfrom utilities import really_useful_func as ru_fn\n\nprint(ru_fn(30))\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[8], line 1\n----&gt; 1 from utilities import really_useful_func as ru_fn\n      3 print(ru_fn(30))\n\nModuleNotFoundError: No module named 'utilities'\n\n\n\nAnother important example is the case where you want to run ‘utilities.py’ as a standalone script, but still want to borrow functions from it to run in other scripts. There’s a way to do this. Let’s change utilities.py to\n# Contents of utilities.py file\ndef really_useful_func(number):\n    return number*10\n\n\ndef default_func():\n    print('Script has run')\n\n\nif __name__ == '__main__':\n    default_func()\nWhat this says is that if we call ‘utilities.py’ from the command line, eg\npython utilities.py\nIt will return Script has run because, by executing the script alone, we are asking for anything in the main block defined at the end of the file to be run. But we can still import anything from utilities into other scripts as before–and in that case it is not the main script, but an import, and so the main block will not be executed by default.\nYou can important several functions at once from a module (aka another script file) like this:\nfrom utilities import really_useful_func, default_func\nkbytaasrctaj Exercise Write your own `utilities.py` that has a `super_useful_func` that accepts a number and returns the number divided by 10. In another script, `main.py`, try a) importing all of utilities and running `super_useful_func` on a number and, b), importing just `super_useful_func` from utilities and running it on a number."
  },
  {
    "objectID": "homework/Lecture1-workflow-basics.html#reading-and-writing-files",
    "href": "homework/Lecture1-workflow-basics.html#reading-and-writing-files",
    "title": "",
    "section": "Reading and writing files",
    "text": "Reading and writing files\nAlthough most applications in economics will use the pandas package to read and write tabular data, it’s sometimes useful to know how to read and write arbitrary files using the built-in Python libraries too. To open a file\nopen('filename', mode)\nwhere mode could be r for read, a for append, w for write, and x to create a file. Create a file called text_example.txt and write a single line in it, ‘hello world’. To open the file and print the text, use:\nwith open('text_example.txt') as f:\n    text_in = f.read()\n\nprint(text_in)\n'hello world!\\n'\n\\n is the new line character. Now let’s try adding a line to the file:\nwith open('text_example.txt', 'a') as f:\n    f.write('this is another line\\n')\nWriting and reading files using the with command is a quick and convenient shorthand for the less concise open, action, close pattern. For example, the above example can also be written as:\nf = open('text_example.txt', 'a')\nf.write('this is another line\\n')\nf.close()\nAlthough this short example shows opening and writing a text file, this approach can be used to edit a wide range of file extensions including .json, .xml, .csv, .tsv, and many more, including binary files in addition to plain text files."
  },
  {
    "objectID": "homework/Lecture1-code-basics.html",
    "href": "homework/Lecture1-code-basics.html",
    "title": "",
    "section": "",
    "text": "(code-basics)= # Coding Basics\nIn this chapter, you’ll learn about the basics of objects, types, operations, conditions, loops, functions, and imports. These are the basic building blocks of almost all programming languages and will serve you well for your coding and economics journey.\nThis chapter has benefited from the excellent Python Programming for Data Science book by Tomas Beuzen."
  },
  {
    "objectID": "homework/Lecture1-code-basics.html#if-you-get-stuck",
    "href": "homework/Lecture1-code-basics.html#if-you-get-stuck",
    "title": "",
    "section": "If you get stuck",
    "text": "If you get stuck\nIt’s worth saying at the outset that no-one memorises half of the stuff you’ll see in this book. 80% or more of time spent programming is actually time spent looking up how to do this or that online, ‘debugging’ a code for errors, or testing code. This applies to all programmers, regardless of level. You are here to learn the skills and concepts of programming, not the precise syntax (which is easy to look up later).\n\n\n\nxkcd-what-did-you-see\n\n\nKnowing how to Google is one of the most important skills of any coder. No-one remembers every function from every library. Here are some useful coding resources:\n\nwhen you have an error, look on Stack Overflow to see if anyone else had the same error (they probably did) and how they overcame it.\nif you’re having trouble navigating a new package or library, look up the documentation online. The best libraries put as much effort into documentation as they do the code base.\nuse cheat sheets to get on top of a range of functionality quickly. For instance, this excellent (mostly) base Python Cheat Sheet.\nif you’re having a coding issue, take a walk to think about the problem, or explain your problem to an animal toy on your desk (traditionally a rubber duck, but other animals are available)."
  },
  {
    "objectID": "homework/Lecture1-code-basics.html#coding-basics",
    "href": "homework/Lecture1-code-basics.html#coding-basics",
    "title": "",
    "section": "Coding Basics",
    "text": "Coding Basics\nLet’s review some basics in the interests of getting you up to speed as quickly as possible. You can use Python as a calculator:\n\nprint(1 / 200 * 30)\nprint((59 + 73 + 2) / 3)\n\n0.15\n44.666666666666664\n\n\n\nprint(1 / 200 * 30)\nprint((59 + 73 + 2) / 3)\n\n0.15\n44.666666666666664\n\n\nThe extra package numpy contains many of the additional mathematical operators that you might need. If you don’t already have numpy installed, open up the terminal in Visual Studio Code (go to “Terminal -&gt; New Terminal” and then type pip install numpy into the terminal then hit return). Once you have numpy installed, you can import it and use it like this:\n\nimport numpy as np\n\nprint(np.sin(np.pi / 2))\n\n1.0\n\n\n\nimport numpy as np\n\nprint(np.sin(np.pi / 2))\n\n1.0\n\n\nYou can create new objects with the assignment operator =. You should think of this as copying the value of whatever is on the right-hand side into the variable on the left-hand side.\n\nx = 3 * 4\nprint(x)\n\n12\n\n\n\nx = 3 * 4\nprint(x)\n\n12\n\n\nThere are several structures in Python that capture multiple objects simultaneously but perhaps the most common is the list, which is designated by square brackets.\n\nprimes = [1, 2, 3, 5, 7, 11, 13]\nprint(primes)\n\n[1, 2, 3, 5, 7, 11, 13]\n\n\n\nprimes = [1, 2, 3, 5, 7, 11, 13]\nprint(primes)\n\n[1, 2, 3, 5, 7, 11, 13]\n\n\nAll Python statements where you create objects (known as assignment statements) have the same form:\nobject_name = value\nWhen reading that code, say “object name gets value” in your head."
  },
  {
    "objectID": "homework/Lecture1-code-basics.html#comments",
    "href": "homework/Lecture1-code-basics.html#comments",
    "title": "",
    "section": "Comments",
    "text": "Comments\nPython will ignore any text after #. This allows to you to write comments, text that is ignored by Python but can be read by other humans. We’ll sometimes include comments in examples explaining what’s happening with the code.\nComments can be helpful for briefly describing what the subsequent code does.\n\n# define primes\nprimes = [1, 2, 3, 5, 7, 11, 13]\n# multiply primes by 2\n[el * 2 for el in primes]\n\n[2, 4, 6, 10, 14, 22, 26]\n\n\n\n# define primes\nprimes = [1, 2, 3, 5, 7, 11, 13]\n# multiply primes by 2\n[el * 2 for el in primes]\n\n[2, 4, 6, 10, 14, 22, 26]\n\n\nWith short pieces of code like this, it is not necessary to leave a command for every single line of code and you should try to use informative names wherever you can because these help readers of your code (likely to be you in the future) understand what is going on!"
  },
  {
    "objectID": "homework/Lecture1-code-basics.html#keeping-track-of-variables",
    "href": "homework/Lecture1-code-basics.html#keeping-track-of-variables",
    "title": "",
    "section": "Keeping Track of Variables",
    "text": "Keeping Track of Variables\nYou can always inspect an already-created object by typing its name into the interactive window:\n\nprimes\n\n[1, 2, 3, 5, 7, 11, 13]\n\n\n\nprimes\n\n[1, 2, 3, 5, 7, 11, 13]\n\n\nIf you want to know what type of object it is, use type(object) in the interactive window like this:\n\ntype(primes)\n\nlist\n\n\n\ntype(primes)\n\nlist\n\n\nVisual Studio Code has some powerful features to help you keep track of objects:\n\nAt the top of your interactive window, you should see a ‘Variables’ button. Click it to see a panel appear with all variables that you’ve defined.\nHover your mouse over variables you’ve previously entered into the interactive window; you will see a pop-up that tells you what type of object it is.\nIf you start typing a variable name into the interactive window, Visual Studio Code will try to auto-complete the name for you. Press the ‘tab’ key on your keyboard to accept the top option."
  },
  {
    "objectID": "homework/Lecture1-code-basics.html#calling-functions",
    "href": "homework/Lecture1-code-basics.html#calling-functions",
    "title": "",
    "section": "Calling Functions",
    "text": "Calling Functions\nIf you’re an economist, you hardly need to be told you what a function is. In coding, it’s much the same as in mathematics: a function has inputs, it performs its function, and it returns any outputs. Python has a large number of built-in functions. You can also import functions from packages (like we did with np.sin) or define your own.\nIn coding, a function has inputs, it performs its function, and it returns any outputs. Let’s see a simple example of using a built-in function, sum():\n\nsum(primes)\n\n42\n\n\n\nsum(primes)\n\n42\n\n\nThe general structure of functions is the function name, followed by brackets, followed by one or more arguments. Sometimes there will also be keyword arguments. For example, sum() comes with a keyword argument that tells the function to start counting from a specific number. Let’s see this in action by starting from ten:\n\nsum(primes, start=10)\n\n52\n\n\n\nsum(primes, start=10)\n\n52\n\n\nIf you’re ever unsure of what a function does, you can call help() on it (itself a function):\n\nhelp(sum)\n\nHelp on built-in function sum in module builtins:\n\nsum(iterable, /, start=0)\n    Return the sum of a 'start' value (default: 0) plus an iterable of numbers\n\n    When the iterable is empty, return the start value.\n    This function is intended specifically for use with numeric values and may\n    reject non-numeric types.\n\n\n\n\nhelp(sum)\n\nHelp on built-in function sum in module builtins:\n\nsum(iterable, /, start=0)\n    Return the sum of a 'start' value (default: 0) plus an iterable of numbers\n\n    When the iterable is empty, return the start value.\n    This function is intended specifically for use with numeric values and may\n    reject non-numeric types.\n\n\n\nOr, in Visual Studio Code, hover your mouse over the function name.\n````euxgwonykhkn Exercise\nWhy does this code not work?\nmy_variable = 10\nmy_varıable\nLook carefully! This may seem like an exercise in pointlessness, but training your brain to notice even the tiniest difference will pay off when programming.\n\n## Values, variables, and types\n\nA value is datum such as a number or text. There are different types of values: 352.3 is known as a float or double, 22 is an integer, and \"Hello World!\" is a string. A variable is a name that refers to a value: you can think of a variable as a box that has a value, or multiple values, packed inside it. \n\nAlmost any word can be a variable name as long as it starts with a letter or an underscore, although there are some special keywords that can't be used because they already have a role in the Python language: these include `if`, `while`, `class`, and `lambda`.\n\nCreating a variable in Python is achieved via an assignment (putting a value in the box), and this assignment is done via the `=` operator. The box, or variable, goes on the left while the value we wish to store appears on the right. It's simpler than it sounds:\n\n::: {#209ef434 .cell execution_count=136}\n``` {.python .cell-code}\na = 10\nprint(a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n10\n```\n:::\n:::\n\n\n::: {#9fb86f40 .cell execution_count=137}\n``` {.python .cell-code}\na = 10\nprint(a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n10\n```\n:::\n:::\n\n\nThis creates a variable `a`, assigns the value 10 to it, and prints it. Sometimes you will hear variables referred to as *objects*. Everything that is not a literal value, such as `10`, is an object. In the above example, `a` is an object that has been assigned the value `10`.\n\nHow about this:\n\n::: {#63c32d9b .cell execution_count=138}\n``` {.python .cell-code}\nb = \"This is a string\"\nprint(b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a string\n```\n:::\n:::\n\n\n::: {#3ae64a36 .cell execution_count=139}\n``` {.python .cell-code}\nb = \"This is a string\"\nprint(b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a string\n```\n:::\n:::\n\n\nIt's the same thing but with a different **type** of data, a string instead of an integer. Python is *dynamically typed*, which means it will guess what type of variable you're creating as you create it. This has pros and cons, with the main pro being that it makes for more concise code.\n\n```{admonition} Important\nEverything is an object, and every object has a type.\n```\n\nThe most basic built-in data types that you'll need to know about are: integers `10`, floats `1.23`, strings `like this`, booleans `True`, and nothing `None`. Python also has a built-in type called a list `[10, 15, 20]` that can contain anything, even *different* types. So\n\n::: {#ad23883a .cell execution_count=140}\n``` {.python .cell-code}\nlist_example = [10, 1.23, \"like this\", True, None]\nprint(list_example)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[10, 1.23, 'like this', True, None]\n```\n:::\n:::\n\n\n::: {#0bdc4bf2 .cell execution_count=141}\n``` {.python .cell-code}\nlist_example = [10, 1.23, \"like this\", True, None]\nprint(list_example)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[10, 1.23, 'like this', True, None]\n```\n:::\n:::\n\n\nis completely valid code. `None` is a special type of nothingness, and represents an object with no value. It has type `NoneType` and is more useful than you might think! \n\nAs well as the built-in types, packages can define their own custom types. If you ever want to check the type of a Python variable, you can call the `type()` function on it like so:\n\n::: {#46a517ee .cell execution_count=142}\n``` {.python .cell-code}\ntype(list_example)\n```\n\n::: {.cell-output .cell-output-display execution_count=142}\n```\nlist\n```\n:::\n:::\n\n\nThis is especially useful for debugging `ValueError` messages.\n\nBelow is a table of common data types in Python:\n\n| Name          | Type name  | Type Category  | Description                                   | Example                                    |\n| :-------------------- | :--------- | :------------- | :-------------------------------------------- | :----------------------------------------- |\n| integer               | `int`      | Numeric Type   | positive/negative whole numbers               | `22`                                       |\n| floating point number | `float`    | Numeric Type   | real number in decimal form                   | `3.14159`                                  |\n| boolean               | `bool`     | Boolean Values | true or false                                 | `True`                                     |\n| string                | `str`      | Sequence Type  | text                                          | `\"Hello World!\"`                 |\n| list                  | `list`     | Sequence Type  | a collection of objects - mutable & ordered   | `['text entry', True, 16]`               |\n| tuple                 | `tuple`    | Sequence Type  | a collection of objects - immutable & ordered | `(51.02, -0.98)`                 |\n| dictionary            | `dict`     | Mapping Type   | mapping of key-value pairs                    | `{'name':'Ada', 'subject':'computer science'}` |\n| none                  | `NoneType` | Null Object    | represents no value                           | `None`                                     |\n| function                  | `function` | Function   | Represents a function                           | `def add_one(x): return x+1`                                     |\n\n````{admonition} Exercise\nWhat type is this Python object?\n\n```python\ncities_to_temps = {\"Paris\": 32, \"London\": 22, \"Seville\": 36, \"Wellesley\": 29}\n```\n\nWhat type is the first key (hint: comma separated entries form key-value pairs)?\n\nBrackets\nYou may notice that there are several kinds of brackets that appear in the code we’ve seen so far, including [], {}, and (). These can play different roles depending on the context, but the most common uses are:\n\n[] is used to denote a list, eg ['a', 'b'], or to signify accessing a position using an index, eg vector[0] to get the first entry of a variable called vector.\n{} is used to denote a set, eg {'a', 'b'}, or a dictionary (with pairs of terms), eg {'first_letter': 'a', 'second_letter': 'b'}.\n() is used to denote a tuple, eg ('a', 'b'), or the arguments to a function, eg function(x) where x is the input passed to the function, or to indicate the order operations are carried out."
  },
  {
    "objectID": "homework/Lecture1-code-basics.html#lists-and-slicing",
    "href": "homework/Lecture1-code-basics.html#lists-and-slicing",
    "title": "",
    "section": "Lists and slicing",
    "text": "Lists and slicing\nLists are a really useful way to work with lots of data at once. They’re defined with square brackets, with entries separated by commas. You can also construct them by appending entries:\n\nlist_example.append(\"one more entry\")\nprint(list_example)\n\n[10, 1.23, 'like this', True, None, 'one more entry']\n\n\n\nlist_example.append(\"one more entry\")\nprint(list_example)\n\n[10, 1.23, 'like this', True, None, 'one more entry', 'one more entry']\n\n\nAnd you can access earlier entries using an index, which begins at 0 and ends at one less than the length of the list (this is the convention in many programming languages). For instance, to print specific entries at the start, using 0, and end, using -1:\n\nprint(list_example[0])\nprint(list_example[-1])\n\n10\none more entry\n\n\n\nprint(list_example[0])\nprint(list_example[-1])\n\n10\none more entry\n\n\neuxgwonykhkn Exercise How might you access the penultimate entry in a list object if you didn't know how many elements it had?\nAs well as accessing positions in lists using indexing, you can use slices on lists. This uses the colon character, :, to stand in for ‘from the beginning’ or ‘until the end’ (when only appearing once). For instance, to print just the last two entries, we would use the index -2: to mean from the second-to-last onwards. Here are two distinct examples: getting the first three and last three entries to be successively printed:\n\nprint(list_example[:3])\nprint(list_example[-3:])\n\n[10, 1.23, 'like this']\n[None, 'one more entry', 'one more entry']\n\n\nSlicing can be even more elaborate than that because we can jump entries using a second colon. Here’s a full example that begins at the second entry (remember the index starts at 0), runs up until the second-to-last entry (exclusive), and jumps every other entry inbetween (range just produces a list of integers from the value to one less than the last):\n\nlist_of_numbers = list(range(1, 11))\nstart = 1\nstop = -1\nstep = 2\nprint(list_of_numbers[start:stop:step])\n\n[2, 4, 6, 8]\n\n\n\nlist_of_numbers = list(range(1, 11))\nstart = 1\nstop = -1\nstep = 2\nprint(list_of_numbers[start:stop:step])\n\n[2, 4, 6, 8]\n\n\nA handy trick is that you can print a reversed list entirely using double colons:\n\nprint(list_of_numbers[::-1])\n\n[10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n\n\n\nprint(list_of_numbers[::-1])\n\n[10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n\n\neuxgwonykhkn Exercise Slice the `list_example` from earlier to get only the first five entries.\nAs noted, lists can hold any type, including other lists! Here’s a valid example of a list that’s got a lot going on:\n\nwacky_list = [\n    3.1415,\n    16,\n    [\"five\", 4, 3],\n    (91, 93, 90),\n    \"Hello World!\",\n    True,\n    None,\n    {\"key\": \"value\", \"key2\": \"value2\"},\n]\nwacky_list\n\n[3.1415,\n 16,\n ['five', 4, 3],\n (91, 93, 90),\n 'Hello World!',\n True,\n None,\n {'key': 'value', 'key2': 'value2'}]\n\n\n\nwacky_list = [\n    3.1415,\n    16,\n    [\"five\", 4, 3],\n    (91, 93, 90),\n    \"Hello World!\",\n    True,\n    None,\n    {\"key\": \"value\", \"key2\": \"value2\"},\n]\nwacky_list\n\n[3.1415,\n 16,\n ['five', 4, 3],\n (91, 93, 90),\n 'Hello World!',\n True,\n None,\n {'key': 'value', 'key2': 'value2'}]\n\n\nIn reality, it’s usually not a good idea to mix data types in a list, but Python is very flexible. Other iterables (objects composed of multiple elements, of which the list is just one in Python) can also store objects of different types.\neuxgwonykhkn Exercise Can you identify the types of each of the entries in `wacky_list`?"
  },
  {
    "objectID": "homework/Lecture1-code-basics.html#operators",
    "href": "homework/Lecture1-code-basics.html#operators",
    "title": "",
    "section": "Operators",
    "text": "Operators\nAll of the basic operators you see in mathematics are available to use: + for addition, - for subtraction, * for multiplication, ** for powers, / for division, and % for modulo. These work as you’d expect on numbers. But these operators are sometimes defined for other built-in data types too. For instance, we can ‘sum’ strings (which really concatenates them):\n\nstring_one = \"This is an example \"\nstring_two = \"of string concatenation\"\nstring_full = string_one + string_two\nprint(string_full)\n\nThis is an example of string concatenation\n\n\n\nstring_one = \"This is an example \"\nstring_two = \"of string concatenation\"\nstring_full = string_one + string_two\nprint(string_full)\n\nThis is an example of string concatenation\n\n\nIt works for lists too:\n\nlist_one = [\"apples\", \"oranges\"]\nlist_two = [\"pears\", \"satsumas\"]\nlist_full = list_one + list_two\nprint(list_full)\n\n['apples', 'oranges', 'pears', 'satsumas']\n\n\n\nlist_one = [\"apples\", \"oranges\"]\nlist_two = [\"pears\", \"satsumas\"]\nlist_full = list_one + list_two\nprint(list_full)\n\n['apples', 'oranges', 'pears', 'satsumas']\n\n\nPerhaps more surprisingly, you can multiply strings!\n\nstring = \"apples, \"\nprint(string * 3)\n\napples, apples, apples, \n\n\n\nstring = \"apples, \"\nprint(string * 3)\n\napples, apples, apples, \n\n\nBelow is a table of the basic arithmetic operations.\n\n\n\nOperator\nDescription\n\n\n\n\n+\naddition\n\n\n-\nsubtraction\n\n\n*\nmultiplication\n\n\n/\ndivision\n\n\n**\nexponentiation\n\n\n//\ninteger division / floor division\n\n\n%\nmodulo\n\n\n@\nmatrix multiplication\n\n\n\nAs well as the usual operators, Python supports assignment operators. An example of one is x+=3, which is equivalent to running x = x + 3. Pretty much all of the operators can be used in this way.\n```euxgwonykhkn Exercise Using Python operations only, what is\n\\[\n\\frac{2^5}{7 \\cdot (4 - 2^3)}\n\\]\n\n## Strings\n\nIn some ways, strings are treated a bit like lists, meaning you can access the individual characters via slicing and indexing. For example:\n\n::: {#4507b65c .cell execution_count=160}\n``` {.python .cell-code}\nstring = \"cheesecake\"\nprint(string[-4:])\n\ncake\n\n:::\n\nstring = \"cheesecake\"\nprint(string[-4:])\n\ncake\n\n\nBoth lists and strings will also allow you to use the len() command to get their length:\n\nstring = \"cheesecake\"\nprint(\"String has length:\")\nprint(len(string))\nlist_of_numbers = range(1, 20)\nprint(\"List of numbers has length:\")\nprint(len(list_of_numbers))\n\nString has length:\n10\nList of numbers has length:\n19\n\n\n\nstring = \"cheesecake\"\nprint(\"String has length:\")\nprint(len(string))\nlist_of_numbers = range(1, 20)\nprint(\"List of numbers has length:\")\nprint(len(list_of_numbers))\n\nString has length:\n10\nList of numbers has length:\n19\n\n\neuxgwonykhkn Exercise What is the `len` of a list created by `range(n)` where `n` could be any integer?\nStrings have type string and can be defined by single or double quotes, eg string = \"cheesecake\" would have been equally valid above. It’s best practice to use one convention and stick to it, and most people use double quotes for strings.\nThere are various functions built into Python to help you work with strings that are particularly useful for cleaning messy data. For example, imagine you have a variable name like ‘This Is /A Variable’. (You may think this is implausibly bad; if only that were true…). Let’s see if we can clean this up:\n\nstring = \"This Is /A Variable   \"\nstring = string.replace(\"/\", \"\").rstrip().lower()\nprint(string)\n\nthis is a variable\n\n\n\nstring = \"This Is /A Variable   \"\nstring = string.replace(\"/\", \"\").rstrip().lower()\nprint(string)\n\nthis is a variable\n\n\nThe steps above replace the character ‘/’, strip out whitespace on the right hand-side of the string, and put everything in lower case. The brackets after the words signify that a function has been applied; we’ll see more of functions later.\neuxgwonykhkn Exercise Using string operations, strip the leading and trailing spaces, make upper case, and remove the underscores from the string `\"    this_is_a_better_variable_name   \"`.\nChanging Type to String\nWe’ll look at this in more detail shortly, but while we’re on strings, it seems useful to mention it now: you’ll often want to output one type of data as another, and Python generally knows what you’re trying to achieve if you, for example, print() a boolean value. For numbers, there are more options and you can see a big list of advice on string formatting of all kinds of things here. For now, let’s just see a simple example of something called an f-string, a string that combines a number and a string (these begin with an f for formatting):\n\nvalue = 20\nsqrt_val = 20 ** 0.5\nprint(f\"The square root of {value:d} is {sqrt_val:.2f}\")\n\nThe square root of 20 is 4.47\n\n\n\nvalue = 20\nsqrt_val = 20 ** 0.5\nprint(f\"The square root of {value:d} is {sqrt_val:.2f}\")\n\nThe square root of 20 is 4.47\n\n\nThe formatting command :d is an instruction to treat value like an integer, while :.2f is an instruction to print it like a float with 2 decimal places.\nf-strings are only available in Python 3.6+\neuxgwonykhkn Exercise Write a print command with the `sqrt_val` expressed to 3 decimal places."
  },
  {
    "objectID": "homework/Lecture1-code-basics.html#booleans-and-conditions",
    "href": "homework/Lecture1-code-basics.html#booleans-and-conditions",
    "title": "",
    "section": "Booleans and conditions",
    "text": "Booleans and conditions\nSome of the most important operations you will perform are with True and False values, also known as boolean data types. There are two types of operation that are associated with booleans: boolean operations, in which existing booleans are combined, and condition operations, which create a boolean when executed.\nBoolean operators that return booleans are as follows:\n\n\n\nOperator\nDescription\n\n\n\n\nx and y\nare x and y both True?\n\n\nx or y\nis at least one of x and y True?\n\n\nnot x\nis x False?\n\n\n\nThese behave as you’d expect: True and False evaluates to False, while True or False evaluates to True. There’s also the not keyword. For example\n\nnot True\n\nFalse\n\n\n\nnot True\n\nFalse\n\n\nas you would expect.\nConditions are expressions that evaluate as booleans. A simple example is 10 == 20. The == is an operator that compares the objects on either side and returns True if they have the same values–though be careful using it with different data types.\nHere’s a table of conditions that return booleans:\n\n\n\nOperator\nDescription\n\n\n\n\nx == y\nis x equal to y?\n\n\nx != y\nis x not equal to y?\n\n\nx &gt; y\nis x greater than y?\n\n\nx &gt;= y\nis x greater than or equal to y?\n\n\nx &lt; y\nis x less than y?\n\n\nx &lt;= y\nis x less than or equal to y?\n\n\nx is y\nis x the same object as y?\n\n\n\nAs you can see from the table, the opposite of == is !=, which you can read as ‘not equal to the value of’. Here’s an example of ==:\n\nboolean_condition = 10 == 20\nprint(boolean_condition)\n\nFalse\n\n\n\nboolean_condition = 10 == 20\nprint(boolean_condition)\n\nFalse\n\n\neuxgwonykhkn Exercise What does `not (not True)` evaluate to?\nThe real power of conditions comes when we start to use them in more complex examples. Some of the keywords that evaluate conditions are if, else, and, or, in, not, and is. Here’s an example showing how some of these conditional keywords work:\n\nname = \"Ada\"\nscore = 99\n\nif name == \"Ada\" and score &gt; 90:\n    print(\"Ada, you achieved a high score.\")\n\nif name == \"Smith\" or score &gt; 90:\n    print(\"You could be called Smith or have a high score\")\n\nif name != \"Smith\" and score &gt; 90:\n    print(\"You are not called Smith and you have a high score\")\n\nAda, you achieved a high score.\nYou could be called Smith or have a high score\nYou are not called Smith and you have a high score\n\n\n\nname = \"Ada\"\nscore = 99\n\nif name == \"Ada\" and score &gt; 90:\n    print(\"Ada, you achieved a high score.\")\n\nif name == \"Smith\" or score &gt; 90:\n    print(\"You could be called Smith or have a high score\")\n\nif name != \"Smith\" and score &gt; 90:\n    print(\"You are not called Smith and you have a high score\")\n\nAda, you achieved a high score.\nYou could be called Smith or have a high score\nYou are not called Smith and you have a high score\n\n\nAll three of these conditions evaluate as True, and so all three messages get printed. Given that == and != test for equality and not equal, respectively, you may be wondering what the keywords is and not are for. Remember that everything in Python is an object, and that values can be assigned to objects. == and != compare values, while is and not compare objects. For example,\n\nname_list = [\"Ada\", \"Adam\"]\nname_list_two = [\"Ada\", \"Adam\"]\n\n# Compare values\nprint(name_list == name_list_two)\n\n# Compare objects\nprint(name_list is name_list_two)\n\nTrue\nFalse\n\n\n\nname_list = [\"Ada\", \"Adam\"]\nname_list_two = [\"Ada\", \"Adam\"]\n\n# Compare values\nprint(name_list == name_list_two)\n\n# Compare objects\nprint(name_list is name_list_two)\n\nTrue\nFalse\n\n\nNote that code with lots of branching if statements is not very helpful to you or to anyone else who reads your code. Some automatic code checkers will pick this up and tell you that your code is too complex. Almost all of the time, there’s a way to rewrite your code without lots of branching logic that will be better and clearer than having many nested if statements.\nOne of the most useful conditional keywords is in. This one must pop up ten times a day in most coders’ lives because it can pick out a variable or make sure something is where it’s supposed to be.\n\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nprint(\"Lovelace\" in name_list)\n\nprint(\"Bob\" in name_list)\n\nTrue\nFalse\n\n\n\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nprint(\"Lovelace\" in name_list)\n\nprint(\"Bob\" in name_list)\n\nTrue\nFalse\n\n\neuxgwonykhkn Exercise Check if \"a\" is in the string \"Walloping weasels\" using `in`. Is \"a\" `in` \"Anodyne\"?\nThe opposite is not in.\nFinally, one conditional construct you’re bound to use at some point, is the if…else structure:\n\nscore = 98\n\nif score == 100:\n    print(\"Top marks!\")\nelif score &gt; 90 and score &lt; 100:\n    print(\"High score!\")\nelif score &gt; 10 and score &lt;= 90:\n    pass\nelse:\n    print(\"Better luck next time.\")\n\nHigh score!\n\n\n\nscore = 98\n\nif score == 100:\n    print(\"Top marks!\")\nelif score &gt; 90 and score &lt; 100:\n    print(\"High score!\")\nelif score &gt; 10 and score &lt;= 90:\n    pass\nelse:\n    print(\"Better luck next time.\")\n\nHigh score!\n\n\nNote that this does nothing if the score is between 11 and 90, and prints a message otherwise.\neuxgwonykhkn Exercise Create a new `if` ... `elif` ... `else` statement that prints \"well done\" if a score is over 90, \"good\" if between 40 and 90, and \"bad luck\" otherwise.\nOne nice feature of Python is that you can make multiple boolean comparisons in a single line.\n\na, b = 3, 6\n\n1 &lt; a &lt; b &lt; 20\n\nTrue\n\n\n\na, b = 3, 6\n\n1 &lt; a &lt; b &lt; 20\n\nTrue"
  },
  {
    "objectID": "homework/Lecture1-code-basics.html#indentation",
    "href": "homework/Lecture1-code-basics.html#indentation",
    "title": "",
    "section": "Indentation",
    "text": "Indentation\nYou’ll have seen that certain parts of the code examples are indented. Code that is part of a function, a conditional clause, or loop is indented. This isn’t a code style choice, it’s actually what tells the language that some code is to be executed as part of, say, a loop and not to executed after the loop is finished.\nHere’s a basic example of indentation as part of an if loop. The print() statement that is indented only executes if the condition evaluates to true.\n\nx = 10\n\nif x &gt; 2:\n    print(\"x is greater than 2\")\n\nx is greater than 2\n\n\n\nx = 10\n\nif x &gt; 2:\n    print(\"x is greater than 2\")\n\nx is greater than 2\n\n\nThe VS Code extension *indent-rainbow* colours different levels of indentation differently for ease of reading.\nWhen functions, conditional clauses, or loops are combined together, they each cause an increase in the level of indentation. Here’s a double indent.\n\nif x &gt; 2:\n    print(\"outer conditional cause\")\n    for i in range(4):\n        print(\"inner loop\")\n\nouter conditional cause\ninner loop\ninner loop\ninner loop\ninner loop\n\n\n\nif x &gt; 2:\n    print(\"outer conditional cause\")\n    for i in range(4):\n        print(\"inner loop\")\n\nouter conditional cause\ninner loop\ninner loop\ninner loop\ninner loop\n\n\nThe standard practice for indentation is that each sub-statement should be indented by 4 spaces. It can be hard to keep track of these but, as usual, Visual Studio Code has you covered. Go to Settings (the cog in the bottom left-hand corner, then click Settings) and type ‘Whitespace’ into the search bar. Under ‘Editor: Render Whitespace’, select ‘boundary’. This will show any whitespace that is more than one character long using faint grey dots. Each level of indentation in your Python code should now begin with four grey dots showing that it consists of four spaces.\nRendering whitespace using Visual Studio Code's settings makes it easier to navigate different levels of indentation.\neuxgwonykhkn Exercise Try writing a code snippet that reaches the triple level of indentation."
  },
  {
    "objectID": "homework/Lecture1-code-basics.html#dictionaries",
    "href": "homework/Lecture1-code-basics.html#dictionaries",
    "title": "",
    "section": "Dictionaries",
    "text": "Dictionaries\nAnother built-in Python type that is enormously useful is the dictionary. This provides a mapping one set of variables to another (either one-to-one or many-to-one). Let’s see an example of defining a dictionary and using it:\n\nfruit_dict = {\n    \"Jazz\": \"Apple\",\n    \"Owari\": \"Satsuma\",\n    \"Seto\": \"Satsuma\",\n    \"Pink Lady\": \"Apple\",\n}\n\n# Add an entry\nfruit_dict.update({\"Cox\": \"Apple\"})\n\nvariety_list = [\"Jazz\", \"Jazz\", \"Seto\", \"Cox\"]\n\nfruit_list = [fruit_dict[x] for x in variety_list]\nprint(fruit_list)\n\n['Apple', 'Apple', 'Satsuma', 'Apple']\n\n\n\nfruit_dict = {\n    \"Jazz\": \"Apple\",\n    \"Owari\": \"Satsuma\",\n    \"Seto\": \"Satsuma\",\n    \"Pink Lady\": \"Apple\",\n}\n\n# Add an entry\nfruit_dict.update({\"Cox\": \"Apple\"})\n\nvariety_list = [\"Jazz\", \"Jazz\", \"Seto\", \"Cox\"]\n\nfruit_list = [fruit_dict[x] for x in variety_list]\nprint(fruit_list)\n\n['Apple', 'Apple', 'Satsuma', 'Apple']\n\n\nFrom an input list of varieties, we get an output list of their associated fruits. Another good trick to know with dictionaries is that you can iterate through their keys and values:\n\nfruit_dict = {\n    \"Jazz\": \"Apple\",\n    \"Owari\": \"Satsuma\",\n    \"Seto\": \"Satsuma\",\n    \"Pink Lady\": \"Apple\",\n}\n\n# Add an entry\nfruit_dict.update({\"Cox\": \"Apple\"})\n\nvariety_list = [\"Jazz\", \"Jazz\", \"Seto\", \"Cox\"]\n\nfruit_list = [fruit_dict[x] for x in variety_list]\nprint(fruit_list)\n\nJazz maps into Apple\nOwari maps into Satsuma\nSeto maps into Satsuma\nPink Lady maps into Apple\nCox maps into Apple\n\n\neuxgwonykhkn Exercise Update the fruit dictionary with another two entries and then iterate through all of the entries printing each mapping using `.items()` as above."
  },
  {
    "objectID": "homework/Lecture1-code-basics.html#loops-and-list-comprehensions",
    "href": "homework/Lecture1-code-basics.html#loops-and-list-comprehensions",
    "title": "",
    "section": "Loops and list comprehensions",
    "text": "Loops and list comprehensions\nA loop is a way of executing a similar piece of code over and over in a similar way. The most useful loops are for loops and list comprehensions.\nA for loop does something for the time that the condition is satisfied. For example,\n\nname_list = [\"Lovelace\", \"Smith\", \"Pigou\", \"Babbage\"]\n\nfor name in name_list:\n    print(name)\n\nLovelace\nSmith\nPigou\nBabbage\n\n\n\nname_list = [\"Lovelace\", \"Smith\", \"Pigou\", \"Babbage\"]\n\nfor name in name_list:\n    print(name)\n\nLovelace\nSmith\nPigou\nBabbage\n\n\nprints out a name until all names have been printed out. Note the colon after the statement and before the indent.\nAs long as your object is an iterable (ie you can iterate over it), then it can be used in this way in a for loop. The most common examples are lists and tuples, but you can also iterate over strings (in which case each character is selected in turn). One gotcha to be aware of is if you iterate over a string, say “hello”, instead of iterating over a list (or tuple) of strings, eg [\"hello\"]. In the latter case, you get:\n\nfor entry in [\"hello\"]:\n    print(entry)\n    print(\"---end entry---\")\n\nhello\n---end entry---\n\n\n\nfor entry in [\"hello\"]:\n    print(entry)\n    print(\"---end entry---\")\n\nhello\n---end entry---\n\n\nWhile in the former you get something quite different and typically not all that useful:\n\nfor entry in \"hello\":\n    print(entry)\n    print(\"---end entry---\")\n\nh\n---end entry---\ne\n---end entry---\nl\n---end entry---\nl\n---end entry---\no\n---end entry---\n\n\n\nfor entry in \"hello\":\n    print(entry)\n    print(\"---end entry---\")\n\nh\n---end entry---\ne\n---end entry---\nl\n---end entry---\nl\n---end entry---\no\n---end entry---\n\n\neuxgwonykhkn Exercise Write a for loop that prints out \"coding for economists\" so that each word is printed in a successive iteration.\nA useful trick with for loops is the enumerate keyword, which runs through an index that keeps track of the place of items in a list:\n\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nfor i, name in enumerate(name_list):\n    print(f\"The name in position {i} is {name}\")\n\nThe name in position 0 is Lovelace\nThe name in position 1 is Smith\nThe name in position 2 is Hopper\nThe name in position 3 is Babbage\n\n\n\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nfor i, name in enumerate(name_list):\n    print(f\"The name in position {i} is {name}\")\n\nThe name in position 0 is Lovelace\nThe name in position 1 is Smith\nThe name in position 2 is Hopper\nThe name in position 3 is Babbage\n\n\nRemember, Python indexes from 0 so the first entry of i will be zero. But, if you’d like to index from a different number, you can:\n\nfor i, name in enumerate(name_list, start=1):\n    print(f\"The name in position {i} is {name}\")\n\nThe name in position 1 is Lovelace\nThe name in position 2 is Smith\nThe name in position 3 is Hopper\nThe name in position 4 is Babbage\n\n\n\nfor i, name in enumerate(name_list, start=1):\n    print(f\"The name in position {i} is {name}\")\n\nThe name in position 1 is Lovelace\nThe name in position 2 is Smith\nThe name in position 3 is Hopper\nThe name in position 4 is Babbage\n\n\nAnother useful pattern when doing for loops with dictionaries is iteration over key, value pairs. As we saw earlier, what distinguishes a dictionary in Python is that it maps a key to a value, for example “apple” might map to “fruit”. Let’s take our example from earlier that mapped cities to temperatures. If we wanted to iterate over both keys and values, we can write a for loop like this:\n\ncities_to_temps = {\"Paris\": 28, \"London\": 22, \"Seville\": 36, \"Wellesley\": 29}\n\nfor key, value in cities_to_temps.items():\n    print(f\"In {key}, the temperature is {value} degrees C today.\")\n\nIn Paris, the temperature is 28 degrees C today.\nIn London, the temperature is 22 degrees C today.\nIn Seville, the temperature is 36 degrees C today.\nIn Wellesley, the temperature is 29 degrees C today.\n\n\n\ncities_to_temps = {\"Paris\": 28, \"London\": 22, \"Seville\": 36, \"Wellesley\": 29}\n\nfor key, value in cities_to_temps.items():\n    print(f\"In {key}, the temperature is {value} degrees C today.\")\n\nIn Paris, the temperature is 28 degrees C today.\nIn London, the temperature is 22 degrees C today.\nIn Seville, the temperature is 36 degrees C today.\nIn Wellesley, the temperature is 29 degrees C today.\n\n\nNote that we added .items() to the end of the dictionary. And note that we didn’t have to call the key key, or the value value: these are set by their position. But part of best practice in writing code is that there should be no surprises, and writing key, value makes it really clear that you’re using values from a dictionary.\neuxgwonykhkn Exercise Write a dictionary that maps four cities you know into their respective countries and print the results using the `key, value` iteration trick.\nAnother useful type of for loop is provided by the zip() function. You can think of the zip() function as being like a zipper, bringing elements from two different iterators together in turn. Here’s an example:\n\nfirst_names = [\"Ada\", \"Adam\", \"Grace\", \"Charles\"]\nlast_names = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nfor forename, surname in zip(first_names, last_names):\n    print(f\"{forename} {surname}\")\n\nAda Lovelace\nAdam Smith\nGrace Hopper\nCharles Babbage\n\n\n\nfirst_names = [\"Ada\", \"Adam\", \"Grace\", \"Charles\"]\nlast_names = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nfor forename, surname in zip(first_names, last_names):\n    print(f\"{forename} {surname}\")\n\nAda Lovelace\nAdam Smith\nGrace Hopper\nCharles Babbage\n\n\nThe zip function is super useful in practice.\n``euxgwonykhkn Exercise Zip together the first names from above with this jumbled list of surnames:[‘Babbage’, ‘Hopper’, ‘Smith’, ‘Lovelace’]`.\n(Hint: you have seen a trick to help re-arrange lists earlier on in the Chapter.)\n\n**List (and Other) Comprehensions**\n\nThere's a second way to do loops in Python and, in most but [not all](https://towardsdatascience.com/list-comprehensions-vs-for-loops-it-is-not-what-you-think-34071d4d8207) [cases](https://stackoverflow.com/questions/22108488/are-list-comprehensions-and-functional-functions-faster-than-for-loops), they run faster. More importantly, and *this* is the reason it's good practice to use them where possible, they are very readable. They are called *list comprehensions*.\n\nList comprehensions can combine what a `for` loop and (if needed) what a `condition` do in a single line of code. First, let's look at a `for` loop that adds one to each value done as a list comprehension (NB: in practice, we would use super-fast **numpy** arrays for this kind of operation):\n\n::: {#50814e5f .cell execution_count=202}\n``` {.python .cell-code}\nnum_list = range(50, 60)\n[1 + num for num in num_list]\n\n[51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n\n:::\n\nnum_list = range(50, 60)\n[1 + num for num in num_list]\n\n[51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n\n\nThe general pattern is a bit similar to with the for loop but there are some differences. There’s no colon, and no indenting. The syntax is “do something with x” then for x in iterable. Finally, the expression is wrapped in a [ and ] to make the output a list.\nNote that lists are not the only wrapping you can provide to this kind of structure. A ( and ) to make it a generator (don’t worry about what this is for now), a { and } to make it a set (an object that only contains unique values), or it’s possible to create a dictionary from a comprehension too! List comprehensions are the most common, so if you only remember one kind, remember them.\n```euxgwonykhkn Exercise Create a list comprehension that multiplies numbers in the range from 1 to 10 by 5.\nDid you get the range right?\n\nLet's now see how to include a condition within a list comprehension. Say we had a list of numbers and wanted to filter it according to whether the numbers divided by 3 or not using the modulo operator:\n\n::: {#4fafa2be .cell execution_count=204}\n``` {.python .cell-code}\nnumber_list = range(1, 40)\ndivide_list = [x for x in number_list if x % 3 == 0]\nprint(divide_list)\n\n[3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39]\n\n:::\n\nnumber_list = range(1, 40)\ndivide_list = [x for x in number_list if x % 3 == 0]\nprint(divide_list)\n\n[3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39]\n\n\nThe syntax here is do something to x for x in something if x satisfies some condition.\nHere’s another example that picks out only the names that include ‘Smith’ in them:\n\nnames_list = [\"Joe Bloggs\", \"Adam Smith\", \"Sandra Noone\", \"leonara smith\"]\nsmith_list = [x for x in names_list if \"smith\" in x.lower()]\nprint(smith_list)\n\n['Adam Smith', 'leonara smith']\n\n\n\nnames_list = [\"Joe Bloggs\", \"Adam Smith\", \"Sandra Noone\", \"leonara smith\"]\nsmith_list = [x for x in names_list if \"smith\" in x.lower()]\nprint(smith_list)\n\n['Adam Smith', 'leonara smith']\n\n\nNote how we used ‘smith’ rather than ‘Smith’ and then used lower() to ensure we matched names regardless of the case they are written in.\nWe can even do a whole if … else construct inside a list comprehension:\n\nnames_list = [\"Joe Bloggs\", \"Adam Smith\", \"Sandra Noone\", \"leonara smith\"]\nsmith_list = [x if \"smith\" in x.lower() else \"Not Smith!\" for x in names_list]\nprint(smith_list)\n\n['Not Smith!', 'Adam Smith', 'Not Smith!', 'leonara smith']\n\n\n\nnames_list = [\"Joe Bloggs\", \"Adam Smith\", \"Sandra Noone\", \"leonara smith\"]\nsmith_list = [x if \"smith\" in x.lower() else \"Not Smith!\" for x in names_list]\nprint(smith_list)\n\n['Not Smith!', 'Adam Smith', 'Not Smith!', 'leonara smith']\n\n\nMany of the constructs we’ve seen can be combined. For instance, there is no reason why we can’t have a nested or repeated list comprehension using zip(), and, perhaps more surprisingly, sometimes these are useful!\n\nfirst_names = [\"Ada\", \"Adam\", \"Grace\", \"Charles\"]\nlast_names = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\nnames_list = [x + \" \" + y for x, y in zip(first_names, last_names)]\nprint(names_list)\n\n['Ada Lovelace', 'Adam Smith', 'Grace Hopper', 'Charles Babbage']\n\n\n\nfirst_names = [\"Ada\", \"Adam\", \"Grace\", \"Charles\"]\nlast_names = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\nnames_list = [x + \" \" + y for x, y in zip(first_names, last_names)]\nprint(names_list)\n\n['Ada Lovelace', 'Adam Smith', 'Grace Hopper', 'Charles Babbage']\n\n\nAn even more extreme use of list comprehensions can deliver nested structures:\n\nfirst_names = [\"Ada\", \"Adam\"]\nlast_names = [\"Lovelace\", \"Smith\"]\nnames_list = [[x + \" \" + y for x in first_names] for y in last_names]\nprint(names_list)\n\n[['Ada Lovelace', 'Adam Lovelace'], ['Ada Smith', 'Adam Smith']]\n\n\n\nfirst_names = [\"Ada\", \"Adam\"]\nlast_names = [\"Lovelace\", \"Smith\"]\nnames_list = [[x + \" \" + y for x in first_names] for y in last_names]\nprint(names_list)\n\n[['Ada Lovelace', 'Adam Lovelace'], ['Ada Smith', 'Adam Smith']]\n\n\nThis gives a nested structure that (in this case) iterates over first_names first, and then last_names. (Note that this object is a list of lists of strings!)\nLet’s see a dictionary comprehension now. These look a bit similar to set comprehensions because they use { and } at either end but they are different because they come with a colon separating the keys from the values:\n\n{key: value for key, value in zip(first_names, last_names)}\n\n{'Ada': 'Lovelace', 'Adam': 'Smith'}\n\n\n\n{key: value for key, value in zip(first_names, last_names)}\n\n{'Ada': 'Lovelace', 'Adam': 'Smith'}\n\n\neuxgwonykhkn Exercise Create a nested list comprehension that results in a list of lists of strings equal to `[['a0', 'b0', 'c0'], ['a1', 'b1', 'c1'], ['a2', 'b2', 'c2']]` (ie a combination of the first three integers and letters of the alphabet). You may find that you need to convert numbers to strings using `str(x)` to do this.\nIf you’d like to learn more about list comprehensions, check out these short video tutorials."
  },
  {
    "objectID": "homework/Lecture1-code-basics.html#writing-functions",
    "href": "homework/Lecture1-code-basics.html#writing-functions",
    "title": "",
    "section": "Writing Functions",
    "text": "Writing Functions\nDeclaring a function starts with a def keyword for ‘define a function’. It then has a name, followed by brackets, (), which may contain function arguments and function keyword arguments. This is followed by a colon. The body of the function is then indented relative to the left-most text. Function arguments are defined in brackets following the name, with different inputs separated by commas. Any outputs are given with the return keyword, again with different variables separated by commas.\n```euxgwonykhkn Arguments and keyword arguments :class: tip\narguments are the variables that functions always need, so a and b in def add(a, b): return a + b. The function won’t work without them! Function arguments are sometimes referred to as args.\nKeyword arguments are the variables that are optional for functions, so c in def add(a, b, c=5): return a + b - c. If you do not provide a value for c when calling the function, it will automatically revert to c=5. Keyword arguments are sometimes referred to as kwargs.\n\nLet's see a very simple example of a function with a single *argument* (or arg):\n\n::: {#0450ad6c .cell execution_count=11}\n``` {.python .cell-code}\ndef welcome_message(name):\n    return f\"Hello {name}, and welcome!\"\n\n\n# Without indentation, this code is not part of function\nname = \"Ada\"\noutput_string = welcome_message(name)\nprint(output_string)\n\nHello Ada, and welcome!\n\n:::\n\ndef welcome_message(name):\n    return f\"Hello {name}, and welcome!\"\n\n\n# Without indentation, this code is not part of function\nname = \"Ada\"\noutput_string = welcome_message(name)\nprint(output_string)\n\nHello Ada, and welcome!\n\n\nOne powerful feature of functions is that we can define defaults for the input arguments. These are called keyword arguments (or kwargs). Let’s see that in action by defining a default value for name, along with multiple outputs–a hello message and a score.\n\ndef score_message(score, name=\"student\"):\n    \"\"\"This is a doc-string, a string describing a function.\n    Args:\n        score (float): Raw score\n        name (str): Name of student\n    Returns:\n        str: A hello message.\n        float: A normalised score.\n    \"\"\"\n    norm_score = (score - 50) / 10\n    return f\"Hello {name}\", norm_score\n\n\n# Without indentation, this code is not part of function\nname = \"Ada\"\nscore = 98\n# No name entered\nprint(score_message(score))\n# Name entered\nprint(score_message(score, name=name))\n\n('Hello student', 4.8)\n('Hello Ada', 4.8)\n\n\n\ndef score_message(score, name=\"student\"):\n    \"\"\"This is a doc-string, a string describing a function.\n    Args:\n        score (float): Raw score\n        name (str): Name of student\n    Returns:\n        str: A hello message.\n        float: A normalised score.\n    \"\"\"\n    norm_score = (score - 50) / 10\n    return f\"Hello {name}\", norm_score\n\n\n# Without indentation, this code is not part of function\nname = \"Ada\"\nscore = 98\n# No name entered\nprint(score_message(score))\n# Name entered\nprint(score_message(score, name=name))\n\n('Hello student', 4.8)\n('Hello Ada', 4.8)\n\n\neuxgwonykhkn Exercise What is the return type of a function with multiple return values separated by commas following the `return` statement?\nIn that last example, you’ll notice that we added some text to the function. This is a doc-string, or documentation string. It’s there to help users (and, most likely, future you) to understand what the function does. Let’s see how this works in action by calling help() on the score_message function:\n\nhelp(score_message)\n\nHelp on function score_message in module __main__:\n\nscore_message(score, name='student')\n    This is a doc-string, a string describing a function.\n    Args:\n        score (float): Raw score\n        name (str): Name of student\n    Returns:\n        str: A hello message.\n        float: A normalised score.\n\n\n\n\nhelp(score_message)\n\nHelp on function score_message in module __main__:\n\nscore_message(score, name='student')\n    This is a doc-string, a string describing a function.\n    Args:\n        score (float): Raw score\n        name (str): Name of student\n    Returns:\n        str: A hello message.\n        float: A normalised score.\n\n\n\n```euxgwonykhkn Exercise Write a function that returns a high five unicode character if the input is equal to “coding for economists” and a sad face, “:-/” otherwise.\nAdd a second argument that takes a default argument of an empty string but, if used, is added (concatenated) to the return message. Use it to create the return output, “:-/ here is my message.”\nWrite a doc-string for your function and call help on it.\n\nTo learn more about args and kwargs, check out these [short video tutorials](https://calmcode.io/args-kwargs/introduction.html).\n\n## Scope\n\nScope refers to what parts of your code can see what other parts. There are three different scopes to bear in mind: local, global, and non-local.\n\n**Local**\n\nIf you define a variable inside a function, the rest of your code won't be able to 'see' it or use it. For example, here's a function that creates a variable and then an example of calling that variable:\n\n```python\ndef var_func():\n    str_variable = 'Hello World!'\n\nvar_func()\nprint(str_variable)\nThis would raise an error, because as far as your general code is concerned str_variable doesn’t exist outside of the function. This is an example of a local variable, one that only exists within a function.\nIf you want to create variables inside a function and have them persist, you need to explicitly pass them out using, for example return str_variable like this:\n\ndef var_func():\n    str_variable = \"Hello World!\"\n    return str_variable\n\n\nreturned_var = var_func()\nprint(returned_var)\n\nHello World!\n\n\n\ndef var_func():\n    str_variable = \"Hello World!\"\n    return str_variable\n\n\nreturned_var = var_func()\nprint(returned_var)\n\nHello World!\n\n\nGlobal\nA variable declared outside of a function is known as a global variable because it is accessible everywhere:\n\ny = \"I'm a global variable\"\n\ndef print_y():\n    print(\"y is inside a function:\", y)\n\n\nprint_y()\nprint(\"y is outside a function:\", y)\n\ny is inside a function: I'm a global variable\ny is outside a function: I'm a global variable\n\n\n\ny = \"I'm a global variable\"\n\ndef print_y():\n    print(\"y is inside a function:\", y)\n\n\nprint_y()\nprint(\"y is outside a function:\", y)\n\ny is inside a function: I'm a global variable\ny is outside a function: I'm a global variable\n\n\nThis is just a taster of what can be done using base Python with few extra packages. For more, especially if you’ve done other chapters in the book already and want to go a bit deeper, see the Chapter on {ref}code-advanced. Otherwise, head on to the next chapter!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Hi, I’m Yang Fan!",
    "section": "",
    "text": "I’m a graduate student studying Education Management. I’m from Sichuan province, which locates in the southwest of China. The reason why I choose this major is because I’m an English teacher working in a Chinese college. And my undergraduate major is English Translation.\nI love English and also love to be a teacher."
  },
  {
    "objectID": "about.html#education-experience",
    "href": "about.html#education-experience",
    "title": "Hi, I’m Yang Fan!",
    "section": "Education Experience",
    "text": "Education Experience\nDuring my undergraduate years, I studied in the English Translation major, embarking on a journey of in-depth exploration of knowledge.\nThe curriculum was diverse and elaborate. From basic English-Chinese and Chinese-English translation courses that strengthened my skills in text conversion to consecutive interpretation and simultaneous interpretation courses which challenged me to achieve instant language transformation, I made solid progress every step of the way.\nIn terms of academic practice, I actively participated in various projects. I once joined the translation volunteer team for an international academic conference organized by our school and was responsible for consecutive interpretation during expert lectures.\nThanks to professional training, I have mastered translation software like Trados proficiently, which empowers me to carry out efficient and high-quality translation work. This learning experience has shaped me into a professional with solid skills nowadays."
  },
  {
    "objectID": "about.html#work-experience",
    "href": "about.html#work-experience",
    "title": "Hi, I’m Yang Fan!",
    "section": "Work Experience",
    "text": "Work Experience\nI have been working as a college English teacher since 2021. In daily teaching, I tailored courses for students of different grades:\n\nFor freshmen, I focused on laying a solid foundation\nFor sophomores and juniors, I organized various activities to boost their advanced skills\n\nOutside the classroom, I engaged in teaching research projects like “[Project Name]” and guided students to success in English competitions, enhancing the campus English learning atmosphere."
  },
  {
    "objectID": "about.html#hobbies-fun-facts",
    "href": "about.html#hobbies-fun-facts",
    "title": "Hi, I’m Yang Fan!",
    "section": "Hobbies & Fun Facts",
    "text": "Hobbies & Fun Facts\nMy interests and hobbies include:\n\nLanguage learning and exploring foreign cultures and civilizations\nWatching movies and TV dramas, especially suspense films and detective dramas\nReading various types of books, with Agatha Christie being my favorite author\nTraveling with friends during holidays for relaxation"
  },
  {
    "objectID": "homework/Lecture1-data-analysis-quickstart.html",
    "href": "homework/Lecture1-data-analysis-quickstart.html",
    "title": "",
    "section": "",
    "text": "(data-quickstart)= # Data Analysis Quickstart"
  },
  {
    "objectID": "homework/Lecture1-data-analysis-quickstart.html#introduction",
    "href": "homework/Lecture1-data-analysis-quickstart.html#introduction",
    "title": "",
    "section": "Introduction",
    "text": "Introduction\nHere we’ll do a whistlestop tour of data analysis in Python using a structure called a dataframe. Dataframes do everything a spreadsheet does, and a whole lot more. At their simplest, dataframes are a tabular representation of data with rows and columns. The data in each column can be anything; text, numbers, Python objects such as lists or dictionaries, or even other dataframes!\nThe ability to extract, clean, and analyse data is one of the core skills any economist needs. Fortunately, the (open source) tools that are available for data analysis have improved enormously in recent years, and working with them can be a delight——even the most badly formatted data can be beaten into shape. You may be sceptical that these open source tools can be as powerful as the costly, closed source tools you may already know: but, over time, you’ll come to see how they do far, far more, and do it faster too.\nIn this chapter, we’ll see analysis on a single dataframe using the Star Wars’ characters dataset as an example. For a more thorough grounding in using data, see the next chapter ({ref}working-with-data).\nThis chapter uses the pandas and numpy packages. If you’re running this code, you may need to install these packages. The Anaconda distribution of Python comes with pandas and numpy installed. If you don’t have these installed, you can install them by running either conda install packagename or pip install packagename on your computer’s command line. You can find a brief guide to installing packages in {ref}code-preliminaries.\nThis chapter is hugely indebted to the fantastic Python Data Science Handbook, and both the pandas documentation and amazing introductory tutorials."
  },
  {
    "objectID": "homework/Lecture1-data-analysis-quickstart.html#loading-data-and-checking-datatypes",
    "href": "homework/Lecture1-data-analysis-quickstart.html#loading-data-and-checking-datatypes",
    "title": "",
    "section": "Loading data and checking datatypes",
    "text": "Loading data and checking datatypes\nFirst we must import the packages we’ll be using in the rest of this chapter.\n\n%pip install pandas numpy matplotlib\n\nRequirement already satisfied: pandas in e:\\anaconda\\lib\\site-packages (2.2.2)\nRequirement already satisfied: numpy in e:\\anaconda\\lib\\site-packages (1.26.4)\nRequirement already satisfied: matplotlib in e:\\anaconda\\lib\\site-packages (3.8.4)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in e:\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in e:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in e:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\nRequirement already satisfied: contourpy&gt;=1.0.1 in e:\\anaconda\\lib\\site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in e:\\anaconda\\lib\\site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in e:\\anaconda\\lib\\site-packages (from matplotlib) (4.51.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in e:\\anaconda\\lib\\site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: packaging&gt;=20.0 in e:\\anaconda\\lib\\site-packages (from matplotlib) (23.2)\nRequirement already satisfied: pillow&gt;=8 in e:\\anaconda\\lib\\site-packages (from matplotlib) (10.3.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in e:\\anaconda\\lib\\site-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: six&gt;=1.5 in e:\\anaconda\\lib\\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# Set seed for random numbers\nseed_for_prng = 78557\nprng = np.random.default_rng(seed_for_prng)  # prng=probabilistic random number generator\n\n\n# Set seed for random numbers\nseed_for_prng = 78557\nprng = np.random.default_rng(seed_for_prng)  # prng=probabilistic random number generator\n\n\nimport matplotlib_inline.backend_inline\n\n# Plot settings\nplt.style.use(\n    \"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\"\n)\nmatplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n\n# Set max rows displayed for readability\npd.set_option(\"display.max_rows\", 20)\n\nLoading data into a dataframe is achieved with commands like df = pd.read_csv(...) or df = pd.read_stata(...). Let’s load the Star Wars data from the internet:\n\ndf = (pd.read_csv(\n    \"https://github.com/aeturrell/coding-for-economists/raw/main/data/starwars.csv\",\n    index_col=0,\n    )\n    .dropna(subset=[\"species\"])\n    )\n# Check info about dataframe\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 82 entries, 0 to 86\nData columns (total 8 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   name        82 non-null     object \n 1   height      77 non-null     float64\n 2   mass        58 non-null     float64\n 3   hair_color  77 non-null     object \n 4   eye_color   80 non-null     object \n 5   gender      79 non-null     object \n 6   homeworld   74 non-null     object \n 7   species     82 non-null     object \ndtypes: float64(2), object(6)\nmemory usage: 5.8+ KB\n\n\n\ndf = (pd.read_csv(\n    \"https://github.com/aeturrell/coding-for-economists/raw/main/data/starwars.csv\",\n    index_col=0,\n    )\n    .dropna(subset=[\"species\"])\n    )\n# Check info about dataframe\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 82 entries, 0 to 86\nData columns (total 8 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   name        82 non-null     object \n 1   height      77 non-null     float64\n 2   mass        58 non-null     float64\n 3   hair_color  77 non-null     object \n 4   eye_color   80 non-null     object \n 5   gender      79 non-null     object \n 6   homeworld   74 non-null     object \n 7   species     82 non-null     object \ndtypes: float64(2), object(6)\nmemory usage: 5.8+ KB\n\n\n\nLook at the first few rows with head()\n\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n\n\n\n\n\n\n\ndyryajoflcmu Exercise What happens if you pass a number to `head()`, eg `head(10)`?\n\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman"
  },
  {
    "objectID": "homework/Lecture1-data-analysis-quickstart.html#filter-rows-and-columns-with-conditions-using-df.locconditions-or-rows-columns",
    "href": "homework/Lecture1-data-analysis-quickstart.html#filter-rows-and-columns-with-conditions-using-df.locconditions-or-rows-columns",
    "title": "",
    "section": "Filter rows and columns with conditions using df.loc[condition(s) or row(s), column(s)]",
    "text": "Filter rows and columns with conditions using df.loc[condition(s) or row(s), column(s)]\n.loc stands for location and allows you to filter (aka subset) a dataframe. .loc works like an index, so it always comes with square brackets, eg df.loc[...].\nloc takes two arguments. The first is a list of the names of the rows that you’d like to select or a condition (ie a list of booleans with the same length as the dataframe) that selects certain rows. Remember, you can easily create a series of booleans by checking a column against a condition, for example df['column1'] == 'black'.\nThe second argument consists of a list of column names you’d like to select. In both cases, : is shorthand for ‘use all rows’ or ‘use all columns’. If you have either condition(s) or column(s) (but not both), you can simply write df[condition(s)] or df[column(s)].\nHere’s an example with a condition built up out of two parts and a list of columns:\n\ndf.loc[(df[\"hair_color\"] == \"brown\") & (df[\"eye_color\"] == \"blue\"), [\"name\", \"species\"]]\n\n\n\n\n\n\n\n\nname\nspecies\n\n\n\n\n6\nBeru Whitesun lars\nHuman\n\n\n12\nChewbacca\nWookiee\n\n\n17\nJek Tono Porkins\nHuman\n\n\n30\nQui-Gon Jinn\nHuman\n\n\n58\nCliegg Lars\nHuman\n\n\n77\nTarfful\nWookiee\n\n\n\n\n\n\n\n\ndf.loc[(df[\"hair_color\"] == \"brown\") & (df[\"eye_color\"] == \"blue\"), [\"name\", \"species\"]]\n\n\n\n\n\n\n\n\nname\nspecies\n\n\n\n\n6\nBeru Whitesun lars\nHuman\n\n\n12\nChewbacca\nWookiee\n\n\n17\nJek Tono Porkins\nHuman\n\n\n30\nQui-Gon Jinn\nHuman\n\n\n58\nCliegg Lars\nHuman\n\n\n77\nTarfful\nWookiee\n\n\n\n\n\n\n\ndyryajoflcmu Exercise Using `loc`, filter the dataframe to `mass` greater than 50 for the `name` and `homeworld` columns\n\ndf.loc[(df['mass'] &gt; 50), ['name', 'homeworld']]\n\n\n\n\n\n\n\n\nname\nhomeworld\n\n\n\n\n0\nLuke Skywalker\nTatooine\n\n\n1\nC-3PO\nTatooine\n\n\n3\nDarth Vader\nTatooine\n\n\n5\nOwen Lars\nTatooine\n\n\n6\nBeru Whitesun lars\nTatooine\n\n\n...\n...\n...\n\n\n75\nShaak Ti\nShili\n\n\n76\nGrievous\nKalee\n\n\n77\nTarfful\nKashyyyk\n\n\n78\nRaymus Antilles\nAlderaan\n\n\n80\nTion Medon\nUtapau\n\n\n\n\n46 rows × 2 columns\n\n\n\n\ndf.loc[(df['mass'] &gt; 50), ['name', 'homeworld']]\n\n\n\n\n\n\n\n\nname\nhomeworld\n\n\n\n\n0\nLuke Skywalker\nTatooine\n\n\n1\nC-3PO\nTatooine\n\n\n3\nDarth Vader\nTatooine\n\n\n5\nOwen Lars\nTatooine\n\n\n6\nBeru Whitesun lars\nTatooine\n\n\n...\n...\n...\n\n\n75\nShaak Ti\nShili\n\n\n76\nGrievous\nKalee\n\n\n77\nTarfful\nKashyyyk\n\n\n78\nRaymus Antilles\nAlderaan\n\n\n80\nTion Medon\nUtapau\n\n\n\n\n46 rows × 2 columns"
  },
  {
    "objectID": "homework/Lecture1-data-analysis-quickstart.html#sort-rows-or-columns-with-.sort_values",
    "href": "homework/Lecture1-data-analysis-quickstart.html#sort-rows-or-columns-with-.sort_values",
    "title": "",
    "section": "Sort rows or columns with .sort_values()",
    "text": "Sort rows or columns with .sort_values()\nUse sort_values(columns, ascending=False) for descending order.\n\ndf.sort_values([\"height\", \"mass\"])\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n18\nYoda\n66.0\n17.0\nwhite\nbrown\nmale\nNaN\nYoda's species\n\n\n71\nRatts Tyerell\n79.0\n15.0\nnone\nNaN\nmale\nAleen Minor\nAleena\n\n\n28\nWicket Systri Warrick\n88.0\n20.0\nbrown\nbrown\nmale\nEndor\nEwok\n\n\n44\nDud Bolt\n94.0\n45.0\nnone\nyellow\nmale\nVulpter\nVulptereen\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n27\nArvel Crynyd\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n81\nFinn\nNaN\nNaN\nblack\ndark\nmale\nNaN\nHuman\n\n\n82\nRey\nNaN\nNaN\nbrown\nhazel\nfemale\nNaN\nHuman\n\n\n83\nPoe Dameron\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n84\nBB8\nNaN\nNaN\nnone\nblack\nnone\nNaN\nDroid\n\n\n\n\n82 rows × 8 columns\n\n\n\n\ndf.sort_values([\"height\", \"mass\"])\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n18\nYoda\n66.0\n17.0\nwhite\nbrown\nmale\nNaN\nYoda's species\n\n\n71\nRatts Tyerell\n79.0\n15.0\nnone\nNaN\nmale\nAleen Minor\nAleena\n\n\n28\nWicket Systri Warrick\n88.0\n20.0\nbrown\nbrown\nmale\nEndor\nEwok\n\n\n44\nDud Bolt\n94.0\n45.0\nnone\nyellow\nmale\nVulpter\nVulptereen\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n27\nArvel Crynyd\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n81\nFinn\nNaN\nNaN\nblack\ndark\nmale\nNaN\nHuman\n\n\n82\nRey\nNaN\nNaN\nbrown\nhazel\nfemale\nNaN\nHuman\n\n\n83\nPoe Dameron\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n84\nBB8\nNaN\nNaN\nnone\nblack\nnone\nNaN\nDroid\n\n\n\n\n82 rows × 8 columns\n\n\n\ndyryajoflcmu Exercise Using `sort_values()`, sort the dataframe by the `name` column.\n\ndf.sort_values('name')\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n25\nAckbar\n180.0\n83.0\nnone\norange\nmale\nMon Cala\nMon Calamari\n\n\n51\nAdi Gallia\n184.0\n50.0\nnone\nblue\nfemale\nCoruscant\nTholothian\n\n\n10\nAnakin Skywalker\n188.0\n84.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n27\nArvel Crynyd\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n43\nAyla Secura\n178.0\n55.0\nnone\nhazel\nfemale\nRyloth\nTwi'lek\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n28\nWicket Systri Warrick\n88.0\n20.0\nbrown\nbrown\nmale\nEndor\nEwok\n\n\n11\nWilhuff Tarkin\n180.0\nNaN\nauburn, grey\nblue\nmale\nEriadu\nHuman\n\n\n53\nYarael Poof\n264.0\nNaN\nnone\nyellow\nmale\nQuermia\nQuermian\n\n\n18\nYoda\n66.0\n17.0\nwhite\nbrown\nmale\nNaN\nYoda's species\n\n\n66\nZam Wesell\n168.0\n55.0\nblonde\nyellow\nfemale\nZolan\nClawdite\n\n\n\n\n82 rows × 8 columns\n\n\n\n\ndf.sort_values('name')\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n25\nAckbar\n180.0\n83.0\nnone\norange\nmale\nMon Cala\nMon Calamari\n\n\n51\nAdi Gallia\n184.0\n50.0\nnone\nblue\nfemale\nCoruscant\nTholothian\n\n\n10\nAnakin Skywalker\n188.0\n84.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n27\nArvel Crynyd\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n43\nAyla Secura\n178.0\n55.0\nnone\nhazel\nfemale\nRyloth\nTwi'lek\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n28\nWicket Systri Warrick\n88.0\n20.0\nbrown\nbrown\nmale\nEndor\nEwok\n\n\n11\nWilhuff Tarkin\n180.0\nNaN\nauburn, grey\nblue\nmale\nEriadu\nHuman\n\n\n53\nYarael Poof\n264.0\nNaN\nnone\nyellow\nmale\nQuermia\nQuermian\n\n\n18\nYoda\n66.0\n17.0\nwhite\nbrown\nmale\nNaN\nYoda's species\n\n\n66\nZam Wesell\n168.0\n55.0\nblonde\nyellow\nfemale\nZolan\nClawdite\n\n\n\n\n82 rows × 8 columns"
  },
  {
    "objectID": "homework/Lecture1-data-analysis-quickstart.html#choose-multiple-rows-or-columns-using-slices",
    "href": "homework/Lecture1-data-analysis-quickstart.html#choose-multiple-rows-or-columns-using-slices",
    "title": "",
    "section": "Choose multiple rows or columns using slices",
    "text": "Choose multiple rows or columns using slices\nSlices can be passed by name using .loc[startrow:stoprow:step, startcolumn:stopcolumn:step] or by position using .iloc[start:stop:step, start:stop:step].\nChoosing every 10th row from the second, and the columns between ‘name’ and ‘gender’:\n\ndf.loc[2::10, \"name\":\"gender\"]\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\n\n\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\n\n\n12\nChewbacca\n228.0\n112.0\nbrown\nblue\nmale\n\n\n22\nBossk\n190.0\n113.0\nnone\nred\nmale\n\n\n32\nFinis Valorum\n170.0\nNaN\nblond\nblue\nmale\n\n\n44\nDud Bolt\n94.0\n45.0\nnone\nyellow\nmale\n\n\n54\nPlo Koon\n188.0\n80.0\nnone\nblack\nmale\n\n\n64\nBail Prestor Organa\n191.0\nNaN\nblack\nbrown\nmale\n\n\n75\nShaak Ti\n178.0\n57.0\nnone\nblack\nfemale\n\n\n\n\n\n\n\n\ndf.loc[2::10, \"name\":\"gender\"]\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\n\n\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\n\n\n12\nChewbacca\n228.0\n112.0\nbrown\nblue\nmale\n\n\n22\nBossk\n190.0\n113.0\nnone\nred\nmale\n\n\n32\nFinis Valorum\n170.0\nNaN\nblond\nblue\nmale\n\n\n44\nDud Bolt\n94.0\n45.0\nnone\nyellow\nmale\n\n\n54\nPlo Koon\n188.0\n80.0\nnone\nblack\nmale\n\n\n64\nBail Prestor Organa\n191.0\nNaN\nblack\nbrown\nmale\n\n\n75\nShaak Ti\n178.0\n57.0\nnone\nblack\nfemale\n\n\n\n\n\n\n\nNote that loc only works here with numbers for rows because it just so happens that the names of the rows are numbers. If the rows had names that were strings, and we wanted to subset rows by their index position, we would have to use iloc instead.\nChoosing the first 5 rows and the last 2 columns by index position:\n\ndf.iloc[:5, -2:]\n\n\n\n\n\n\n\n\nhomeworld\nspecies\n\n\n\n\n0\nTatooine\nHuman\n\n\n1\nTatooine\nDroid\n\n\n2\nNaboo\nDroid\n\n\n3\nTatooine\nHuman\n\n\n4\nAlderaan\nHuman\n\n\n\n\n\n\n\n\ndf.iloc[:5, -2:]\n\n\n\n\n\n\n\n\nhomeworld\nspecies\n\n\n\n\n0\nTatooine\nHuman\n\n\n1\nTatooine\nDroid\n\n\n2\nNaboo\nDroid\n\n\n3\nTatooine\nHuman\n\n\n4\nAlderaan\nHuman\n\n\n\n\n\n\n\ndyryajoflcmu Exercise Using `.iloc`, display the first 6 rows and last 6 columns.\n\ndf.iloc[:6, -6:]\n\n\n\n\n\n\n\n\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n1\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n\n\n2\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n3\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n\n\n4\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n\n\n5\n120.0\nbrown, grey\nblue\nmale\nTatooine\nHuman\n\n\n\n\n\n\n\n\ndf.iloc[:6, -6:]\n\n\n\n\n\n\n\n\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n1\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n\n\n2\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n3\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n\n\n4\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n\n\n5\n120.0\nbrown, grey\nblue\nmale\nTatooine\nHuman"
  },
  {
    "objectID": "homework/Lecture1-data-analysis-quickstart.html#randomly-selecting-a-sample-using-.sample",
    "href": "homework/Lecture1-data-analysis-quickstart.html#randomly-selecting-a-sample-using-.sample",
    "title": "",
    "section": "Randomly selecting a sample using .sample",
    "text": "Randomly selecting a sample using .sample\n.sample(n) randomly selects n rows, .sample(frac=0.4) selects 40% of the data, replace=True samples with replacement, and passing weights= selects a number or fraction with the probabilities given by the passed weights. (Note that weights passed should have the same length as the dataframe.)\nTaking a sample of 5 rows:\n\ndf.sample(5)\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n69\nTaun We\n213.0\nNaN\nnone\nblack\nfemale\nKamino\nKaminoan\n\n\n59\nPoggle the Lesser\n183.0\n80.0\nnone\nyellow\nmale\nGeonosis\nGeonosian\n\n\n65\nJango Fett\n183.0\n79.0\nblack\nbrown\nmale\nConcord Dawn\nHuman\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n22\nBossk\n190.0\n113.0\nnone\nred\nmale\nTrandosha\nTrandoshan\n\n\n\n\n\n\n\n\ndf.sample(5)\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n6\nBeru Whitesun lars\n165.0\n75.0\nbrown\nblue\nfemale\nTatooine\nHuman\n\n\n70\nJocasta Nu\n167.0\nNaN\nwhite\nblue\nfemale\nCoruscant\nHuman\n\n\n80\nTion Medon\n206.0\n80.0\nnone\nblack\nmale\nUtapau\nPau'an\n\n\n57\nCordé\n157.0\nNaN\nbrown\nbrown\nfemale\nNaboo\nHuman\n\n\n71\nRatts Tyerell\n79.0\n15.0\nnone\nNaN\nmale\nAleen Minor\nAleena\n\n\n\n\n\n\n\ndyryajoflcmu Exercise Use `.sample()` to sample 5% of the dataframe.\n\ndf.sample(frac=0.05)\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n24\nLobot\n175.0\n79.0\nnone\nblue\nmale\nBespin\nHuman\n\n\n66\nZam Wesell\n168.0\n55.0\nblonde\nyellow\nfemale\nZolan\nClawdite\n\n\n23\nLando Calrissian\n177.0\n79.0\nblack\nbrown\nmale\nSocorro\nHuman\n\n\n64\nBail Prestor Organa\n191.0\nNaN\nblack\nbrown\nmale\nAlderaan\nHuman"
  },
  {
    "objectID": "homework/Lecture1-data-analysis-quickstart.html#rename-with-.rename",
    "href": "homework/Lecture1-data-analysis-quickstart.html#rename-with-.rename",
    "title": "",
    "section": "Rename with .rename()",
    "text": "Rename with .rename()\nYou can rename all columns by passing a function, for instance df.rename(columns=str.lower) to put all columns in lower case. Alternatively, use a dictionary to say which columns should be mapped to what:\n\ndf.rename(columns={\"homeworld\": \"home_world\"})\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhome_world\nspecies\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n81\nFinn\nNaN\nNaN\nblack\ndark\nmale\nNaN\nHuman\n\n\n82\nRey\nNaN\nNaN\nbrown\nhazel\nfemale\nNaN\nHuman\n\n\n83\nPoe Dameron\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n84\nBB8\nNaN\nNaN\nnone\nblack\nnone\nNaN\nDroid\n\n\n86\nPadmé Amidala\n165.0\n45.0\nbrown\nbrown\nfemale\nNaboo\nHuman\n\n\n\n\n82 rows × 8 columns\n\n\n\n\ndf.rename(columns={\"homeworld\": \"home_world\"})\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhome_world\nspecies\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n81\nFinn\nNaN\nNaN\nblack\ndark\nmale\nNaN\nHuman\n\n\n82\nRey\nNaN\nNaN\nbrown\nhazel\nfemale\nNaN\nHuman\n\n\n83\nPoe Dameron\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n84\nBB8\nNaN\nNaN\nnone\nblack\nnone\nNaN\nDroid\n\n\n86\nPadmé Amidala\n165.0\n45.0\nbrown\nbrown\nfemale\nNaboo\nHuman\n\n\n\n\n82 rows × 8 columns"
  },
  {
    "objectID": "homework/Lecture1-data-analysis-quickstart.html#add-new-columns-with-.assign-or-assignment",
    "href": "homework/Lecture1-data-analysis-quickstart.html#add-new-columns-with-.assign-or-assignment",
    "title": "",
    "section": "Add new columns with .assign() or assignment",
    "text": "Add new columns with .assign() or assignment\nVery often you will want to create new columns based on existing columns.\n\nThere are two ways to do this. Let’s see them both with an example where we’d like to create a new column that contains height in metres, called \"height_m:.\n\nThe first, and most commonly used, is called assignment and involves just entering the new column name within your dataframe and putting it on the left-hand side of an assignment expression that has an operation based on existing dataframe columns on the right-hand side. For example, df['height_m'] = df['height']/100.\nThe second is to use the assign() method on a dataframe directly. In this case, the assignment statement appears inside the brackets but you don’t need to write as much text because it’s clear from the context that, on the left-hand side of the assignment, we’re talking about the given dataframe. An example is df.assign(height_m=df[\"height\"] / 100).\n\nLet’s see working examples of both of these assignment methods.\nFirst let’s use the assignment approach:\n\ndf['height_m'] = df['height']/100\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n\n\n\n\n\n\n\n\ndf['height_m'] = df['height']/100\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n\n\n\n\n\n\n\nAnd now with the .assign() function:\n\ndf = df.assign(height_m=df[\"height\"] / 100)\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n\n\n\n\n\n\n\n\ndf = df.assign(height_m=df[\"height\"] / 100)\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n\n\n\n\n\n\n\nThis was added to the end; ideally, we’d like it next to the height column, which we can achieve by sorting the columns (axis=1) alphabetically:\n\n(df.assign(height_m=df[\"height\"] / 100).sort_index(axis=1))\n\n\n\n\n\n\n\n\neye_color\ngender\nhair_color\nheight\nheight_m\nhomeworld\nmass\nname\nspecies\n\n\n\n\n0\nblue\nmale\nblond\n172.0\n1.72\nTatooine\n77.0\nLuke Skywalker\nHuman\n\n\n1\nyellow\nNaN\nNaN\n167.0\n1.67\nTatooine\n75.0\nC-3PO\nDroid\n\n\n2\nred\nNaN\nNaN\n96.0\n0.96\nNaboo\n32.0\nR2-D2\nDroid\n\n\n3\nyellow\nmale\nnone\n202.0\n2.02\nTatooine\n136.0\nDarth Vader\nHuman\n\n\n4\nbrown\nfemale\nbrown\n150.0\n1.50\nAlderaan\n49.0\nLeia Organa\nHuman\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n81\ndark\nmale\nblack\nNaN\nNaN\nNaN\nNaN\nFinn\nHuman\n\n\n82\nhazel\nfemale\nbrown\nNaN\nNaN\nNaN\nNaN\nRey\nHuman\n\n\n83\nbrown\nmale\nbrown\nNaN\nNaN\nNaN\nNaN\nPoe Dameron\nHuman\n\n\n84\nblack\nnone\nnone\nNaN\nNaN\nNaN\nNaN\nBB8\nDroid\n\n\n86\nbrown\nfemale\nbrown\n165.0\n1.65\nNaboo\n45.0\nPadmé Amidala\nHuman\n\n\n\n\n82 rows × 9 columns\n\n\n\n\n(df.assign(height_m=df[\"height\"] / 100).sort_index(axis=1))\n\n\n\n\n\n\n\n\neye_color\ngender\nhair_color\nheight\nheight_m\nhomeworld\nmass\nname\nspecies\n\n\n\n\n0\nblue\nmale\nblond\n172.0\n1.72\nTatooine\n77.0\nLuke Skywalker\nHuman\n\n\n1\nyellow\nNaN\nNaN\n167.0\n1.67\nTatooine\n75.0\nC-3PO\nDroid\n\n\n2\nred\nNaN\nNaN\n96.0\n0.96\nNaboo\n32.0\nR2-D2\nDroid\n\n\n3\nyellow\nmale\nnone\n202.0\n2.02\nTatooine\n136.0\nDarth Vader\nHuman\n\n\n4\nbrown\nfemale\nbrown\n150.0\n1.50\nAlderaan\n49.0\nLeia Organa\nHuman\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n81\ndark\nmale\nblack\nNaN\nNaN\nNaN\nNaN\nFinn\nHuman\n\n\n82\nhazel\nfemale\nbrown\nNaN\nNaN\nNaN\nNaN\nRey\nHuman\n\n\n83\nbrown\nmale\nbrown\nNaN\nNaN\nNaN\nNaN\nPoe Dameron\nHuman\n\n\n84\nblack\nnone\nnone\nNaN\nNaN\nNaN\nNaN\nBB8\nDroid\n\n\n86\nbrown\nfemale\nbrown\n165.0\n1.65\nNaboo\n45.0\nPadmé Amidala\nHuman\n\n\n\n\n82 rows × 9 columns\n\n\n\nTo overwrite existing columns just use height = df['height']/100 with the assign method or df['height'] = df['height']/100 with an assignment expression.\ndyryajoflcmu Exercise Add a new column that gives the ratio of mass to height.\n\ndf['mass_height_ratio'] = df['mass'] / df['height']\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\nmass_height_ratio\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n0.447674\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n0.449102\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n0.333333\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n0.673267\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n0.326667\n\n\n\n\n\n\n\n\ndf['mass_height_ratio'] = df['mass'] / df['height']\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\nmass_height_ratio\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n0.447674\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n0.449102\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n0.333333\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n0.673267\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n0.326667\n\n\n\n\n\n\n\n\ndf = df.assign(mass_height_ratio=df['mass'] / df['height'])\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\nmass_height_ratio\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n0.447674\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n0.449102\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n0.333333\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n0.673267\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n0.326667\n\n\n\n\n\n\n\n\ndf = df.assign(mass_height_ratio=df['mass'] / df['height'])\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\nmass_height_ratio\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n0.447674\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n0.449102\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n0.333333\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n0.673267\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n0.326667"
  },
  {
    "objectID": "homework/Lecture1-data-analysis-quickstart.html#summarise-numerical-values-with-.describe",
    "href": "homework/Lecture1-data-analysis-quickstart.html#summarise-numerical-values-with-.describe",
    "title": "",
    "section": "Summarise numerical values with .describe()",
    "text": "Summarise numerical values with .describe()\n\ndf.describe()\n\n\n\n\n\n\n\n\nheight\nmass\nheight_m\nmass_height_ratio\n\n\n\n\ncount\n77.000000\n58.000000\n77.000000\n58.000000\n\n\nmean\n175.103896\n98.162069\n1.751039\n0.552307\n\n\nstd\n34.483629\n170.810183\n0.344836\n0.969546\n\n\nmin\n66.000000\n15.000000\n0.660000\n0.189873\n\n\n25%\n167.000000\n56.400000\n1.670000\n0.341837\n\n\n50%\n180.000000\n79.000000\n1.800000\n0.434426\n\n\n75%\n191.000000\n84.750000\n1.910000\n0.459349\n\n\nmax\n264.000000\n1358.000000\n2.640000\n7.760000\n\n\n\n\n\n\n\n\ndf.describe()\n\n\n\n\n\n\n\n\nheight\nmass\nheight_m\nmass_height_ratio\n\n\n\n\ncount\n77.000000\n58.000000\n77.000000\n58.000000\n\n\nmean\n175.103896\n98.162069\n1.751039\n0.552307\n\n\nstd\n34.483629\n170.810183\n0.344836\n0.969546\n\n\nmin\n66.000000\n15.000000\n0.660000\n0.189873\n\n\n25%\n167.000000\n56.400000\n1.670000\n0.341837\n\n\n50%\n180.000000\n79.000000\n1.800000\n0.434426\n\n\n75%\n191.000000\n84.750000\n1.910000\n0.459349\n\n\nmax\n264.000000\n1358.000000\n2.640000\n7.760000"
  },
  {
    "objectID": "homework/Lecture1-data-analysis-quickstart.html#group-variables-values-with-.groupby",
    "href": "homework/Lecture1-data-analysis-quickstart.html#group-variables-values-with-.groupby",
    "title": "",
    "section": "Group variables values with .groupby()",
    "text": "Group variables values with .groupby()\n\ndf.groupby(\"species\")[[\"height\", \"mass\"]].mean()\n\n\n\n\n\n\n\n\nheight\nmass\n\n\nspecies\n\n\n\n\n\n\nAleena\n79.0\n15.0\n\n\nBesalisk\n198.0\n102.0\n\n\nCerean\n198.0\n82.0\n\n\nChagrian\n196.0\nNaN\n\n\nClawdite\n168.0\n55.0\n\n\n...\n...\n...\n\n\nVulptereen\n94.0\n45.0\n\n\nWookiee\n231.0\n124.0\n\n\nXexto\n122.0\nNaN\n\n\nYoda's species\n66.0\n17.0\n\n\nZabrak\n173.0\n80.0\n\n\n\n\n37 rows × 2 columns\n\n\n\n\ndf.groupby(\"species\")[[\"height\", \"mass\"]].mean()\n\n\n\n\n\n\n\n\nheight\nmass\n\n\nspecies\n\n\n\n\n\n\nAleena\n79.0\n15.0\n\n\nBesalisk\n198.0\n102.0\n\n\nCerean\n198.0\n82.0\n\n\nChagrian\n196.0\nNaN\n\n\nClawdite\n168.0\n55.0\n\n\n...\n...\n...\n\n\nVulptereen\n94.0\n45.0\n\n\nWookiee\n231.0\n124.0\n\n\nXexto\n122.0\nNaN\n\n\nYoda's species\n66.0\n17.0\n\n\nZabrak\n173.0\n80.0\n\n\n\n\n37 rows × 2 columns\n\n\n\ndyryajoflcmu Exercise Find the standard deviation (using `std()`) of masses by `homeworld`.\n\ndf.groupby('homeworld')['mass'].std()\n\nhomeworld\nAlderaan          21.213203\nAleen Minor             NaN\nBespin                  NaN\nBestine IV              NaN\nCato Neimoidia          NaN\n                    ...    \nTroiken                 NaN\nTund                    NaN\nUtapau                  NaN\nVulpter                 NaN\nZolan                   NaN\nName: mass, Length: 47, dtype: float64\n\n\n\ndf.groupby('homeworld')['mass'].std()\n\nhomeworld\nAlderaan          21.213203\nAleen Minor             NaN\nBespin                  NaN\nBestine IV              NaN\nCato Neimoidia          NaN\n                    ...    \nTroiken                 NaN\nTund                    NaN\nUtapau                  NaN\nVulpter                 NaN\nZolan                   NaN\nName: mass, Length: 47, dtype: float64"
  },
  {
    "objectID": "homework/Lecture1-data-analysis-quickstart.html#add-transformed-columns-using-.transform",
    "href": "homework/Lecture1-data-analysis-quickstart.html#add-transformed-columns-using-.transform",
    "title": "",
    "section": "Add transformed columns using .transform()",
    "text": "Add transformed columns using .transform()\nQuite often, it’s useful to put a column into a dataframe that is the result of an intermediate groupby and aggregation. For example, subtracting the group mean or normalisation. Transform does this and returns a transformed column with the same shape as the original dataframe. Transform preserves the original index. (There are other methods, such as apply, that return a new dataframe with the groupby variables as a new index.)\nBelow is an example of transform being used to demean a variable according to the mean by species. Note that we are using lambda functions here. Lambda functions are a quick way of writing functions without needing to give them a name, e.g. lambda x: x+1 defines a function that adds one to x. In the example below, the x in the lambda function takes on the role of mass grouped by species.\n\ndf[\"mass_demean_species\"] = df.groupby(\"species\")[\"mass\"].transform(lambda x: x - x.mean())\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\nmass_height_ratio\nmass_demean_species\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n0.447674\n-5.781818\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n0.449102\n5.250000\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n0.333333\n-37.750000\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n0.673267\n53.218182\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n0.326667\n-33.781818\n\n\n\n\n\n\n\n\ndf[\"mass_demean_species\"] = df.groupby(\"species\")[\"mass\"].transform(lambda x: x - x.mean())\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\nmass_height_ratio\nmass_demean_species\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n0.447674\n-5.781818\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n0.449102\n5.250000\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n0.333333\n-37.750000\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n0.673267\n53.218182\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n0.326667\n-33.781818\n\n\n\n\n\n\n\ndyryajoflcmu Exercise Create a `height_demean_homeworld` column that gives the height column with the mean height by homeworld subtracted."
  },
  {
    "objectID": "homework/Lecture1-data-analysis-quickstart.html#make-quick-charts-with-.plot.",
    "href": "homework/Lecture1-data-analysis-quickstart.html#make-quick-charts-with-.plot.",
    "title": "",
    "section": "Make quick charts with .plot.*()",
    "text": "Make quick charts with .plot.*()\nIncluding scatter, area, bar, box, density, hexbin, histogram, kde, and line.\n\ndf.plot.scatter(\"mass\", \"height\", alpha=0.5);\n\n\n\n\n\n\n\n\n\ndf.plot.scatter(\"mass\", \"height\", alpha=0.5);\n\n\n\n\n\n\n\n\n\ndf.plot.box(column=\"height\");\n\n\n\n\n\n\n\n\n\ndf.plot.box(column=\"height\");\n\n\n\n\n\n\n\n\n\n%pip install scipy\n\nRequirement already satisfied: scipy in e:\\anaconda\\lib\\site-packages (1.13.1)\nRequirement already satisfied: numpy&lt;2.3,&gt;=1.22.4 in e:\\anaconda\\lib\\site-packages (from scipy) (1.26.4)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n%pip install scipy\n\nRequirement already satisfied: scipy in e:\\anaconda\\lib\\site-packages (1.13.1)\nRequirement already satisfied: numpy&lt;2.3,&gt;=1.22.4 in e:\\anaconda\\lib\\site-packages (from scipy) (1.26.4)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\ndf[\"height\"].plot.kde(bw_method=0.3);"
  },
  {
    "objectID": "homework/Lecture1-data-analysis-quickstart.html#export-results-and-descriptive-statistics",
    "href": "homework/Lecture1-data-analysis-quickstart.html#export-results-and-descriptive-statistics",
    "title": "",
    "section": "Export results and descriptive statistics",
    "text": "Export results and descriptive statistics\nYou’ll often want to export your results to a latex file for inclusion in a paper, presentation, or poster. Let’s say we had some descriptive statistics on a dataframe:\n\ntable = df[[\"mass\", \"height\"]].agg(['mean', 'std'])\ntable\n\n\n\n\n\n\n\n\nmass\nheight\n\n\n\n\nmean\n98.162069\n175.103896\n\n\nstd\n170.810183\n34.483629\n\n\n\n\n\n\n\n\ntable = df[[\"mass\", \"height\"]].agg(['mean', 'std'])\ntable\n\n\n\n\n\n\n\n\nmass\nheight\n\n\n\n\nmean\n98.162069\n175.103896\n\n\nstd\n170.810183\n34.483629\n\n\n\n\n\n\n\nYou can export this to a range of formats, including string, html, xml, markdown, the clipboard (so you can paste it), Excel, and more. In your favourite IDE (integrated development environment) with a Python language server (eg Visual Studio Code, JupyterLab) start typing table.to and a list of possible methods beginning to should appear, including to_string().\nHere is an example of exporting your pandas table to CSV (comma separated values):\n\ntable.to_csv()\n\n',mass,height\\nmean,98.16206896551724,175.1038961038961\\nstd,170.81018276436322,34.483628615842896\\n'\n\n\n\ntable.to_csv()\n\n',mass,height\\r\\nmean,98.16206896551724,175.1038961038961\\r\\nstd,170.8101827643632,34.483628615842896\\r\\n'\n\n\nOne output format that doesn’t conform to this is LaTeX, for which you need the following:\nWriting to the terminal isn’t that useful for getting your paper or report done! To export to a file, use table.style.to_latex('file.tex', ...) for LaTeX and table.to_csv('file.csv', ...).\n``dyryajoflcmu Exercise Try exporting the table above using theto_string(“table.txt”)` method.\nIf you are running this locally, the file should appear in the directory in which you are running this notebook.\nIf you are using Google Colab to do these exercises, you can check that the file exported by running !ls in a new code cell to see all files in the current notebook directory. To get the contents of the file you created, run !cat table.txt. ```"
  },
  {
    "objectID": "homework/Lecture1-data-analysis-quickstart.html#summary",
    "href": "homework/Lecture1-data-analysis-quickstart.html#summary",
    "title": "",
    "section": "Summary",
    "text": "Summary\nThis has been a quick tour of what pandas can do, and shows the power of this ubiquitous tool, but we’ve barely seen a fraction of its features. The next chapter will go deeper into how to use pandas."
  },
  {
    "objectID": "homework/Lecture2-homework-pet-names.html",
    "href": "homework/Lecture2-homework-pet-names.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\ndf = pd.read_csv('seattle_pet_licenses.csv')\n\n\ndf\n\n\n\n\n\n\n\n\nanimal_s_name\nlicense_issue_date\nlicense_number\nprimary_breed\nsecondary_breed\nspecies\nzip_code\n\n\n\n\n0\nOzzy\n2005-03-29T00:00:00.000\n130651.0\nDachshund, Standard Smooth Haired\nNaN\nDog\n98104\n\n\n1\nJack\n2009-12-23T00:00:00.000\n898148.0\nSchnauzer, Miniature\nTerrier, Rat\nDog\n98107\n\n\n2\nGinger\n2006-01-20T00:00:00.000\n29654.0\nRetriever, Golden\nRetriever, Labrador\nDog\n98117\n\n\n3\nPepper\n2006-02-07T00:00:00.000\n75432.0\nManx\nMix\nCat\n98103\n\n\n4\nAddy\n2006-08-04T00:00:00.000\n729899.0\nRetriever, Golden\nNaN\nDog\n98105\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n66037\nLily\n2016-12-27T00:00:00.000\nNaN\nDomestic Shorthair\nMix\nCat\n98117\n\n\n66038\nEllie\n2016-11-29T00:00:00.000\nNaN\nGerman Shepherd\nMix\nDog\n98105\n\n\n66039\nSammy\n2016-12-05T00:00:00.000\nNaN\nTerrier\nMaltese\nDog\n98105\n\n\n66040\nBuddy\n2016-12-06T00:00:00.000\nNaN\nBullmastiff\nMix\nDog\n98105\n\n\n66041\nAku\n2016-12-07T00:00:00.000\nNaN\nChihuahua, Short Coat\nTerrier\nDog\n98106\n\n\n\n\n66042 rows × 7 columns\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 66042 entries, 0 to 66041\nData columns (total 7 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   animal_s_name       64685 non-null  object \n 1   license_issue_date  66042 non-null  object \n 2   license_number      43885 non-null  float64\n 3   primary_breed       66042 non-null  object \n 4   secondary_breed     22538 non-null  object \n 5   species             66042 non-null  object \n 6   zip_code            65884 non-null  object \ndtypes: float64(1), object(6)\nmemory usage: 3.5+ MB\n\n\n\ndf['animal_s_name'].value_counts()\n\nanimal_s_name\nLucy          566\nBella         451\nCharlie       447\nMax           374\nLuna          361\n             ... \nManasseh        1\nTaba            1\nMiriam          1\nNumber Six      1\nRollins         1\nName: count, Length: 15795, dtype: int64"
  },
  {
    "objectID": "homework/Lecture3-homework2-YangFan.html",
    "href": "homework/Lecture3-homework2-YangFan.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nurl ='https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\ndf = pd.read_csv(url)\nprint(df.head())\n\n   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n\n\n\ndf\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n887\n0\n2\nMontvila, Rev. Juozas\nmale\n27.0\n0\n0\n211536\n13.0000\nNaN\nS\n\n\n887\n888\n1\n1\nGraham, Miss. Margaret Edith\nfemale\n19.0\n0\n0\n112053\n30.0000\nB42\nS\n\n\n888\n889\n0\n3\nJohnston, Miss. Catherine Helen \"Carrie\"\nfemale\nNaN\n1\n2\nW./C. 6607\n23.4500\nNaN\nS\n\n\n889\n890\n1\n1\nBehr, Mr. Karl Howell\nmale\n26.0\n0\n0\n111369\n30.0000\nC148\nC\n\n\n890\n891\n0\n3\nDooley, Mr. Patrick\nmale\n32.0\n0\n0\n370376\n7.7500\nNaN\nQ\n\n\n\n\n891 rows × 12 columns\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n\n\n\nfrom skimpy import clean_columns\ndf = clean_columns(df,case=\"snake\")\nprint(df.columns)\n\nIndex(['passenger_id', 'survived', 'pclass', 'name', 'sex', 'age', 'sib_sp',\n       'parch', 'ticket', 'fare', 'cabin', 'embarked'],\n      dtype='object')\n\n\n\ndf.fillna(\"-\")\n\n\n\n\n\n\n\n\npassenger_id\nsurvived\npclass\nname\nsex\nage\nsib_sp\nparch\nticket\nfare\ncabin\nembarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\n-\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\n-\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\n-\nS\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n887\n0\n2\nMontvila, Rev. Juozas\nmale\n27.0\n0\n0\n211536\n13.0000\n-\nS\n\n\n887\n888\n1\n1\nGraham, Miss. Margaret Edith\nfemale\n19.0\n0\n0\n112053\n30.0000\nB42\nS\n\n\n888\n889\n0\n3\nJohnston, Miss. Catherine Helen \"Carrie\"\nfemale\n-\n1\n2\nW./C. 6607\n23.4500\n-\nS\n\n\n889\n890\n1\n1\nBehr, Mr. Karl Howell\nmale\n26.0\n0\n0\n111369\n30.0000\nC148\nC\n\n\n890\n891\n0\n3\nDooley, Mr. Patrick\nmale\n32.0\n0\n0\n370376\n7.7500\n-\nQ\n\n\n\n\n891 rows × 12 columns\n\n\n\n\ndf.describe()\n\n\n\n\n\n\n\n\npassenger_id\nsurvived\npclass\nsib_sp\nparch\nfare\n\n\n\n\ncount\n891.000000\n891.000000\n891.000000\n891.000000\n891.000000\n891.000000\n\n\nmean\n446.000000\n0.383838\n2.308642\n0.523008\n0.381594\n32.204208\n\n\nstd\n257.353842\n0.486592\n0.836071\n1.102743\n0.806057\n49.693429\n\n\nmin\n1.000000\n0.000000\n1.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n223.500000\n0.000000\n2.000000\n0.000000\n0.000000\n7.910400\n\n\n50%\n446.000000\n0.000000\n3.000000\n0.000000\n0.000000\n14.454200\n\n\n75%\n668.500000\n1.000000\n3.000000\n1.000000\n0.000000\n31.000000\n\n\nmax\n891.000000\n1.000000\n3.000000\n8.000000\n6.000000\n512.329200\n\n\n\n\n\n\n\n\nsum_table = df.describe().round(2)\nsum_table\n\n\n\n\n\n\n\n\npassenger_id\nsurvived\npclass\nsib_sp\nparch\nfare\n\n\n\n\ncount\n891.00\n891.00\n891.00\n891.00\n891.00\n891.00\n\n\nmean\n446.00\n0.38\n2.31\n0.52\n0.38\n32.20\n\n\nstd\n257.35\n0.49\n0.84\n1.10\n0.81\n49.69\n\n\nmin\n1.00\n0.00\n1.00\n0.00\n0.00\n0.00\n\n\n25%\n223.50\n0.00\n2.00\n0.00\n0.00\n7.91\n\n\n50%\n446.00\n0.00\n3.00\n0.00\n0.00\n14.45\n\n\n75%\n668.50\n1.00\n3.00\n1.00\n0.00\n31.00\n\n\nmax\n891.00\n1.00\n3.00\n8.00\n6.00\n512.33\n\n\n\n\n\n\n\n\ndf.dropna()\n\n\n\n\n\n\n\n\npassenger_id\nsurvived\npclass\nname\nsex\nage\nsib_sp\nparch\nticket\nfare\ncabin\nembarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\n-\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\n-\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\n-\nS\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n887\n0\n2\nMontvila, Rev. Juozas\nmale\n27.0\n0\n0\n211536\n13.0000\n-\nS\n\n\n887\n888\n1\n1\nGraham, Miss. Margaret Edith\nfemale\n19.0\n0\n0\n112053\n30.0000\nB42\nS\n\n\n888\n889\n0\n3\nJohnston, Miss. Catherine Helen \"Carrie\"\nfemale\n-\n1\n2\nW./C. 6607\n23.4500\n-\nS\n\n\n889\n890\n1\n1\nBehr, Mr. Karl Howell\nmale\n26.0\n0\n0\n111369\n30.0000\nC148\nC\n\n\n890\n891\n0\n3\nDooley, Mr. Patrick\nmale\n32.0\n0\n0\n370376\n7.7500\n-\nQ\n\n\n\n\n891 rows × 12 columns"
  },
  {
    "objectID": "homework.html",
    "href": "homework.html",
    "title": "Lecture1-code-basics",
    "section": "",
    "text": "(code-basics)= # Coding Basics\nIn this chapter, you’ll learn about the basics of objects, types, operations, conditions, loops, functions, and imports. These are the basic building blocks of almost all programming languages and will serve you well for your coding and economics journey.\nThis chapter has benefited from the excellent Python Programming for Data Science book by Tomas Beuzen.\nRemember, you can launch this page interactively by using the 'Colab' button under the rocket symbol (&lt;i class=\"fas fa-rocket\"&gt;&lt;/i&gt;) at the top of the page. You can also download this page as a Jupyter Notebook to run on your own computer: use the 'download .ipynb' button under the download symbol the top of the page and open that file using Visual Studio Code.\n\n\nIt’s worth saying at the outset that no-one memorises half of the stuff you’ll see in this book. 80% or more of time spent programming is actually time spent looking up how to do this or that online, ‘debugging’ a code for errors, or testing code. This applies to all programmers, regardless of level. You are here to learn the skills and concepts of programming, not the precise syntax (which is easy to look up later).\n\n\n\nxkcd-what-did-you-see\n\n\nKnowing how to Google is one of the most important skills of any coder. No-one remembers every function from every library. Here are some useful coding resources:\n\nwhen you have an error, look on Stack Overflow to see if anyone else had the same error (they probably did) and how they overcame it.\nif you’re having trouble navigating a new package or library, look up the documentation online. The best libraries put as much effort into documentation as they do the code base.\nuse cheat sheets to get on top of a range of functionality quickly. For instance, this excellent (mostly) base Python Cheat Sheet.\nif you’re having a coding issue, take a walk to think about the problem, or explain your problem to an animal toy on your desk (traditionally a rubber duck, but other animals are available).\n\n\n\n\nLet’s review some basics in the interests of getting you up to speed as quickly as possible. You can use Python as a calculator:\n\nprint(1 / 200 * 30)\nprint((59 + 73 + 2) / 3)\n\n0.15\n44.666666666666664\n\n\n\nprint(1 / 200 * 30)\nprint((59 + 73 + 2) / 3)\n\n0.15\n44.666666666666664\n\n\nThe extra package numpy contains many of the additional mathematical operators that you might need. If you don’t already have numpy installed, open up the terminal in Visual Studio Code (go to “Terminal -&gt; New Terminal” and then type pip install numpy into the terminal then hit return). Once you have numpy installed, you can import it and use it like this:\n\nimport numpy as np\n\nprint(np.sin(np.pi / 2))\n\n1.0\n\n\n\nimport numpy as np\n\nprint(np.sin(np.pi / 2))\n\n1.0\n\n\nYou can create new objects with the assignment operator =. You should think of this as copying the value of whatever is on the right-hand side into the variable on the left-hand side.\n\nx = 3 * 4\nprint(x)\n\n12\n\n\n\nx = 3 * 4\nprint(x)\n\n12\n\n\nThere are several structures in Python that capture multiple objects simultaneously but perhaps the most common is the list, which is designated by square brackets.\n\nprimes = [1, 2, 3, 5, 7, 11, 13]\nprint(primes)\n\n[1, 2, 3, 5, 7, 11, 13]\n\n\n\nprimes = [1, 2, 3, 5, 7, 11, 13]\nprint(primes)\n\n[1, 2, 3, 5, 7, 11, 13]\n\n\nAll Python statements where you create objects (known as assignment statements) have the same form:\nobject_name = value\nWhen reading that code, say “object name gets value” in your head.\n\n\n\nPython will ignore any text after #. This allows to you to write comments, text that is ignored by Python but can be read by other humans. We’ll sometimes include comments in examples explaining what’s happening with the code.\nComments can be helpful for briefly describing what the subsequent code does.\n\n# define primes\nprimes = [1, 2, 3, 5, 7, 11, 13]\n# multiply primes by 2\n[el * 2 for el in primes]\n\n[2, 4, 6, 10, 14, 22, 26]\n\n\n\n# define primes\nprimes = [1, 2, 3, 5, 7, 11, 13]\n# multiply primes by 2\n[el * 2 for el in primes]\n\n[2, 4, 6, 10, 14, 22, 26]\n\n\nWith short pieces of code like this, it is not necessary to leave a command for every single line of code and you should try to use informative names wherever you can because these help readers of your code (likely to be you in the future) understand what is going on!\n\n\n\nYou can always inspect an already-created object by typing its name into the interactive window:\n\nprimes\n\n[1, 2, 3, 5, 7, 11, 13]\n\n\n\nprimes\n\n[1, 2, 3, 5, 7, 11, 13]\n\n\nIf you want to know what type of object it is, use type(object) in the interactive window like this:\n\ntype(primes)\n\nlist\n\n\n\ntype(primes)\n\nlist\n\n\nVisual Studio Code has some powerful features to help you keep track of objects:\n\nAt the top of your interactive window, you should see a ‘Variables’ button. Click it to see a panel appear with all variables that you’ve defined.\nHover your mouse over variables you’ve previously entered into the interactive window; you will see a pop-up that tells you what type of object it is.\nIf you start typing a variable name into the interactive window, Visual Studio Code will try to auto-complete the name for you. Press the ‘tab’ key on your keyboard to accept the top option.\n\n\n\n\nIf you’re an economist, you hardly need to be told you what a function is. In coding, it’s much the same as in mathematics: a function has inputs, it performs its function, and it returns any outputs. Python has a large number of built-in functions. You can also import functions from packages (like we did with np.sin) or define your own.\nIn coding, a function has inputs, it performs its function, and it returns any outputs. Let’s see a simple example of using a built-in function, sum():\n\nsum(primes)\n\n42\n\n\n\nsum(primes)\n\n42\n\n\nThe general structure of functions is the function name, followed by brackets, followed by one or more arguments. Sometimes there will also be keyword arguments. For example, sum() comes with a keyword argument that tells the function to start counting from a specific number. Let’s see this in action by starting from ten:\n\nsum(primes, start=10)\n\n52\n\n\n\nsum(primes, start=10)\n\n52\n\n\nIf you’re ever unsure of what a function does, you can call help() on it (itself a function):\n\nhelp(sum)\n\nHelp on built-in function sum in module builtins:\n\nsum(iterable, /, start=0)\n    Return the sum of a 'start' value (default: 0) plus an iterable of numbers\n\n    When the iterable is empty, return the start value.\n    This function is intended specifically for use with numeric values and may\n    reject non-numeric types.\n\n\n\n\nhelp(sum)\n\nHelp on built-in function sum in module builtins:\n\nsum(iterable, /, start=0)\n    Return the sum of a 'start' value (default: 0) plus an iterable of numbers\n\n    When the iterable is empty, return the start value.\n    This function is intended specifically for use with numeric values and may\n    reject non-numeric types.\n\n\n\nOr, in Visual Studio Code, hover your mouse over the function name.\n````unxpefgkyezn Exercise\nWhy does this code not work?\nmy_variable = 10\nmy_varıable\nLook carefully! This may seem like an exercise in pointlessness, but training your brain to notice even the tiniest difference will pay off when programming.\n\n## Values, variables, and types\n\nA value is datum such as a number or text. There are different types of values: 352.3 is known as a float or double, 22 is an integer, and \"Hello World!\" is a string. A variable is a name that refers to a value: you can think of a variable as a box that has a value, or multiple values, packed inside it. \n\nAlmost any word can be a variable name as long as it starts with a letter or an underscore, although there are some special keywords that can't be used because they already have a role in the Python language: these include `if`, `while`, `class`, and `lambda`.\n\nCreating a variable in Python is achieved via an assignment (putting a value in the box), and this assignment is done via the `=` operator. The box, or variable, goes on the left while the value we wish to store appears on the right. It's simpler than it sounds:\n\n::: {#209ef434 .cell execution_count=136}\n``` {.python .cell-code}\na = 10\nprint(a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n10\n```\n:::\n:::\n\n\n::: {#9fb86f40 .cell execution_count=137}\n``` {.python .cell-code}\na = 10\nprint(a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n10\n```\n:::\n:::\n\n\nThis creates a variable `a`, assigns the value 10 to it, and prints it. Sometimes you will hear variables referred to as *objects*. Everything that is not a literal value, such as `10`, is an object. In the above example, `a` is an object that has been assigned the value `10`.\n\nHow about this:\n\n::: {#63c32d9b .cell execution_count=138}\n``` {.python .cell-code}\nb = \"This is a string\"\nprint(b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a string\n```\n:::\n:::\n\n\n::: {#3ae64a36 .cell execution_count=139}\n``` {.python .cell-code}\nb = \"This is a string\"\nprint(b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a string\n```\n:::\n:::\n\n\nIt's the same thing but with a different **type** of data, a string instead of an integer. Python is *dynamically typed*, which means it will guess what type of variable you're creating as you create it. This has pros and cons, with the main pro being that it makes for more concise code.\n\n```{admonition} Important\nEverything is an object, and every object has a type.\n```\n\nThe most basic built-in data types that you'll need to know about are: integers `10`, floats `1.23`, strings `like this`, booleans `True`, and nothing `None`. Python also has a built-in type called a list `[10, 15, 20]` that can contain anything, even *different* types. So\n\n::: {#ad23883a .cell execution_count=140}\n``` {.python .cell-code}\nlist_example = [10, 1.23, \"like this\", True, None]\nprint(list_example)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[10, 1.23, 'like this', True, None]\n```\n:::\n:::\n\n\n::: {#0bdc4bf2 .cell execution_count=141}\n``` {.python .cell-code}\nlist_example = [10, 1.23, \"like this\", True, None]\nprint(list_example)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[10, 1.23, 'like this', True, None]\n```\n:::\n:::\n\n\nis completely valid code. `None` is a special type of nothingness, and represents an object with no value. It has type `NoneType` and is more useful than you might think! \n\nAs well as the built-in types, packages can define their own custom types. If you ever want to check the type of a Python variable, you can call the `type()` function on it like so:\n\n::: {#46a517ee .cell execution_count=142}\n``` {.python .cell-code}\ntype(list_example)\n```\n\n::: {.cell-output .cell-output-display execution_count=142}\n```\nlist\n```\n:::\n:::\n\n\nThis is especially useful for debugging `ValueError` messages.\n\nBelow is a table of common data types in Python:\n\n| Name          | Type name  | Type Category  | Description                                   | Example                                    |\n| :-------------------- | :--------- | :------------- | :-------------------------------------------- | :----------------------------------------- |\n| integer               | `int`      | Numeric Type   | positive/negative whole numbers               | `22`                                       |\n| floating point number | `float`    | Numeric Type   | real number in decimal form                   | `3.14159`                                  |\n| boolean               | `bool`     | Boolean Values | true or false                                 | `True`                                     |\n| string                | `str`      | Sequence Type  | text                                          | `\"Hello World!\"`                 |\n| list                  | `list`     | Sequence Type  | a collection of objects - mutable & ordered   | `['text entry', True, 16]`               |\n| tuple                 | `tuple`    | Sequence Type  | a collection of objects - immutable & ordered | `(51.02, -0.98)`                 |\n| dictionary            | `dict`     | Mapping Type   | mapping of key-value pairs                    | `{'name':'Ada', 'subject':'computer science'}` |\n| none                  | `NoneType` | Null Object    | represents no value                           | `None`                                     |\n| function                  | `function` | Function   | Represents a function                           | `def add_one(x): return x+1`                                     |\n\n````{admonition} Exercise\nWhat type is this Python object?\n\n```python\ncities_to_temps = {\"Paris\": 32, \"London\": 22, \"Seville\": 36, \"Wellesley\": 29}\n```\n\nWhat type is the first key (hint: comma separated entries form key-value pairs)?\n\n\nYou may notice that there are several kinds of brackets that appear in the code we’ve seen so far, including [], {}, and (). These can play different roles depending on the context, but the most common uses are:\n\n[] is used to denote a list, eg ['a', 'b'], or to signify accessing a position using an index, eg vector[0] to get the first entry of a variable called vector.\n{} is used to denote a set, eg {'a', 'b'}, or a dictionary (with pairs of terms), eg {'first_letter': 'a', 'second_letter': 'b'}.\n() is used to denote a tuple, eg ('a', 'b'), or the arguments to a function, eg function(x) where x is the input passed to the function, or to indicate the order operations are carried out.\n\n\n\n\n\nLists are a really useful way to work with lots of data at once. They’re defined with square brackets, with entries separated by commas. You can also construct them by appending entries:\n\nlist_example.append(\"one more entry\")\nprint(list_example)\n\n[10, 1.23, 'like this', True, None, 'one more entry']\n\n\n\nlist_example.append(\"one more entry\")\nprint(list_example)\n\n[10, 1.23, 'like this', True, None, 'one more entry', 'one more entry']\n\n\nAnd you can access earlier entries using an index, which begins at 0 and ends at one less than the length of the list (this is the convention in many programming languages). For instance, to print specific entries at the start, using 0, and end, using -1:\n\nprint(list_example[0])\nprint(list_example[-1])\n\n10\none more entry\n\n\n\nprint(list_example[0])\nprint(list_example[-1])\n\n10\none more entry\n\n\nunxpefgkyezn Exercise How might you access the penultimate entry in a list object if you didn't know how many elements it had?\nAs well as accessing positions in lists using indexing, you can use slices on lists. This uses the colon character, :, to stand in for ‘from the beginning’ or ‘until the end’ (when only appearing once). For instance, to print just the last two entries, we would use the index -2: to mean from the second-to-last onwards. Here are two distinct examples: getting the first three and last three entries to be successively printed:\n\nprint(list_example[:3])\nprint(list_example[-3:])\n\n[10, 1.23, 'like this']\n[None, 'one more entry', 'one more entry']\n\n\nSlicing can be even more elaborate than that because we can jump entries using a second colon. Here’s a full example that begins at the second entry (remember the index starts at 0), runs up until the second-to-last entry (exclusive), and jumps every other entry inbetween (range just produces a list of integers from the value to one less than the last):\n\nlist_of_numbers = list(range(1, 11))\nstart = 1\nstop = -1\nstep = 2\nprint(list_of_numbers[start:stop:step])\n\n[2, 4, 6, 8]\n\n\n\nlist_of_numbers = list(range(1, 11))\nstart = 1\nstop = -1\nstep = 2\nprint(list_of_numbers[start:stop:step])\n\n[2, 4, 6, 8]\n\n\nA handy trick is that you can print a reversed list entirely using double colons:\n\nprint(list_of_numbers[::-1])\n\n[10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n\n\n\nprint(list_of_numbers[::-1])\n\n[10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n\n\nunxpefgkyezn Exercise Slice the `list_example` from earlier to get only the first five entries.\nAs noted, lists can hold any type, including other lists! Here’s a valid example of a list that’s got a lot going on:\n\nwacky_list = [\n    3.1415,\n    16,\n    [\"five\", 4, 3],\n    (91, 93, 90),\n    \"Hello World!\",\n    True,\n    None,\n    {\"key\": \"value\", \"key2\": \"value2\"},\n]\nwacky_list\n\n[3.1415,\n 16,\n ['five', 4, 3],\n (91, 93, 90),\n 'Hello World!',\n True,\n None,\n {'key': 'value', 'key2': 'value2'}]\n\n\n\nwacky_list = [\n    3.1415,\n    16,\n    [\"five\", 4, 3],\n    (91, 93, 90),\n    \"Hello World!\",\n    True,\n    None,\n    {\"key\": \"value\", \"key2\": \"value2\"},\n]\nwacky_list\n\n[3.1415,\n 16,\n ['five', 4, 3],\n (91, 93, 90),\n 'Hello World!',\n True,\n None,\n {'key': 'value', 'key2': 'value2'}]\n\n\nIn reality, it’s usually not a good idea to mix data types in a list, but Python is very flexible. Other iterables (objects composed of multiple elements, of which the list is just one in Python) can also store objects of different types.\nunxpefgkyezn Exercise Can you identify the types of each of the entries in `wacky_list`?\n\n\n\nAll of the basic operators you see in mathematics are available to use: + for addition, - for subtraction, * for multiplication, ** for powers, / for division, and % for modulo. These work as you’d expect on numbers. But these operators are sometimes defined for other built-in data types too. For instance, we can ‘sum’ strings (which really concatenates them):\n\nstring_one = \"This is an example \"\nstring_two = \"of string concatenation\"\nstring_full = string_one + string_two\nprint(string_full)\n\nThis is an example of string concatenation\n\n\n\nstring_one = \"This is an example \"\nstring_two = \"of string concatenation\"\nstring_full = string_one + string_two\nprint(string_full)\n\nThis is an example of string concatenation\n\n\nIt works for lists too:\n\nlist_one = [\"apples\", \"oranges\"]\nlist_two = [\"pears\", \"satsumas\"]\nlist_full = list_one + list_two\nprint(list_full)\n\n['apples', 'oranges', 'pears', 'satsumas']\n\n\n\nlist_one = [\"apples\", \"oranges\"]\nlist_two = [\"pears\", \"satsumas\"]\nlist_full = list_one + list_two\nprint(list_full)\n\n['apples', 'oranges', 'pears', 'satsumas']\n\n\nPerhaps more surprisingly, you can multiply strings!\n\nstring = \"apples, \"\nprint(string * 3)\n\napples, apples, apples, \n\n\n\nstring = \"apples, \"\nprint(string * 3)\n\napples, apples, apples, \n\n\nBelow is a table of the basic arithmetic operations.\n\n\n\nOperator\nDescription\n\n\n\n\n+\naddition\n\n\n-\nsubtraction\n\n\n*\nmultiplication\n\n\n/\ndivision\n\n\n**\nexponentiation\n\n\n//\ninteger division / floor division\n\n\n%\nmodulo\n\n\n@\nmatrix multiplication\n\n\n\nAs well as the usual operators, Python supports assignment operators. An example of one is x+=3, which is equivalent to running x = x + 3. Pretty much all of the operators can be used in this way.\n```unxpefgkyezn Exercise Using Python operations only, what is\n$ $\n\n## Strings\n\nIn some ways, strings are treated a bit like lists, meaning you can access the individual characters via slicing and indexing. For example:\n\n::: {#4507b65c .cell execution_count=160}\n``` {.python .cell-code}\nstring = \"cheesecake\"\nprint(string[-4:])\n\ncake\n\n\nSource: Coding Basics\n\nstring = \"cheesecake\"\nprint(string[-4:])\n\ncake\n\n\nBoth lists and strings will also allow you to use the len() command to get their length:\n\nstring = \"cheesecake\"\nprint(\"String has length:\")\nprint(len(string))\nlist_of_numbers = range(1, 20)\nprint(\"List of numbers has length:\")\nprint(len(list_of_numbers))\n\nString has length:\n10\nList of numbers has length:\n19\n\n\n\nstring = \"cheesecake\"\nprint(\"String has length:\")\nprint(len(string))\nlist_of_numbers = range(1, 20)\nprint(\"List of numbers has length:\")\nprint(len(list_of_numbers))\n\nString has length:\n10\nList of numbers has length:\n19\n\n\nunxpefgkyezn Exercise What is the `len` of a list created by `range(n)` where `n` could be any integer?\nStrings have type string and can be defined by single or double quotes, eg string = \"cheesecake\" would have been equally valid above. It’s best practice to use one convention and stick to it, and most people use double quotes for strings.\nThere are various functions built into Python to help you work with strings that are particularly useful for cleaning messy data. For example, imagine you have a variable name like ‘This Is /A Variable’. (You may think this is implausibly bad; if only that were true…). Let’s see if we can clean this up:\n\nstring = \"This Is /A Variable   \"\nstring = string.replace(\"/\", \"\").rstrip().lower()\nprint(string)\n\nthis is a variable\n\n\n\nstring = \"This Is /A Variable   \"\nstring = string.replace(\"/\", \"\").rstrip().lower()\nprint(string)\n\nthis is a variable\n\n\nThe steps above replace the character ‘/’, strip out whitespace on the right hand-side of the string, and put everything in lower case. The brackets after the words signify that a function has been applied; we’ll see more of functions later.\nunxpefgkyezn Exercise Using string operations, strip the leading and trailing spaces, make upper case, and remove the underscores from the string `\"    this_is_a_better_variable_name   \"`.\nChanging Type to String\nWe’ll look at this in more detail shortly, but while we’re on strings, it seems useful to mention it now: you’ll often want to output one type of data as another, and Python generally knows what you’re trying to achieve if you, for example, print() a boolean value. For numbers, there are more options and you can see a big list of advice on string formatting of all kinds of things here. For now, let’s just see a simple example of something called an f-string, a string that combines a number and a string (these begin with an f for formatting):\n\nvalue = 20\nsqrt_val = 20 ** 0.5\nprint(f\"The square root of {value:d} is {sqrt_val:.2f}\")\n\nThe square root of 20 is 4.47\n\n\n\nvalue = 20\nsqrt_val = 20 ** 0.5\nprint(f\"The square root of {value:d} is {sqrt_val:.2f}\")\n\nThe square root of 20 is 4.47\n\n\nThe formatting command :d is an instruction to treat value like an integer, while :.2f is an instruction to print it like a float with 2 decimal places.\nf-strings are only available in Python 3.6+\nunxpefgkyezn Exercise Write a print command with the `sqrt_val` expressed to 3 decimal places.\n\n\nSome of the most important operations you will perform are with True and False values, also known as boolean data types. There are two types of operation that are associated with booleans: boolean operations, in which existing booleans are combined, and condition operations, which create a boolean when executed.\nBoolean operators that return booleans are as follows:\n\n\n\nOperator\nDescription\n\n\n\n\nx and y\nare x and y both True?\n\n\nx or y\nis at least one of x and y True?\n\n\nnot x\nis x False?\n\n\n\nThese behave as you’d expect: True and False evaluates to False, while True or False evaluates to True. There’s also the not keyword. For example\n\nnot True\n\nFalse\n\n\n\nnot True\n\nFalse\n\n\nas you would expect.\nConditions are expressions that evaluate as booleans. A simple example is 10 == 20. The == is an operator that compares the objects on either side and returns True if they have the same values–though be careful using it with different data types.\nHere’s a table of conditions that return booleans:\n\n\n\nOperator\nDescription\n\n\n\n\nx == y\nis x equal to y?\n\n\nx != y\nis x not equal to y?\n\n\nx &gt; y\nis x greater than y?\n\n\nx &gt;= y\nis x greater than or equal to y?\n\n\nx &lt; y\nis x less than y?\n\n\nx &lt;= y\nis x less than or equal to y?\n\n\nx is y\nis x the same object as y?\n\n\n\nAs you can see from the table, the opposite of == is !=, which you can read as ‘not equal to the value of’. Here’s an example of ==:\n\nboolean_condition = 10 == 20\nprint(boolean_condition)\n\nFalse\n\n\n\nboolean_condition = 10 == 20\nprint(boolean_condition)\n\nFalse\n\n\nunxpefgkyezn Exercise What does `not (not True)` evaluate to?\nThe real power of conditions comes when we start to use them in more complex examples. Some of the keywords that evaluate conditions are if, else, and, or, in, not, and is. Here’s an example showing how some of these conditional keywords work:\n\nname = \"Ada\"\nscore = 99\n\nif name == \"Ada\" and score &gt; 90:\n    print(\"Ada, you achieved a high score.\")\n\nif name == \"Smith\" or score &gt; 90:\n    print(\"You could be called Smith or have a high score\")\n\nif name != \"Smith\" and score &gt; 90:\n    print(\"You are not called Smith and you have a high score\")\n\nAda, you achieved a high score.\nYou could be called Smith or have a high score\nYou are not called Smith and you have a high score\n\n\n\nname = \"Ada\"\nscore = 99\n\nif name == \"Ada\" and score &gt; 90:\n    print(\"Ada, you achieved a high score.\")\n\nif name == \"Smith\" or score &gt; 90:\n    print(\"You could be called Smith or have a high score\")\n\nif name != \"Smith\" and score &gt; 90:\n    print(\"You are not called Smith and you have a high score\")\n\nAda, you achieved a high score.\nYou could be called Smith or have a high score\nYou are not called Smith and you have a high score\n\n\nAll three of these conditions evaluate as True, and so all three messages get printed. Given that == and != test for equality and not equal, respectively, you may be wondering what the keywords is and not are for. Remember that everything in Python is an object, and that values can be assigned to objects. == and != compare values, while is and not compare objects. For example,\n\nname_list = [\"Ada\", \"Adam\"]\nname_list_two = [\"Ada\", \"Adam\"]\n\n# Compare values\nprint(name_list == name_list_two)\n\n# Compare objects\nprint(name_list is name_list_two)\n\nTrue\nFalse\n\n\n\nname_list = [\"Ada\", \"Adam\"]\nname_list_two = [\"Ada\", \"Adam\"]\n\n# Compare values\nprint(name_list == name_list_two)\n\n# Compare objects\nprint(name_list is name_list_two)\n\nTrue\nFalse\n\n\nNote that code with lots of branching if statements is not very helpful to you or to anyone else who reads your code. Some automatic code checkers will pick this up and tell you that your code is too complex. Almost all of the time, there’s a way to rewrite your code without lots of branching logic that will be better and clearer than having many nested if statements.\nOne of the most useful conditional keywords is in. This one must pop up ten times a day in most coders’ lives because it can pick out a variable or make sure something is where it’s supposed to be.\n\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nprint(\"Lovelace\" in name_list)\n\nprint(\"Bob\" in name_list)\n\nTrue\nFalse\n\n\n\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nprint(\"Lovelace\" in name_list)\n\nprint(\"Bob\" in name_list)\n\nTrue\nFalse\n\n\nunxpefgkyezn Exercise Check if \"a\" is in the string \"Walloping weasels\" using `in`. Is \"a\" `in` \"Anodyne\"?\nThe opposite is not in.\nFinally, one conditional construct you’re bound to use at some point, is the if…else structure:\n\nscore = 98\n\nif score == 100:\n    print(\"Top marks!\")\nelif score &gt; 90 and score &lt; 100:\n    print(\"High score!\")\nelif score &gt; 10 and score &lt;= 90:\n    pass\nelse:\n    print(\"Better luck next time.\")\n\nHigh score!\n\n\n\nscore = 98\n\nif score == 100:\n    print(\"Top marks!\")\nelif score &gt; 90 and score &lt; 100:\n    print(\"High score!\")\nelif score &gt; 10 and score &lt;= 90:\n    pass\nelse:\n    print(\"Better luck next time.\")\n\nHigh score!\n\n\nNote that this does nothing if the score is between 11 and 90, and prints a message otherwise.\nunxpefgkyezn Exercise Create a new `if` ... `elif` ... `else` statement that prints \"well done\" if a score is over 90, \"good\" if between 40 and 90, and \"bad luck\" otherwise.\nOne nice feature of Python is that you can make multiple boolean comparisons in a single line.\n\na, b = 3, 6\n\n1 &lt; a &lt; b &lt; 20\n\nTrue\n\n\n\na, b = 3, 6\n\n1 &lt; a &lt; b &lt; 20\n\nTrue\n\n\n\n\n\nYou’ll have seen that certain parts of the code examples are indented. Code that is part of a function, a conditional clause, or loop is indented. This isn’t a code style choice, it’s actually what tells the language that some code is to be executed as part of, say, a loop and not to executed after the loop is finished.\nHere’s a basic example of indentation as part of an if loop. The print() statement that is indented only executes if the condition evaluates to true.\n\nx = 10\n\nif x &gt; 2:\n    print(\"x is greater than 2\")\n\nx is greater than 2\n\n\n\nx = 10\n\nif x &gt; 2:\n    print(\"x is greater than 2\")\n\nx is greater than 2\n\n\nThe VS Code extension *indent-rainbow* colours different levels of indentation differently for ease of reading.\nWhen functions, conditional clauses, or loops are combined together, they each cause an increase in the level of indentation. Here’s a double indent.\n\nif x &gt; 2:\n    print(\"outer conditional cause\")\n    for i in range(4):\n        print(\"inner loop\")\n\nouter conditional cause\ninner loop\ninner loop\ninner loop\ninner loop\n\n\n\nif x &gt; 2:\n    print(\"outer conditional cause\")\n    for i in range(4):\n        print(\"inner loop\")\n\nouter conditional cause\ninner loop\ninner loop\ninner loop\ninner loop\n\n\nThe standard practice for indentation is that each sub-statement should be indented by 4 spaces. It can be hard to keep track of these but, as usual, Visual Studio Code has you covered. Go to Settings (the cog in the bottom left-hand corner, then click Settings) and type ‘Whitespace’ into the search bar. Under ‘Editor: Render Whitespace’, select ‘boundary’. This will show any whitespace that is more than one character long using faint grey dots. Each level of indentation in your Python code should now begin with four grey dots showing that it consists of four spaces.\nRendering whitespace using Visual Studio Code's settings makes it easier to navigate different levels of indentation.\nunxpefgkyezn Exercise Try writing a code snippet that reaches the triple level of indentation.\n\n\n\nAnother built-in Python type that is enormously useful is the dictionary. This provides a mapping one set of variables to another (either one-to-one or many-to-one). Let’s see an example of defining a dictionary and using it:\n\nfruit_dict = {\n    \"Jazz\": \"Apple\",\n    \"Owari\": \"Satsuma\",\n    \"Seto\": \"Satsuma\",\n    \"Pink Lady\": \"Apple\",\n}\n\n# Add an entry\nfruit_dict.update({\"Cox\": \"Apple\"})\n\nvariety_list = [\"Jazz\", \"Jazz\", \"Seto\", \"Cox\"]\n\nfruit_list = [fruit_dict[x] for x in variety_list]\nprint(fruit_list)\n\n['Apple', 'Apple', 'Satsuma', 'Apple']\n\n\n\nfruit_dict = {\n    \"Jazz\": \"Apple\",\n    \"Owari\": \"Satsuma\",\n    \"Seto\": \"Satsuma\",\n    \"Pink Lady\": \"Apple\",\n}\n\n# Add an entry\nfruit_dict.update({\"Cox\": \"Apple\"})\n\nvariety_list = [\"Jazz\", \"Jazz\", \"Seto\", \"Cox\"]\n\nfruit_list = [fruit_dict[x] for x in variety_list]\nprint(fruit_list)\n\n['Apple', 'Apple', 'Satsuma', 'Apple']\n\n\nFrom an input list of varieties, we get an output list of their associated fruits. Another good trick to know with dictionaries is that you can iterate through their keys and values:\n\nfruit_dict = {\n    \"Jazz\": \"Apple\",\n    \"Owari\": \"Satsuma\",\n    \"Seto\": \"Satsuma\",\n    \"Pink Lady\": \"Apple\",\n}\n\n# Add an entry\nfruit_dict.update({\"Cox\": \"Apple\"})\n\nvariety_list = [\"Jazz\", \"Jazz\", \"Seto\", \"Cox\"]\n\nfruit_list = [fruit_dict[x] for x in variety_list]\nprint(fruit_list)\n\nJazz maps into Apple\nOwari maps into Satsuma\nSeto maps into Satsuma\nPink Lady maps into Apple\nCox maps into Apple\n\n\nunxpefgkyezn Exercise Update the fruit dictionary with another two entries and then iterate through all of the entries printing each mapping using `.items()` as above.\n\n\n\nA loop is a way of executing a similar piece of code over and over in a similar way. The most useful loops are for loops and list comprehensions.\nA for loop does something for the time that the condition is satisfied. For example,\n\nname_list = [\"Lovelace\", \"Smith\", \"Pigou\", \"Babbage\"]\n\nfor name in name_list:\n    print(name)\n\nLovelace\nSmith\nPigou\nBabbage\n\n\n\nname_list = [\"Lovelace\", \"Smith\", \"Pigou\", \"Babbage\"]\n\nfor name in name_list:\n    print(name)\n\nLovelace\nSmith\nPigou\nBabbage\n\n\nprints out a name until all names have been printed out. Note the colon after the statement and before the indent.\nAs long as your object is an iterable (ie you can iterate over it), then it can be used in this way in a for loop. The most common examples are lists and tuples, but you can also iterate over strings (in which case each character is selected in turn). One gotcha to be aware of is if you iterate over a string, say “hello”, instead of iterating over a list (or tuple) of strings, eg [\"hello\"]. In the latter case, you get:\n\nfor entry in [\"hello\"]:\n    print(entry)\n    print(\"---end entry---\")\n\nhello\n---end entry---\n\n\n\nfor entry in [\"hello\"]:\n    print(entry)\n    print(\"---end entry---\")\n\nhello\n---end entry---\n\n\nWhile in the former you get something quite different and typically not all that useful:\n\nfor entry in \"hello\":\n    print(entry)\n    print(\"---end entry---\")\n\nh\n---end entry---\ne\n---end entry---\nl\n---end entry---\nl\n---end entry---\no\n---end entry---\n\n\n\nfor entry in \"hello\":\n    print(entry)\n    print(\"---end entry---\")\n\nh\n---end entry---\ne\n---end entry---\nl\n---end entry---\nl\n---end entry---\no\n---end entry---\n\n\nunxpefgkyezn Exercise Write a for loop that prints out \"coding for economists\" so that each word is printed in a successive iteration.\nA useful trick with for loops is the enumerate keyword, which runs through an index that keeps track of the place of items in a list:\n\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nfor i, name in enumerate(name_list):\n    print(f\"The name in position {i} is {name}\")\n\nThe name in position 0 is Lovelace\nThe name in position 1 is Smith\nThe name in position 2 is Hopper\nThe name in position 3 is Babbage\n\n\n\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nfor i, name in enumerate(name_list):\n    print(f\"The name in position {i} is {name}\")\n\nThe name in position 0 is Lovelace\nThe name in position 1 is Smith\nThe name in position 2 is Hopper\nThe name in position 3 is Babbage\n\n\nRemember, Python indexes from 0 so the first entry of i will be zero. But, if you’d like to index from a different number, you can:\n\nfor i, name in enumerate(name_list, start=1):\n    print(f\"The name in position {i} is {name}\")\n\nThe name in position 1 is Lovelace\nThe name in position 2 is Smith\nThe name in position 3 is Hopper\nThe name in position 4 is Babbage\n\n\n\nfor i, name in enumerate(name_list, start=1):\n    print(f\"The name in position {i} is {name}\")\n\nThe name in position 1 is Lovelace\nThe name in position 2 is Smith\nThe name in position 3 is Hopper\nThe name in position 4 is Babbage\n\n\nAnother useful pattern when doing for loops with dictionaries is iteration over key, value pairs. As we saw earlier, what distinguishes a dictionary in Python is that it maps a key to a value, for example “apple” might map to “fruit”. Let’s take our example from earlier that mapped cities to temperatures. If we wanted to iterate over both keys and values, we can write a for loop like this:\n\ncities_to_temps = {\"Paris\": 28, \"London\": 22, \"Seville\": 36, \"Wellesley\": 29}\n\nfor key, value in cities_to_temps.items():\n    print(f\"In {key}, the temperature is {value} degrees C today.\")\n\nIn Paris, the temperature is 28 degrees C today.\nIn London, the temperature is 22 degrees C today.\nIn Seville, the temperature is 36 degrees C today.\nIn Wellesley, the temperature is 29 degrees C today.\n\n\n\ncities_to_temps = {\"Paris\": 28, \"London\": 22, \"Seville\": 36, \"Wellesley\": 29}\n\nfor key, value in cities_to_temps.items():\n    print(f\"In {key}, the temperature is {value} degrees C today.\")\n\nIn Paris, the temperature is 28 degrees C today.\nIn London, the temperature is 22 degrees C today.\nIn Seville, the temperature is 36 degrees C today.\nIn Wellesley, the temperature is 29 degrees C today.\n\n\nNote that we added .items() to the end of the dictionary. And note that we didn’t have to call the key key, or the value value: these are set by their position. But part of best practice in writing code is that there should be no surprises, and writing key, value makes it really clear that you’re using values from a dictionary.\nunxpefgkyezn Exercise Write a dictionary that maps four cities you know into their respective countries and print the results using the `key, value` iteration trick.\nAnother useful type of for loop is provided by the zip() function. You can think of the zip() function as being like a zipper, bringing elements from two different iterators together in turn. Here’s an example:\n\nfirst_names = [\"Ada\", \"Adam\", \"Grace\", \"Charles\"]\nlast_names = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nfor forename, surname in zip(first_names, last_names):\n    print(f\"{forename} {surname}\")\n\nAda Lovelace\nAdam Smith\nGrace Hopper\nCharles Babbage\n\n\n\nfirst_names = [\"Ada\", \"Adam\", \"Grace\", \"Charles\"]\nlast_names = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nfor forename, surname in zip(first_names, last_names):\n    print(f\"{forename} {surname}\")\n\nAda Lovelace\nAdam Smith\nGrace Hopper\nCharles Babbage\n\n\nThe zip function is super useful in practice.\n``unxpefgkyezn Exercise Zip together the first names from above with this jumbled list of surnames:[‘Babbage’, ‘Hopper’, ‘Smith’, ‘Lovelace’]`.\n(Hint: you have seen a trick to help re-arrange lists earlier on in the Chapter.)\n\n**List (and Other) Comprehensions**\n\nThere's a second way to do loops in Python and, in most but [not all](https://towardsdatascience.com/list-comprehensions-vs-for-loops-it-is-not-what-you-think-34071d4d8207) [cases](https://stackoverflow.com/questions/22108488/are-list-comprehensions-and-functional-functions-faster-than-for-loops), they run faster. More importantly, and *this* is the reason it's good practice to use them where possible, they are very readable. They are called *list comprehensions*.\n\nList comprehensions can combine what a `for` loop and (if needed) what a `condition` do in a single line of code. First, let's look at a `for` loop that adds one to each value done as a list comprehension (NB: in practice, we would use super-fast **numpy** arrays for this kind of operation):\n\n::: {#50814e5f .cell execution_count=202}\n``` {.python .cell-code}\nnum_list = range(50, 60)\n[1 + num for num in num_list]\n\n[51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n\n:::\n\nnum_list = range(50, 60)\n[1 + num for num in num_list]\n\n[51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n\n\nThe general pattern is a bit similar to with the for loop but there are some differences. There’s no colon, and no indenting. The syntax is “do something with x” then for x in iterable. Finally, the expression is wrapped in a [ and ] to make the output a list.\nNote that lists are not the only wrapping you can provide to this kind of structure. A ( and ) to make it a generator (don’t worry about what this is for now), a { and } to make it a set (an object that only contains unique values), or it’s possible to create a dictionary from a comprehension too! List comprehensions are the most common, so if you only remember one kind, remember them.\n```unxpefgkyezn Exercise Create a list comprehension that multiplies numbers in the range from 1 to 10 by 5.\nDid you get the range right?\n\nLet's now see how to include a condition within a list comprehension. Say we had a list of numbers and wanted to filter it according to whether the numbers divided by 3 or not using the modulo operator:\n\n::: {#4fafa2be .cell execution_count=204}\n``` {.python .cell-code}\nnumber_list = range(1, 40)\ndivide_list = [x for x in number_list if x % 3 == 0]\nprint(divide_list)\n\n[3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39]\n\n:::\n\nnumber_list = range(1, 40)\ndivide_list = [x for x in number_list if x % 3 == 0]\nprint(divide_list)\n\n[3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39]\n\n\nThe syntax here is do something to x for x in something if x satisfies some condition.\nHere’s another example that picks out only the names that include ‘Smith’ in them:\n\nnames_list = [\"Joe Bloggs\", \"Adam Smith\", \"Sandra Noone\", \"leonara smith\"]\nsmith_list = [x for x in names_list if \"smith\" in x.lower()]\nprint(smith_list)\n\n['Adam Smith', 'leonara smith']\n\n\n\nnames_list = [\"Joe Bloggs\", \"Adam Smith\", \"Sandra Noone\", \"leonara smith\"]\nsmith_list = [x for x in names_list if \"smith\" in x.lower()]\nprint(smith_list)\n\n['Adam Smith', 'leonara smith']\n\n\nNote how we used ‘smith’ rather than ‘Smith’ and then used lower() to ensure we matched names regardless of the case they are written in.\nWe can even do a whole if … else construct inside a list comprehension:\n\nnames_list = [\"Joe Bloggs\", \"Adam Smith\", \"Sandra Noone\", \"leonara smith\"]\nsmith_list = [x if \"smith\" in x.lower() else \"Not Smith!\" for x in names_list]\nprint(smith_list)\n\n['Not Smith!', 'Adam Smith', 'Not Smith!', 'leonara smith']\n\n\n\nnames_list = [\"Joe Bloggs\", \"Adam Smith\", \"Sandra Noone\", \"leonara smith\"]\nsmith_list = [x if \"smith\" in x.lower() else \"Not Smith!\" for x in names_list]\nprint(smith_list)\n\n['Not Smith!', 'Adam Smith', 'Not Smith!', 'leonara smith']\n\n\nMany of the constructs we’ve seen can be combined. For instance, there is no reason why we can’t have a nested or repeated list comprehension using zip(), and, perhaps more surprisingly, sometimes these are useful!\n\nfirst_names = [\"Ada\", \"Adam\", \"Grace\", \"Charles\"]\nlast_names = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\nnames_list = [x + \" \" + y for x, y in zip(first_names, last_names)]\nprint(names_list)\n\n['Ada Lovelace', 'Adam Smith', 'Grace Hopper', 'Charles Babbage']\n\n\n\nfirst_names = [\"Ada\", \"Adam\", \"Grace\", \"Charles\"]\nlast_names = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\nnames_list = [x + \" \" + y for x, y in zip(first_names, last_names)]\nprint(names_list)\n\n['Ada Lovelace', 'Adam Smith', 'Grace Hopper', 'Charles Babbage']\n\n\nAn even more extreme use of list comprehensions can deliver nested structures:\n\nfirst_names = [\"Ada\", \"Adam\"]\nlast_names = [\"Lovelace\", \"Smith\"]\nnames_list = [[x + \" \" + y for x in first_names] for y in last_names]\nprint(names_list)\n\n[['Ada Lovelace', 'Adam Lovelace'], ['Ada Smith', 'Adam Smith']]\n\n\n\nfirst_names = [\"Ada\", \"Adam\"]\nlast_names = [\"Lovelace\", \"Smith\"]\nnames_list = [[x + \" \" + y for x in first_names] for y in last_names]\nprint(names_list)\n\n[['Ada Lovelace', 'Adam Lovelace'], ['Ada Smith', 'Adam Smith']]\n\n\nThis gives a nested structure that (in this case) iterates over first_names first, and then last_names. (Note that this object is a list of lists of strings!)\nLet’s see a dictionary comprehension now. These look a bit similar to set comprehensions because they use { and } at either end but they are different because they come with a colon separating the keys from the values:\n\n{key: value for key, value in zip(first_names, last_names)}\n\n{'Ada': 'Lovelace', 'Adam': 'Smith'}\n\n\n\n{key: value for key, value in zip(first_names, last_names)}\n\n{'Ada': 'Lovelace', 'Adam': 'Smith'}\n\n\nunxpefgkyezn Exercise Create a nested list comprehension that results in a list of lists of strings equal to `[['a0', 'b0', 'c0'], ['a1', 'b1', 'c1'], ['a2', 'b2', 'c2']]` (ie a combination of the first three integers and letters of the alphabet). You may find that you need to convert numbers to strings using `str(x)` to do this.\nIf you’d like to learn more about list comprehensions, check out these short video tutorials.\n\n\n\nDeclaring a function starts with a def keyword for ‘define a function’. It then has a name, followed by brackets, (), which may contain function arguments and function keyword arguments. This is followed by a colon. The body of the function is then indented relative to the left-most text. Function arguments are defined in brackets following the name, with different inputs separated by commas. Any outputs are given with the return keyword, again with different variables separated by commas.\n```unxpefgkyezn Arguments and keyword arguments :class: tip\narguments are the variables that functions always need, so a and b in def add(a, b): return a + b. The function won’t work without them! Function arguments are sometimes referred to as args.\nKeyword arguments are the variables that are optional for functions, so c in def add(a, b, c=5): return a + b - c. If you do not provide a value for c when calling the function, it will automatically revert to c=5. Keyword arguments are sometimes referred to as kwargs.\n\nLet's see a very simple example of a function with a single *argument* (or arg):\n\n::: {#0450ad6c .cell execution_count=11}\n``` {.python .cell-code}\ndef welcome_message(name):\n    return f\"Hello {name}, and welcome!\"\n\n\n# Without indentation, this code is not part of function\nname = \"Ada\"\noutput_string = welcome_message(name)\nprint(output_string)\n\nHello Ada, and welcome!\n\n:::\n\ndef welcome_message(name):\n    return f\"Hello {name}, and welcome!\"\n\n\n# Without indentation, this code is not part of function\nname = \"Ada\"\noutput_string = welcome_message(name)\nprint(output_string)\n\nHello Ada, and welcome!\n\n\nOne powerful feature of functions is that we can define defaults for the input arguments. These are called keyword arguments (or kwargs). Let’s see that in action by defining a default value for name, along with multiple outputs–a hello message and a score.\n\ndef score_message(score, name=\"student\"):\n    \"\"\"This is a doc-string, a string describing a function.\n    Args:\n        score (float): Raw score\n        name (str): Name of student\n    Returns:\n        str: A hello message.\n        float: A normalised score.\n    \"\"\"\n    norm_score = (score - 50) / 10\n    return f\"Hello {name}\", norm_score\n\n\n# Without indentation, this code is not part of function\nname = \"Ada\"\nscore = 98\n# No name entered\nprint(score_message(score))\n# Name entered\nprint(score_message(score, name=name))\n\n('Hello student', 4.8)\n('Hello Ada', 4.8)\n\n\n\ndef score_message(score, name=\"student\"):\n    \"\"\"This is a doc-string, a string describing a function.\n    Args:\n        score (float): Raw score\n        name (str): Name of student\n    Returns:\n        str: A hello message.\n        float: A normalised score.\n    \"\"\"\n    norm_score = (score - 50) / 10\n    return f\"Hello {name}\", norm_score\n\n\n# Without indentation, this code is not part of function\nname = \"Ada\"\nscore = 98\n# No name entered\nprint(score_message(score))\n# Name entered\nprint(score_message(score, name=name))\n\n('Hello student', 4.8)\n('Hello Ada', 4.8)\n\n\nunxpefgkyezn Exercise What is the return type of a function with multiple return values separated by commas following the `return` statement?\nIn that last example, you’ll notice that we added some text to the function. This is a doc-string, or documentation string. It’s there to help users (and, most likely, future you) to understand what the function does. Let’s see how this works in action by calling help() on the score_message function:\n\nhelp(score_message)\n\nHelp on function score_message in module __main__:\n\nscore_message(score, name='student')\n    This is a doc-string, a string describing a function.\n    Args:\n        score (float): Raw score\n        name (str): Name of student\n    Returns:\n        str: A hello message.\n        float: A normalised score.\n\n\n\n\nhelp(score_message)\n\nHelp on function score_message in module __main__:\n\nscore_message(score, name='student')\n    This is a doc-string, a string describing a function.\n    Args:\n        score (float): Raw score\n        name (str): Name of student\n    Returns:\n        str: A hello message.\n        float: A normalised score.\n\n\n\n```unxpefgkyezn Exercise Write a function that returns a high five unicode character if the input is equal to “coding for economists” and a sad face, “:-/” otherwise.\nAdd a second argument that takes a default argument of an empty string but, if used, is added (concatenated) to the return message. Use it to create the return output, “:-/ here is my message.”\nWrite a doc-string for your function and call help on it.\n\nTo learn more about args and kwargs, check out these [short video tutorials](https://calmcode.io/args-kwargs/introduction.html).\n\n## Scope\n\nScope refers to what parts of your code can see what other parts. There are three different scopes to bear in mind: local, global, and non-local.\n\n**Local**\n\nIf you define a variable inside a function, the rest of your code won't be able to 'see' it or use it. For example, here's a function that creates a variable and then an example of calling that variable:\n\n```python\ndef var_func():\n    str_variable = 'Hello World!'\n\nvar_func()\nprint(str_variable)\nThis would raise an error, because as far as your general code is concerned str_variable doesn’t exist outside of the function. This is an example of a local variable, one that only exists within a function.\nIf you want to create variables inside a function and have them persist, you need to explicitly pass them out using, for example return str_variable like this:\n\ndef var_func():\n    str_variable = \"Hello World!\"\n    return str_variable\n\n\nreturned_var = var_func()\nprint(returned_var)\n\nHello World!\n\n\n\ndef var_func():\n    str_variable = \"Hello World!\"\n    return str_variable\n\n\nreturned_var = var_func()\nprint(returned_var)\n\nHello World!\n\n\nGlobal\nA variable declared outside of a function is known as a global variable because it is accessible everywhere:\n\ny = \"I'm a global variable\"\n\ndef print_y():\n    print(\"y is inside a function:\", y)\n\n\nprint_y()\nprint(\"y is outside a function:\", y)\n\ny is inside a function: I'm a global variable\ny is outside a function: I'm a global variable\n\n\n\ny = \"I'm a global variable\"\n\ndef print_y():\n    print(\"y is inside a function:\", y)\n\n\nprint_y()\nprint(\"y is outside a function:\", y)\n\ny is inside a function: I'm a global variable\ny is outside a function: I'm a global variable\n\n\nThis is just a taster of what can be done using base Python with few extra packages. For more, especially if you’ve done other chapters in the book already and want to go a bit deeper, see the Chapter on {ref}code-advanced. Otherwise, head on to the next chapter!\n:::"
  },
  {
    "objectID": "homework.html#if-you-get-stuck",
    "href": "homework.html#if-you-get-stuck",
    "title": "Lecture1-code-basics",
    "section": "",
    "text": "It’s worth saying at the outset that no-one memorises half of the stuff you’ll see in this book. 80% or more of time spent programming is actually time spent looking up how to do this or that online, ‘debugging’ a code for errors, or testing code. This applies to all programmers, regardless of level. You are here to learn the skills and concepts of programming, not the precise syntax (which is easy to look up later).\n\n\n\nxkcd-what-did-you-see\n\n\nKnowing how to Google is one of the most important skills of any coder. No-one remembers every function from every library. Here are some useful coding resources:\n\nwhen you have an error, look on Stack Overflow to see if anyone else had the same error (they probably did) and how they overcame it.\nif you’re having trouble navigating a new package or library, look up the documentation online. The best libraries put as much effort into documentation as they do the code base.\nuse cheat sheets to get on top of a range of functionality quickly. For instance, this excellent (mostly) base Python Cheat Sheet.\nif you’re having a coding issue, take a walk to think about the problem, or explain your problem to an animal toy on your desk (traditionally a rubber duck, but other animals are available)."
  },
  {
    "objectID": "homework.html#coding-basics",
    "href": "homework.html#coding-basics",
    "title": "Lecture1-code-basics",
    "section": "",
    "text": "Let’s review some basics in the interests of getting you up to speed as quickly as possible. You can use Python as a calculator:\n\nprint(1 / 200 * 30)\nprint((59 + 73 + 2) / 3)\n\n0.15\n44.666666666666664\n\n\n\nprint(1 / 200 * 30)\nprint((59 + 73 + 2) / 3)\n\n0.15\n44.666666666666664\n\n\nThe extra package numpy contains many of the additional mathematical operators that you might need. If you don’t already have numpy installed, open up the terminal in Visual Studio Code (go to “Terminal -&gt; New Terminal” and then type pip install numpy into the terminal then hit return). Once you have numpy installed, you can import it and use it like this:\n\nimport numpy as np\n\nprint(np.sin(np.pi / 2))\n\n1.0\n\n\n\nimport numpy as np\n\nprint(np.sin(np.pi / 2))\n\n1.0\n\n\nYou can create new objects with the assignment operator =. You should think of this as copying the value of whatever is on the right-hand side into the variable on the left-hand side.\n\nx = 3 * 4\nprint(x)\n\n12\n\n\n\nx = 3 * 4\nprint(x)\n\n12\n\n\nThere are several structures in Python that capture multiple objects simultaneously but perhaps the most common is the list, which is designated by square brackets.\n\nprimes = [1, 2, 3, 5, 7, 11, 13]\nprint(primes)\n\n[1, 2, 3, 5, 7, 11, 13]\n\n\n\nprimes = [1, 2, 3, 5, 7, 11, 13]\nprint(primes)\n\n[1, 2, 3, 5, 7, 11, 13]\n\n\nAll Python statements where you create objects (known as assignment statements) have the same form:\nobject_name = value\nWhen reading that code, say “object name gets value” in your head."
  },
  {
    "objectID": "homework.html#comments",
    "href": "homework.html#comments",
    "title": "Lecture1-code-basics",
    "section": "",
    "text": "Python will ignore any text after #. This allows to you to write comments, text that is ignored by Python but can be read by other humans. We’ll sometimes include comments in examples explaining what’s happening with the code.\nComments can be helpful for briefly describing what the subsequent code does.\n\n# define primes\nprimes = [1, 2, 3, 5, 7, 11, 13]\n# multiply primes by 2\n[el * 2 for el in primes]\n\n[2, 4, 6, 10, 14, 22, 26]\n\n\n\n# define primes\nprimes = [1, 2, 3, 5, 7, 11, 13]\n# multiply primes by 2\n[el * 2 for el in primes]\n\n[2, 4, 6, 10, 14, 22, 26]\n\n\nWith short pieces of code like this, it is not necessary to leave a command for every single line of code and you should try to use informative names wherever you can because these help readers of your code (likely to be you in the future) understand what is going on!"
  },
  {
    "objectID": "homework.html#keeping-track-of-variables",
    "href": "homework.html#keeping-track-of-variables",
    "title": "Lecture1-code-basics",
    "section": "",
    "text": "You can always inspect an already-created object by typing its name into the interactive window:\n\nprimes\n\n[1, 2, 3, 5, 7, 11, 13]\n\n\n\nprimes\n\n[1, 2, 3, 5, 7, 11, 13]\n\n\nIf you want to know what type of object it is, use type(object) in the interactive window like this:\n\ntype(primes)\n\nlist\n\n\n\ntype(primes)\n\nlist\n\n\nVisual Studio Code has some powerful features to help you keep track of objects:\n\nAt the top of your interactive window, you should see a ‘Variables’ button. Click it to see a panel appear with all variables that you’ve defined.\nHover your mouse over variables you’ve previously entered into the interactive window; you will see a pop-up that tells you what type of object it is.\nIf you start typing a variable name into the interactive window, Visual Studio Code will try to auto-complete the name for you. Press the ‘tab’ key on your keyboard to accept the top option."
  },
  {
    "objectID": "homework.html#calling-functions",
    "href": "homework.html#calling-functions",
    "title": "Lecture1-code-basics",
    "section": "",
    "text": "If you’re an economist, you hardly need to be told you what a function is. In coding, it’s much the same as in mathematics: a function has inputs, it performs its function, and it returns any outputs. Python has a large number of built-in functions. You can also import functions from packages (like we did with np.sin) or define your own.\nIn coding, a function has inputs, it performs its function, and it returns any outputs. Let’s see a simple example of using a built-in function, sum():\n\nsum(primes)\n\n42\n\n\n\nsum(primes)\n\n42\n\n\nThe general structure of functions is the function name, followed by brackets, followed by one or more arguments. Sometimes there will also be keyword arguments. For example, sum() comes with a keyword argument that tells the function to start counting from a specific number. Let’s see this in action by starting from ten:\n\nsum(primes, start=10)\n\n52\n\n\n\nsum(primes, start=10)\n\n52\n\n\nIf you’re ever unsure of what a function does, you can call help() on it (itself a function):\n\nhelp(sum)\n\nHelp on built-in function sum in module builtins:\n\nsum(iterable, /, start=0)\n    Return the sum of a 'start' value (default: 0) plus an iterable of numbers\n\n    When the iterable is empty, return the start value.\n    This function is intended specifically for use with numeric values and may\n    reject non-numeric types.\n\n\n\n\nhelp(sum)\n\nHelp on built-in function sum in module builtins:\n\nsum(iterable, /, start=0)\n    Return the sum of a 'start' value (default: 0) plus an iterable of numbers\n\n    When the iterable is empty, return the start value.\n    This function is intended specifically for use with numeric values and may\n    reject non-numeric types.\n\n\n\nOr, in Visual Studio Code, hover your mouse over the function name.\n````unxpefgkyezn Exercise\nWhy does this code not work?\nmy_variable = 10\nmy_varıable\nLook carefully! This may seem like an exercise in pointlessness, but training your brain to notice even the tiniest difference will pay off when programming.\n\n## Values, variables, and types\n\nA value is datum such as a number or text. There are different types of values: 352.3 is known as a float or double, 22 is an integer, and \"Hello World!\" is a string. A variable is a name that refers to a value: you can think of a variable as a box that has a value, or multiple values, packed inside it. \n\nAlmost any word can be a variable name as long as it starts with a letter or an underscore, although there are some special keywords that can't be used because they already have a role in the Python language: these include `if`, `while`, `class`, and `lambda`.\n\nCreating a variable in Python is achieved via an assignment (putting a value in the box), and this assignment is done via the `=` operator. The box, or variable, goes on the left while the value we wish to store appears on the right. It's simpler than it sounds:\n\n::: {#209ef434 .cell execution_count=136}\n``` {.python .cell-code}\na = 10\nprint(a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n10\n```\n:::\n:::\n\n\n::: {#9fb86f40 .cell execution_count=137}\n``` {.python .cell-code}\na = 10\nprint(a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n10\n```\n:::\n:::\n\n\nThis creates a variable `a`, assigns the value 10 to it, and prints it. Sometimes you will hear variables referred to as *objects*. Everything that is not a literal value, such as `10`, is an object. In the above example, `a` is an object that has been assigned the value `10`.\n\nHow about this:\n\n::: {#63c32d9b .cell execution_count=138}\n``` {.python .cell-code}\nb = \"This is a string\"\nprint(b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a string\n```\n:::\n:::\n\n\n::: {#3ae64a36 .cell execution_count=139}\n``` {.python .cell-code}\nb = \"This is a string\"\nprint(b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a string\n```\n:::\n:::\n\n\nIt's the same thing but with a different **type** of data, a string instead of an integer. Python is *dynamically typed*, which means it will guess what type of variable you're creating as you create it. This has pros and cons, with the main pro being that it makes for more concise code.\n\n```{admonition} Important\nEverything is an object, and every object has a type.\n```\n\nThe most basic built-in data types that you'll need to know about are: integers `10`, floats `1.23`, strings `like this`, booleans `True`, and nothing `None`. Python also has a built-in type called a list `[10, 15, 20]` that can contain anything, even *different* types. So\n\n::: {#ad23883a .cell execution_count=140}\n``` {.python .cell-code}\nlist_example = [10, 1.23, \"like this\", True, None]\nprint(list_example)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[10, 1.23, 'like this', True, None]\n```\n:::\n:::\n\n\n::: {#0bdc4bf2 .cell execution_count=141}\n``` {.python .cell-code}\nlist_example = [10, 1.23, \"like this\", True, None]\nprint(list_example)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[10, 1.23, 'like this', True, None]\n```\n:::\n:::\n\n\nis completely valid code. `None` is a special type of nothingness, and represents an object with no value. It has type `NoneType` and is more useful than you might think! \n\nAs well as the built-in types, packages can define their own custom types. If you ever want to check the type of a Python variable, you can call the `type()` function on it like so:\n\n::: {#46a517ee .cell execution_count=142}\n``` {.python .cell-code}\ntype(list_example)\n```\n\n::: {.cell-output .cell-output-display execution_count=142}\n```\nlist\n```\n:::\n:::\n\n\nThis is especially useful for debugging `ValueError` messages.\n\nBelow is a table of common data types in Python:\n\n| Name          | Type name  | Type Category  | Description                                   | Example                                    |\n| :-------------------- | :--------- | :------------- | :-------------------------------------------- | :----------------------------------------- |\n| integer               | `int`      | Numeric Type   | positive/negative whole numbers               | `22`                                       |\n| floating point number | `float`    | Numeric Type   | real number in decimal form                   | `3.14159`                                  |\n| boolean               | `bool`     | Boolean Values | true or false                                 | `True`                                     |\n| string                | `str`      | Sequence Type  | text                                          | `\"Hello World!\"`                 |\n| list                  | `list`     | Sequence Type  | a collection of objects - mutable & ordered   | `['text entry', True, 16]`               |\n| tuple                 | `tuple`    | Sequence Type  | a collection of objects - immutable & ordered | `(51.02, -0.98)`                 |\n| dictionary            | `dict`     | Mapping Type   | mapping of key-value pairs                    | `{'name':'Ada', 'subject':'computer science'}` |\n| none                  | `NoneType` | Null Object    | represents no value                           | `None`                                     |\n| function                  | `function` | Function   | Represents a function                           | `def add_one(x): return x+1`                                     |\n\n````{admonition} Exercise\nWhat type is this Python object?\n\n```python\ncities_to_temps = {\"Paris\": 32, \"London\": 22, \"Seville\": 36, \"Wellesley\": 29}\n```\n\nWhat type is the first key (hint: comma separated entries form key-value pairs)?\n\n\nYou may notice that there are several kinds of brackets that appear in the code we’ve seen so far, including [], {}, and (). These can play different roles depending on the context, but the most common uses are:\n\n[] is used to denote a list, eg ['a', 'b'], or to signify accessing a position using an index, eg vector[0] to get the first entry of a variable called vector.\n{} is used to denote a set, eg {'a', 'b'}, or a dictionary (with pairs of terms), eg {'first_letter': 'a', 'second_letter': 'b'}.\n() is used to denote a tuple, eg ('a', 'b'), or the arguments to a function, eg function(x) where x is the input passed to the function, or to indicate the order operations are carried out."
  },
  {
    "objectID": "homework.html#lists-and-slicing",
    "href": "homework.html#lists-and-slicing",
    "title": "Lecture1-code-basics",
    "section": "",
    "text": "Lists are a really useful way to work with lots of data at once. They’re defined with square brackets, with entries separated by commas. You can also construct them by appending entries:\n\nlist_example.append(\"one more entry\")\nprint(list_example)\n\n[10, 1.23, 'like this', True, None, 'one more entry']\n\n\n\nlist_example.append(\"one more entry\")\nprint(list_example)\n\n[10, 1.23, 'like this', True, None, 'one more entry', 'one more entry']\n\n\nAnd you can access earlier entries using an index, which begins at 0 and ends at one less than the length of the list (this is the convention in many programming languages). For instance, to print specific entries at the start, using 0, and end, using -1:\n\nprint(list_example[0])\nprint(list_example[-1])\n\n10\none more entry\n\n\n\nprint(list_example[0])\nprint(list_example[-1])\n\n10\none more entry\n\n\nunxpefgkyezn Exercise How might you access the penultimate entry in a list object if you didn't know how many elements it had?\nAs well as accessing positions in lists using indexing, you can use slices on lists. This uses the colon character, :, to stand in for ‘from the beginning’ or ‘until the end’ (when only appearing once). For instance, to print just the last two entries, we would use the index -2: to mean from the second-to-last onwards. Here are two distinct examples: getting the first three and last three entries to be successively printed:\n\nprint(list_example[:3])\nprint(list_example[-3:])\n\n[10, 1.23, 'like this']\n[None, 'one more entry', 'one more entry']\n\n\nSlicing can be even more elaborate than that because we can jump entries using a second colon. Here’s a full example that begins at the second entry (remember the index starts at 0), runs up until the second-to-last entry (exclusive), and jumps every other entry inbetween (range just produces a list of integers from the value to one less than the last):\n\nlist_of_numbers = list(range(1, 11))\nstart = 1\nstop = -1\nstep = 2\nprint(list_of_numbers[start:stop:step])\n\n[2, 4, 6, 8]\n\n\n\nlist_of_numbers = list(range(1, 11))\nstart = 1\nstop = -1\nstep = 2\nprint(list_of_numbers[start:stop:step])\n\n[2, 4, 6, 8]\n\n\nA handy trick is that you can print a reversed list entirely using double colons:\n\nprint(list_of_numbers[::-1])\n\n[10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n\n\n\nprint(list_of_numbers[::-1])\n\n[10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n\n\nunxpefgkyezn Exercise Slice the `list_example` from earlier to get only the first five entries.\nAs noted, lists can hold any type, including other lists! Here’s a valid example of a list that’s got a lot going on:\n\nwacky_list = [\n    3.1415,\n    16,\n    [\"five\", 4, 3],\n    (91, 93, 90),\n    \"Hello World!\",\n    True,\n    None,\n    {\"key\": \"value\", \"key2\": \"value2\"},\n]\nwacky_list\n\n[3.1415,\n 16,\n ['five', 4, 3],\n (91, 93, 90),\n 'Hello World!',\n True,\n None,\n {'key': 'value', 'key2': 'value2'}]\n\n\n\nwacky_list = [\n    3.1415,\n    16,\n    [\"five\", 4, 3],\n    (91, 93, 90),\n    \"Hello World!\",\n    True,\n    None,\n    {\"key\": \"value\", \"key2\": \"value2\"},\n]\nwacky_list\n\n[3.1415,\n 16,\n ['five', 4, 3],\n (91, 93, 90),\n 'Hello World!',\n True,\n None,\n {'key': 'value', 'key2': 'value2'}]\n\n\nIn reality, it’s usually not a good idea to mix data types in a list, but Python is very flexible. Other iterables (objects composed of multiple elements, of which the list is just one in Python) can also store objects of different types.\nunxpefgkyezn Exercise Can you identify the types of each of the entries in `wacky_list`?"
  },
  {
    "objectID": "homework.html#operators",
    "href": "homework.html#operators",
    "title": "Lecture1-code-basics",
    "section": "",
    "text": "All of the basic operators you see in mathematics are available to use: + for addition, - for subtraction, * for multiplication, ** for powers, / for division, and % for modulo. These work as you’d expect on numbers. But these operators are sometimes defined for other built-in data types too. For instance, we can ‘sum’ strings (which really concatenates them):\n\nstring_one = \"This is an example \"\nstring_two = \"of string concatenation\"\nstring_full = string_one + string_two\nprint(string_full)\n\nThis is an example of string concatenation\n\n\n\nstring_one = \"This is an example \"\nstring_two = \"of string concatenation\"\nstring_full = string_one + string_two\nprint(string_full)\n\nThis is an example of string concatenation\n\n\nIt works for lists too:\n\nlist_one = [\"apples\", \"oranges\"]\nlist_two = [\"pears\", \"satsumas\"]\nlist_full = list_one + list_two\nprint(list_full)\n\n['apples', 'oranges', 'pears', 'satsumas']\n\n\n\nlist_one = [\"apples\", \"oranges\"]\nlist_two = [\"pears\", \"satsumas\"]\nlist_full = list_one + list_two\nprint(list_full)\n\n['apples', 'oranges', 'pears', 'satsumas']\n\n\nPerhaps more surprisingly, you can multiply strings!\n\nstring = \"apples, \"\nprint(string * 3)\n\napples, apples, apples, \n\n\n\nstring = \"apples, \"\nprint(string * 3)\n\napples, apples, apples, \n\n\nBelow is a table of the basic arithmetic operations.\n\n\n\nOperator\nDescription\n\n\n\n\n+\naddition\n\n\n-\nsubtraction\n\n\n*\nmultiplication\n\n\n/\ndivision\n\n\n**\nexponentiation\n\n\n//\ninteger division / floor division\n\n\n%\nmodulo\n\n\n@\nmatrix multiplication\n\n\n\nAs well as the usual operators, Python supports assignment operators. An example of one is x+=3, which is equivalent to running x = x + 3. Pretty much all of the operators can be used in this way.\n```unxpefgkyezn Exercise Using Python operations only, what is\n$ $\n\n## Strings\n\nIn some ways, strings are treated a bit like lists, meaning you can access the individual characters via slicing and indexing. For example:\n\n::: {#4507b65c .cell execution_count=160}\n``` {.python .cell-code}\nstring = \"cheesecake\"\nprint(string[-4:])\n\ncake"
  },
  {
    "objectID": "homework.html#booleans-and-conditions",
    "href": "homework.html#booleans-and-conditions",
    "title": "Lecture1-code-basics",
    "section": "",
    "text": "Some of the most important operations you will perform are with True and False values, also known as boolean data types. There are two types of operation that are associated with booleans: boolean operations, in which existing booleans are combined, and condition operations, which create a boolean when executed.\nBoolean operators that return booleans are as follows:\n\n\n\nOperator\nDescription\n\n\n\n\nx and y\nare x and y both True?\n\n\nx or y\nis at least one of x and y True?\n\n\nnot x\nis x False?\n\n\n\nThese behave as you’d expect: True and False evaluates to False, while True or False evaluates to True. There’s also the not keyword. For example\n\nnot True\n\nFalse\n\n\n\nnot True\n\nFalse\n\n\nas you would expect.\nConditions are expressions that evaluate as booleans. A simple example is 10 == 20. The == is an operator that compares the objects on either side and returns True if they have the same values–though be careful using it with different data types.\nHere’s a table of conditions that return booleans:\n\n\n\nOperator\nDescription\n\n\n\n\nx == y\nis x equal to y?\n\n\nx != y\nis x not equal to y?\n\n\nx &gt; y\nis x greater than y?\n\n\nx &gt;= y\nis x greater than or equal to y?\n\n\nx &lt; y\nis x less than y?\n\n\nx &lt;= y\nis x less than or equal to y?\n\n\nx is y\nis x the same object as y?\n\n\n\nAs you can see from the table, the opposite of == is !=, which you can read as ‘not equal to the value of’. Here’s an example of ==:\n\nboolean_condition = 10 == 20\nprint(boolean_condition)\n\nFalse\n\n\n\nboolean_condition = 10 == 20\nprint(boolean_condition)\n\nFalse\n\n\nunxpefgkyezn Exercise What does `not (not True)` evaluate to?\nThe real power of conditions comes when we start to use them in more complex examples. Some of the keywords that evaluate conditions are if, else, and, or, in, not, and is. Here’s an example showing how some of these conditional keywords work:\n\nname = \"Ada\"\nscore = 99\n\nif name == \"Ada\" and score &gt; 90:\n    print(\"Ada, you achieved a high score.\")\n\nif name == \"Smith\" or score &gt; 90:\n    print(\"You could be called Smith or have a high score\")\n\nif name != \"Smith\" and score &gt; 90:\n    print(\"You are not called Smith and you have a high score\")\n\nAda, you achieved a high score.\nYou could be called Smith or have a high score\nYou are not called Smith and you have a high score\n\n\n\nname = \"Ada\"\nscore = 99\n\nif name == \"Ada\" and score &gt; 90:\n    print(\"Ada, you achieved a high score.\")\n\nif name == \"Smith\" or score &gt; 90:\n    print(\"You could be called Smith or have a high score\")\n\nif name != \"Smith\" and score &gt; 90:\n    print(\"You are not called Smith and you have a high score\")\n\nAda, you achieved a high score.\nYou could be called Smith or have a high score\nYou are not called Smith and you have a high score\n\n\nAll three of these conditions evaluate as True, and so all three messages get printed. Given that == and != test for equality and not equal, respectively, you may be wondering what the keywords is and not are for. Remember that everything in Python is an object, and that values can be assigned to objects. == and != compare values, while is and not compare objects. For example,\n\nname_list = [\"Ada\", \"Adam\"]\nname_list_two = [\"Ada\", \"Adam\"]\n\n# Compare values\nprint(name_list == name_list_two)\n\n# Compare objects\nprint(name_list is name_list_two)\n\nTrue\nFalse\n\n\n\nname_list = [\"Ada\", \"Adam\"]\nname_list_two = [\"Ada\", \"Adam\"]\n\n# Compare values\nprint(name_list == name_list_two)\n\n# Compare objects\nprint(name_list is name_list_two)\n\nTrue\nFalse\n\n\nNote that code with lots of branching if statements is not very helpful to you or to anyone else who reads your code. Some automatic code checkers will pick this up and tell you that your code is too complex. Almost all of the time, there’s a way to rewrite your code without lots of branching logic that will be better and clearer than having many nested if statements.\nOne of the most useful conditional keywords is in. This one must pop up ten times a day in most coders’ lives because it can pick out a variable or make sure something is where it’s supposed to be.\n\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nprint(\"Lovelace\" in name_list)\n\nprint(\"Bob\" in name_list)\n\nTrue\nFalse\n\n\n\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nprint(\"Lovelace\" in name_list)\n\nprint(\"Bob\" in name_list)\n\nTrue\nFalse\n\n\nunxpefgkyezn Exercise Check if \"a\" is in the string \"Walloping weasels\" using `in`. Is \"a\" `in` \"Anodyne\"?\nThe opposite is not in.\nFinally, one conditional construct you’re bound to use at some point, is the if…else structure:\n\nscore = 98\n\nif score == 100:\n    print(\"Top marks!\")\nelif score &gt; 90 and score &lt; 100:\n    print(\"High score!\")\nelif score &gt; 10 and score &lt;= 90:\n    pass\nelse:\n    print(\"Better luck next time.\")\n\nHigh score!\n\n\n\nscore = 98\n\nif score == 100:\n    print(\"Top marks!\")\nelif score &gt; 90 and score &lt; 100:\n    print(\"High score!\")\nelif score &gt; 10 and score &lt;= 90:\n    pass\nelse:\n    print(\"Better luck next time.\")\n\nHigh score!\n\n\nNote that this does nothing if the score is between 11 and 90, and prints a message otherwise.\nunxpefgkyezn Exercise Create a new `if` ... `elif` ... `else` statement that prints \"well done\" if a score is over 90, \"good\" if between 40 and 90, and \"bad luck\" otherwise.\nOne nice feature of Python is that you can make multiple boolean comparisons in a single line.\n\na, b = 3, 6\n\n1 &lt; a &lt; b &lt; 20\n\nTrue\n\n\n\na, b = 3, 6\n\n1 &lt; a &lt; b &lt; 20\n\nTrue"
  },
  {
    "objectID": "homework.html#indentation",
    "href": "homework.html#indentation",
    "title": "Lecture1-code-basics",
    "section": "",
    "text": "You’ll have seen that certain parts of the code examples are indented. Code that is part of a function, a conditional clause, or loop is indented. This isn’t a code style choice, it’s actually what tells the language that some code is to be executed as part of, say, a loop and not to executed after the loop is finished.\nHere’s a basic example of indentation as part of an if loop. The print() statement that is indented only executes if the condition evaluates to true.\n\nx = 10\n\nif x &gt; 2:\n    print(\"x is greater than 2\")\n\nx is greater than 2\n\n\n\nx = 10\n\nif x &gt; 2:\n    print(\"x is greater than 2\")\n\nx is greater than 2\n\n\nThe VS Code extension *indent-rainbow* colours different levels of indentation differently for ease of reading.\nWhen functions, conditional clauses, or loops are combined together, they each cause an increase in the level of indentation. Here’s a double indent.\n\nif x &gt; 2:\n    print(\"outer conditional cause\")\n    for i in range(4):\n        print(\"inner loop\")\n\nouter conditional cause\ninner loop\ninner loop\ninner loop\ninner loop\n\n\n\nif x &gt; 2:\n    print(\"outer conditional cause\")\n    for i in range(4):\n        print(\"inner loop\")\n\nouter conditional cause\ninner loop\ninner loop\ninner loop\ninner loop\n\n\nThe standard practice for indentation is that each sub-statement should be indented by 4 spaces. It can be hard to keep track of these but, as usual, Visual Studio Code has you covered. Go to Settings (the cog in the bottom left-hand corner, then click Settings) and type ‘Whitespace’ into the search bar. Under ‘Editor: Render Whitespace’, select ‘boundary’. This will show any whitespace that is more than one character long using faint grey dots. Each level of indentation in your Python code should now begin with four grey dots showing that it consists of four spaces.\nRendering whitespace using Visual Studio Code's settings makes it easier to navigate different levels of indentation.\nunxpefgkyezn Exercise Try writing a code snippet that reaches the triple level of indentation."
  },
  {
    "objectID": "homework.html#dictionaries",
    "href": "homework.html#dictionaries",
    "title": "Lecture1-code-basics",
    "section": "",
    "text": "Another built-in Python type that is enormously useful is the dictionary. This provides a mapping one set of variables to another (either one-to-one or many-to-one). Let’s see an example of defining a dictionary and using it:\n\nfruit_dict = {\n    \"Jazz\": \"Apple\",\n    \"Owari\": \"Satsuma\",\n    \"Seto\": \"Satsuma\",\n    \"Pink Lady\": \"Apple\",\n}\n\n# Add an entry\nfruit_dict.update({\"Cox\": \"Apple\"})\n\nvariety_list = [\"Jazz\", \"Jazz\", \"Seto\", \"Cox\"]\n\nfruit_list = [fruit_dict[x] for x in variety_list]\nprint(fruit_list)\n\n['Apple', 'Apple', 'Satsuma', 'Apple']\n\n\n\nfruit_dict = {\n    \"Jazz\": \"Apple\",\n    \"Owari\": \"Satsuma\",\n    \"Seto\": \"Satsuma\",\n    \"Pink Lady\": \"Apple\",\n}\n\n# Add an entry\nfruit_dict.update({\"Cox\": \"Apple\"})\n\nvariety_list = [\"Jazz\", \"Jazz\", \"Seto\", \"Cox\"]\n\nfruit_list = [fruit_dict[x] for x in variety_list]\nprint(fruit_list)\n\n['Apple', 'Apple', 'Satsuma', 'Apple']\n\n\nFrom an input list of varieties, we get an output list of their associated fruits. Another good trick to know with dictionaries is that you can iterate through their keys and values:\n\nfruit_dict = {\n    \"Jazz\": \"Apple\",\n    \"Owari\": \"Satsuma\",\n    \"Seto\": \"Satsuma\",\n    \"Pink Lady\": \"Apple\",\n}\n\n# Add an entry\nfruit_dict.update({\"Cox\": \"Apple\"})\n\nvariety_list = [\"Jazz\", \"Jazz\", \"Seto\", \"Cox\"]\n\nfruit_list = [fruit_dict[x] for x in variety_list]\nprint(fruit_list)\n\nJazz maps into Apple\nOwari maps into Satsuma\nSeto maps into Satsuma\nPink Lady maps into Apple\nCox maps into Apple\n\n\nunxpefgkyezn Exercise Update the fruit dictionary with another two entries and then iterate through all of the entries printing each mapping using `.items()` as above."
  },
  {
    "objectID": "homework.html#loops-and-list-comprehensions",
    "href": "homework.html#loops-and-list-comprehensions",
    "title": "Lecture1-code-basics",
    "section": "",
    "text": "A loop is a way of executing a similar piece of code over and over in a similar way. The most useful loops are for loops and list comprehensions.\nA for loop does something for the time that the condition is satisfied. For example,\n\nname_list = [\"Lovelace\", \"Smith\", \"Pigou\", \"Babbage\"]\n\nfor name in name_list:\n    print(name)\n\nLovelace\nSmith\nPigou\nBabbage\n\n\n\nname_list = [\"Lovelace\", \"Smith\", \"Pigou\", \"Babbage\"]\n\nfor name in name_list:\n    print(name)\n\nLovelace\nSmith\nPigou\nBabbage\n\n\nprints out a name until all names have been printed out. Note the colon after the statement and before the indent.\nAs long as your object is an iterable (ie you can iterate over it), then it can be used in this way in a for loop. The most common examples are lists and tuples, but you can also iterate over strings (in which case each character is selected in turn). One gotcha to be aware of is if you iterate over a string, say “hello”, instead of iterating over a list (or tuple) of strings, eg [\"hello\"]. In the latter case, you get:\n\nfor entry in [\"hello\"]:\n    print(entry)\n    print(\"---end entry---\")\n\nhello\n---end entry---\n\n\n\nfor entry in [\"hello\"]:\n    print(entry)\n    print(\"---end entry---\")\n\nhello\n---end entry---\n\n\nWhile in the former you get something quite different and typically not all that useful:\n\nfor entry in \"hello\":\n    print(entry)\n    print(\"---end entry---\")\n\nh\n---end entry---\ne\n---end entry---\nl\n---end entry---\nl\n---end entry---\no\n---end entry---\n\n\n\nfor entry in \"hello\":\n    print(entry)\n    print(\"---end entry---\")\n\nh\n---end entry---\ne\n---end entry---\nl\n---end entry---\nl\n---end entry---\no\n---end entry---\n\n\nunxpefgkyezn Exercise Write a for loop that prints out \"coding for economists\" so that each word is printed in a successive iteration.\nA useful trick with for loops is the enumerate keyword, which runs through an index that keeps track of the place of items in a list:\n\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nfor i, name in enumerate(name_list):\n    print(f\"The name in position {i} is {name}\")\n\nThe name in position 0 is Lovelace\nThe name in position 1 is Smith\nThe name in position 2 is Hopper\nThe name in position 3 is Babbage\n\n\n\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nfor i, name in enumerate(name_list):\n    print(f\"The name in position {i} is {name}\")\n\nThe name in position 0 is Lovelace\nThe name in position 1 is Smith\nThe name in position 2 is Hopper\nThe name in position 3 is Babbage\n\n\nRemember, Python indexes from 0 so the first entry of i will be zero. But, if you’d like to index from a different number, you can:\n\nfor i, name in enumerate(name_list, start=1):\n    print(f\"The name in position {i} is {name}\")\n\nThe name in position 1 is Lovelace\nThe name in position 2 is Smith\nThe name in position 3 is Hopper\nThe name in position 4 is Babbage\n\n\n\nfor i, name in enumerate(name_list, start=1):\n    print(f\"The name in position {i} is {name}\")\n\nThe name in position 1 is Lovelace\nThe name in position 2 is Smith\nThe name in position 3 is Hopper\nThe name in position 4 is Babbage\n\n\nAnother useful pattern when doing for loops with dictionaries is iteration over key, value pairs. As we saw earlier, what distinguishes a dictionary in Python is that it maps a key to a value, for example “apple” might map to “fruit”. Let’s take our example from earlier that mapped cities to temperatures. If we wanted to iterate over both keys and values, we can write a for loop like this:\n\ncities_to_temps = {\"Paris\": 28, \"London\": 22, \"Seville\": 36, \"Wellesley\": 29}\n\nfor key, value in cities_to_temps.items():\n    print(f\"In {key}, the temperature is {value} degrees C today.\")\n\nIn Paris, the temperature is 28 degrees C today.\nIn London, the temperature is 22 degrees C today.\nIn Seville, the temperature is 36 degrees C today.\nIn Wellesley, the temperature is 29 degrees C today.\n\n\n\ncities_to_temps = {\"Paris\": 28, \"London\": 22, \"Seville\": 36, \"Wellesley\": 29}\n\nfor key, value in cities_to_temps.items():\n    print(f\"In {key}, the temperature is {value} degrees C today.\")\n\nIn Paris, the temperature is 28 degrees C today.\nIn London, the temperature is 22 degrees C today.\nIn Seville, the temperature is 36 degrees C today.\nIn Wellesley, the temperature is 29 degrees C today.\n\n\nNote that we added .items() to the end of the dictionary. And note that we didn’t have to call the key key, or the value value: these are set by their position. But part of best practice in writing code is that there should be no surprises, and writing key, value makes it really clear that you’re using values from a dictionary.\nunxpefgkyezn Exercise Write a dictionary that maps four cities you know into their respective countries and print the results using the `key, value` iteration trick.\nAnother useful type of for loop is provided by the zip() function. You can think of the zip() function as being like a zipper, bringing elements from two different iterators together in turn. Here’s an example:\n\nfirst_names = [\"Ada\", \"Adam\", \"Grace\", \"Charles\"]\nlast_names = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nfor forename, surname in zip(first_names, last_names):\n    print(f\"{forename} {surname}\")\n\nAda Lovelace\nAdam Smith\nGrace Hopper\nCharles Babbage\n\n\n\nfirst_names = [\"Ada\", \"Adam\", \"Grace\", \"Charles\"]\nlast_names = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nfor forename, surname in zip(first_names, last_names):\n    print(f\"{forename} {surname}\")\n\nAda Lovelace\nAdam Smith\nGrace Hopper\nCharles Babbage\n\n\nThe zip function is super useful in practice.\n``unxpefgkyezn Exercise Zip together the first names from above with this jumbled list of surnames:[‘Babbage’, ‘Hopper’, ‘Smith’, ‘Lovelace’]`.\n(Hint: you have seen a trick to help re-arrange lists earlier on in the Chapter.)\n\n**List (and Other) Comprehensions**\n\nThere's a second way to do loops in Python and, in most but [not all](https://towardsdatascience.com/list-comprehensions-vs-for-loops-it-is-not-what-you-think-34071d4d8207) [cases](https://stackoverflow.com/questions/22108488/are-list-comprehensions-and-functional-functions-faster-than-for-loops), they run faster. More importantly, and *this* is the reason it's good practice to use them where possible, they are very readable. They are called *list comprehensions*.\n\nList comprehensions can combine what a `for` loop and (if needed) what a `condition` do in a single line of code. First, let's look at a `for` loop that adds one to each value done as a list comprehension (NB: in practice, we would use super-fast **numpy** arrays for this kind of operation):\n\n::: {#50814e5f .cell execution_count=202}\n``` {.python .cell-code}\nnum_list = range(50, 60)\n[1 + num for num in num_list]\n\n[51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n\n:::\n\nnum_list = range(50, 60)\n[1 + num for num in num_list]\n\n[51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n\n\nThe general pattern is a bit similar to with the for loop but there are some differences. There’s no colon, and no indenting. The syntax is “do something with x” then for x in iterable. Finally, the expression is wrapped in a [ and ] to make the output a list.\nNote that lists are not the only wrapping you can provide to this kind of structure. A ( and ) to make it a generator (don’t worry about what this is for now), a { and } to make it a set (an object that only contains unique values), or it’s possible to create a dictionary from a comprehension too! List comprehensions are the most common, so if you only remember one kind, remember them.\n```unxpefgkyezn Exercise Create a list comprehension that multiplies numbers in the range from 1 to 10 by 5.\nDid you get the range right?\n\nLet's now see how to include a condition within a list comprehension. Say we had a list of numbers and wanted to filter it according to whether the numbers divided by 3 or not using the modulo operator:\n\n::: {#4fafa2be .cell execution_count=204}\n``` {.python .cell-code}\nnumber_list = range(1, 40)\ndivide_list = [x for x in number_list if x % 3 == 0]\nprint(divide_list)\n\n[3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39]\n\n:::\n\nnumber_list = range(1, 40)\ndivide_list = [x for x in number_list if x % 3 == 0]\nprint(divide_list)\n\n[3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39]\n\n\nThe syntax here is do something to x for x in something if x satisfies some condition.\nHere’s another example that picks out only the names that include ‘Smith’ in them:\n\nnames_list = [\"Joe Bloggs\", \"Adam Smith\", \"Sandra Noone\", \"leonara smith\"]\nsmith_list = [x for x in names_list if \"smith\" in x.lower()]\nprint(smith_list)\n\n['Adam Smith', 'leonara smith']\n\n\n\nnames_list = [\"Joe Bloggs\", \"Adam Smith\", \"Sandra Noone\", \"leonara smith\"]\nsmith_list = [x for x in names_list if \"smith\" in x.lower()]\nprint(smith_list)\n\n['Adam Smith', 'leonara smith']\n\n\nNote how we used ‘smith’ rather than ‘Smith’ and then used lower() to ensure we matched names regardless of the case they are written in.\nWe can even do a whole if … else construct inside a list comprehension:\n\nnames_list = [\"Joe Bloggs\", \"Adam Smith\", \"Sandra Noone\", \"leonara smith\"]\nsmith_list = [x if \"smith\" in x.lower() else \"Not Smith!\" for x in names_list]\nprint(smith_list)\n\n['Not Smith!', 'Adam Smith', 'Not Smith!', 'leonara smith']\n\n\n\nnames_list = [\"Joe Bloggs\", \"Adam Smith\", \"Sandra Noone\", \"leonara smith\"]\nsmith_list = [x if \"smith\" in x.lower() else \"Not Smith!\" for x in names_list]\nprint(smith_list)\n\n['Not Smith!', 'Adam Smith', 'Not Smith!', 'leonara smith']\n\n\nMany of the constructs we’ve seen can be combined. For instance, there is no reason why we can’t have a nested or repeated list comprehension using zip(), and, perhaps more surprisingly, sometimes these are useful!\n\nfirst_names = [\"Ada\", \"Adam\", \"Grace\", \"Charles\"]\nlast_names = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\nnames_list = [x + \" \" + y for x, y in zip(first_names, last_names)]\nprint(names_list)\n\n['Ada Lovelace', 'Adam Smith', 'Grace Hopper', 'Charles Babbage']\n\n\n\nfirst_names = [\"Ada\", \"Adam\", \"Grace\", \"Charles\"]\nlast_names = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\nnames_list = [x + \" \" + y for x, y in zip(first_names, last_names)]\nprint(names_list)\n\n['Ada Lovelace', 'Adam Smith', 'Grace Hopper', 'Charles Babbage']\n\n\nAn even more extreme use of list comprehensions can deliver nested structures:\n\nfirst_names = [\"Ada\", \"Adam\"]\nlast_names = [\"Lovelace\", \"Smith\"]\nnames_list = [[x + \" \" + y for x in first_names] for y in last_names]\nprint(names_list)\n\n[['Ada Lovelace', 'Adam Lovelace'], ['Ada Smith', 'Adam Smith']]\n\n\n\nfirst_names = [\"Ada\", \"Adam\"]\nlast_names = [\"Lovelace\", \"Smith\"]\nnames_list = [[x + \" \" + y for x in first_names] for y in last_names]\nprint(names_list)\n\n[['Ada Lovelace', 'Adam Lovelace'], ['Ada Smith', 'Adam Smith']]\n\n\nThis gives a nested structure that (in this case) iterates over first_names first, and then last_names. (Note that this object is a list of lists of strings!)\nLet’s see a dictionary comprehension now. These look a bit similar to set comprehensions because they use { and } at either end but they are different because they come with a colon separating the keys from the values:\n\n{key: value for key, value in zip(first_names, last_names)}\n\n{'Ada': 'Lovelace', 'Adam': 'Smith'}\n\n\n\n{key: value for key, value in zip(first_names, last_names)}\n\n{'Ada': 'Lovelace', 'Adam': 'Smith'}\n\n\nunxpefgkyezn Exercise Create a nested list comprehension that results in a list of lists of strings equal to `[['a0', 'b0', 'c0'], ['a1', 'b1', 'c1'], ['a2', 'b2', 'c2']]` (ie a combination of the first three integers and letters of the alphabet). You may find that you need to convert numbers to strings using `str(x)` to do this.\nIf you’d like to learn more about list comprehensions, check out these short video tutorials."
  },
  {
    "objectID": "homework.html#writing-functions",
    "href": "homework.html#writing-functions",
    "title": "Lecture1-code-basics",
    "section": "",
    "text": "Declaring a function starts with a def keyword for ‘define a function’. It then has a name, followed by brackets, (), which may contain function arguments and function keyword arguments. This is followed by a colon. The body of the function is then indented relative to the left-most text. Function arguments are defined in brackets following the name, with different inputs separated by commas. Any outputs are given with the return keyword, again with different variables separated by commas.\n```unxpefgkyezn Arguments and keyword arguments :class: tip\narguments are the variables that functions always need, so a and b in def add(a, b): return a + b. The function won’t work without them! Function arguments are sometimes referred to as args.\nKeyword arguments are the variables that are optional for functions, so c in def add(a, b, c=5): return a + b - c. If you do not provide a value for c when calling the function, it will automatically revert to c=5. Keyword arguments are sometimes referred to as kwargs.\n\nLet's see a very simple example of a function with a single *argument* (or arg):\n\n::: {#0450ad6c .cell execution_count=11}\n``` {.python .cell-code}\ndef welcome_message(name):\n    return f\"Hello {name}, and welcome!\"\n\n\n# Without indentation, this code is not part of function\nname = \"Ada\"\noutput_string = welcome_message(name)\nprint(output_string)\n\nHello Ada, and welcome!\n\n:::\n\ndef welcome_message(name):\n    return f\"Hello {name}, and welcome!\"\n\n\n# Without indentation, this code is not part of function\nname = \"Ada\"\noutput_string = welcome_message(name)\nprint(output_string)\n\nHello Ada, and welcome!\n\n\nOne powerful feature of functions is that we can define defaults for the input arguments. These are called keyword arguments (or kwargs). Let’s see that in action by defining a default value for name, along with multiple outputs–a hello message and a score.\n\ndef score_message(score, name=\"student\"):\n    \"\"\"This is a doc-string, a string describing a function.\n    Args:\n        score (float): Raw score\n        name (str): Name of student\n    Returns:\n        str: A hello message.\n        float: A normalised score.\n    \"\"\"\n    norm_score = (score - 50) / 10\n    return f\"Hello {name}\", norm_score\n\n\n# Without indentation, this code is not part of function\nname = \"Ada\"\nscore = 98\n# No name entered\nprint(score_message(score))\n# Name entered\nprint(score_message(score, name=name))\n\n('Hello student', 4.8)\n('Hello Ada', 4.8)\n\n\n\ndef score_message(score, name=\"student\"):\n    \"\"\"This is a doc-string, a string describing a function.\n    Args:\n        score (float): Raw score\n        name (str): Name of student\n    Returns:\n        str: A hello message.\n        float: A normalised score.\n    \"\"\"\n    norm_score = (score - 50) / 10\n    return f\"Hello {name}\", norm_score\n\n\n# Without indentation, this code is not part of function\nname = \"Ada\"\nscore = 98\n# No name entered\nprint(score_message(score))\n# Name entered\nprint(score_message(score, name=name))\n\n('Hello student', 4.8)\n('Hello Ada', 4.8)\n\n\nunxpefgkyezn Exercise What is the return type of a function with multiple return values separated by commas following the `return` statement?\nIn that last example, you’ll notice that we added some text to the function. This is a doc-string, or documentation string. It’s there to help users (and, most likely, future you) to understand what the function does. Let’s see how this works in action by calling help() on the score_message function:\n\nhelp(score_message)\n\nHelp on function score_message in module __main__:\n\nscore_message(score, name='student')\n    This is a doc-string, a string describing a function.\n    Args:\n        score (float): Raw score\n        name (str): Name of student\n    Returns:\n        str: A hello message.\n        float: A normalised score.\n\n\n\n\nhelp(score_message)\n\nHelp on function score_message in module __main__:\n\nscore_message(score, name='student')\n    This is a doc-string, a string describing a function.\n    Args:\n        score (float): Raw score\n        name (str): Name of student\n    Returns:\n        str: A hello message.\n        float: A normalised score.\n\n\n\n```unxpefgkyezn Exercise Write a function that returns a high five unicode character if the input is equal to “coding for economists” and a sad face, “:-/” otherwise.\nAdd a second argument that takes a default argument of an empty string but, if used, is added (concatenated) to the return message. Use it to create the return output, “:-/ here is my message.”\nWrite a doc-string for your function and call help on it.\n\nTo learn more about args and kwargs, check out these [short video tutorials](https://calmcode.io/args-kwargs/introduction.html).\n\n## Scope\n\nScope refers to what parts of your code can see what other parts. There are three different scopes to bear in mind: local, global, and non-local.\n\n**Local**\n\nIf you define a variable inside a function, the rest of your code won't be able to 'see' it or use it. For example, here's a function that creates a variable and then an example of calling that variable:\n\n```python\ndef var_func():\n    str_variable = 'Hello World!'\n\nvar_func()\nprint(str_variable)\nThis would raise an error, because as far as your general code is concerned str_variable doesn’t exist outside of the function. This is an example of a local variable, one that only exists within a function.\nIf you want to create variables inside a function and have them persist, you need to explicitly pass them out using, for example return str_variable like this:\n\ndef var_func():\n    str_variable = \"Hello World!\"\n    return str_variable\n\n\nreturned_var = var_func()\nprint(returned_var)\n\nHello World!\n\n\n\ndef var_func():\n    str_variable = \"Hello World!\"\n    return str_variable\n\n\nreturned_var = var_func()\nprint(returned_var)\n\nHello World!\n\n\nGlobal\nA variable declared outside of a function is known as a global variable because it is accessible everywhere:\n\ny = \"I'm a global variable\"\n\ndef print_y():\n    print(\"y is inside a function:\", y)\n\n\nprint_y()\nprint(\"y is outside a function:\", y)\n\ny is inside a function: I'm a global variable\ny is outside a function: I'm a global variable\n\n\n\ny = \"I'm a global variable\"\n\ndef print_y():\n    print(\"y is inside a function:\", y)\n\n\nprint_y()\nprint(\"y is outside a function:\", y)\n\ny is inside a function: I'm a global variable\ny is outside a function: I'm a global variable\n\n\nThis is just a taster of what can be done using base Python with few extra packages. For more, especially if you’ve done other chapters in the book already and want to go a bit deeper, see the Chapter on {ref}code-advanced. Otherwise, head on to the next chapter!\n:::"
  },
  {
    "objectID": "homework.html#introduction",
    "href": "homework.html#introduction",
    "title": "Lecture1-code-basics",
    "section": "Introduction",
    "text": "Introduction\nHere we’ll do a whistlestop tour of data analysis in Python using a structure called a dataframe. Dataframes do everything a spreadsheet does, and a whole lot more. At their simplest, dataframes are a tabular representation of data with rows and columns. The data in each column can be anything; text, numbers, Python objects such as lists or dictionaries, or even other dataframes!\nThe ability to extract, clean, and analyse data is one of the core skills any economist needs. Fortunately, the (open source) tools that are available for data analysis have improved enormously in recent years, and working with them can be a delight——even the most badly formatted data can be beaten into shape. You may be sceptical that these open source tools can be as powerful as the costly, closed source tools you may already know: but, over time, you’ll come to see how they do far, far more, and do it faster too.\nIn this chapter, we’ll see analysis on a single dataframe using the Star Wars’ characters dataset as an example. For a more thorough grounding in using data, see the next chapter ({ref}working-with-data).\nThis chapter uses the pandas and numpy packages. If you’re running this code, you may need to install these packages. The Anaconda distribution of Python comes with pandas and numpy installed. If you don’t have these installed, you can install them by running either conda install packagename or pip install packagename on your computer’s command line. You can find a brief guide to installing packages in {ref}code-preliminaries.\nThis chapter is hugely indebted to the fantastic Python Data Science Handbook, and both the pandas documentation and amazing introductory tutorials."
  },
  {
    "objectID": "homework.html#loading-data-and-checking-datatypes",
    "href": "homework.html#loading-data-and-checking-datatypes",
    "title": "Lecture1-code-basics",
    "section": "Loading data and checking datatypes",
    "text": "Loading data and checking datatypes\nFirst we must import the packages we’ll be using in the rest of this chapter.\n\n%pip install pandas numpy matplotlib\n\nRequirement already satisfied: pandas in e:\\anaconda\\lib\\site-packages (2.2.2)\nRequirement already satisfied: numpy in e:\\anaconda\\lib\\site-packages (1.26.4)\nRequirement already satisfied: matplotlib in e:\\anaconda\\lib\\site-packages (3.8.4)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in e:\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in e:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in e:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\nRequirement already satisfied: contourpy&gt;=1.0.1 in e:\\anaconda\\lib\\site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in e:\\anaconda\\lib\\site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in e:\\anaconda\\lib\\site-packages (from matplotlib) (4.51.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in e:\\anaconda\\lib\\site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: packaging&gt;=20.0 in e:\\anaconda\\lib\\site-packages (from matplotlib) (23.2)\nRequirement already satisfied: pillow&gt;=8 in e:\\anaconda\\lib\\site-packages (from matplotlib) (10.3.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in e:\\anaconda\\lib\\site-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: six&gt;=1.5 in e:\\anaconda\\lib\\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# Set seed for random numbers\nseed_for_prng = 78557\nprng = np.random.default_rng(seed_for_prng)  # prng=probabilistic random number generator\n\n\n# Set seed for random numbers\nseed_for_prng = 78557\nprng = np.random.default_rng(seed_for_prng)  # prng=probabilistic random number generator\n\n\nimport matplotlib_inline.backend_inline\n\n# Plot settings\nplt.style.use(\n    \"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\"\n)\nmatplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n\n# Set max rows displayed for readability\npd.set_option(\"display.max_rows\", 20)\n\nLoading data into a dataframe is achieved with commands like df = pd.read_csv(...) or df = pd.read_stata(...). Let’s load the Star Wars data from the internet:\n\ndf = (pd.read_csv(\n    \"https://github.com/aeturrell/coding-for-economists/raw/main/data/starwars.csv\",\n    index_col=0,\n    )\n    .dropna(subset=[\"species\"])\n    )\n# Check info about dataframe\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 82 entries, 0 to 86\nData columns (total 8 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   name        82 non-null     object \n 1   height      77 non-null     float64\n 2   mass        58 non-null     float64\n 3   hair_color  77 non-null     object \n 4   eye_color   80 non-null     object \n 5   gender      79 non-null     object \n 6   homeworld   74 non-null     object \n 7   species     82 non-null     object \ndtypes: float64(2), object(6)\nmemory usage: 5.8+ KB\n\n\n\ndf = (pd.read_csv(\n    \"https://github.com/aeturrell/coding-for-economists/raw/main/data/starwars.csv\",\n    index_col=0,\n    )\n    .dropna(subset=[\"species\"])\n    )\n# Check info about dataframe\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 82 entries, 0 to 86\nData columns (total 8 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   name        82 non-null     object \n 1   height      77 non-null     float64\n 2   mass        58 non-null     float64\n 3   hair_color  77 non-null     object \n 4   eye_color   80 non-null     object \n 5   gender      79 non-null     object \n 6   homeworld   74 non-null     object \n 7   species     82 non-null     object \ndtypes: float64(2), object(6)\nmemory usage: 5.8+ KB\n\n\n\nLook at the first few rows with head()\n\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n\n\n\n\n\n\n\nunxpefgkyezn Exercise What happens if you pass a number to `head()`, eg `head(10)`?\n\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman"
  },
  {
    "objectID": "homework.html#filter-rows-and-columns-with-conditions-using-df.locconditions-or-rows-columns",
    "href": "homework.html#filter-rows-and-columns-with-conditions-using-df.locconditions-or-rows-columns",
    "title": "Lecture1-code-basics",
    "section": "Filter rows and columns with conditions using df.loc[condition(s) or row(s), column(s)]",
    "text": "Filter rows and columns with conditions using df.loc[condition(s) or row(s), column(s)]\n.loc stands for location and allows you to filter (aka subset) a dataframe. .loc works like an index, so it always comes with square brackets, eg df.loc[...].\nloc takes two arguments. The first is a list of the names of the rows that you’d like to select or a condition (ie a list of booleans with the same length as the dataframe) that selects certain rows. Remember, you can easily create a series of booleans by checking a column against a condition, for example df['column1'] == 'black'.\nThe second argument consists of a list of column names you’d like to select. In both cases, : is shorthand for ‘use all rows’ or ‘use all columns’. If you have either condition(s) or column(s) (but not both), you can simply write df[condition(s)] or df[column(s)].\nHere’s an example with a condition built up out of two parts and a list of columns:\n\ndf.loc[(df[\"hair_color\"] == \"brown\") & (df[\"eye_color\"] == \"blue\"), [\"name\", \"species\"]]\n\n\n\n\n\n\n\n\nname\nspecies\n\n\n\n\n6\nBeru Whitesun lars\nHuman\n\n\n12\nChewbacca\nWookiee\n\n\n17\nJek Tono Porkins\nHuman\n\n\n30\nQui-Gon Jinn\nHuman\n\n\n58\nCliegg Lars\nHuman\n\n\n77\nTarfful\nWookiee\n\n\n\n\n\n\n\n\ndf.loc[(df[\"hair_color\"] == \"brown\") & (df[\"eye_color\"] == \"blue\"), [\"name\", \"species\"]]\n\n\n\n\n\n\n\n\nname\nspecies\n\n\n\n\n6\nBeru Whitesun lars\nHuman\n\n\n12\nChewbacca\nWookiee\n\n\n17\nJek Tono Porkins\nHuman\n\n\n30\nQui-Gon Jinn\nHuman\n\n\n58\nCliegg Lars\nHuman\n\n\n77\nTarfful\nWookiee\n\n\n\n\n\n\n\nunxpefgkyezn Exercise Using `loc`, filter the dataframe to `mass` greater than 50 for the `name` and `homeworld` columns\n\ndf.loc[(df['mass'] &gt; 50), ['name', 'homeworld']]\n\n\n\n\n\n\n\n\nname\nhomeworld\n\n\n\n\n0\nLuke Skywalker\nTatooine\n\n\n1\nC-3PO\nTatooine\n\n\n3\nDarth Vader\nTatooine\n\n\n5\nOwen Lars\nTatooine\n\n\n6\nBeru Whitesun lars\nTatooine\n\n\n...\n...\n...\n\n\n75\nShaak Ti\nShili\n\n\n76\nGrievous\nKalee\n\n\n77\nTarfful\nKashyyyk\n\n\n78\nRaymus Antilles\nAlderaan\n\n\n80\nTion Medon\nUtapau\n\n\n\n\n46 rows × 2 columns\n\n\n\n\ndf.loc[(df['mass'] &gt; 50), ['name', 'homeworld']]\n\n\n\n\n\n\n\n\nname\nhomeworld\n\n\n\n\n0\nLuke Skywalker\nTatooine\n\n\n1\nC-3PO\nTatooine\n\n\n3\nDarth Vader\nTatooine\n\n\n5\nOwen Lars\nTatooine\n\n\n6\nBeru Whitesun lars\nTatooine\n\n\n...\n...\n...\n\n\n75\nShaak Ti\nShili\n\n\n76\nGrievous\nKalee\n\n\n77\nTarfful\nKashyyyk\n\n\n78\nRaymus Antilles\nAlderaan\n\n\n80\nTion Medon\nUtapau\n\n\n\n\n46 rows × 2 columns"
  },
  {
    "objectID": "homework.html#sort-rows-or-columns-with-.sort_values",
    "href": "homework.html#sort-rows-or-columns-with-.sort_values",
    "title": "Lecture1-code-basics",
    "section": "Sort rows or columns with .sort_values()",
    "text": "Sort rows or columns with .sort_values()\nUse sort_values(columns, ascending=False) for descending order.\n\ndf.sort_values([\"height\", \"mass\"])\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n18\nYoda\n66.0\n17.0\nwhite\nbrown\nmale\nNaN\nYoda's species\n\n\n71\nRatts Tyerell\n79.0\n15.0\nnone\nNaN\nmale\nAleen Minor\nAleena\n\n\n28\nWicket Systri Warrick\n88.0\n20.0\nbrown\nbrown\nmale\nEndor\nEwok\n\n\n44\nDud Bolt\n94.0\n45.0\nnone\nyellow\nmale\nVulpter\nVulptereen\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n27\nArvel Crynyd\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n81\nFinn\nNaN\nNaN\nblack\ndark\nmale\nNaN\nHuman\n\n\n82\nRey\nNaN\nNaN\nbrown\nhazel\nfemale\nNaN\nHuman\n\n\n83\nPoe Dameron\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n84\nBB8\nNaN\nNaN\nnone\nblack\nnone\nNaN\nDroid\n\n\n\n\n82 rows × 8 columns\n\n\n\n\ndf.sort_values([\"height\", \"mass\"])\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n18\nYoda\n66.0\n17.0\nwhite\nbrown\nmale\nNaN\nYoda's species\n\n\n71\nRatts Tyerell\n79.0\n15.0\nnone\nNaN\nmale\nAleen Minor\nAleena\n\n\n28\nWicket Systri Warrick\n88.0\n20.0\nbrown\nbrown\nmale\nEndor\nEwok\n\n\n44\nDud Bolt\n94.0\n45.0\nnone\nyellow\nmale\nVulpter\nVulptereen\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n27\nArvel Crynyd\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n81\nFinn\nNaN\nNaN\nblack\ndark\nmale\nNaN\nHuman\n\n\n82\nRey\nNaN\nNaN\nbrown\nhazel\nfemale\nNaN\nHuman\n\n\n83\nPoe Dameron\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n84\nBB8\nNaN\nNaN\nnone\nblack\nnone\nNaN\nDroid\n\n\n\n\n82 rows × 8 columns\n\n\n\nunxpefgkyezn Exercise Using `sort_values()`, sort the dataframe by the `name` column.\n\ndf.sort_values('name')\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n25\nAckbar\n180.0\n83.0\nnone\norange\nmale\nMon Cala\nMon Calamari\n\n\n51\nAdi Gallia\n184.0\n50.0\nnone\nblue\nfemale\nCoruscant\nTholothian\n\n\n10\nAnakin Skywalker\n188.0\n84.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n27\nArvel Crynyd\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n43\nAyla Secura\n178.0\n55.0\nnone\nhazel\nfemale\nRyloth\nTwi'lek\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n28\nWicket Systri Warrick\n88.0\n20.0\nbrown\nbrown\nmale\nEndor\nEwok\n\n\n11\nWilhuff Tarkin\n180.0\nNaN\nauburn, grey\nblue\nmale\nEriadu\nHuman\n\n\n53\nYarael Poof\n264.0\nNaN\nnone\nyellow\nmale\nQuermia\nQuermian\n\n\n18\nYoda\n66.0\n17.0\nwhite\nbrown\nmale\nNaN\nYoda's species\n\n\n66\nZam Wesell\n168.0\n55.0\nblonde\nyellow\nfemale\nZolan\nClawdite\n\n\n\n\n82 rows × 8 columns\n\n\n\n\ndf.sort_values('name')\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n25\nAckbar\n180.0\n83.0\nnone\norange\nmale\nMon Cala\nMon Calamari\n\n\n51\nAdi Gallia\n184.0\n50.0\nnone\nblue\nfemale\nCoruscant\nTholothian\n\n\n10\nAnakin Skywalker\n188.0\n84.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n27\nArvel Crynyd\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n43\nAyla Secura\n178.0\n55.0\nnone\nhazel\nfemale\nRyloth\nTwi'lek\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n28\nWicket Systri Warrick\n88.0\n20.0\nbrown\nbrown\nmale\nEndor\nEwok\n\n\n11\nWilhuff Tarkin\n180.0\nNaN\nauburn, grey\nblue\nmale\nEriadu\nHuman\n\n\n53\nYarael Poof\n264.0\nNaN\nnone\nyellow\nmale\nQuermia\nQuermian\n\n\n18\nYoda\n66.0\n17.0\nwhite\nbrown\nmale\nNaN\nYoda's species\n\n\n66\nZam Wesell\n168.0\n55.0\nblonde\nyellow\nfemale\nZolan\nClawdite\n\n\n\n\n82 rows × 8 columns"
  },
  {
    "objectID": "homework.html#choose-multiple-rows-or-columns-using-slices",
    "href": "homework.html#choose-multiple-rows-or-columns-using-slices",
    "title": "Lecture1-code-basics",
    "section": "Choose multiple rows or columns using slices",
    "text": "Choose multiple rows or columns using slices\nSlices can be passed by name using .loc[startrow:stoprow:step, startcolumn:stopcolumn:step] or by position using .iloc[start:stop:step, start:stop:step].\nChoosing every 10th row from the second, and the columns between ‘name’ and ‘gender’:\n\ndf.loc[2::10, \"name\":\"gender\"]\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\n\n\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\n\n\n12\nChewbacca\n228.0\n112.0\nbrown\nblue\nmale\n\n\n22\nBossk\n190.0\n113.0\nnone\nred\nmale\n\n\n32\nFinis Valorum\n170.0\nNaN\nblond\nblue\nmale\n\n\n44\nDud Bolt\n94.0\n45.0\nnone\nyellow\nmale\n\n\n54\nPlo Koon\n188.0\n80.0\nnone\nblack\nmale\n\n\n64\nBail Prestor Organa\n191.0\nNaN\nblack\nbrown\nmale\n\n\n75\nShaak Ti\n178.0\n57.0\nnone\nblack\nfemale\n\n\n\n\n\n\n\n\ndf.loc[2::10, \"name\":\"gender\"]\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\n\n\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\n\n\n12\nChewbacca\n228.0\n112.0\nbrown\nblue\nmale\n\n\n22\nBossk\n190.0\n113.0\nnone\nred\nmale\n\n\n32\nFinis Valorum\n170.0\nNaN\nblond\nblue\nmale\n\n\n44\nDud Bolt\n94.0\n45.0\nnone\nyellow\nmale\n\n\n54\nPlo Koon\n188.0\n80.0\nnone\nblack\nmale\n\n\n64\nBail Prestor Organa\n191.0\nNaN\nblack\nbrown\nmale\n\n\n75\nShaak Ti\n178.0\n57.0\nnone\nblack\nfemale\n\n\n\n\n\n\n\nNote that loc only works here with numbers for rows because it just so happens that the names of the rows are numbers. If the rows had names that were strings, and we wanted to subset rows by their index position, we would have to use iloc instead.\nChoosing the first 5 rows and the last 2 columns by index position:\n\ndf.iloc[:5, -2:]\n\n\n\n\n\n\n\n\nhomeworld\nspecies\n\n\n\n\n0\nTatooine\nHuman\n\n\n1\nTatooine\nDroid\n\n\n2\nNaboo\nDroid\n\n\n3\nTatooine\nHuman\n\n\n4\nAlderaan\nHuman\n\n\n\n\n\n\n\n\ndf.iloc[:5, -2:]\n\n\n\n\n\n\n\n\nhomeworld\nspecies\n\n\n\n\n0\nTatooine\nHuman\n\n\n1\nTatooine\nDroid\n\n\n2\nNaboo\nDroid\n\n\n3\nTatooine\nHuman\n\n\n4\nAlderaan\nHuman\n\n\n\n\n\n\n\nunxpefgkyezn Exercise Using `.iloc`, display the first 6 rows and last 6 columns.\n\ndf.iloc[:6, -6:]\n\n\n\n\n\n\n\n\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n1\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n\n\n2\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n3\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n\n\n4\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n\n\n5\n120.0\nbrown, grey\nblue\nmale\nTatooine\nHuman\n\n\n\n\n\n\n\n\ndf.iloc[:6, -6:]\n\n\n\n\n\n\n\n\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n1\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n\n\n2\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n3\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n\n\n4\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n\n\n5\n120.0\nbrown, grey\nblue\nmale\nTatooine\nHuman"
  },
  {
    "objectID": "homework.html#randomly-selecting-a-sample-using-.sample",
    "href": "homework.html#randomly-selecting-a-sample-using-.sample",
    "title": "Lecture1-code-basics",
    "section": "Randomly selecting a sample using .sample",
    "text": "Randomly selecting a sample using .sample\n.sample(n) randomly selects n rows, .sample(frac=0.4) selects 40% of the data, replace=True samples with replacement, and passing weights= selects a number or fraction with the probabilities given by the passed weights. (Note that weights passed should have the same length as the dataframe.)\nTaking a sample of 5 rows:\n\ndf.sample(5)\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n69\nTaun We\n213.0\nNaN\nnone\nblack\nfemale\nKamino\nKaminoan\n\n\n59\nPoggle the Lesser\n183.0\n80.0\nnone\nyellow\nmale\nGeonosis\nGeonosian\n\n\n65\nJango Fett\n183.0\n79.0\nblack\nbrown\nmale\nConcord Dawn\nHuman\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n22\nBossk\n190.0\n113.0\nnone\nred\nmale\nTrandosha\nTrandoshan\n\n\n\n\n\n\n\n\ndf.sample(5)\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n6\nBeru Whitesun lars\n165.0\n75.0\nbrown\nblue\nfemale\nTatooine\nHuman\n\n\n70\nJocasta Nu\n167.0\nNaN\nwhite\nblue\nfemale\nCoruscant\nHuman\n\n\n80\nTion Medon\n206.0\n80.0\nnone\nblack\nmale\nUtapau\nPau'an\n\n\n57\nCordé\n157.0\nNaN\nbrown\nbrown\nfemale\nNaboo\nHuman\n\n\n71\nRatts Tyerell\n79.0\n15.0\nnone\nNaN\nmale\nAleen Minor\nAleena\n\n\n\n\n\n\n\nunxpefgkyezn Exercise Use `.sample()` to sample 5% of the dataframe.\n\ndf.sample(frac=0.05)\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\n\n\n\n\n24\nLobot\n175.0\n79.0\nnone\nblue\nmale\nBespin\nHuman\n\n\n66\nZam Wesell\n168.0\n55.0\nblonde\nyellow\nfemale\nZolan\nClawdite\n\n\n23\nLando Calrissian\n177.0\n79.0\nblack\nbrown\nmale\nSocorro\nHuman\n\n\n64\nBail Prestor Organa\n191.0\nNaN\nblack\nbrown\nmale\nAlderaan\nHuman"
  },
  {
    "objectID": "homework.html#rename-with-.rename",
    "href": "homework.html#rename-with-.rename",
    "title": "Lecture1-code-basics",
    "section": "Rename with .rename()",
    "text": "Rename with .rename()\nYou can rename all columns by passing a function, for instance df.rename(columns=str.lower) to put all columns in lower case. Alternatively, use a dictionary to say which columns should be mapped to what:\n\ndf.rename(columns={\"homeworld\": \"home_world\"})\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhome_world\nspecies\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n81\nFinn\nNaN\nNaN\nblack\ndark\nmale\nNaN\nHuman\n\n\n82\nRey\nNaN\nNaN\nbrown\nhazel\nfemale\nNaN\nHuman\n\n\n83\nPoe Dameron\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n84\nBB8\nNaN\nNaN\nnone\nblack\nnone\nNaN\nDroid\n\n\n86\nPadmé Amidala\n165.0\n45.0\nbrown\nbrown\nfemale\nNaboo\nHuman\n\n\n\n\n82 rows × 8 columns\n\n\n\n\ndf.rename(columns={\"homeworld\": \"home_world\"})\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhome_world\nspecies\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n81\nFinn\nNaN\nNaN\nblack\ndark\nmale\nNaN\nHuman\n\n\n82\nRey\nNaN\nNaN\nbrown\nhazel\nfemale\nNaN\nHuman\n\n\n83\nPoe Dameron\nNaN\nNaN\nbrown\nbrown\nmale\nNaN\nHuman\n\n\n84\nBB8\nNaN\nNaN\nnone\nblack\nnone\nNaN\nDroid\n\n\n86\nPadmé Amidala\n165.0\n45.0\nbrown\nbrown\nfemale\nNaboo\nHuman\n\n\n\n\n82 rows × 8 columns"
  },
  {
    "objectID": "homework.html#add-new-columns-with-.assign-or-assignment",
    "href": "homework.html#add-new-columns-with-.assign-or-assignment",
    "title": "Lecture1-code-basics",
    "section": "Add new columns with .assign() or assignment",
    "text": "Add new columns with .assign() or assignment\nVery often you will want to create new columns based on existing columns.\n\nThere are two ways to do this. Let’s see them both with an example where we’d like to create a new column that contains height in metres, called \"height_m:.\n\nThe first, and most commonly used, is called assignment and involves just entering the new column name within your dataframe and putting it on the left-hand side of an assignment expression that has an operation based on existing dataframe columns on the right-hand side. For example, df['height_m'] = df['height']/100.\nThe second is to use the assign() method on a dataframe directly. In this case, the assignment statement appears inside the brackets but you don’t need to write as much text because it’s clear from the context that, on the left-hand side of the assignment, we’re talking about the given dataframe. An example is df.assign(height_m=df[\"height\"] / 100).\n\nLet’s see working examples of both of these assignment methods.\nFirst let’s use the assignment approach:\n\ndf['height_m'] = df['height']/100\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n\n\n\n\n\n\n\n\ndf['height_m'] = df['height']/100\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n\n\n\n\n\n\n\nAnd now with the .assign() function:\n\ndf = df.assign(height_m=df[\"height\"] / 100)\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n\n\n\n\n\n\n\n\ndf = df.assign(height_m=df[\"height\"] / 100)\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n\n\n\n\n\n\n\nThis was added to the end; ideally, we’d like it next to the height column, which we can achieve by sorting the columns (axis=1) alphabetically:\n\n(df.assign(height_m=df[\"height\"] / 100).sort_index(axis=1))\n\n\n\n\n\n\n\n\neye_color\ngender\nhair_color\nheight\nheight_m\nhomeworld\nmass\nname\nspecies\n\n\n\n\n0\nblue\nmale\nblond\n172.0\n1.72\nTatooine\n77.0\nLuke Skywalker\nHuman\n\n\n1\nyellow\nNaN\nNaN\n167.0\n1.67\nTatooine\n75.0\nC-3PO\nDroid\n\n\n2\nred\nNaN\nNaN\n96.0\n0.96\nNaboo\n32.0\nR2-D2\nDroid\n\n\n3\nyellow\nmale\nnone\n202.0\n2.02\nTatooine\n136.0\nDarth Vader\nHuman\n\n\n4\nbrown\nfemale\nbrown\n150.0\n1.50\nAlderaan\n49.0\nLeia Organa\nHuman\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n81\ndark\nmale\nblack\nNaN\nNaN\nNaN\nNaN\nFinn\nHuman\n\n\n82\nhazel\nfemale\nbrown\nNaN\nNaN\nNaN\nNaN\nRey\nHuman\n\n\n83\nbrown\nmale\nbrown\nNaN\nNaN\nNaN\nNaN\nPoe Dameron\nHuman\n\n\n84\nblack\nnone\nnone\nNaN\nNaN\nNaN\nNaN\nBB8\nDroid\n\n\n86\nbrown\nfemale\nbrown\n165.0\n1.65\nNaboo\n45.0\nPadmé Amidala\nHuman\n\n\n\n\n82 rows × 9 columns\n\n\n\n\n(df.assign(height_m=df[\"height\"] / 100).sort_index(axis=1))\n\n\n\n\n\n\n\n\neye_color\ngender\nhair_color\nheight\nheight_m\nhomeworld\nmass\nname\nspecies\n\n\n\n\n0\nblue\nmale\nblond\n172.0\n1.72\nTatooine\n77.0\nLuke Skywalker\nHuman\n\n\n1\nyellow\nNaN\nNaN\n167.0\n1.67\nTatooine\n75.0\nC-3PO\nDroid\n\n\n2\nred\nNaN\nNaN\n96.0\n0.96\nNaboo\n32.0\nR2-D2\nDroid\n\n\n3\nyellow\nmale\nnone\n202.0\n2.02\nTatooine\n136.0\nDarth Vader\nHuman\n\n\n4\nbrown\nfemale\nbrown\n150.0\n1.50\nAlderaan\n49.0\nLeia Organa\nHuman\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n81\ndark\nmale\nblack\nNaN\nNaN\nNaN\nNaN\nFinn\nHuman\n\n\n82\nhazel\nfemale\nbrown\nNaN\nNaN\nNaN\nNaN\nRey\nHuman\n\n\n83\nbrown\nmale\nbrown\nNaN\nNaN\nNaN\nNaN\nPoe Dameron\nHuman\n\n\n84\nblack\nnone\nnone\nNaN\nNaN\nNaN\nNaN\nBB8\nDroid\n\n\n86\nbrown\nfemale\nbrown\n165.0\n1.65\nNaboo\n45.0\nPadmé Amidala\nHuman\n\n\n\n\n82 rows × 9 columns\n\n\n\nTo overwrite existing columns just use height = df['height']/100 with the assign method or df['height'] = df['height']/100 with an assignment expression.\nunxpefgkyezn Exercise Add a new column that gives the ratio of mass to height.\n\ndf['mass_height_ratio'] = df['mass'] / df['height']\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\nmass_height_ratio\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n0.447674\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n0.449102\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n0.333333\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n0.673267\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n0.326667\n\n\n\n\n\n\n\n\ndf['mass_height_ratio'] = df['mass'] / df['height']\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\nmass_height_ratio\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n0.447674\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n0.449102\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n0.333333\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n0.673267\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n0.326667\n\n\n\n\n\n\n\n\ndf = df.assign(mass_height_ratio=df['mass'] / df['height'])\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\nmass_height_ratio\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n0.447674\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n0.449102\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n0.333333\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n0.673267\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n0.326667\n\n\n\n\n\n\n\n\ndf = df.assign(mass_height_ratio=df['mass'] / df['height'])\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\nmass_height_ratio\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n0.447674\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n0.449102\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n0.333333\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n0.673267\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n0.326667"
  },
  {
    "objectID": "homework.html#summarise-numerical-values-with-.describe",
    "href": "homework.html#summarise-numerical-values-with-.describe",
    "title": "Lecture1-code-basics",
    "section": "Summarise numerical values with .describe()",
    "text": "Summarise numerical values with .describe()\n\ndf.describe()\n\n\n\n\n\n\n\n\nheight\nmass\nheight_m\nmass_height_ratio\n\n\n\n\ncount\n77.000000\n58.000000\n77.000000\n58.000000\n\n\nmean\n175.103896\n98.162069\n1.751039\n0.552307\n\n\nstd\n34.483629\n170.810183\n0.344836\n0.969546\n\n\nmin\n66.000000\n15.000000\n0.660000\n0.189873\n\n\n25%\n167.000000\n56.400000\n1.670000\n0.341837\n\n\n50%\n180.000000\n79.000000\n1.800000\n0.434426\n\n\n75%\n191.000000\n84.750000\n1.910000\n0.459349\n\n\nmax\n264.000000\n1358.000000\n2.640000\n7.760000\n\n\n\n\n\n\n\n\ndf.describe()\n\n\n\n\n\n\n\n\nheight\nmass\nheight_m\nmass_height_ratio\n\n\n\n\ncount\n77.000000\n58.000000\n77.000000\n58.000000\n\n\nmean\n175.103896\n98.162069\n1.751039\n0.552307\n\n\nstd\n34.483629\n170.810183\n0.344836\n0.969546\n\n\nmin\n66.000000\n15.000000\n0.660000\n0.189873\n\n\n25%\n167.000000\n56.400000\n1.670000\n0.341837\n\n\n50%\n180.000000\n79.000000\n1.800000\n0.434426\n\n\n75%\n191.000000\n84.750000\n1.910000\n0.459349\n\n\nmax\n264.000000\n1358.000000\n2.640000\n7.760000"
  },
  {
    "objectID": "homework.html#group-variables-values-with-.groupby",
    "href": "homework.html#group-variables-values-with-.groupby",
    "title": "Lecture1-code-basics",
    "section": "Group variables values with .groupby()",
    "text": "Group variables values with .groupby()\n\ndf.groupby(\"species\")[[\"height\", \"mass\"]].mean()\n\n\n\n\n\n\n\n\nheight\nmass\n\n\nspecies\n\n\n\n\n\n\nAleena\n79.0\n15.0\n\n\nBesalisk\n198.0\n102.0\n\n\nCerean\n198.0\n82.0\n\n\nChagrian\n196.0\nNaN\n\n\nClawdite\n168.0\n55.0\n\n\n...\n...\n...\n\n\nVulptereen\n94.0\n45.0\n\n\nWookiee\n231.0\n124.0\n\n\nXexto\n122.0\nNaN\n\n\nYoda's species\n66.0\n17.0\n\n\nZabrak\n173.0\n80.0\n\n\n\n\n37 rows × 2 columns\n\n\n\n\ndf.groupby(\"species\")[[\"height\", \"mass\"]].mean()\n\n\n\n\n\n\n\n\nheight\nmass\n\n\nspecies\n\n\n\n\n\n\nAleena\n79.0\n15.0\n\n\nBesalisk\n198.0\n102.0\n\n\nCerean\n198.0\n82.0\n\n\nChagrian\n196.0\nNaN\n\n\nClawdite\n168.0\n55.0\n\n\n...\n...\n...\n\n\nVulptereen\n94.0\n45.0\n\n\nWookiee\n231.0\n124.0\n\n\nXexto\n122.0\nNaN\n\n\nYoda's species\n66.0\n17.0\n\n\nZabrak\n173.0\n80.0\n\n\n\n\n37 rows × 2 columns\n\n\n\nunxpefgkyezn Exercise Find the standard deviation (using `std()`) of masses by `homeworld`.\n\ndf.groupby('homeworld')['mass'].std()\n\nhomeworld\nAlderaan          21.213203\nAleen Minor             NaN\nBespin                  NaN\nBestine IV              NaN\nCato Neimoidia          NaN\n                    ...    \nTroiken                 NaN\nTund                    NaN\nUtapau                  NaN\nVulpter                 NaN\nZolan                   NaN\nName: mass, Length: 47, dtype: float64\n\n\n\ndf.groupby('homeworld')['mass'].std()\n\nhomeworld\nAlderaan          21.213203\nAleen Minor             NaN\nBespin                  NaN\nBestine IV              NaN\nCato Neimoidia          NaN\n                    ...    \nTroiken                 NaN\nTund                    NaN\nUtapau                  NaN\nVulpter                 NaN\nZolan                   NaN\nName: mass, Length: 47, dtype: float64"
  },
  {
    "objectID": "homework.html#add-transformed-columns-using-.transform",
    "href": "homework.html#add-transformed-columns-using-.transform",
    "title": "Lecture1-code-basics",
    "section": "Add transformed columns using .transform()",
    "text": "Add transformed columns using .transform()\nQuite often, it’s useful to put a column into a dataframe that is the result of an intermediate groupby and aggregation. For example, subtracting the group mean or normalisation. Transform does this and returns a transformed column with the same shape as the original dataframe. Transform preserves the original index. (There are other methods, such as apply, that return a new dataframe with the groupby variables as a new index.)\nBelow is an example of transform being used to demean a variable according to the mean by species. Note that we are using lambda functions here. Lambda functions are a quick way of writing functions without needing to give them a name, e.g. lambda x: x+1 defines a function that adds one to x. In the example below, the x in the lambda function takes on the role of mass grouped by species.\n\ndf[\"mass_demean_species\"] = df.groupby(\"species\")[\"mass\"].transform(lambda x: x - x.mean())\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\nmass_height_ratio\nmass_demean_species\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n0.447674\n-5.781818\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n0.449102\n5.250000\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n0.333333\n-37.750000\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n0.673267\n53.218182\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n0.326667\n-33.781818\n\n\n\n\n\n\n\n\ndf[\"mass_demean_species\"] = df.groupby(\"species\")[\"mass\"].transform(lambda x: x - x.mean())\ndf.head()\n\n\n\n\n\n\n\n\nname\nheight\nmass\nhair_color\neye_color\ngender\nhomeworld\nspecies\nheight_m\nmass_height_ratio\nmass_demean_species\n\n\n\n\n0\nLuke Skywalker\n172.0\n77.0\nblond\nblue\nmale\nTatooine\nHuman\n1.72\n0.447674\n-5.781818\n\n\n1\nC-3PO\n167.0\n75.0\nNaN\nyellow\nNaN\nTatooine\nDroid\n1.67\n0.449102\n5.250000\n\n\n2\nR2-D2\n96.0\n32.0\nNaN\nred\nNaN\nNaboo\nDroid\n0.96\n0.333333\n-37.750000\n\n\n3\nDarth Vader\n202.0\n136.0\nnone\nyellow\nmale\nTatooine\nHuman\n2.02\n0.673267\n53.218182\n\n\n4\nLeia Organa\n150.0\n49.0\nbrown\nbrown\nfemale\nAlderaan\nHuman\n1.50\n0.326667\n-33.781818\n\n\n\n\n\n\n\nunxpefgkyezn Exercise Create a `height_demean_homeworld` column that gives the height column with the mean height by homeworld subtracted."
  },
  {
    "objectID": "homework.html#make-quick-charts-with-.plot.",
    "href": "homework.html#make-quick-charts-with-.plot.",
    "title": "Lecture1-code-basics",
    "section": "Make quick charts with .plot.*()",
    "text": "Make quick charts with .plot.*()\nIncluding scatter, area, bar, box, density, hexbin, histogram, kde, and line.\n\ndf.plot.scatter(\"mass\", \"height\", alpha=0.5);\n\n\n\n\n\n\n\n\n\ndf.plot.scatter(\"mass\", \"height\", alpha=0.5);\n\n\n\n\n\n\n\n\n\ndf.plot.box(column=\"height\");\n\n\n\n\n\n\n\n\n\ndf.plot.box(column=\"height\");\n\n\n\n\n\n\n\n\n\n%pip install scipy\n\nRequirement already satisfied: scipy in e:\\anaconda\\lib\\site-packages (1.13.1)\nRequirement already satisfied: numpy&lt;2.3,&gt;=1.22.4 in e:\\anaconda\\lib\\site-packages (from scipy) (1.26.4)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n%pip install scipy\n\nRequirement already satisfied: scipy in e:\\anaconda\\lib\\site-packages (1.13.1)\nRequirement already satisfied: numpy&lt;2.3,&gt;=1.22.4 in e:\\anaconda\\lib\\site-packages (from scipy) (1.26.4)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\ndf[\"height\"].plot.kde(bw_method=0.3);"
  },
  {
    "objectID": "homework.html#export-results-and-descriptive-statistics",
    "href": "homework.html#export-results-and-descriptive-statistics",
    "title": "Lecture1-code-basics",
    "section": "Export results and descriptive statistics",
    "text": "Export results and descriptive statistics\nYou’ll often want to export your results to a latex file for inclusion in a paper, presentation, or poster. Let’s say we had some descriptive statistics on a dataframe:\n\ntable = df[[\"mass\", \"height\"]].agg(['mean', 'std'])\ntable\n\n\n\n\n\n\n\n\nmass\nheight\n\n\n\n\nmean\n98.162069\n175.103896\n\n\nstd\n170.810183\n34.483629\n\n\n\n\n\n\n\n\ntable = df[[\"mass\", \"height\"]].agg(['mean', 'std'])\ntable\n\n\n\n\n\n\n\n\nmass\nheight\n\n\n\n\nmean\n98.162069\n175.103896\n\n\nstd\n170.810183\n34.483629\n\n\n\n\n\n\n\nYou can export this to a range of formats, including string, html, xml, markdown, the clipboard (so you can paste it), Excel, and more. In your favourite IDE (integrated development environment) with a Python language server (eg Visual Studio Code, JupyterLab) start typing table.to and a list of possible methods beginning to should appear, including to_string().\nHere is an example of exporting your pandas table to CSV (comma separated values):\n\ntable.to_csv()\n\n',mass,height\\nmean,98.16206896551724,175.1038961038961\\nstd,170.81018276436322,34.483628615842896\\n'\n\n\n\ntable.to_csv()\n\n',mass,height\\r\\nmean,98.16206896551724,175.1038961038961\\r\\nstd,170.8101827643632,34.483628615842896\\r\\n'\n\n\nOne output format that doesn’t conform to this is LaTeX, for which you need the following:\nWriting to the terminal isn’t that useful for getting your paper or report done! To export to a file, use table.style.to_latex('file.tex', ...) for LaTeX and table.to_csv('file.csv', ...).\n``unxpefgkyezn Exercise Try exporting the table above using theto_string(“table.txt”)` method.\nIf you are running this locally, the file should appear in the directory in which you are running this notebook.\nIf you are using Google Colab to do these exercises, you can check that the file exported by running !ls in a new code cell to see all files in the current notebook directory. To get the contents of the file you created, run !cat table.txt.\n\n## Summary\n\nThis has been a quick tour of what **pandas** can do, and shows the power of this ubiquitous tool, but we've barely seen a fraction of its features. The next chapter will go deeper into how to use **pandas**.\n\n\n\n:::\n\n\n\n\n\n\n\n\n\n# Lecture1-workflow-basics\n\n\n\n\n\n:::{.quarto-embed-nb-cell notebook=\"D:\\code\\jiedan\\12-28\\test\\homework\\Lecture1-workflow-basics.ipynb\" notebook-title=\"Workflow Basics\" notebook-cellId=\"cell-0\"}\n\n(workflow-basics)=\n# Workflow Basics\n\nThis chapter will take you through some of the essential parts of a Python workflow.\n\n## Prerequisites\n\nYou'll need an installation of Python and Visual Studio Code with the Python extensions to get to grips with this chapter. If you haven't installed those yet, head back to {ref}`code-preliminaries` and follow the instructions there.\n\n## Working with Python scripts and the interactive window\n\nAs a reminder, the figure below shows the typical layout of Visual Studio Code.\n\n![A typical user view in Visual Studio Code](https://github.com/aeturrell/coding-for-economists/blob/main/img/vscode_layout.png?raw=true)\n\nWhen you create a new script (File-&gt;New File-&gt;Save as 'your_script_name.py), it will appear in the part of the screen labelled as 3.\n\nTo run a script, select the code you want to run, right click, and select \"Run Selection/Line in Interactive Window\". You can also hit shift + enter if you set this shortcut up; if you haven't it's well worth doing and you can find the instructions in {ref}`code-preliminaries`.\n\nUsing the \"Run Selection/Line in Interactive Window\" option or using the shortcut will cause panel 5 in the above diagram (the interactive window) to appear, where you will see the code run and the outputs of your script appear.\n\n```{tip}\nIf you have an issue getting the code to run in the interactive window, first check the instructions in {ref}`code-preliminaries`. If you're still having issues, it may be that Visual Studio Code isn't sure which Python to run, or where Python is on your system. To fix the latter problem, hit the \"Select kernel\" button in the top right-hand side of the interactive window.\nWhen you are first writing a script, it’s useful to be able to move back and forth between the script and the interactive window. You might execute a line of code (put the cursor on the relevant line and hit shift and enter) in the interactive window, then manually write out some code in the interactive window’s execution box (seen at the bottom of panel 5 saying “Type code here…”), and then explore some of the variables you’ve created with the variable explorer (using the button “Variables”) at the top of the interactive window.\nBut, once you’ve honed the code in your script, it’s good to make the script a complete analytical process that you are happy running end-to-end and that—for production or ‘final’ work—you would use the “Run Current File in Interactive Window” option to run all the way through. This is good practice because what is in your script is reproducible but what you’ve entered manually in the interactive window is not. And you want the outputs from your code to be reproducible and understandable by others (including future you!), but this is hard if there are undocumented extra lines of code that you only did on the fly via the interactive window’s execution box."
  },
  {
    "objectID": "homework.html#using-installed-packages-and-modules",
    "href": "homework.html#using-installed-packages-and-modules",
    "title": "Lecture1-code-basics",
    "section": "Using installed packages and modules",
    "text": "Using installed packages and modules\nWe already saw how to install packages in {ref}code-preliminaries. If you forgot, look back at how to do this now. In short, packages are installed using the command line or, on Windows, the Anaconda prompt. With either of these open, type conda install packagename and hit enter to both search for and install the package you need.\nWhat about using a package that you’ve installed? That’s what we’ll look at now.\nLet’s see an example of using the powerful numerical library numpy. There are different ways to import packages to use within a script or notebook; you can import the entire package in one go or just import the functions you need (if you know their names). When an entire package is imported, you can give it any name you like and the convention for numpy is to import it as the shortened ‘np’. All of the functions and methods of the package can be accessed by typing np followed by . and then typing the function name. This convention of importing packages with a given name makes your code easier to read, because you know exactly which package is doing what, and avoids any conflicts when functions from different packages have the same name.\nAs well as demonstrating importing the whole package for numpy, the example below shows importing just one specific function from numpy, inv, which does matrix inversion. Note that because inv was imported separately it can be used without an np prefix.\n\nimport numpy as np\nfrom numpy.linalg import inv\n\nmatrix = np.array([[4.0, 2.0, 4.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n\nprint(\"Matrix:\")\nprint(matrix)\n\ninv_mat = inv(matrix)\nprint(\"Inverse:\")\nprint(inv_mat)\n\nMatrix:\n[[4. 2. 4.]\n [4. 5. 6.]\n [7. 8. 9.]]\nInverse:\n[[ 0.25       -1.16666667  0.66666667]\n [-0.5        -0.66666667  0.66666667]\n [ 0.25        1.5        -1.        ]]\n\n\n\nimport numpy as np\nfrom numpy.linalg import inv\n\nmatrix = np.array([[4.0, 2.0, 4.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n\nprint(\"Matrix:\")\nprint(matrix)\n\ninv_mat = inv(matrix)\nprint(\"Inverse:\")\nprint(inv_mat)\n\nMatrix:\n[[4. 2. 4.]\n [4. 5. 6.]\n [7. 8. 9.]]\nInverse:\n[[ 0.25       -1.16666667  0.66666667]\n [-0.5        -0.66666667  0.66666667]\n [ 0.25        1.5        -1.        ]]\n\n\nWe could have imported all of numpy and it used it without extension using from numpy import * but this is considered bad practice as it fills our ‘namespace’ with function names that might clash with other packages and it’s less easy to read because you don’t know which function came from which package (one of Python’s mantras is “explicit is better than implict”). However, some packages are designed to be used like this, so, for example, you will see from lets_plot import * in this book.\nIf you want to check what packages you have installed in your Python environment, run `conda list` on your computer's command line (aka the *terminal* or *command prompt*).\nSometimes you might forget what a function you have imported does! Or at least, you might not be sure what all of the optional arguments are. In Visual Studio Code, you can just hover your cursor over the name of the function and a box will come up that tells you everything you need to know about it. This box is auto-generated by doc-strings; information that is written in text just under a function’s definition (def statement).\nAn alternative way to see what a function does is to use a wonderful package called rich that does many things including providing an inspect() function. You will need to use pip to install rich by running pip install rich on the command line. Here’s an example of using rich’s inpsect method on the inv() function we imported above (methods=True reports all of the functionality of inv()):\n\nfrom rich import inspect\n\ninspect(inv, help=True)\n\n╭─────────────── &lt;function inv at 0x000002308AF6F560&gt; ────────────────╮\n│ def inv(a):                                                         │\n│                                                                     │\n│ Compute the (multiplicative) inverse of a matrix.                   │\n│                                                                     │\n│ Given a square matrix `a`, return the matrix `ainv` satisfying      │\n│ ``dot(a, ainv) = dot(ainv, a) = eye(a.shape[0])``.                  │\n│                                                                     │\n│ Parameters                                                          │\n│ ----------                                                          │\n│ a : (..., M, M) array_like                                          │\n│     Matrix to be inverted.                                          │\n│                                                                     │\n│ Returns                                                             │\n│ -------                                                             │\n│ ainv : (..., M, M) ndarray or matrix                                │\n│     (Multiplicative) inverse of the matrix `a`.                     │\n│                                                                     │\n│ Raises                                                              │\n│ ------                                                              │\n│ LinAlgError                                                         │\n│     If `a` is not square or inversion fails.                        │\n│                                                                     │\n│ See Also                                                            │\n│ --------                                                            │\n│ scipy.linalg.inv : Similar function in SciPy.                       │\n│                                                                     │\n│ Notes                                                               │\n│ -----                                                               │\n│                                                                     │\n│ .. versionadded:: 1.8.0                                             │\n│                                                                     │\n│ Broadcasting rules apply, see the `numpy.linalg` documentation for  │\n│ details.                                                            │\n│                                                                     │\n│ Examples                                                            │\n│ --------                                                            │\n│ &gt;&gt;&gt; from numpy.linalg import inv                                    │\n│ &gt;&gt;&gt; a = np.array([[1., 2.], [3., 4.]])                              │\n│ &gt;&gt;&gt; ainv = inv(a)                                                   │\n│ &gt;&gt;&gt; np.allclose(np.dot(a, ainv), np.eye(2))                         │\n│ True                                                                │\n│ &gt;&gt;&gt; np.allclose(np.dot(ainv, a), np.eye(2))                         │\n│ True                                                                │\n│                                                                     │\n│ If a is a matrix object, then the return value is a matrix as well: │\n│                                                                     │\n│ &gt;&gt;&gt; ainv = inv(np.matrix(a))                                        │\n│ &gt;&gt;&gt; ainv                                                            │\n│ matrix([[-2. ,  1. ],                                               │\n│         [ 1.5, -0.5]])                                              │\n│                                                                     │\n│ Inverses of several matrices can be computed at once:               │\n│                                                                     │\n│ &gt;&gt;&gt; a = np.array([[[1., 2.], [3., 4.]], [[1, 3], [3, 5]]])          │\n│ &gt;&gt;&gt; inv(a)                                                          │\n│ array([[[-2.  ,  1.  ],                                             │\n│         [ 1.5 , -0.5 ]],                                            │\n│        [[-1.25,  0.75],                                             │\n│         [ 0.75, -0.25]]])                                           │\n│                                                                     │\n│ 34 attribute(s) not shown. Run inspect(inspect) for options.        │\n╰─────────────────────────────────────────────────────────────────────╯\n\n\n\n\nfrom rich import inspect\n\ninspect(inv, help=True)\n\n╭─────────────── &lt;function inv at 0x000002308AF6F560&gt; ────────────────╮\n│ def inv(a):                                                         │\n│                                                                     │\n│ Compute the (multiplicative) inverse of a matrix.                   │\n│                                                                     │\n│ Given a square matrix `a`, return the matrix `ainv` satisfying      │\n│ ``dot(a, ainv) = dot(ainv, a) = eye(a.shape[0])``.                  │\n│                                                                     │\n│ Parameters                                                          │\n│ ----------                                                          │\n│ a : (..., M, M) array_like                                          │\n│     Matrix to be inverted.                                          │\n│                                                                     │\n│ Returns                                                             │\n│ -------                                                             │\n│ ainv : (..., M, M) ndarray or matrix                                │\n│     (Multiplicative) inverse of the matrix `a`.                     │\n│                                                                     │\n│ Raises                                                              │\n│ ------                                                              │\n│ LinAlgError                                                         │\n│     If `a` is not square or inversion fails.                        │\n│                                                                     │\n│ See Also                                                            │\n│ --------                                                            │\n│ scipy.linalg.inv : Similar function in SciPy.                       │\n│                                                                     │\n│ Notes                                                               │\n│ -----                                                               │\n│                                                                     │\n│ .. versionadded:: 1.8.0                                             │\n│                                                                     │\n│ Broadcasting rules apply, see the `numpy.linalg` documentation for  │\n│ details.                                                            │\n│                                                                     │\n│ Examples                                                            │\n│ --------                                                            │\n│ &gt;&gt;&gt; from numpy.linalg import inv                                    │\n│ &gt;&gt;&gt; a = np.array([[1., 2.], [3., 4.]])                              │\n│ &gt;&gt;&gt; ainv = inv(a)                                                   │\n│ &gt;&gt;&gt; np.allclose(np.dot(a, ainv), np.eye(2))                         │\n│ True                                                                │\n│ &gt;&gt;&gt; np.allclose(np.dot(ainv, a), np.eye(2))                         │\n│ True                                                                │\n│                                                                     │\n│ If a is a matrix object, then the return value is a matrix as well: │\n│                                                                     │\n│ &gt;&gt;&gt; ainv = inv(np.matrix(a))                                        │\n│ &gt;&gt;&gt; ainv                                                            │\n│ matrix([[-2. ,  1. ],                                               │\n│         [ 1.5, -0.5]])                                              │\n│                                                                     │\n│ Inverses of several matrices can be computed at once:               │\n│                                                                     │\n│ &gt;&gt;&gt; a = np.array([[[1., 2.], [3., 4.]], [[1, 3], [3, 5]]])          │\n│ &gt;&gt;&gt; inv(a)                                                          │\n│ array([[[-2.  ,  1.  ],                                             │\n│         [ 1.5 , -0.5 ]],                                            │\n│        [[-1.25,  0.75],                                             │\n│         [ 0.75, -0.25]]])                                           │\n│                                                                     │\n│ 34 attribute(s) not shown. Run inspect(inspect) for options.        │\n╰─────────────────────────────────────────────────────────────────────╯\n\n\n\nunxpefgkyezn Exercise Write a code block that imports the **numpy** function `numpy.linalg.det()` as `det()`. Run `inspect()` on it. Find the determinant of `[[4, 3], [1, 7]]`.\n\nModules\nSometimes, you will want to call in some code from a different script that you wrote (rather than from a package provided by someone else). Imagine you have several scripts with code in, a, b, and c, all of which need to use the same underlying function that you have written. What do you do? (Note that “script with code in” is just a text file that has a .py extension and contains code.)\nA central tenet of good coding is that you do not repeat yourself. Therefore, a bad solution to this problem would be to copy and paste the same code into all three of the scripts. A good solution is to write the code that’s need just once in a separate ‘utility’ script and have the other scripts import that one function. This also adheres to another important programming principle: that of writing modular code.\nThis schematic shows the kind of situation we’re talking about:\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport matplotlib_inline.backend_inline\n\n# Plot settings\nplt.style.use(\n    \"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\"\n)\nmatplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n\n\ngraph = nx.DiGraph()\ngraph.add_edges_from(\n    [\n        (\"Utility script\", \"code file a\"),\n        (\"Utility script\", \"code file b\"),\n        (\"code file a\", \"code file c\"),\n        (\"code file b\", \"code file c\"),\n        (\"Utility script\", \"code file c\"),\n    ]\n)\ncolour_node = \"#AFCBFF\"\nfixed_pos = nx.spring_layout(graph, seed=100)\nnx.draw(graph, pos=fixed_pos, with_labels=True, node_size=6000, node_color=colour_node)\nextent = 1.4\nplt.xlim(-extent, extent)\nplt.ylim(-extent, extent)\nplt.show();\n\n\n\n\n\n\n\n\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport matplotlib_inline.backend_inline\n\n# Plot settings\nplt.style.use(\n    \"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\"\n)\nmatplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n\n\ngraph = nx.DiGraph()\ngraph.add_edges_from(\n    [\n        (\"Utility script\", \"code file a\"),\n        (\"Utility script\", \"code file b\"),\n        (\"code file a\", \"code file c\"),\n        (\"code file b\", \"code file c\"),\n        (\"Utility script\", \"code file c\"),\n    ]\n)\ncolour_node = \"#AFCBFF\"\nfixed_pos = nx.spring_layout(graph, seed=100)\nnx.draw(graph, pos=fixed_pos, with_labels=True, node_size=6000, node_color=colour_node)\nextent = 1.4\nplt.xlim(-extent, extent)\nplt.ylim(-extent, extent)\nplt.show();\n\n\n\n\n\n\n\n\nHow can we give code files a, b, and c access to the functions etc in the “Utility script”? We would define a file ‘utilities.py’ that had the following function in that we would like to use in the other code files:\n# Contents of utilities.py file\ndef really_useful_func(number):\n    return number*10\nThen, in ‘code_script_a.py’, we would write:\n\nimport utilities as utils\n\nprint(utils.really_useful_func(20))\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[7], line 1\n----&gt; 1 import utilities as utils\n      3 print(utils.really_useful_func(20))\n\nModuleNotFoundError: No module named 'utilities'\n\n\n\nAn alternative is to just import the function we want, with the name we want:\n\nfrom utilities import really_useful_func as ru_fn\n\nprint(ru_fn(30))\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[8], line 1\n----&gt; 1 from utilities import really_useful_func as ru_fn\n      3 print(ru_fn(30))\n\nModuleNotFoundError: No module named 'utilities'\n\n\n\nAnother important example is the case where you want to run ‘utilities.py’ as a standalone script, but still want to borrow functions from it to run in other scripts. There’s a way to do this. Let’s change utilities.py to\n# Contents of utilities.py file\ndef really_useful_func(number):\n    return number*10\n\n\ndef default_func():\n    print('Script has run')\n\n\nif __name__ == '__main__':\n    default_func()\nWhat this says is that if we call ‘utilities.py’ from the command line, eg\npython utilities.py\nIt will return Script has run because, by executing the script alone, we are asking for anything in the main block defined at the end of the file to be run. But we can still import anything from utilities into other scripts as before–and in that case it is not the main script, but an import, and so the main block will not be executed by default.\nYou can important several functions at once from a module (aka another script file) like this:\nfrom utilities import really_useful_func, default_func\nunxpefgkyezn Exercise Write your own `utilities.py` that has a `super_useful_func` that accepts a number and returns the number divided by 10. In another script, `main.py`, try a) importing all of utilities and running `super_useful_func` on a number and, b), importing just `super_useful_func` from utilities and running it on a number."
  },
  {
    "objectID": "homework.html#reading-and-writing-files",
    "href": "homework.html#reading-and-writing-files",
    "title": "Lecture1-code-basics",
    "section": "Reading and writing files",
    "text": "Reading and writing files\nAlthough most applications in economics will use the pandas package to read and write tabular data, it’s sometimes useful to know how to read and write arbitrary files using the built-in Python libraries too. To open a file\nopen('filename', mode)\nwhere mode could be r for read, a for append, w for write, and x to create a file. Create a file called text_example.txt and write a single line in it, ‘hello world’. To open the file and print the text, use:\nwith open('text_example.txt') as f:\n    text_in = f.read()\n\nprint(text_in)\n'hello world!\\n'\n\\n is the new line character. Now let’s try adding a line to the file:\nwith open('text_example.txt', 'a') as f:\n    f.write('this is another line\\n')\nWriting and reading files using the with command is a quick and convenient shorthand for the less concise open, action, close pattern. For example, the above example can also be written as:\nf = open('text_example.txt', 'a')\nf.write('this is another line\\n')\nf.close()\nAlthough this short example shows opening and writing a text file, this approach can be used to edit a wide range of file extensions including .json, .xml, .csv, .tsv, and many more, including binary files in addition to plain text files."
  },
  {
    "objectID": "labs/Labexercises/01Chipotle-Exercises-with-solutions.html",
    "href": "labs/Labexercises/01Chipotle-Exercises-with-solutions.html",
    "title": "Ex2 - Getting and Knowing your Data",
    "section": "",
    "text": "This time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport numpy as np\n\n\n\nStep 2. Import the dataset from this address.\n\nchipo = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv', sep= '\\t')\n\n\n\nStep 3. Assign it to a variable called chipo.\n\nchipo = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv', sep= '\\t')\n\n\n\nStep 4. See the first 10 entries\n\nchipo.head(10)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n0\n1\n1\nChips and Fresh Tomato Salsa\nNaN\n$2.39\n\n\n1\n1\n1\nIzze\n[Clementine]\n$3.39\n\n\n2\n1\n1\nNantucket Nectar\n[Apple]\n$3.39\n\n\n3\n1\n1\nChips and Tomatillo-Green Chili Salsa\nNaN\n$2.39\n\n\n4\n2\n2\nChicken Bowl\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98\n\n\n5\n3\n1\nChicken Bowl\n[Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...\n$10.98\n\n\n6\n3\n1\nSide of Chips\nNaN\n$1.69\n\n\n7\n4\n1\nSteak Burrito\n[Tomatillo Red Chili Salsa, [Fajita Vegetables...\n$11.75\n\n\n8\n4\n1\nSteak Soft Tacos\n[Tomatillo Green Chili Salsa, [Pinto Beans, Ch...\n$9.25\n\n\n9\n5\n1\nSteak Burrito\n[Fresh Tomato Salsa, [Rice, Black Beans, Pinto...\n$9.25\n\n\n\n\n\n\n\n\n\nStep 5. What is the number of observations in the dataset?\n\n# Solution 1\n\nchipo.shape\n\n(4622, 5)\n\n\n\n# Solution 2\n\nchipo.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 4622 entries, 0 to 4621\nData columns (total 5 columns):\n #   Column              Non-Null Count  Dtype \n---  ------              --------------  ----- \n 0   order_id            4622 non-null   int64 \n 1   quantity            4622 non-null   int64 \n 2   item_name           4622 non-null   object\n 3   choice_description  3376 non-null   object\n 4   item_price          4622 non-null   object\ndtypes: int64(2), object(3)\nmemory usage: 180.7+ KB\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\nchipo.shape[1]\n\n5\n\n\n\n\nStep 7. Print the name of all the columns.\n\nchipo.columns\n\nIndex(['order_id', 'quantity', 'item_name', 'choice_description',\n       'item_price'],\n      dtype='object')\n\n\n\n\nStep 8. How is the dataset indexed?\n\nchipo.index\n\nRangeIndex(start=0, stop=4622, step=1)\n\n\n\n\nStep 9. Which was the most-ordered item?\n\nchipo.groupby(by=\"item_name\").sum().sort_values('quantity',ascending=False).head(1)\n\n\n\n\n\n\n\n\norder_id\nquantity\nchoice_description\nitem_price\n\n\nitem_name\n\n\n\n\n\n\n\n\nChicken Bowl\n713926\n761\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98 $10.98 $11.25 $8.75 $8.49 $11.25 $8.75 ...\n\n\n\n\n\n\n\n\n\nStep 10. For the most-ordered item, how many items were ordered?\n\nchipo.groupby(by=\"item_name\").sum().sort_values('quantity',ascending=False).head(1)\n\n\n\n\n\n\n\n\norder_id\nquantity\nchoice_description\nitem_price\n\n\nitem_name\n\n\n\n\n\n\n\n\nChicken Bowl\n713926\n761\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98 $10.98 $11.25 $8.75 $8.49 $11.25 $8.75 ...\n\n\n\n\n\n\n\n\n\nStep 11. What was the most ordered item in the choice_description column?\n\nchipo.groupby(by=\"choice_description\").sum().sort_values('quantity',ascending=False).head(1)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nitem_price\n\n\nchoice_description\n\n\n\n\n\n\n\n\n[Diet Coke]\n123455\n159\nCanned SodaCanned SodaCanned Soda6 Pack Soft D...\n$2.18 $1.09 $1.09 $6.49 $2.18 $1.25 $1.09 $6.4...\n\n\n\n\n\n\n\n\n\nStep 12. How many items were orderd in total?\n\nchipo.item_name.count()\n\n4622\n\n\n\n\nStep 13. Turn the item price into a float\n\nStep 13.a. Check the item price type\n\nchipo.item_price.dtype\n\ndtype('O')\n\n\n\n\nStep 13.b. Create a lambda function and change the type of item price\n\ndollarizer = lambda x: float(x[1:-1])\nchipo.item_price = chipo.item_price.apply(dollarizer)\n\n\n\nStep 13.c. Check the item price type\n\nchipo.item_price.dtype\n\ndtype('float64')\n\n\n\n\n\nStep 14. How much was the revenue for the period in the dataset?\n\nrevenue =  (chipo.item_price * chipo.quantity).sum()\nprint('Revenue is : $ '+ str(revenue))\n\nRevenue is : $ 39237.02\n\n\n\n\nStep 15. How many orders were made in the period?\n\nchipo.order_id.value_counts().count()\n\n1834\n\n\n\n\nStep 16. What is the average revenue amount per order?\n\n# Solution 1\nchipo['revenue'] = chipo['quantity'] * chipo['item_price']\norder_grouped = chipo.groupby(by=['order_id']).sum()\norder_grouped['revenue'].mean()\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[8], line 4\n      2 chipo['revenue'] = chipo['quantity'] * chipo['item_price']\n      3 order_grouped = chipo.groupby(by=['order_id']).sum()\n----&gt; 4 order_grouped['revenue'].mean()\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6549, in Series.mean(self, axis, skipna, numeric_only, **kwargs)\n   6541 @doc(make_doc(\"mean\", ndim=1))\n   6542 def mean(\n   6543     self,\n   (...)\n   6547     **kwargs,\n   6548 ):\n-&gt; 6549     return NDFrame.mean(self, axis, skipna, numeric_only, **kwargs)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12420, in NDFrame.mean(self, axis, skipna, numeric_only, **kwargs)\n  12413 def mean(\n  12414     self,\n  12415     axis: Axis | None = 0,\n   (...)\n  12418     **kwargs,\n  12419 ) -&gt; Series | float:\n&gt; 12420     return self._stat_function(\n  12421         \"mean\", nanops.nanmean, axis, skipna, numeric_only, **kwargs\n  12422     )\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12377, in NDFrame._stat_function(self, name, func, axis, skipna, numeric_only, **kwargs)\n  12373 nv.validate_func(name, (), kwargs)\n  12375 validate_bool_kwarg(skipna, \"skipna\", none_allowed=False)\n&gt; 12377 return self._reduce(\n  12378     func, name=name, axis=axis, skipna=skipna, numeric_only=numeric_only\n  12379 )\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6457, in Series._reduce(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\n   6452     # GH#47500 - change to TypeError to match other methods\n   6453     raise TypeError(\n   6454         f\"Series.{name} does not allow {kwd_name}={numeric_only} \"\n   6455         \"with non-numeric dtypes.\"\n   6456     )\n-&gt; 6457 return op(delegate, skipna=skipna, **kwds)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147, in bottleneck_switch.__call__.&lt;locals&gt;.f(values, axis, skipna, **kwds)\n    145         result = alt(values, axis=axis, skipna=skipna, **kwds)\n    146 else:\n--&gt; 147     result = alt(values, axis=axis, skipna=skipna, **kwds)\n    149 return result\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404, in _datetimelike_compat.&lt;locals&gt;.new_func(values, axis, skipna, mask, **kwargs)\n    401 if datetimelike and mask is None:\n    402     mask = isna(values)\n--&gt; 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)\n    406 if datetimelike:\n    407     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:720, in nanmean(values, axis, skipna, mask)\n    718 count = _get_counts(values.shape, mask, axis, dtype=dtype_count)\n    719 the_sum = values.sum(axis, dtype=dtype_sum)\n--&gt; 720 the_sum = _ensure_numeric(the_sum)\n    722 if axis is not None and getattr(the_sum, \"ndim\", False):\n    723     count = cast(np.ndarray, count)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1701, in _ensure_numeric(x)\n   1698 elif not (is_float(x) or is_integer(x) or is_complex(x)):\n   1699     if isinstance(x, str):\n   1700         # GH#44008, GH#36703 avoid casting e.g. strings to numeric\n-&gt; 1701         raise TypeError(f\"Could not convert string '{x}' to numeric\")\n   1702     try:\n   1703         x = float(x)\n\nTypeError: Could not convert string '$2.39 $3.39 $3.39 $2.39 $16.98 $16.98 $10.98 $1.69 $11.75 $9.25 $9.25 $4.45 $8.75 $8.75 $11.25 $4.45 $2.39 $8.49 $8.49 $2.18 $2.18 $8.75 $4.45 $8.99 $3.39 $10.98 $3.39 $2.39 $8.49 $8.99 $1.09 $8.49 $2.39 $8.99 $1.69 $8.99 $1.09 $8.75 $8.75 $4.45 $2.95 $11.75 $2.15 $4.45 $11.25 $11.75 $8.75 $10.98 $8.99 $3.39 $8.99 $3.99 $8.99 $2.18 $2.18 $10.98 $1.09 $8.99 $2.39 $9.25 $11.25 $11.75 $2.15 $4.45 $9.25 $11.25 $8.75 $8.99 $8.99 $3.39 $8.99 $10.98 $8.99 $1.69 $8.99 $3.99 $8.75 $4.45 $8.75 $8.75 $2.15 $8.75 $11.25 $2.15 $9.25 $8.75 $8.75 $9.25 $8.49 $8.99 $1.09 $9.25 $2.95 $11.75 $11.75 $9.25 $11.75 $4.45 $9.25 $4.45 $11.75 $8.75 $8.75 $4.45 $8.99 $8.99 $3.99 $8.49 $3.39 $8.99 $1.09 $9.25 $4.45 $8.75 $2.95 $4.45 $2.39 $8.49 $8.99 $8.49 $1.09 $8.99 $3.99 $8.75 $9.25 $4.45 $11.25 $4.45 $8.99 $1.09 $9.25 $2.95 $4.45 $11.75 $4.45 $8.49 $2.39 $10.98 $22.50 $22.50 $11.75 $4.45 $11.25 $4.45 $11.25 $4.45 $11.25 $11.25 $11.75 $9.25 $4.45 $11.48 $17.98 $17.98 $1.69 $17.50 $17.50 $4.45 $8.49 $2.39 $17.50 $17.50 $4.45 $4.45 $11.25 $11.75 $10.98 $8.49 $10.98 $2.18 $2.18 $11.48 $8.49 $2.39 $4.45 $11.25 $11.75 $8.75 $8.49 $2.18 $2.18 $8.49 $3.39 $8.49 $8.99 $10.98 $11.48 $8.49 $1.09 $1.09 $9.25 $8.75 $2.95 $9.25 $4.45 $11.25 $11.48 $8.49 $8.49 $8.99 $2.39 $11.25 $8.75 $2.95 $1.09 $8.99 $8.49 $2.39 $10.98 $1.09 $3.99 $11.25 $8.75 $8.49 $3.39 $8.75 $9.25 $2.15 $11.25 $11.25 $11.25 $4.45 $22.50 $22.50 $4.45 $11.75 $8.75 $17.50 $17.50 $8.75 $9.25 $8.75 $2.15 $9.25 $4.30 $4.30 $8.75 $11.25 $2.15 $8.99 $1.09 $8.99 $3.99 $8.75 $2.95 $2.95 $11.75 $5.90 $5.90 $9.25 $9.25 $11.75 $9.25 $2.95 $17.50 $17.50 $8.75 $9.25 $10.98 $8.99 $1.09 $1.09 $1.09 $8.99 $10.98 $1.09 $8.75 $8.75 $9.25 $9.25 $8.75 $8.75 $8.99 $8.99 $8.99 $1.09 $11.75 $1.25 $8.99 $2.39 $9.25 $2.95 $8.99 $3.99 $8.49 $2.39 $8.49 $8.49 $8.49 $1.69 $8.49 $3.99 $8.99 $1.69 $1.09 $23.78 $23.78 $17.50 $17.50 $2.15 $8.75 $9.25 $9.25 $8.75 $4.45 $8.75 $11.25 $11.25 $1.25 $9.25 $4.45 $11.25 $11.75 $11.75 $6.49 $8.99 $2.39 $8.49 $2.39 $11.25 $8.75 $2.15 $8.99 $1.69 $8.75 $11.25 $2.15 $4.45 $8.75 $8.49 $8.99 $17.50 $17.50 $8.49 $1.09 $1.09 $8.75 $1.25 $2.15 $11.08 $8.49 $8.49 $8.99 $2.39 $8.75 $2.15 $1.50 $11.25 $2.15 $8.49 $8.49 $11.75 $9.25 $11.75 $1.25 $11.25 $8.75 $4.45 $6.49 $9.25 $2.95 $11.25 $4.45 $1.25 $1.25 $8.49 $2.39 $2.18 $2.18 $8.49 $2.18 $2.18 $22.16 $22.16 $17.50 $17.50 $8.75 $2.95 $6.49 $8.99 $3.39 $3.39 $8.99 $8.49 $11.25 $2.15 $11.25 $2.95 $11.25 $1.25 $8.99 $1.09 $8.75 $8.75 $9.25 $2.95 $11.75 $1.50 $8.99 $1.09 $11.25 $1.25 $1.25 $11.25 $11.75 $2.15 $8.99 $1.69 $11.75 $6.49 $8.75 $9.25 $11.25 $4.45 $1.25 $11.25 $4.45 $8.49 $8.99 $8.49 $8.99 $11.25 $1.25 $11.75 $1.25 $11.75 $9.25 $4.45 $11.25 $2.15 $32.94 $32.94 $32.94 $1.25 $11.25 $11.48 $1.69 $1.09 $17.50 $17.50 $4.45 $6.49 $9.25 $8.75 $9.25 $9.25 $8.75 $8.75 $2.15 $2.95 $17.50 $17.50 $10.98 $11.48 $11.48 $3.39 $8.99 $1.69 $8.99 $1.09 $10.98 $3.39 $8.99 $1.09 $9.25 $8.75 $11.25 $4.45 $2.95 $9.25 $22.20 $22.20 $22.20 $8.49 $8.99 $8.75 $8.75 $11.75 $8.75 $11.25 $9.25 $11.25 $11.25 $8.75 $11.25 $2.95 $1.25 $8.49 $1.69 $11.75 $11.25 $8.75 $8.75 $4.45 $8.49 $3.99 $8.49 $3.99 $11.48 $1.69 $1.09 $11.25 $1.50 $10.58 $1.69 $9.25 $11.25 $8.75 $9.25 $11.25 $11.25 $8.75 $11.75 $8.75 $8.75 $8.75 $2.15 $11.25 $11.75 $2.50 $2.50 $4.45 $9.25 $4.45 $11.25 $8.49 $3.99 $9.25 $9.25 $11.25 $9.25 $11.75 $11.25 $1.25 $23.50 $23.50 $1.25 $8.99 $8.49 $7.40 $7.40 $8.75 $1.25 $4.45 $8.75 $2.15 $8.75 $4.45 $7.40 $7.40 $7.40 $8.99 $3.99 $8.99 $1.69 $8.75 $8.75 $8.75 $8.75 $11.25 $11.25 $2.95 $8.75 $18.50 $18.50 $8.49 $3.99 $2.95 $9.25 $9.25 $3.00 $3.00 $1.25 $8.75 $9.25 $4.45 $8.75 $11.25 $4.45 $10.98 $22.16 $22.16 $4.45 $8.75 $9.25 $6.49 $9.25 $11.25 $8.75 $9.25 $2.15 $9.25 $4.45 $9.25 $2.95 $9.25 $8.75 $9.25 $1.25 $1.25 $8.75 $8.75 $9.25 $4.45 $11.75 $11.75 $11.75 $9.25 $9.25 $16.98 $16.98 $2.39 $3.39 $3.39 $9.25 $11.75 $11.25 $2.15 $8.75 $9.25 $4.45 $10.98 $11.25 $9.25 $22.50 $22.50 $9.25 $2.95 $1.50 $11.48 $8.49 $1.69 $8.49 $8.49 $8.49 $6.78 $6.78 $11.75 $4.45 $8.75 $4.45 $11.89 $9.39 $8.75 $2.95 $1.25 $9.25 $8.75 $23.78 $23.78 $8.75 $9.25 $2.15 $2.15 $1.25 $8.49 $3.99 $10.98 $1.09 $8.75 $4.45 $8.75 $11.75 $2.95 $4.45 $9.25 $8.75 $8.49 $3.99 $22.50 $22.50 $11.25 $1.25 $8.75 $8.75 $18.50 $18.50 $6.49 $8.75 $8.75 $4.45 $8.49 $3.99 $8.99 $1.09 $8.49 $2.39 $11.48 $1.69 $2.50 $2.50 $9.25 $1.50 $17.50 $17.50 $2.95 $8.75 $4.45 $11.75 $8.75 $8.49 $1.69 $8.49 $3.99 $8.99 $8.99 $3.99 $8.99 $11.25 $4.45 $1.25 $3.99 $10.98 $7.40 $3.00 $7.40 $4.00 $8.49 $3.99 $9.25 $4.45 $11.25 $1.25 $11.75 $1.25 $11.25 $2.15 $11.25 $4.45 $3.75 $3.75 $3.75 $11.75 $8.99 $2.39 $8.75 $4.45 $1.25 $8.99 $8.49 $2.18 $2.18 $8.49 $2.18 $2.18 $1.09 $8.75 $2.95 $1.25 $1.50 $11.25 $9.25 $2.95 $1.25 $8.49 $3.99 $11.48 $3.99 $8.49 $11.25 $1.25 $8.99 $1.69 $11.25 $1.25 $6.49 $8.75 $9.25 $8.75 $2.95 $8.75 $11.75 $8.69 $8.69 $2.29 $3.99 $8.49 $8.75 $8.75 $1.25 $11.75 $11.25 $11.25 $11.25 $1.25 $9.25 $11.75 $6.49 $3.99 $8.49 $11.25 $2.15 $11.25 $11.89 $8.99 $1.69 $8.99 $8.99 $3.99 $8.99 $9.25 $9.25 $2.15 $7.40 $7.40 $8.75 $8.75 $9.25 $4.45 $11.25 $1.25 $11.75 $11.25 $1.25 $3.99 $8.49 $8.49 $8.49 $8.99 $8.75 $2.15 $1.25 $8.49 $1.09 $1.09 $8.75 $2.95 $1.25 $9.25 $1.25 $2.15 $11.25 $1.25 $4.45 $8.75 $2.50 $2.50 $8.90 $8.90 $8.75 $8.75 $8.75 $11.25 $11.25 $10.98 $3.99 $10.98 $3.99 $1.69 $8.99 $9.25 $8.75 $8.99 $1.09 $9.25 $2.95 $8.75 $9.25 $3.99 $8.49 $8.75 $8.75 $22.50 $22.50 $10.98 $3.27 $3.27 $3.27 $3.99 $8.99 $1.09 $11.08 $8.75 $4.45 $11.08 $3.99 $8.49 $4.30 $4.30 $9.25 $8.75 $11.25 $11.25 $9.25 $8.49 $8.99 $8.49 $8.75 $2.95 $4.45 $9.25 $2.95 $9.25 $8.75 $11.25 $4.45 $16.98 $16.98 $8.49 $2.39 $11.25 $3.75 $3.75 $3.75 $9.25 $4.45 $9.25 $9.25 $4.45 $8.75 $9.25 $8.75 $9.25 $9.25 $9.25 $11.48 $8.99 $22.50 $22.50 $11.75 $11.25 $1.25 $8.75 $2.15 $1.25 $11.25 $8.75 $1.25 $11.25 $1.50 $11.25 $11.25 $9.25 $6.49 $8.90 $8.90 $8.75 $4.45 $11.25 $1.25 $17.50 $17.50 $9.25 $8.75 $11.75 $3.00 $3.00 $8.49 $8.49 $10.98 $8.99 $3.99 $8.75 $4.45 $8.99 $1.69 $11.75 $8.75 $11.25 $4.45 $11.75 $1.25 $11.75 $2.95 $8.99 $8.99 $2.18 $2.18 $17.98 $17.98 $8.99 $8.49 $1.69 $11.75 $11.25 $2.95 $3.75 $3.75 $3.75 $9.25 $11.75 $8.75 $2.15 $1.50 $8.49 $8.49 $3.39 $8.69 $3.89 $8.75 $4.45 $8.75 $11.25 $2.15 $8.75 $8.49 $1.69 $8.49 $8.49 $1.25 $8.75 $11.75 $11.75 $8.99 $1.09 $8.75 $4.45 $8.75 $2.95 $8.75 $2.15 $3.99 $8.49 $8.99 $3.99 $8.49 $1.69 $1.09 $8.99 $1.09 $9.25 $8.75 $8.99 $2.39 $1.25 $1.25 $11.25 $11.25 $9.25 $9.25 $11.25 $1.50 $3.99 $8.49 $11.25 $9.25 $11.25 $17.50 $17.50 $8.75 $8.90 $8.90 $8.75 $8.75 $8.99 $2.39 $11.25 $9.25 $2.15 $11.25 $1.25 $11.75 $1.25 $11.25 $11.75 $1.25 $11.25 $11.25 $8.49 $10.98 $8.75 $1.25 $8.75 $8.49 $8.49 $1.50 $1.50 $8.75 $4.45 $11.25 $1.25 $11.75 $8.49 $2.39 $9.25 $4.45 $9.25 $8.75 $8.99 $1.69 $17.50 $17.50 $2.39 $8.99 $8.99 $11.25 $4.45 $8.75 $4.45 $9.25 $6.49 $10.98 $8.49 $8.49 $1.09 $1.69 $9.25 $4.45 $8.75 $1.25 $2.95 $3.99 $8.49 $11.75 $11.75 $2.15 $11.48 $8.75 $2.15 $1.25 $11.25 $2.15 $1.25 $8.75 $8.75 $6.49 $1.69 $8.99 $8.75 $11.75 $10.98 $1.09 $8.49 $3.39 $8.75 $2.15 $1.25 $11.48 $10.98 $10.98 $8.49 $2.95 $9.25 $9.25 $11.75 $4.45 $11.48 $11.25 $8.75 $4.45 $1.69 $8.99 $8.75 $4.45 $1.50 $11.75 $2.15 $8.99 $2.39 $8.75 $2.95 $1.25 $8.75 $2.15 $1.25 $2.18 $2.18 $2.18 $2.18 $11.48 $8.75 $2.95 $11.75 $11.75 $1.25 $10.58 $8.99 $2.39 $11.75 $4.45 $11.25 $11.25 $17.50 $17.50 $8.75 $8.75 $8.75 $22.50 $22.50 $9.25 $8.75 $4.45 $11.75 $1.25 $11.25 $11.25 $2.95 $8.99 $1.69 $11.25 $4.45 $8.75 $6.49 $8.75 $4.45 $9.25 $4.45 $11.75 $11.75 $4.45 $11.89 $11.75 $11.25 $2.95 $1.50 $4.45 $8.75 $8.99 $1.09 $8.99 $1.09 $3.99 $11.48 $8.49 $9.25 $4.45 $11.48 $9.25 $2.95 $9.25 $8.49 $8.99 $8.99 $8.49 $8.75 $2.95 $4.45 $11.89 $10.58 $8.19 $1.69 $8.75 $2.15 $1.25 $17.50 $17.50 $6.49 $9.25 $2.15 $8.75 $4.45 $8.75 $1.25 $11.48 $11.48 $8.99 $2.18 $2.18 $8.49 $8.99 $2.39 $2.39 $2.18 $2.18 $8.75 $4.45 $11.25 $9.25 $9.25 $11.25 $11.25 $4.45 $2.95 $11.75 $8.49 $8.49 $8.99 $1.69 $9.25 $11.25 $11.75 $9.25 $8.75 $11.75 $8.75 $8.75 $11.25 $11.25 $10.98 $11.25 $4.45 $10.98 $8.49 $8.99 $3.39 $3.99 $8.99 $1.09 $1.09 $2.39 $17.50 $17.50 $4.45 $11.25 $11.25 $4.45 $9.25 $4.45 $8.75 $2.15 $1.25 $11.89 $2.95 $11.75 $1.25 $11.25 $4.45 $11.48 $11.48 $2.95 $9.25 $8.75 $9.25 $2.95 $11.25 $1.25 $11.75 $1.25 $8.99 $2.39 $1.25 $11.25 $1.25 $11.25 $8.49 $3.99 $35.00 $35.00 $35.00 $35.00 $27.75 $27.75 $27.75 $8.75 $11.80 $11.80 $11.80 $11.80 $8.90 $8.90 $5.90 $5.90 $6.49 $10.98 $17.98 $17.98 $2.39 $9.25 $8.75 $2.15 $8.75 $4.45 $8.49 $1.69 $8.19 $8.69 $10.98 $3.99 $11.48 $11.48 $4.45 $8.75 $6.49 $8.75 $8.75 $9.25 $1.25 $4.45 $8.49 $1.69 $9.25 $4.45 $8.99 $1.09 $11.25 $2.95 $11.08 $11.08 $3.89 $10.98 $11.25 $8.75 $11.25 $9.25 $4.30 $4.30 $8.75 $8.49 $3.99 $1.69 $8.99 $8.49 $1.69 $11.75 $11.25 $11.89 $9.25 $2.95 $9.25 $2.95 $8.75 $4.45 $4.45 $8.75 $10.98 $11.48 $8.49 $9.25 $4.45 $11.75 $11.89 $8.99 $8.49 $8.75 $9.25 $8.75 $8.75 $11.75 $11.75 $4.45 $11.25 $11.75 $2.50 $2.50 $8.99 $1.69 $11.75 $2.15 $1.25 $9.25 $8.75 $8.90 $8.90 $9.25 $2.95 $8.75 $11.25 $8.90 $8.90 $11.25 $11.75 $11.48 $1.69 $3.39 $9.25 $2.95 $8.99 $1.69 $8.49 $10.98 $11.25 $2.95 $8.99 $1.69 $8.75 $2.15 $1.25 $8.75 $2.95 $9.25 $2.50 $2.50 $11.25 $1.25 $11.75 $2.50 $2.50 $11.25 $1.50 $8.75 $1.25 $2.95 $11.48 $11.48 $8.75 $8.75 $2.15 $11.75 $1.25 $9.25 $9.25 $6.49 $11.75 $8.49 $8.49 $1.09 $10.98 $8.75 $1.25 $2.15 $11.25 $1.50 $11.25 $11.25 $8.49 $8.49 $8.75 $1.50 $1.25 $1.50 $8.75 $2.50 $2.50 $2.15 $7.40 $7.40 $4.00 $9.25 $9.39 $9.25 $9.25 $9.39 $11.25 $8.90 $8.90 $11.25 $6.00 $6.00 $6.00 $6.00 $11.25 $11.25 $11.25 $22.50 $22.50 $11.48 $1.09 $8.49 $8.49 $17.50 $17.50 $11.25 $1.50 $9.25 $8.75 $3.99 $8.49 $8.75 $8.75 $8.75 $8.75 $8.75 $11.75 $1.50 $11.25 $11.25 $2.95 $8.99 $10.98 $9.25 $8.75 $4.45 $8.49 $1.09 $2.39 $8.75 $8.75 $11.48 $8.99 $8.49 $8.49 $2.39 $10.98 $8.49 $3.99 $11.75 $4.45 $8.75 $2.15 $1.25 $10.98 $8.99 $11.25 $1.50 $8.75 $2.15 $1.25 $8.75 $9.25 $8.75 $11.25 $1.50 $8.75 $1.25 $4.45 $10.98 $8.75 $2.95 $1.25 $8.75 $2.95 $1.25 $8.49 $8.49 $2.39 $11.25 $1.25 $8.75 $8.75 $9.25 $8.75 $11.89 $1.25 $8.75 $2.15 $1.25 $8.99 $1.09 $8.75 $4.45 $26.25 $26.25 $26.25 $8.75 $4.45 $11.75 $2.95 $8.75 $8.75 $11.75 $8.75 $11.25 $11.25 $11.25 $4.45 $1.25 $8.49 $8.49 $8.49 $8.99 $8.99 $2.39 $2.39 $3.99 $8.75 $4.45 $2.15 $9.25 $1.25 $11.25 $11.75 $8.75 $4.45 $11.25 $2.15 $8.75 $4.45 $8.75 $8.75 $1.25 $11.25 $2.15 $8.75 $5.90 $5.90 $11.75 $1.25 $9.25 $3.75 $3.75 $3.75 $8.75 $1.25 $4.45 $11.75 $4.45 $8.75 $23.50 $23.50 $8.75 $2.95 $8.75 $8.75 $11.89 $4.45 $2.95 $1.25 $8.75 $4.45 $2.95 $1.25 $8.75 $2.15 $1.25 $11.75 $2.95 $8.99 $3.39 $9.25 $9.25 $17.50 $17.50 $2.95 $11.89 $1.50 $11.25 $2.95 $9.25 $11.25 $11.25 $2.95 $8.75 $9.25 $4.30 $4.30 $8.75 $8.75 $11.25 $8.75 $4.30 $4.30 $8.75 $1.25 $2.15 $8.49 $8.49 $3.39 $3.39 $10.98 $10.98 $2.39 $11.25 $11.75 $11.75 $1.25 $5.90 $5.90 $8.75 $11.25 $9.25 $4.45 $1.50 $3.39 $8.99 $2.39 $11.25 $2.15 $11.25 $11.75 $11.75 $4.45 $11.75 $4.45 $9.25 $8.75 $8.49 $8.99 $8.49 $8.99 $11.75 $8.75 $8.49 $3.99 $3.89 $11.08 $8.49 $8.99 $8.49 $8.49 $8.49 $11.25 $2.15 $17.50 $17.50 $8.75 $2.95 $8.49 $8.49 $10.98 $1.09 $11.25 $2.15 $2.95 $1.25 $8.75 $9.25 $9.25 $9.25 $2.95 $8.75 $2.15 $1.25 $8.99 $3.99 $11.75 $2.15 $8.99 $3.39 $9.25 $8.75 $11.25 $11.25 $4.45 $8.75 $2.15 $1.25 $11.75 $4.45 $9.25 $2.95 $8.49 $8.49 $11.25 $8.75 $4.45 $11.25 $11.25 $11.25 $11.25 $4.45 $8.49 $1.69 $8.49 $3.39 $8.75 $11.25 $9.25 $8.75 $11.25 $11.25 $11.75 $11.25 $11.75 $11.25 $11.75 $21.96 $21.96 $10.98 $1.69 $11.48 $8.99 $8.49 $1.69 $9.25 $2.15 $1.50 $11.25 $1.50 $8.75 $8.75 $2.95 $8.49 $1.69 $8.75 $2.95 $1.25 $11.25 $2.15 $11.08 $8.49 $8.49 $8.49 $11.75 $1.25 $11.75 $8.75 $8.75 $8.75 $4.45 $11.25 $1.50 $23.50 $23.50 $11.75 $6.49 $8.75 $4.45 $6.49 $8.75 $2.50 $2.50 $2.15 $8.49 $2.39 $8.75 $11.75 $4.45 $8.99 $10.98 $9.25 $2.95 $9.25 $9.25 $11.75 $8.75 $8.75 $8.75 $10.98 $11.25 $9.25 $8.75 $8.75 $2.15 $11.25 $2.15 $4.45 $11.75 $8.49 $2.39 $9.25 $1.25 $1.25 $1.25 $1.25 $8.75 $2.15 $8.49 $1.69 $11.25 $1.50 $8.75 $8.75 $8.49 $3.99 $8.99 $1.09 $11.25 $1.25 $8.49 $2.39 $8.49 $8.75 $9.25 $11.25 $4.45 $11.25 $11.89 $8.99 $8.49 $8.75 $4.45 $8.75 $11.75 $11.75 $8.90 $8.90 $9.39 $2.95 $8.49 $3.99 $8.75 $2.15 $1.25 $21.96 $21.96 $8.49 $1.69 $8.75 $4.45 $8.49 $8.99 $8.49 $3.99 $8.75 $8.75 $2.95 $8.75 $17.50 $17.50 $9.25 $2.95 $8.75 $6.49 $4.30 $4.30 $8.75 $8.75 $2.15 $1.50 $8.49 $8.49 $2.39 $9.25 $4.45 $6.49 $11.75 $4.45 $10.98 $1.69 $9.39 $9.25 $9.25 $2.95 $8.75 $2.15 $1.25 $11.25 $9.25 $8.75 $11.25 $8.75 $11.25 $2.50 $2.50 $2.50 $2.50 $6.00 $6.00 $6.00 $6.00 $8.90 $8.90 $5.90 $5.90 $11.25 $11.25 $8.49 $10.98 $8.75 $2.15 $1.50 $9.25 $1.25 $1.50 $2.15 $1.25 $8.75 $2.95 $8.49 $3.99 $11.25 $4.30 $4.30 $11.75 $2.15 $18.50 $18.50 $8.49 $2.39 $8.75 $4.45 $11.75 $8.99 $3.99 $9.25 $9.25 $1.50 $8.75 $2.95 $6.49 $11.75 $8.49 $8.99 $8.75 $4.45 $6.49 $22.50 $22.50 $9.25 $2.95 $8.49 $1.69 $10.98 $8.75 $4.45 $11.25 $2.95 $8.99 $8.49 $2.39 $11.75 $6.49 $11.25 $11.75 $2.95 $8.99 $1.69 $8.99 $2.18 $2.18 $1.09 $8.99 $8.99 $1.09 $8.99 $8.99 $8.49 $10.98 $1.09 $11.75 $9.25 $11.25 $11.25 $2.15 $11.25 $8.75 $4.45 $2.95 $11.75 $1.50 $8.99 $10.98 $2.39 $8.75 $2.15 $9.25 $1.50 $8.75 $2.15 $3.99 $8.99 $6.49 $8.75 $8.90 $8.90 $8.99 $3.99 $17.50 $17.50 $11.25 $1.25 $10.98 $9.25 $4.45 $1.25 $3.00 $3.00 $11.25 $4.45 $4.45 $2.95 $9.25 $11.25 $2.15 $11.25 $11.25 $4.45 $2.95 $9.25 $11.25 $1.25 $8.75 $2.95 $1.25 $8.75 $4.45 $11.48 $11.48 $8.49 $2.39 $11.25 $11.75 $2.15 $1.50 $2.15 $8.75 $11.25 $8.90 $8.90 $11.25 $11.25 $1.25 $4.45 $9.25 $9.25 $8.75 $9.25 $8.75 $8.75 $9.25 $8.75 $11.75 $11.75 $8.75 $8.75 $8.90 $8.90 $2.95 $10.98 $8.49 $8.49 $10.98 $8.99 $8.99 $11.75 $17.50 $17.50 $11.75 $3.99 $8.49 $10.98 $1.69 $17.50 $17.50 $8.99 $2.39 $8.99 $2.39 $1.25 $8.75 $2.95 $11.75 $11.25 $17.50 $17.50 $8.49 $8.49 $2.39 $11.25 $1.50 $8.75 $3.00 $3.00 $1.25 $8.75 $4.45 $11.75 $11.75 $4.45 $21.96 $21.96 $8.75 $4.45 $8.75 $11.25 $9.25 $8.99 $2.39 $9.25 $8.75 $10.98 $8.49 $3.99 $3.39 $11.75 $1.50 $4.45 $9.25 $8.75 $1.25 $11.75 $8.75 $1.50 $8.75 $8.75 $2.15 $1.50 $8.75 $2.95 $8.75 $8.75 $17.50 $17.50 $8.75 $6.49 $4.45 $11.25 $11.25 $4.30 $4.30 $8.75 $11.25 $4.45 $8.99 $2.39 $9.25 $9.25 $9.25 $4.45 $11.75 $11.25 $2.95 $2.15 $11.25 $11.25 $8.75 $2.15 $1.50 $9.25 $4.45 $10.98 $8.99 $2.18 $2.18 $8.75 $4.45 $1.25 $8.99 $2.39 $4.45 $8.75 $10.98 $11.75 $1.50 $10.98 $8.99 $8.49 $3.99 $8.99 $8.49 $3.99 $8.49 $8.49 $8.99 $11.25 $11.25 $10.98 $10.98 $10.98 $2.39 $3.39 $8.75 $1.25 $2.95 $11.75 $1.50 $10.98 $1.69 $4.45 $8.75 $8.75 $8.75 $8.75 $4.45 $9.25 $8.75 $11.25 $8.75 $3.99 $8.99 $8.49 $11.25 $11.25 $8.75 $4.45 $8.75 $4.45 $1.25 $8.75 $8.75 $1.50 $2.15 $11.75 $11.75 $11.75 $11.75 $11.75 $1.50 $8.75 $9.25 $1.25 $8.75 $2.15 $8.99 $1.09 $4.45 $11.25 $11.75 $2.15 $8.75 $8.75 $1.25 $9.25 $2.15 $11.75 $11.25 $8.75 $11.25 $4.45 $8.49 $1.69 $8.75 $8.75 $8.99 $8.49 $9.25 $11.25 $2.95 $4.45 $11.75 $6.49 $11.48 $8.99 $4.36 $4.36 $4.36 $4.36 $11.48 $8.99 $8.49 $11.48 $8.75 $2.15 $1.50 $8.99 $1.69 $11.25 $1.25 $9.25 $9.25 $8.75 $9.25 $8.90 $8.90 $2.15 $9.25 $10.98 $8.49 $8.75 $9.25 $4.30 $4.30 $9.25 $8.75 $8.75 $2.15 $1.25 $8.75 $1.25 $8.75 $5.90 $5.90 $9.25 $8.75 $9.25 $4.45 $9.25 $11.75 $2.50 $2.50 $9.25 $2.15 $9.25 $1.50 $1.25 $11.25 $2.95 $8.75 $8.75 $8.75 $10.98 $8.75 $8.75 $8.75 $2.15 $1.25 $10.98 $8.75 $2.15 $1.50 $8.75 $2.95 $1.25 $9.25 $9.25 $8.49 $2.39 $8.75 $4.45 $9.25 $8.75 $8.75 $8.75 $9.25 $8.75 $9.25 $8.75 $8.75 $8.75 $8.75 $9.25 $8.75 $9.25 $8.75 $9.25 $8.75 $8.75 $8.75 $9.25 $8.75 $9.25 $8.75 $8.99 $8.99 $8.75 $2.95 $1.25 $11.75 $1.50 $11.25 $11.25 $8.75 $1.50 $2.15 $16.98 $16.98 $11.75 $1.50 $8.75 $4.30 $4.30 $1.50 $8.75 $2.95 $1.25 $1.25 $9.25 $4.45 $11.25 $8.75 $4.45 $8.75 $2.15 $1.25 $10.98 $1.69 $8.75 $1.25 $8.75 $1.25 $11.25 $8.75 $8.75 $8.49 $1.69 $9.25 $11.75 $8.49 $2.39 $9.25 $2.95 $6.49 $8.75 $8.75 $9.25 $8.75 $6.78 $6.78 $17.98 $17.98 $3.39 $11.75 $11.25 $8.75 $4.45 $11.75 $9.25 $8.75 $6.49 $8.99 $2.39 $8.75 $11.25 $11.75 $4.45 $8.75 $2.15 $9.25 $9.25 $9.25 $11.89 $11.75 $11.25 $9.25 $9.25 $8.75 $8.75 $8.49 $1.69 $1.09 $11.25 $1.50 $11.25 $11.25 $11.75 $1.50 $8.49 $8.99 $22.50 $22.50 $8.75 $4.30 $4.30 $8.75 $11.25 $2.15 $11.25 $2.95 $4.45 $11.25 $8.49 $3.39 $2.39 $11.75 $2.15 $11.75 $8.99 $2.39 $8.75 $11.75 $11.89 $1.25 $7.50 $7.50 $7.50 $7.50 $7.50 $11.89 $1.09 $8.49 $2.39 $8.75 $8.75 $8.75 $8.75 $9.25 $11.25 $8.75 $8.90 $8.90 $9.25 $8.75 $8.75 $11.75 $3.00 $3.00 $1.50 $11.25 $11.75 $8.99 $10.98 $4.45 $8.75 $2.15 $9.25 $11.25 $4.45 $1.69 $10.98 $9.25 $11.75 $9.25 $4.45 $10.98 $3.99 $8.49 $1.25 $9.25 $4.45 $10.98 $8.75 $8.75 $11.75 $11.25 $8.49 $11.48 $4.45 $1.25 $11.25 $8.99 $1.09 $2.39 $11.25 $2.15 $8.75 $4.45 $8.49 $1.69 $10.98 $1.69 $9.25 $4.45 $11.25 $8.75 $11.25 $11.75 $11.25 $22.50 $22.50 $8.49 $2.39 $2.50 $2.50 $8.75 $8.75 $9.25 $9.25 $11.25 $8.99 $1.09 $8.99 $1.69 $11.75 $1.25 $21.96 $21.96 $8.75 $2.15 $1.25 $8.75 $11.25 $9.25 $11.25 $8.75 $8.75 $11.25 $2.15 $8.99 $1.09 $1.69 $8.75 $2.15 $1.25 $8.49 $1.09 $1.09 $1.69 $11.48 $8.49 $8.49 $4.78 $4.78 $9.25 $1.25 $1.25 $1.25 $11.25 $11.25 $11.75 $4.45 $11.25 $4.45 $8.99 $1.09 $11.25 $2.15 $11.25 $9.25 $11.75 $11.25 $11.25 $9.25 $2.95 $11.25 $4.45 $8.75 $2.95 $2.95 $11.25 $1.50 $10.98 $16.98 $16.98 $18.50 $18.50 $10.98 $3.99 $1.09 $9.25 $9.25 $8.75 $4.45 $17.50 $17.50 $8.75 $4.45 $8.75 $1.25 $4.45 $9.25 $8.75 $8.75 $17.50 $17.50 $4.45 $9.39 $1.25 $2.95 $11.25 $8.75 $8.75 $11.25 $2.15 $8.90 $8.90 $11.25 $11.89 $10.98 $11.25 $4.45 $11.25 $11.25 $8.49 $10.98 $8.49 $3.39 $9.25 $8.75 $2.95 $3.00 $3.00 $9.39 $11.75 $2.95 $1.50 $11.25 $11.75 $8.75 $2.15 $1.50 $8.49 $3.39 $11.75 $1.25 $17.50 $17.50 $11.25 $1.25 $8.75 $2.95 $1.25 $11.25 $11.75 $13.35 $13.35 $13.35 $11.25 $11.75 $11.25 $11.25 $4.45 $11.25 $8.49 $3.39 $9.25 $2.95 $4.78 $4.78 $2.39 $3.99 $8.99 $8.99 $11.25 $11.25 $8.75 $11.25 $2.95 $4.45 $9.25 $8.75 $4.45 $8.49 $8.49 $10.98 $10.98 $3.99 $11.75 $8.75 $11.75 $4.45 $1.50 $1.25 $8.49 $8.49 $8.75 $8.75 $8.75 $9.25 $8.75 $2.95 $1.25 $11.25 $1.50 $11.25 $4.45 $9.25 $8.75 $8.75 $9.25 $8.75 $4.45 $1.50 $8.75 $8.75 $8.49 $1.69 $8.75 $2.15 $9.25 $2.15 $1.50 $11.25 $11.75 $2.15 $6.49 $9.25 $9.25 $11.25 $11.25 $11.75 $11.75 $11.75 $11.25 $8.75 $2.15 $1.25 $11.75 $9.25 $11.25 $8.75 $5.90 $5.90 $8.75 $4.45 $9.25 $9.25 $4.45 $11.25 $4.45 $11.25 $8.75 $2.15 $11.89 $11.25 $8.75 $2.95 $1.50 $8.75 $4.30 $4.30 $8.75 $11.25 $11.75 $11.75 $2.15 $11.25 $8.99 $1.09 $8.49 $8.49 $8.49 $3.39 $8.99 $10.98 $3.99 $11.75 $2.15 $8.75 $4.45 $2.50 $2.50 $11.48 $1.09 $8.49 $8.49 $16.98 $16.98 $3.99 $10.98 $1.09 $8.75 $2.95 $8.75 $8.75 $2.95 $9.25 $11.25 $2.15 $9.25 $4.45 $4.45 $9.25 $11.75 $11.75 $2.15 $9.25 $8.75 $11.25 $6.49 $8.75 $11.25 $2.95 $10.98 $3.99 $1.50 $9.25 $2.15 $8.75 $11.25 $11.89 $4.45 $1.50 $1.25 $8.75 $8.75 $4.45 $11.25 $11.75 $8.49 $1.09 $1.09 $1.69 $8.99 $3.39 $8.99 $1.69 $8.49 $8.99 $3.27 $3.27 $3.27 $8.99 $8.99 $1.09 $10.98 $1.69 $3.99 $8.49 $1.09 $8.75 $8.75 $11.75 $8.75 $9.25 $8.75 $3.39 $8.99 $8.99 $2.39 $9.25 $8.75 $9.25 $9.25 $8.99 $3.99 $2.39 $8.49 $1.09 $8.49 $8.99 $3.39 $11.25 $1.25 $8.99 $3.99 $8.75 $8.90 $8.90 $6.49 $8.75 $9.25 $11.25 $11.25 $11.25 $1.25 $8.75 $9.25 $4.45 $1.25 $8.75 $1.25 $2.15 $17.98 $17.98 $8.99 $8.75 $2.95 $1.25 $11.75 $1.50 $1.50 $8.75 $8.75 $11.08 $8.99 $1.69 $8.99 $1.69 $10.98 $3.99 $3.39 $11.75 $2.15 $11.75 $2.95 $8.75 $8.75 $11.75 $11.25 $11.75 $11.25 $4.45 $11.25 $1.25 $2.18 $2.18 $2.18 $2.18 $2.39 $8.49 $8.99 $2.39 $11.25 $8.75 $11.75 $11.75 $11.25 $4.45 $2.15 $8.19 $10.58 $4.45 $9.25 $1.09 $8.99 $11.25 $1.50 $8.99 $3.99 $4.45 $11.75 $2.15 $11.25 $8.75 $4.45 $8.75 $9.25 $6.45 $6.45 $6.45 $8.75 $11.25 $11.25 $8.75 $11.75 $21.96 $21.96 $8.99 $5.07 $5.07 $5.07 $8.49 $9.25 $11.25 $4.45 $3.39 $8.49 $8.99 $8.49 $17.50 $17.50 $22.96 $22.96 $8.75 $11.25 $11.89 $11.25 $8.49 $1.69 $1.09 $8.99 $8.99 $9.25 $8.75 $9.25 $2.95 $8.49 $3.99 $8.99 $8.49 $7.17 $7.17 $7.17 $8.49 $8.99 $17.50 $17.50 $9.25 $9.25 $11.25 $1.25 $8.99 $1.09 $8.75 $4.45 $11.25 $2.15 $11.75 $11.25 $11.25 $8.75 $8.75 $4.45 $1.25 $11.75 $11.75 $2.50 $2.50 $8.49 $8.99 $2.18 $2.18 $11.25 $4.45 $11.25 $11.75 $8.49 $8.99 $1.69 $1.09 $8.99 $8.99 $11.25 $6.49 $11.25 $8.75 $4.45 $8.99 $1.69 $11.48 $11.75 $2.50 $2.50 $8.49 $1.09 $1.09 $1.69 $8.49 $2.39 $11.75 $1.25 $8.49 $1.69 $8.49 $1.69 $11.75 $4.45 $8.75 $8.75 $4.45 $8.75 $11.25 $11.25 $8.75 $7.98 $7.98 $8.49 $1.09 $8.49 $3.99 $8.49 $3.99 $8.99 $3.99 $11.25 $4.45 $8.49 $2.39 $8.49 $2.39 $3.99 $8.49 $1.25 $11.25 $4.45 $9.25 $4.45 $1.09 $8.99 $3.99 $11.25 $8.90 $8.90 $9.25 $11.25 $8.75 $11.25 $11.25 $11.25 $11.25 $11.25 $8.99 $8.49 $8.75 $8.75 $4.45 $16.98 $16.98 $11.75 $11.25 $9.25 $4.45 $9.25 $2.95 $8.49 $1.69 $3.75 $3.75 $3.75 $4.45 $9.25 $1.50 $11.25 $11.48 $11.25 $2.15 $8.75 $9.39 $8.49 $3.99 $8.19 $2.29 $11.48 $1.69 $11.48 $3.99 $8.49 $1.69 $9.25 $2.95 $8.49 $1.69 $11.25 $4.45 $9.39 $9.25 $8.75 $8.75 $4.45 $11.89 $4.45 $4.45 $8.75 $8.75 $8.75 $2.15 $8.75 $3.75 $3.75 $3.75 $9.25 $11.25 $4.45 $6.49 $16.98 $16.98 $18.50 $18.50 $2.50 $2.50 $2.95 $3.99 $8.49 $8.19 $11.08 $6.49 $11.75 $2.39 $8.99 $1.09 $11.25 $4.45 $11.25 $8.99 $1.69 $21.96 $21.96 $2.18 $2.18 $8.99 $8.99 $2.39 $8.69 $1.69 $8.90 $8.90 $2.50 $2.50 $8.75 $8.99 $1.09 $8.49 $8.49 $8.75 $4.45 $17.50 $17.50 $8.75 $9.25 $8.49 $2.39 $8.75 $4.45 $11.25 $11.25 $11.75 $8.75 $8.49 $8.49 $8.49 $8.99 $8.75 $4.45 $11.48 $8.75 $1.25 $2.15 $9.25 $4.45 $11.75 $2.15 $11.25 $8.99 $2.39 $8.69 $8.69 $11.75 $2.95 $11.75 $1.50 $9.25 $4.45 $1.50 $11.48 $8.99 $2.39 $11.25 $11.89 $2.15 $1.25 $11.75 $4.45 $8.75 $8.75 $11.25 $4.45 $11.25 $2.15 $4.45 $8.49 $1.09 $3.99 $11.25 $11.25 $8.49 $2.39 $8.99 $2.39 $11.25 $2.15 $8.75 $2.95 $1.25 $8.75 $11.25 $17.50 $17.50 $11.75 $11.75 $11.25 $11.25 $4.45 $2.50 $2.50 $8.75 $8.99 $8.99 $1.69 $8.99 $1.69 $11.25 $1.25 $11.08 $8.69 $8.99 $1.09 $11.25 $11.25 $2.95 $1.25 $8.75 $1.25 $8.75 $8.75 $2.15 $1.25 $8.49 $3.99 $8.49 $2.39 $8.49 $7.17 $7.17 $7.17 $8.75 $4.45 $11.48 $8.75 $8.75 $11.48 $8.75 $9.25 $8.49 $3.99 $1.50 $11.25 $11.25 $8.75 $8.75 $4.45 $9.25 $4.45 $8.75 $8.75 $4.30 $4.30 $2.95 $8.75 $4.50 $4.50 $4.50 $9.25 $11.25 $4.45 $11.25 $11.25 $8.75 $9.25 $8.75 $2.15 $1.25 $8.75 $2.15 $1.25 $8.99 $8.49 $8.75 $8.75 $1.25 $11.75 $4.50 $4.50 $4.50 $8.75 $8.75 $3.99 $3.39 $8.49 $2.39 $8.99 $1.50 $11.25 $11.25 $8.75 $8.75 $2.15 $8.75 $2.15 $1.25 $21.96 $21.96 $8.49 $1.69 $26.07 $26.07 $26.07 $11.75 $1.50 $8.99 $8.99 $11.48 $9.25 $9.25 $8.75 $8.75 $8.75 $9.25 $8.75 $8.75 $2.15 $1.25 $11.89 $8.75 $11.75 $4.45 $18.50 $18.50 $9.25 $9.39 $8.49 $2.39 $8.49 $1.69 $1.09 $8.99 $8.49 $2.18 $2.18 $11.25 $1.25 $8.49 $3.39 $8.49 $3.99 $11.25 $8.75 $8.49 $1.69 $16.98 $16.98 $9.25 $9.25 $11.75 $1.25 $11.25 $8.75 $8.49 $8.49 $8.75 $1.25 $1.25 $1.25 $11.25 $12.98 $12.98 $11.75 $11.75 $4.45 $11.25 $11.75 $10.98 $8.49 $8.49 $2.39 $9.25 $11.25 $8.75 $2.95 $1.50 $11.25 $2.95 $9.25 $2.95 $9.25 $8.75 $11.25 $8.75 $8.75 $4.45 $11.25 $1.25 $8.75 $2.95 $2.50 $2.50 $9.25 $9.25 $9.25 $6.49 $17.50 $17.50 $8.49 $1.69 $8.49 $3.99 $8.75 $2.95 $2.95 $8.49 $8.99 $8.99 $1.09 $8.75 $4.45 $1.25 $11.25 $11.75 $11.25 $9.25 $11.25 $1.50 $11.25 $2.15 $10.98 $8.75 $11.75 $2.95 $11.25 $11.25 $9.25 $8.75 $9.25 $8.75 $8.75 $8.75 $1.25 $11.25 $1.50 $2.15 $8.75 $8.75 $11.25 $8.75 $8.75 $11.25 $4.45 $8.49 $8.49 $8.49 $8.49 $8.99 $1.69 $2.39 $1.09 $1.09 $11.25 $2.95 $35.25 $35.25 $35.25 $8.75 $2.95 $1.25 $11.25 $2.15 $9.25 $4.45 $8.75 $8.75 $8.75 $4.45 $1.25 $11.89 $8.75 $2.15 $1.25 $8.49 $1.09 $1.09 $1.69 $8.69 $8.69 $9.25 $2.95 $10.98 $2.39 $22.50 $22.50 $21.96 $21.96 $10.98 $8.49 $1.69 $11.75 $2.95 $8.75 $11.25 $8.75 $9.25 $8.75 $8.19 $10.58 $8.75 $2.95 $1.50 $2.50 $2.50 $9.25 $4.45 $9.25 $11.25 $8.69 $8.69 $3.89 $8.69 $1.69 $4.45 $9.25 $11.25 $4.45 $2.15 $8.19 $8.69 $4.45 $11.25 $1.25 $11.25 $8.75 $11.89 $11.75 $11.75 $9.25 $8.75 $2.15 $1.50 $11.75 $4.45 $3.99 $8.99 $10.98 $2.39 $1.25 $2.95 $8.75 $2.95 $9.25 $9.25 $9.25 $8.75 $2.15 $9.25 $9.25 $3.39 $8.49 $8.49 $2.39 $10.98 $1.09 $1.09 $8.49 $11.25 $1.25 $8.99 $1.09 $8.75 $2.15 $1.50 $3.99 $8.49 $8.75 $2.15 $1.50 $8.49 $10.98 $2.18 $2.18 $8.75 $2.15 $1.50 $4.45 $9.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $10.50 $10.50 $10.50 $10.50 $10.50 $10.50 $10.50 $6.49 $33.75 $33.75 $33.75 $35.00 $35.00 $35.00 $35.00 $27.75 $27.75 $27.75 $3.00 $3.00 $11.25 $11.75 $10.98 $2.39 $2.50 $2.50 $8.75 $4.45 $16.98 $16.98 $8.75 $6.49 $16.98 $16.98 $17.98 $17.98 $16.98 $16.98 $16.98 $16.98 $8.99 $8.99 $8.49 $9.25 $8.75 $2.95 $11.48 $2.39 $8.99 $2.39 $11.25 $4.45 $8.75 $9.25 $6.49 $26.25 $26.25 $26.25 $8.75 $26.25 $26.25 $26.25 $8.75 $8.75 $11.25 $11.25 $2.15 $1.25 $11.75 $8.75 $2.15 $1.50 $11.25 $2.15 $8.99 $2.39 $11.25 $11.25 $2.15 $11.25 $11.25 $8.75 $4.78 $4.78 $21.96 $21.96 $8.49 $2.39 $9.25 $2.95 $16.98 $16.98 $8.19 $3.89 $8.99 $1.09 $8.99 $3.39 $9.25 $4.45 $10.98 $10.98 $17.50 $17.50 $11.25 $1.25 $8.75 $11.75 $4.45 $11.25 $11.25 $8.99 $1.09 $10.98 $8.49 $1.69 $11.25 $9.25 $16.98 $16.98 $8.75 $4.45 $11.25 $6.49 $11.75 $9.25 $9.25 $8.75 $4.45 $2.50 $2.50 $8.75 $11.75 $8.75 $9.25 $11.75 $9.25 $8.75 $9.25 $8.75 $11.25 $11.75 $9.25 $8.75 $11.75 $8.49 $1.09 $1.09 $8.49 $1.09 $1.69 $11.25 $1.25 $8.75 $2.15 $1.50 $8.49 $1.69 $1.25 $8.75 $2.95 $8.49 $3.99 $8.49 $8.49 $8.75 $11.25 $2.15 $1.50 $11.75 $8.99 $1.09 $10.98 $10.98 $11.25 $1.25 $8.75 $4.45 $4.45 $1.25 $11.89 $8.99 $8.99 $11.25 $4.45 $23.50 $23.50 $8.49 $3.99 $9.25 $4.45 $4.45 $9.25 $8.75 $4.45 $8.75 $8.75 $11.75 $6.49 $17.50 $17.50 $4.45 $8.75 $2.95 $1.50 $8.75 $8.75 $8.75 $4.45 $11.25 $11.25 $11.75 $11.25 $2.95 $11.25 $4.45 $3.00 $3.00 $1.25 $2.95 $9.25 $8.99 $2.39 $6.49 $8.75 $8.90 $8.90 $11.48 $1.09 $10.98 $9.25 $9.25 $11.25 $8.75 $11.75 $11.25 $11.25 $1.25 $9.25 $4.45 $9.25 $6.49 $11.75 $11.75 $8.99 $2.39 $8.49 $8.49 $9.25 $9.25 $1.25 $8.75 $2.95 $11.75 $2.15 $8.49 $8.49 $8.69 $16.38 $16.38 $8.19 $3.89 $2.29 $11.75 $8.75 $8.75 $8.75 $4.45 $8.49 $8.49 $9.25 $8.75 $6.49 $2.95 $11.25 $11.25 $2.15 $9.25 $11.75 $21.96 $21.96 $8.49 $3.39 $1.69 $8.49 $8.75 $4.45 $8.49 $3.99 $11.25 $8.75 $11.25 $2.15 $11.75 $4.45 $11.25 $9.25 $8.75 $18.50 $18.50 $1.50 $8.75 $2.15 $11.48 $2.18 $2.18 $3.99 $11.25 $1.50 $8.99 $2.39 $11.75 $1.50 $11.25 $6.49 $4.45 $11.25 $8.49 $3.99 $2.50 $2.50 $8.75 $9.25 $3.99 $8.99 $8.75 $6.49 $13.52 $13.52 $13.52 $13.52 $13.52 $13.52 $13.52 $13.52 $16.98 $16.98 $16.98 $16.98 $17.98 $17.98 $16.98 $16.98 $8.75 $8.75 $11.25 $11.25 $8.49 $1.09 $1.69 $1.25 $9.25 $2.95 $8.69 $8.19 $8.49 $2.39 $8.49 $2.39 $10.98 $8.99 $8.99 $1.69 $8.49 $8.75 $8.75 $11.25 $4.45 $4.45 $17.50 $17.50 $8.75 $4.45 $8.75 $2.15 $1.50 $1.50 $8.99 $1.09 $8.75 $4.45 $8.75 $8.75 $11.25 $4.30 $4.30 $8.49 $1.69 $1.09 $1.09 $8.75 $2.15 $1.50 $8.99 $8.49 $3.99 $8.75 $2.15 $1.25 $9.25 $2.95 $11.25 $4.45 $9.25 $2.95 $3.99 $8.99 $8.49 $8.75 $8.75 $11.25 $9.25 $8.75 $4.45 $11.25 $1.25 $9.25 $11.25 $4.45 $2.95 $10.98 $8.75 $8.75 $18.50 $18.50 $9.25 $9.25 $5.00 $5.00 $5.00 $5.00 $8.75 $2.95 $16.98 $16.98 $11.25 $2.95 $8.75 $2.15 $1.50 $8.49 $2.39 $9.25 $2.15 $1.25 $8.19 $8.69 $8.19 $8.19 $8.75 $2.95 $1.25 $9.25 $2.95 $11.25 $8.75 $11.25 $11.25 $8.99 $1.09 $9.25 $9.25 $4.45 $8.49 $3.99 $2.39 $1.09 $8.99 $8.49 $8.75 $8.75 $11.25 $11.75 $4.45 $2.50 $2.50 $8.75 $8.49 $3.39 $8.75 $9.25 $4.45 $1.25 $11.25 $2.15 $4.45 $2.50 $2.50 $8.99 $3.99 $8.75 $2.15 $11.75 $11.75 $1.25 $8.75 $9.39 $11.25 $9.25 $9.25 $2.95 $9.25 $4.45 $1.25 $9.25 $8.75 $11.75 $1.50 $8.75 $4.45 $8.99 $1.09 $9.25 $2.95 $8.99 $1.69 $8.69 $1.69 $11.25 $4.45 $8.75 $8.75 $4.45 $11.25 $8.75 $2.95 $1.50 $8.19 $8.69 $1.09 $1.69 $8.49 $8.75 $2.95 $1.25 $8.49 $3.99 $10.98 $3.39 $11.25 $11.25 $2.15 $18.50 $18.50 $8.49 $8.49 $11.25 $1.50 $8.49 $2.39 $8.99 $2.39 $11.75 $4.45 $17.50 $17.50 $9.25 $9.25 $8.75 $4.45 $3.75 $3.75 $3.75 $8.75 $4.45 $11.75 $2.95 $1.25 $4.45 $8.75 $1.25 $1.50 $9.25 $11.25 $11.25 $11.25 $11.25 $9.25 $11.25 $4.45 $8.75 $9.25 $8.75 $8.75 $4.45 $8.75 $1.25 $2.15 $8.75 $8.75 $4.30 $4.30 $8.75 $1.25 $2.95 $9.25 $2.95 $4.45 $11.25 $11.25 $9.25 $9.25 $4.50 $4.50 $4.50 $11.75 $1.25 $11.75 $11.75 $1.25 $1.25 $9.25 $4.45 $11.25 $11.75 $17.50 $17.50 $2.15 $1.25 $11.25 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $11.25 $4.45 $4.45 $2.95 $11.25 $2.15 $1.25 $1.50 $8.75 $11.25 $2.95 $11.25 $1.25 $2.15 $11.25 $9.25 $6.49 $1.25 $8.75 $2.15 $8.75 $6.49 $11.25 $1.50 $8.75 $4.45 $8.75 $4.45 $9.25 $9.25 $1.25 $1.25 $8.75 $4.50 $4.50 $4.50 $11.25 $1.25 $1.50 $9.25 $2.15 $11.25 $4.45 $11.25 $4.45 $8.75 $4.45 $9.25 $4.45 $1.25 $11.25 $4.45 $8.75 $4.45 $8.75 $2.15 $8.75 $4.45 $8.75 $11.75 $1.50 $11.25 $4.45 $8.75 $2.15 $1.50 $8.75 $4.45 $8.75 $11.75 $8.75 $8.75 $11.25 $11.25 $1.50 $8.75 $2.15 $11.75 $2.15 $9.25 $2.95 $18.50 $18.50 $1.25 $4.45 $8.50 $8.50 $8.50 $8.50 $11.25 $11.89 $1.25 $9.39 $4.45 $8.75 $2.15 $1.50 $11.75 $8.75 $9.25 $9.25 $4.45 $1.25 $11.25 $9.25 $2.95 $8.75 $8.75 $2.15 $8.75 $11.25 $11.25 $11.25 $11.75 $11.25 $2.15 $11.25 $2.15 $8.99 $8.99 $8.75 $9.25 $9.25 $11.25 $8.75 $4.45 $8.75 $1.25 $4.45 $11.25 $1.25 $8.75 $8.75 $11.25 $8.75 $1.25 $1.25 $1.25 $9.25 $11.75 $2.15 $8.75 $4.45 $8.75 $4.45 $11.25 $9.25 $8.75 $9.25 $4.45 $11.75 $4.45 $1.25 $4.45 $11.75 $9.25 $11.25 $2.15 $23.50 $23.50 $9.25 $2.15 $18.50 $18.50 $8.75 $5.90 $5.90 $11.89 $4.45 $8.75 $4.45 $9.25 $2.95 $11.25 $2.95 $11.25 $11.25 $11.25 $2.95 $11.75 $9.25 $9.25 $2.95 $11.25 $2.15 $9.25 $8.90 $8.90 $8.75 $11.25 $11.25 $11.25 $8.75 $2.15 $1.25 $11.25 $1.25 $8.75 $4.45 $1.25 $11.25 $11.25 $11.75 $1.25 $11.25 $11.25 $11.25 $8.75 $8.75 $18.50 $18.50 $11.75 $1.25 $4.45 $9.25 $6.49 $4.45 $8.75 $11.25 $6.49 $11.75 $8.75 $9.25 $11.25 $2.15 $8.75 $4.45 $11.25 $4.45 $8.75 $9.25 $4.45 $1.25 $1.25 $8.75 $11.25 $11.75 $2.15 $11.75 $4.45 $11.75 $1.25 $11.75 $11.75 $11.25 $4.30 $4.30 $9.39 $9.39 $8.75 $1.25 $9.25 $4.45 $11.25 $1.25 $8.75 $1.25 $2.95 $11.25 $4.45 $8.75 $1.50 $4.45 $4.45 $9.25 $8.75 $2.95 $1.25 $11.25 $2.95 $8.75 $8.75 $8.75 $8.75 $4.30 $4.30 $9.25 $9.39 $4.45 $9.25 $1.25 $22.50 $22.50 $4.45 $2.95 $2.15 $23.50 $23.50 $11.75 $2.15 $1.25 $9.25 $4.45 $11.25 $11.75 $17.50 $17.50 $8.75 $11.75 $11.25 $8.75 $4.45 $11.75 $1.50 $8.75 $8.75 $11.75 $9.25 $11.25 $4.45 $11.75 $9.25 $4.45 $11.25 $8.75 $8.75 $2.15 $1.50 $8.75 $4.45 $9.25 $8.75 $1.50 $1.25 $1.25 $1.25 $8.75 $2.95 $11.25 $11.25 $1.50 $11.75 $11.25 $2.15 $9.25 $8.75 $11.75 $2.95 $1.50 $8.75 $1.50 $1.25 $8.75 $11.75 $11.25 $11.25 $11.75 $11.25 $11.75 $8.75 $17.80 $17.80 $17.80 $17.80 $5.00 $5.00 $5.00 $5.00 $5.00 $5.00 $5.00 $5.00 $8.75 $2.95 $1.25 $11.25 $1.25 $2.15 $11.25 $2.50 $2.50 $9.25 $1.25 $11.25 $2.95 $11.75 $2.15 $11.25 $1.50 $8.99 $1.99 $11.49 $8.75 $4.45 $1.25 $8.75 $4.45 $1.25 $1.50 $11.75 $8.75 $8.75 $11.25 $6.49 $11.75 $8.75 $2.15 $1.25 $6.49 $8.75 $4.45 $8.75 $4.45 $8.75 $11.25 $4.45 $6.49 $9.25 $8.75 $1.25 $4.45 $11.25 $8.75 $1.50 $8.75 $1.50 $1.25 $9.25 $9.39 $4.45 $9.25 $8.75 $4.45 $1.25 $11.25 $11.75 $8.75 $11.25 $9.25 $8.75 $11.25 $2.50 $2.50 $17.50 $17.50 $9.25 $4.45 $11.25 $1.25 $8.75 $4.45 $1.50 $8.75 $1.50 $1.25 $9.39 $8.75 $8.75 $4.45 $11.25 $1.25 $9.25 $4.45 $11.25 $8.75 $3.00 $3.00 $8.75 $2.15 $1.25 $11.25 $11.25 $4.45 $11.25 $11.25 $8.75 $11.75 $11.75 $11.75 $8.75 $4.45 $1.25 $1.50 $8.75 $4.45 $1.25 $9.25 $9.25 $8.75 $4.45 $1.25 $11.75 $11.25 $1.25 $11.75 $11.25 $9.25 $2.15 $1.50 $8.75 $4.45 $11.75 $11.75 $11.25 $8.75 $8.75 ' to numeric\n\n\n\n\n# Solution 2\n\nchipo.groupby(by=['order_id']).sum()['revenue'].mean()\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[9], line 3\n      1 # Solution 2\n----&gt; 3 chipo.groupby(by=['order_id']).sum()['revenue'].mean()\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6549, in Series.mean(self, axis, skipna, numeric_only, **kwargs)\n   6541 @doc(make_doc(\"mean\", ndim=1))\n   6542 def mean(\n   6543     self,\n   (...)\n   6547     **kwargs,\n   6548 ):\n-&gt; 6549     return NDFrame.mean(self, axis, skipna, numeric_only, **kwargs)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12420, in NDFrame.mean(self, axis, skipna, numeric_only, **kwargs)\n  12413 def mean(\n  12414     self,\n  12415     axis: Axis | None = 0,\n   (...)\n  12418     **kwargs,\n  12419 ) -&gt; Series | float:\n&gt; 12420     return self._stat_function(\n  12421         \"mean\", nanops.nanmean, axis, skipna, numeric_only, **kwargs\n  12422     )\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12377, in NDFrame._stat_function(self, name, func, axis, skipna, numeric_only, **kwargs)\n  12373 nv.validate_func(name, (), kwargs)\n  12375 validate_bool_kwarg(skipna, \"skipna\", none_allowed=False)\n&gt; 12377 return self._reduce(\n  12378     func, name=name, axis=axis, skipna=skipna, numeric_only=numeric_only\n  12379 )\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6457, in Series._reduce(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\n   6452     # GH#47500 - change to TypeError to match other methods\n   6453     raise TypeError(\n   6454         f\"Series.{name} does not allow {kwd_name}={numeric_only} \"\n   6455         \"with non-numeric dtypes.\"\n   6456     )\n-&gt; 6457 return op(delegate, skipna=skipna, **kwds)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147, in bottleneck_switch.__call__.&lt;locals&gt;.f(values, axis, skipna, **kwds)\n    145         result = alt(values, axis=axis, skipna=skipna, **kwds)\n    146 else:\n--&gt; 147     result = alt(values, axis=axis, skipna=skipna, **kwds)\n    149 return result\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404, in _datetimelike_compat.&lt;locals&gt;.new_func(values, axis, skipna, mask, **kwargs)\n    401 if datetimelike and mask is None:\n    402     mask = isna(values)\n--&gt; 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)\n    406 if datetimelike:\n    407     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:720, in nanmean(values, axis, skipna, mask)\n    718 count = _get_counts(values.shape, mask, axis, dtype=dtype_count)\n    719 the_sum = values.sum(axis, dtype=dtype_sum)\n--&gt; 720 the_sum = _ensure_numeric(the_sum)\n    722 if axis is not None and getattr(the_sum, \"ndim\", False):\n    723     count = cast(np.ndarray, count)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1701, in _ensure_numeric(x)\n   1698 elif not (is_float(x) or is_integer(x) or is_complex(x)):\n   1699     if isinstance(x, str):\n   1700         # GH#44008, GH#36703 avoid casting e.g. strings to numeric\n-&gt; 1701         raise TypeError(f\"Could not convert string '{x}' to numeric\")\n   1702     try:\n   1703         x = float(x)\n\nTypeError: Could not convert string '$2.39 $3.39 $3.39 $2.39 $16.98 $16.98 $10.98 $1.69 $11.75 $9.25 $9.25 $4.45 $8.75 $8.75 $11.25 $4.45 $2.39 $8.49 $8.49 $2.18 $2.18 $8.75 $4.45 $8.99 $3.39 $10.98 $3.39 $2.39 $8.49 $8.99 $1.09 $8.49 $2.39 $8.99 $1.69 $8.99 $1.09 $8.75 $8.75 $4.45 $2.95 $11.75 $2.15 $4.45 $11.25 $11.75 $8.75 $10.98 $8.99 $3.39 $8.99 $3.99 $8.99 $2.18 $2.18 $10.98 $1.09 $8.99 $2.39 $9.25 $11.25 $11.75 $2.15 $4.45 $9.25 $11.25 $8.75 $8.99 $8.99 $3.39 $8.99 $10.98 $8.99 $1.69 $8.99 $3.99 $8.75 $4.45 $8.75 $8.75 $2.15 $8.75 $11.25 $2.15 $9.25 $8.75 $8.75 $9.25 $8.49 $8.99 $1.09 $9.25 $2.95 $11.75 $11.75 $9.25 $11.75 $4.45 $9.25 $4.45 $11.75 $8.75 $8.75 $4.45 $8.99 $8.99 $3.99 $8.49 $3.39 $8.99 $1.09 $9.25 $4.45 $8.75 $2.95 $4.45 $2.39 $8.49 $8.99 $8.49 $1.09 $8.99 $3.99 $8.75 $9.25 $4.45 $11.25 $4.45 $8.99 $1.09 $9.25 $2.95 $4.45 $11.75 $4.45 $8.49 $2.39 $10.98 $22.50 $22.50 $11.75 $4.45 $11.25 $4.45 $11.25 $4.45 $11.25 $11.25 $11.75 $9.25 $4.45 $11.48 $17.98 $17.98 $1.69 $17.50 $17.50 $4.45 $8.49 $2.39 $17.50 $17.50 $4.45 $4.45 $11.25 $11.75 $10.98 $8.49 $10.98 $2.18 $2.18 $11.48 $8.49 $2.39 $4.45 $11.25 $11.75 $8.75 $8.49 $2.18 $2.18 $8.49 $3.39 $8.49 $8.99 $10.98 $11.48 $8.49 $1.09 $1.09 $9.25 $8.75 $2.95 $9.25 $4.45 $11.25 $11.48 $8.49 $8.49 $8.99 $2.39 $11.25 $8.75 $2.95 $1.09 $8.99 $8.49 $2.39 $10.98 $1.09 $3.99 $11.25 $8.75 $8.49 $3.39 $8.75 $9.25 $2.15 $11.25 $11.25 $11.25 $4.45 $22.50 $22.50 $4.45 $11.75 $8.75 $17.50 $17.50 $8.75 $9.25 $8.75 $2.15 $9.25 $4.30 $4.30 $8.75 $11.25 $2.15 $8.99 $1.09 $8.99 $3.99 $8.75 $2.95 $2.95 $11.75 $5.90 $5.90 $9.25 $9.25 $11.75 $9.25 $2.95 $17.50 $17.50 $8.75 $9.25 $10.98 $8.99 $1.09 $1.09 $1.09 $8.99 $10.98 $1.09 $8.75 $8.75 $9.25 $9.25 $8.75 $8.75 $8.99 $8.99 $8.99 $1.09 $11.75 $1.25 $8.99 $2.39 $9.25 $2.95 $8.99 $3.99 $8.49 $2.39 $8.49 $8.49 $8.49 $1.69 $8.49 $3.99 $8.99 $1.69 $1.09 $23.78 $23.78 $17.50 $17.50 $2.15 $8.75 $9.25 $9.25 $8.75 $4.45 $8.75 $11.25 $11.25 $1.25 $9.25 $4.45 $11.25 $11.75 $11.75 $6.49 $8.99 $2.39 $8.49 $2.39 $11.25 $8.75 $2.15 $8.99 $1.69 $8.75 $11.25 $2.15 $4.45 $8.75 $8.49 $8.99 $17.50 $17.50 $8.49 $1.09 $1.09 $8.75 $1.25 $2.15 $11.08 $8.49 $8.49 $8.99 $2.39 $8.75 $2.15 $1.50 $11.25 $2.15 $8.49 $8.49 $11.75 $9.25 $11.75 $1.25 $11.25 $8.75 $4.45 $6.49 $9.25 $2.95 $11.25 $4.45 $1.25 $1.25 $8.49 $2.39 $2.18 $2.18 $8.49 $2.18 $2.18 $22.16 $22.16 $17.50 $17.50 $8.75 $2.95 $6.49 $8.99 $3.39 $3.39 $8.99 $8.49 $11.25 $2.15 $11.25 $2.95 $11.25 $1.25 $8.99 $1.09 $8.75 $8.75 $9.25 $2.95 $11.75 $1.50 $8.99 $1.09 $11.25 $1.25 $1.25 $11.25 $11.75 $2.15 $8.99 $1.69 $11.75 $6.49 $8.75 $9.25 $11.25 $4.45 $1.25 $11.25 $4.45 $8.49 $8.99 $8.49 $8.99 $11.25 $1.25 $11.75 $1.25 $11.75 $9.25 $4.45 $11.25 $2.15 $32.94 $32.94 $32.94 $1.25 $11.25 $11.48 $1.69 $1.09 $17.50 $17.50 $4.45 $6.49 $9.25 $8.75 $9.25 $9.25 $8.75 $8.75 $2.15 $2.95 $17.50 $17.50 $10.98 $11.48 $11.48 $3.39 $8.99 $1.69 $8.99 $1.09 $10.98 $3.39 $8.99 $1.09 $9.25 $8.75 $11.25 $4.45 $2.95 $9.25 $22.20 $22.20 $22.20 $8.49 $8.99 $8.75 $8.75 $11.75 $8.75 $11.25 $9.25 $11.25 $11.25 $8.75 $11.25 $2.95 $1.25 $8.49 $1.69 $11.75 $11.25 $8.75 $8.75 $4.45 $8.49 $3.99 $8.49 $3.99 $11.48 $1.69 $1.09 $11.25 $1.50 $10.58 $1.69 $9.25 $11.25 $8.75 $9.25 $11.25 $11.25 $8.75 $11.75 $8.75 $8.75 $8.75 $2.15 $11.25 $11.75 $2.50 $2.50 $4.45 $9.25 $4.45 $11.25 $8.49 $3.99 $9.25 $9.25 $11.25 $9.25 $11.75 $11.25 $1.25 $23.50 $23.50 $1.25 $8.99 $8.49 $7.40 $7.40 $8.75 $1.25 $4.45 $8.75 $2.15 $8.75 $4.45 $7.40 $7.40 $7.40 $8.99 $3.99 $8.99 $1.69 $8.75 $8.75 $8.75 $8.75 $11.25 $11.25 $2.95 $8.75 $18.50 $18.50 $8.49 $3.99 $2.95 $9.25 $9.25 $3.00 $3.00 $1.25 $8.75 $9.25 $4.45 $8.75 $11.25 $4.45 $10.98 $22.16 $22.16 $4.45 $8.75 $9.25 $6.49 $9.25 $11.25 $8.75 $9.25 $2.15 $9.25 $4.45 $9.25 $2.95 $9.25 $8.75 $9.25 $1.25 $1.25 $8.75 $8.75 $9.25 $4.45 $11.75 $11.75 $11.75 $9.25 $9.25 $16.98 $16.98 $2.39 $3.39 $3.39 $9.25 $11.75 $11.25 $2.15 $8.75 $9.25 $4.45 $10.98 $11.25 $9.25 $22.50 $22.50 $9.25 $2.95 $1.50 $11.48 $8.49 $1.69 $8.49 $8.49 $8.49 $6.78 $6.78 $11.75 $4.45 $8.75 $4.45 $11.89 $9.39 $8.75 $2.95 $1.25 $9.25 $8.75 $23.78 $23.78 $8.75 $9.25 $2.15 $2.15 $1.25 $8.49 $3.99 $10.98 $1.09 $8.75 $4.45 $8.75 $11.75 $2.95 $4.45 $9.25 $8.75 $8.49 $3.99 $22.50 $22.50 $11.25 $1.25 $8.75 $8.75 $18.50 $18.50 $6.49 $8.75 $8.75 $4.45 $8.49 $3.99 $8.99 $1.09 $8.49 $2.39 $11.48 $1.69 $2.50 $2.50 $9.25 $1.50 $17.50 $17.50 $2.95 $8.75 $4.45 $11.75 $8.75 $8.49 $1.69 $8.49 $3.99 $8.99 $8.99 $3.99 $8.99 $11.25 $4.45 $1.25 $3.99 $10.98 $7.40 $3.00 $7.40 $4.00 $8.49 $3.99 $9.25 $4.45 $11.25 $1.25 $11.75 $1.25 $11.25 $2.15 $11.25 $4.45 $3.75 $3.75 $3.75 $11.75 $8.99 $2.39 $8.75 $4.45 $1.25 $8.99 $8.49 $2.18 $2.18 $8.49 $2.18 $2.18 $1.09 $8.75 $2.95 $1.25 $1.50 $11.25 $9.25 $2.95 $1.25 $8.49 $3.99 $11.48 $3.99 $8.49 $11.25 $1.25 $8.99 $1.69 $11.25 $1.25 $6.49 $8.75 $9.25 $8.75 $2.95 $8.75 $11.75 $8.69 $8.69 $2.29 $3.99 $8.49 $8.75 $8.75 $1.25 $11.75 $11.25 $11.25 $11.25 $1.25 $9.25 $11.75 $6.49 $3.99 $8.49 $11.25 $2.15 $11.25 $11.89 $8.99 $1.69 $8.99 $8.99 $3.99 $8.99 $9.25 $9.25 $2.15 $7.40 $7.40 $8.75 $8.75 $9.25 $4.45 $11.25 $1.25 $11.75 $11.25 $1.25 $3.99 $8.49 $8.49 $8.49 $8.99 $8.75 $2.15 $1.25 $8.49 $1.09 $1.09 $8.75 $2.95 $1.25 $9.25 $1.25 $2.15 $11.25 $1.25 $4.45 $8.75 $2.50 $2.50 $8.90 $8.90 $8.75 $8.75 $8.75 $11.25 $11.25 $10.98 $3.99 $10.98 $3.99 $1.69 $8.99 $9.25 $8.75 $8.99 $1.09 $9.25 $2.95 $8.75 $9.25 $3.99 $8.49 $8.75 $8.75 $22.50 $22.50 $10.98 $3.27 $3.27 $3.27 $3.99 $8.99 $1.09 $11.08 $8.75 $4.45 $11.08 $3.99 $8.49 $4.30 $4.30 $9.25 $8.75 $11.25 $11.25 $9.25 $8.49 $8.99 $8.49 $8.75 $2.95 $4.45 $9.25 $2.95 $9.25 $8.75 $11.25 $4.45 $16.98 $16.98 $8.49 $2.39 $11.25 $3.75 $3.75 $3.75 $9.25 $4.45 $9.25 $9.25 $4.45 $8.75 $9.25 $8.75 $9.25 $9.25 $9.25 $11.48 $8.99 $22.50 $22.50 $11.75 $11.25 $1.25 $8.75 $2.15 $1.25 $11.25 $8.75 $1.25 $11.25 $1.50 $11.25 $11.25 $9.25 $6.49 $8.90 $8.90 $8.75 $4.45 $11.25 $1.25 $17.50 $17.50 $9.25 $8.75 $11.75 $3.00 $3.00 $8.49 $8.49 $10.98 $8.99 $3.99 $8.75 $4.45 $8.99 $1.69 $11.75 $8.75 $11.25 $4.45 $11.75 $1.25 $11.75 $2.95 $8.99 $8.99 $2.18 $2.18 $17.98 $17.98 $8.99 $8.49 $1.69 $11.75 $11.25 $2.95 $3.75 $3.75 $3.75 $9.25 $11.75 $8.75 $2.15 $1.50 $8.49 $8.49 $3.39 $8.69 $3.89 $8.75 $4.45 $8.75 $11.25 $2.15 $8.75 $8.49 $1.69 $8.49 $8.49 $1.25 $8.75 $11.75 $11.75 $8.99 $1.09 $8.75 $4.45 $8.75 $2.95 $8.75 $2.15 $3.99 $8.49 $8.99 $3.99 $8.49 $1.69 $1.09 $8.99 $1.09 $9.25 $8.75 $8.99 $2.39 $1.25 $1.25 $11.25 $11.25 $9.25 $9.25 $11.25 $1.50 $3.99 $8.49 $11.25 $9.25 $11.25 $17.50 $17.50 $8.75 $8.90 $8.90 $8.75 $8.75 $8.99 $2.39 $11.25 $9.25 $2.15 $11.25 $1.25 $11.75 $1.25 $11.25 $11.75 $1.25 $11.25 $11.25 $8.49 $10.98 $8.75 $1.25 $8.75 $8.49 $8.49 $1.50 $1.50 $8.75 $4.45 $11.25 $1.25 $11.75 $8.49 $2.39 $9.25 $4.45 $9.25 $8.75 $8.99 $1.69 $17.50 $17.50 $2.39 $8.99 $8.99 $11.25 $4.45 $8.75 $4.45 $9.25 $6.49 $10.98 $8.49 $8.49 $1.09 $1.69 $9.25 $4.45 $8.75 $1.25 $2.95 $3.99 $8.49 $11.75 $11.75 $2.15 $11.48 $8.75 $2.15 $1.25 $11.25 $2.15 $1.25 $8.75 $8.75 $6.49 $1.69 $8.99 $8.75 $11.75 $10.98 $1.09 $8.49 $3.39 $8.75 $2.15 $1.25 $11.48 $10.98 $10.98 $8.49 $2.95 $9.25 $9.25 $11.75 $4.45 $11.48 $11.25 $8.75 $4.45 $1.69 $8.99 $8.75 $4.45 $1.50 $11.75 $2.15 $8.99 $2.39 $8.75 $2.95 $1.25 $8.75 $2.15 $1.25 $2.18 $2.18 $2.18 $2.18 $11.48 $8.75 $2.95 $11.75 $11.75 $1.25 $10.58 $8.99 $2.39 $11.75 $4.45 $11.25 $11.25 $17.50 $17.50 $8.75 $8.75 $8.75 $22.50 $22.50 $9.25 $8.75 $4.45 $11.75 $1.25 $11.25 $11.25 $2.95 $8.99 $1.69 $11.25 $4.45 $8.75 $6.49 $8.75 $4.45 $9.25 $4.45 $11.75 $11.75 $4.45 $11.89 $11.75 $11.25 $2.95 $1.50 $4.45 $8.75 $8.99 $1.09 $8.99 $1.09 $3.99 $11.48 $8.49 $9.25 $4.45 $11.48 $9.25 $2.95 $9.25 $8.49 $8.99 $8.99 $8.49 $8.75 $2.95 $4.45 $11.89 $10.58 $8.19 $1.69 $8.75 $2.15 $1.25 $17.50 $17.50 $6.49 $9.25 $2.15 $8.75 $4.45 $8.75 $1.25 $11.48 $11.48 $8.99 $2.18 $2.18 $8.49 $8.99 $2.39 $2.39 $2.18 $2.18 $8.75 $4.45 $11.25 $9.25 $9.25 $11.25 $11.25 $4.45 $2.95 $11.75 $8.49 $8.49 $8.99 $1.69 $9.25 $11.25 $11.75 $9.25 $8.75 $11.75 $8.75 $8.75 $11.25 $11.25 $10.98 $11.25 $4.45 $10.98 $8.49 $8.99 $3.39 $3.99 $8.99 $1.09 $1.09 $2.39 $17.50 $17.50 $4.45 $11.25 $11.25 $4.45 $9.25 $4.45 $8.75 $2.15 $1.25 $11.89 $2.95 $11.75 $1.25 $11.25 $4.45 $11.48 $11.48 $2.95 $9.25 $8.75 $9.25 $2.95 $11.25 $1.25 $11.75 $1.25 $8.99 $2.39 $1.25 $11.25 $1.25 $11.25 $8.49 $3.99 $35.00 $35.00 $35.00 $35.00 $27.75 $27.75 $27.75 $8.75 $11.80 $11.80 $11.80 $11.80 $8.90 $8.90 $5.90 $5.90 $6.49 $10.98 $17.98 $17.98 $2.39 $9.25 $8.75 $2.15 $8.75 $4.45 $8.49 $1.69 $8.19 $8.69 $10.98 $3.99 $11.48 $11.48 $4.45 $8.75 $6.49 $8.75 $8.75 $9.25 $1.25 $4.45 $8.49 $1.69 $9.25 $4.45 $8.99 $1.09 $11.25 $2.95 $11.08 $11.08 $3.89 $10.98 $11.25 $8.75 $11.25 $9.25 $4.30 $4.30 $8.75 $8.49 $3.99 $1.69 $8.99 $8.49 $1.69 $11.75 $11.25 $11.89 $9.25 $2.95 $9.25 $2.95 $8.75 $4.45 $4.45 $8.75 $10.98 $11.48 $8.49 $9.25 $4.45 $11.75 $11.89 $8.99 $8.49 $8.75 $9.25 $8.75 $8.75 $11.75 $11.75 $4.45 $11.25 $11.75 $2.50 $2.50 $8.99 $1.69 $11.75 $2.15 $1.25 $9.25 $8.75 $8.90 $8.90 $9.25 $2.95 $8.75 $11.25 $8.90 $8.90 $11.25 $11.75 $11.48 $1.69 $3.39 $9.25 $2.95 $8.99 $1.69 $8.49 $10.98 $11.25 $2.95 $8.99 $1.69 $8.75 $2.15 $1.25 $8.75 $2.95 $9.25 $2.50 $2.50 $11.25 $1.25 $11.75 $2.50 $2.50 $11.25 $1.50 $8.75 $1.25 $2.95 $11.48 $11.48 $8.75 $8.75 $2.15 $11.75 $1.25 $9.25 $9.25 $6.49 $11.75 $8.49 $8.49 $1.09 $10.98 $8.75 $1.25 $2.15 $11.25 $1.50 $11.25 $11.25 $8.49 $8.49 $8.75 $1.50 $1.25 $1.50 $8.75 $2.50 $2.50 $2.15 $7.40 $7.40 $4.00 $9.25 $9.39 $9.25 $9.25 $9.39 $11.25 $8.90 $8.90 $11.25 $6.00 $6.00 $6.00 $6.00 $11.25 $11.25 $11.25 $22.50 $22.50 $11.48 $1.09 $8.49 $8.49 $17.50 $17.50 $11.25 $1.50 $9.25 $8.75 $3.99 $8.49 $8.75 $8.75 $8.75 $8.75 $8.75 $11.75 $1.50 $11.25 $11.25 $2.95 $8.99 $10.98 $9.25 $8.75 $4.45 $8.49 $1.09 $2.39 $8.75 $8.75 $11.48 $8.99 $8.49 $8.49 $2.39 $10.98 $8.49 $3.99 $11.75 $4.45 $8.75 $2.15 $1.25 $10.98 $8.99 $11.25 $1.50 $8.75 $2.15 $1.25 $8.75 $9.25 $8.75 $11.25 $1.50 $8.75 $1.25 $4.45 $10.98 $8.75 $2.95 $1.25 $8.75 $2.95 $1.25 $8.49 $8.49 $2.39 $11.25 $1.25 $8.75 $8.75 $9.25 $8.75 $11.89 $1.25 $8.75 $2.15 $1.25 $8.99 $1.09 $8.75 $4.45 $26.25 $26.25 $26.25 $8.75 $4.45 $11.75 $2.95 $8.75 $8.75 $11.75 $8.75 $11.25 $11.25 $11.25 $4.45 $1.25 $8.49 $8.49 $8.49 $8.99 $8.99 $2.39 $2.39 $3.99 $8.75 $4.45 $2.15 $9.25 $1.25 $11.25 $11.75 $8.75 $4.45 $11.25 $2.15 $8.75 $4.45 $8.75 $8.75 $1.25 $11.25 $2.15 $8.75 $5.90 $5.90 $11.75 $1.25 $9.25 $3.75 $3.75 $3.75 $8.75 $1.25 $4.45 $11.75 $4.45 $8.75 $23.50 $23.50 $8.75 $2.95 $8.75 $8.75 $11.89 $4.45 $2.95 $1.25 $8.75 $4.45 $2.95 $1.25 $8.75 $2.15 $1.25 $11.75 $2.95 $8.99 $3.39 $9.25 $9.25 $17.50 $17.50 $2.95 $11.89 $1.50 $11.25 $2.95 $9.25 $11.25 $11.25 $2.95 $8.75 $9.25 $4.30 $4.30 $8.75 $8.75 $11.25 $8.75 $4.30 $4.30 $8.75 $1.25 $2.15 $8.49 $8.49 $3.39 $3.39 $10.98 $10.98 $2.39 $11.25 $11.75 $11.75 $1.25 $5.90 $5.90 $8.75 $11.25 $9.25 $4.45 $1.50 $3.39 $8.99 $2.39 $11.25 $2.15 $11.25 $11.75 $11.75 $4.45 $11.75 $4.45 $9.25 $8.75 $8.49 $8.99 $8.49 $8.99 $11.75 $8.75 $8.49 $3.99 $3.89 $11.08 $8.49 $8.99 $8.49 $8.49 $8.49 $11.25 $2.15 $17.50 $17.50 $8.75 $2.95 $8.49 $8.49 $10.98 $1.09 $11.25 $2.15 $2.95 $1.25 $8.75 $9.25 $9.25 $9.25 $2.95 $8.75 $2.15 $1.25 $8.99 $3.99 $11.75 $2.15 $8.99 $3.39 $9.25 $8.75 $11.25 $11.25 $4.45 $8.75 $2.15 $1.25 $11.75 $4.45 $9.25 $2.95 $8.49 $8.49 $11.25 $8.75 $4.45 $11.25 $11.25 $11.25 $11.25 $4.45 $8.49 $1.69 $8.49 $3.39 $8.75 $11.25 $9.25 $8.75 $11.25 $11.25 $11.75 $11.25 $11.75 $11.25 $11.75 $21.96 $21.96 $10.98 $1.69 $11.48 $8.99 $8.49 $1.69 $9.25 $2.15 $1.50 $11.25 $1.50 $8.75 $8.75 $2.95 $8.49 $1.69 $8.75 $2.95 $1.25 $11.25 $2.15 $11.08 $8.49 $8.49 $8.49 $11.75 $1.25 $11.75 $8.75 $8.75 $8.75 $4.45 $11.25 $1.50 $23.50 $23.50 $11.75 $6.49 $8.75 $4.45 $6.49 $8.75 $2.50 $2.50 $2.15 $8.49 $2.39 $8.75 $11.75 $4.45 $8.99 $10.98 $9.25 $2.95 $9.25 $9.25 $11.75 $8.75 $8.75 $8.75 $10.98 $11.25 $9.25 $8.75 $8.75 $2.15 $11.25 $2.15 $4.45 $11.75 $8.49 $2.39 $9.25 $1.25 $1.25 $1.25 $1.25 $8.75 $2.15 $8.49 $1.69 $11.25 $1.50 $8.75 $8.75 $8.49 $3.99 $8.99 $1.09 $11.25 $1.25 $8.49 $2.39 $8.49 $8.75 $9.25 $11.25 $4.45 $11.25 $11.89 $8.99 $8.49 $8.75 $4.45 $8.75 $11.75 $11.75 $8.90 $8.90 $9.39 $2.95 $8.49 $3.99 $8.75 $2.15 $1.25 $21.96 $21.96 $8.49 $1.69 $8.75 $4.45 $8.49 $8.99 $8.49 $3.99 $8.75 $8.75 $2.95 $8.75 $17.50 $17.50 $9.25 $2.95 $8.75 $6.49 $4.30 $4.30 $8.75 $8.75 $2.15 $1.50 $8.49 $8.49 $2.39 $9.25 $4.45 $6.49 $11.75 $4.45 $10.98 $1.69 $9.39 $9.25 $9.25 $2.95 $8.75 $2.15 $1.25 $11.25 $9.25 $8.75 $11.25 $8.75 $11.25 $2.50 $2.50 $2.50 $2.50 $6.00 $6.00 $6.00 $6.00 $8.90 $8.90 $5.90 $5.90 $11.25 $11.25 $8.49 $10.98 $8.75 $2.15 $1.50 $9.25 $1.25 $1.50 $2.15 $1.25 $8.75 $2.95 $8.49 $3.99 $11.25 $4.30 $4.30 $11.75 $2.15 $18.50 $18.50 $8.49 $2.39 $8.75 $4.45 $11.75 $8.99 $3.99 $9.25 $9.25 $1.50 $8.75 $2.95 $6.49 $11.75 $8.49 $8.99 $8.75 $4.45 $6.49 $22.50 $22.50 $9.25 $2.95 $8.49 $1.69 $10.98 $8.75 $4.45 $11.25 $2.95 $8.99 $8.49 $2.39 $11.75 $6.49 $11.25 $11.75 $2.95 $8.99 $1.69 $8.99 $2.18 $2.18 $1.09 $8.99 $8.99 $1.09 $8.99 $8.99 $8.49 $10.98 $1.09 $11.75 $9.25 $11.25 $11.25 $2.15 $11.25 $8.75 $4.45 $2.95 $11.75 $1.50 $8.99 $10.98 $2.39 $8.75 $2.15 $9.25 $1.50 $8.75 $2.15 $3.99 $8.99 $6.49 $8.75 $8.90 $8.90 $8.99 $3.99 $17.50 $17.50 $11.25 $1.25 $10.98 $9.25 $4.45 $1.25 $3.00 $3.00 $11.25 $4.45 $4.45 $2.95 $9.25 $11.25 $2.15 $11.25 $11.25 $4.45 $2.95 $9.25 $11.25 $1.25 $8.75 $2.95 $1.25 $8.75 $4.45 $11.48 $11.48 $8.49 $2.39 $11.25 $11.75 $2.15 $1.50 $2.15 $8.75 $11.25 $8.90 $8.90 $11.25 $11.25 $1.25 $4.45 $9.25 $9.25 $8.75 $9.25 $8.75 $8.75 $9.25 $8.75 $11.75 $11.75 $8.75 $8.75 $8.90 $8.90 $2.95 $10.98 $8.49 $8.49 $10.98 $8.99 $8.99 $11.75 $17.50 $17.50 $11.75 $3.99 $8.49 $10.98 $1.69 $17.50 $17.50 $8.99 $2.39 $8.99 $2.39 $1.25 $8.75 $2.95 $11.75 $11.25 $17.50 $17.50 $8.49 $8.49 $2.39 $11.25 $1.50 $8.75 $3.00 $3.00 $1.25 $8.75 $4.45 $11.75 $11.75 $4.45 $21.96 $21.96 $8.75 $4.45 $8.75 $11.25 $9.25 $8.99 $2.39 $9.25 $8.75 $10.98 $8.49 $3.99 $3.39 $11.75 $1.50 $4.45 $9.25 $8.75 $1.25 $11.75 $8.75 $1.50 $8.75 $8.75 $2.15 $1.50 $8.75 $2.95 $8.75 $8.75 $17.50 $17.50 $8.75 $6.49 $4.45 $11.25 $11.25 $4.30 $4.30 $8.75 $11.25 $4.45 $8.99 $2.39 $9.25 $9.25 $9.25 $4.45 $11.75 $11.25 $2.95 $2.15 $11.25 $11.25 $8.75 $2.15 $1.50 $9.25 $4.45 $10.98 $8.99 $2.18 $2.18 $8.75 $4.45 $1.25 $8.99 $2.39 $4.45 $8.75 $10.98 $11.75 $1.50 $10.98 $8.99 $8.49 $3.99 $8.99 $8.49 $3.99 $8.49 $8.49 $8.99 $11.25 $11.25 $10.98 $10.98 $10.98 $2.39 $3.39 $8.75 $1.25 $2.95 $11.75 $1.50 $10.98 $1.69 $4.45 $8.75 $8.75 $8.75 $8.75 $4.45 $9.25 $8.75 $11.25 $8.75 $3.99 $8.99 $8.49 $11.25 $11.25 $8.75 $4.45 $8.75 $4.45 $1.25 $8.75 $8.75 $1.50 $2.15 $11.75 $11.75 $11.75 $11.75 $11.75 $1.50 $8.75 $9.25 $1.25 $8.75 $2.15 $8.99 $1.09 $4.45 $11.25 $11.75 $2.15 $8.75 $8.75 $1.25 $9.25 $2.15 $11.75 $11.25 $8.75 $11.25 $4.45 $8.49 $1.69 $8.75 $8.75 $8.99 $8.49 $9.25 $11.25 $2.95 $4.45 $11.75 $6.49 $11.48 $8.99 $4.36 $4.36 $4.36 $4.36 $11.48 $8.99 $8.49 $11.48 $8.75 $2.15 $1.50 $8.99 $1.69 $11.25 $1.25 $9.25 $9.25 $8.75 $9.25 $8.90 $8.90 $2.15 $9.25 $10.98 $8.49 $8.75 $9.25 $4.30 $4.30 $9.25 $8.75 $8.75 $2.15 $1.25 $8.75 $1.25 $8.75 $5.90 $5.90 $9.25 $8.75 $9.25 $4.45 $9.25 $11.75 $2.50 $2.50 $9.25 $2.15 $9.25 $1.50 $1.25 $11.25 $2.95 $8.75 $8.75 $8.75 $10.98 $8.75 $8.75 $8.75 $2.15 $1.25 $10.98 $8.75 $2.15 $1.50 $8.75 $2.95 $1.25 $9.25 $9.25 $8.49 $2.39 $8.75 $4.45 $9.25 $8.75 $8.75 $8.75 $9.25 $8.75 $9.25 $8.75 $8.75 $8.75 $8.75 $9.25 $8.75 $9.25 $8.75 $9.25 $8.75 $8.75 $8.75 $9.25 $8.75 $9.25 $8.75 $8.99 $8.99 $8.75 $2.95 $1.25 $11.75 $1.50 $11.25 $11.25 $8.75 $1.50 $2.15 $16.98 $16.98 $11.75 $1.50 $8.75 $4.30 $4.30 $1.50 $8.75 $2.95 $1.25 $1.25 $9.25 $4.45 $11.25 $8.75 $4.45 $8.75 $2.15 $1.25 $10.98 $1.69 $8.75 $1.25 $8.75 $1.25 $11.25 $8.75 $8.75 $8.49 $1.69 $9.25 $11.75 $8.49 $2.39 $9.25 $2.95 $6.49 $8.75 $8.75 $9.25 $8.75 $6.78 $6.78 $17.98 $17.98 $3.39 $11.75 $11.25 $8.75 $4.45 $11.75 $9.25 $8.75 $6.49 $8.99 $2.39 $8.75 $11.25 $11.75 $4.45 $8.75 $2.15 $9.25 $9.25 $9.25 $11.89 $11.75 $11.25 $9.25 $9.25 $8.75 $8.75 $8.49 $1.69 $1.09 $11.25 $1.50 $11.25 $11.25 $11.75 $1.50 $8.49 $8.99 $22.50 $22.50 $8.75 $4.30 $4.30 $8.75 $11.25 $2.15 $11.25 $2.95 $4.45 $11.25 $8.49 $3.39 $2.39 $11.75 $2.15 $11.75 $8.99 $2.39 $8.75 $11.75 $11.89 $1.25 $7.50 $7.50 $7.50 $7.50 $7.50 $11.89 $1.09 $8.49 $2.39 $8.75 $8.75 $8.75 $8.75 $9.25 $11.25 $8.75 $8.90 $8.90 $9.25 $8.75 $8.75 $11.75 $3.00 $3.00 $1.50 $11.25 $11.75 $8.99 $10.98 $4.45 $8.75 $2.15 $9.25 $11.25 $4.45 $1.69 $10.98 $9.25 $11.75 $9.25 $4.45 $10.98 $3.99 $8.49 $1.25 $9.25 $4.45 $10.98 $8.75 $8.75 $11.75 $11.25 $8.49 $11.48 $4.45 $1.25 $11.25 $8.99 $1.09 $2.39 $11.25 $2.15 $8.75 $4.45 $8.49 $1.69 $10.98 $1.69 $9.25 $4.45 $11.25 $8.75 $11.25 $11.75 $11.25 $22.50 $22.50 $8.49 $2.39 $2.50 $2.50 $8.75 $8.75 $9.25 $9.25 $11.25 $8.99 $1.09 $8.99 $1.69 $11.75 $1.25 $21.96 $21.96 $8.75 $2.15 $1.25 $8.75 $11.25 $9.25 $11.25 $8.75 $8.75 $11.25 $2.15 $8.99 $1.09 $1.69 $8.75 $2.15 $1.25 $8.49 $1.09 $1.09 $1.69 $11.48 $8.49 $8.49 $4.78 $4.78 $9.25 $1.25 $1.25 $1.25 $11.25 $11.25 $11.75 $4.45 $11.25 $4.45 $8.99 $1.09 $11.25 $2.15 $11.25 $9.25 $11.75 $11.25 $11.25 $9.25 $2.95 $11.25 $4.45 $8.75 $2.95 $2.95 $11.25 $1.50 $10.98 $16.98 $16.98 $18.50 $18.50 $10.98 $3.99 $1.09 $9.25 $9.25 $8.75 $4.45 $17.50 $17.50 $8.75 $4.45 $8.75 $1.25 $4.45 $9.25 $8.75 $8.75 $17.50 $17.50 $4.45 $9.39 $1.25 $2.95 $11.25 $8.75 $8.75 $11.25 $2.15 $8.90 $8.90 $11.25 $11.89 $10.98 $11.25 $4.45 $11.25 $11.25 $8.49 $10.98 $8.49 $3.39 $9.25 $8.75 $2.95 $3.00 $3.00 $9.39 $11.75 $2.95 $1.50 $11.25 $11.75 $8.75 $2.15 $1.50 $8.49 $3.39 $11.75 $1.25 $17.50 $17.50 $11.25 $1.25 $8.75 $2.95 $1.25 $11.25 $11.75 $13.35 $13.35 $13.35 $11.25 $11.75 $11.25 $11.25 $4.45 $11.25 $8.49 $3.39 $9.25 $2.95 $4.78 $4.78 $2.39 $3.99 $8.99 $8.99 $11.25 $11.25 $8.75 $11.25 $2.95 $4.45 $9.25 $8.75 $4.45 $8.49 $8.49 $10.98 $10.98 $3.99 $11.75 $8.75 $11.75 $4.45 $1.50 $1.25 $8.49 $8.49 $8.75 $8.75 $8.75 $9.25 $8.75 $2.95 $1.25 $11.25 $1.50 $11.25 $4.45 $9.25 $8.75 $8.75 $9.25 $8.75 $4.45 $1.50 $8.75 $8.75 $8.49 $1.69 $8.75 $2.15 $9.25 $2.15 $1.50 $11.25 $11.75 $2.15 $6.49 $9.25 $9.25 $11.25 $11.25 $11.75 $11.75 $11.75 $11.25 $8.75 $2.15 $1.25 $11.75 $9.25 $11.25 $8.75 $5.90 $5.90 $8.75 $4.45 $9.25 $9.25 $4.45 $11.25 $4.45 $11.25 $8.75 $2.15 $11.89 $11.25 $8.75 $2.95 $1.50 $8.75 $4.30 $4.30 $8.75 $11.25 $11.75 $11.75 $2.15 $11.25 $8.99 $1.09 $8.49 $8.49 $8.49 $3.39 $8.99 $10.98 $3.99 $11.75 $2.15 $8.75 $4.45 $2.50 $2.50 $11.48 $1.09 $8.49 $8.49 $16.98 $16.98 $3.99 $10.98 $1.09 $8.75 $2.95 $8.75 $8.75 $2.95 $9.25 $11.25 $2.15 $9.25 $4.45 $4.45 $9.25 $11.75 $11.75 $2.15 $9.25 $8.75 $11.25 $6.49 $8.75 $11.25 $2.95 $10.98 $3.99 $1.50 $9.25 $2.15 $8.75 $11.25 $11.89 $4.45 $1.50 $1.25 $8.75 $8.75 $4.45 $11.25 $11.75 $8.49 $1.09 $1.09 $1.69 $8.99 $3.39 $8.99 $1.69 $8.49 $8.99 $3.27 $3.27 $3.27 $8.99 $8.99 $1.09 $10.98 $1.69 $3.99 $8.49 $1.09 $8.75 $8.75 $11.75 $8.75 $9.25 $8.75 $3.39 $8.99 $8.99 $2.39 $9.25 $8.75 $9.25 $9.25 $8.99 $3.99 $2.39 $8.49 $1.09 $8.49 $8.99 $3.39 $11.25 $1.25 $8.99 $3.99 $8.75 $8.90 $8.90 $6.49 $8.75 $9.25 $11.25 $11.25 $11.25 $1.25 $8.75 $9.25 $4.45 $1.25 $8.75 $1.25 $2.15 $17.98 $17.98 $8.99 $8.75 $2.95 $1.25 $11.75 $1.50 $1.50 $8.75 $8.75 $11.08 $8.99 $1.69 $8.99 $1.69 $10.98 $3.99 $3.39 $11.75 $2.15 $11.75 $2.95 $8.75 $8.75 $11.75 $11.25 $11.75 $11.25 $4.45 $11.25 $1.25 $2.18 $2.18 $2.18 $2.18 $2.39 $8.49 $8.99 $2.39 $11.25 $8.75 $11.75 $11.75 $11.25 $4.45 $2.15 $8.19 $10.58 $4.45 $9.25 $1.09 $8.99 $11.25 $1.50 $8.99 $3.99 $4.45 $11.75 $2.15 $11.25 $8.75 $4.45 $8.75 $9.25 $6.45 $6.45 $6.45 $8.75 $11.25 $11.25 $8.75 $11.75 $21.96 $21.96 $8.99 $5.07 $5.07 $5.07 $8.49 $9.25 $11.25 $4.45 $3.39 $8.49 $8.99 $8.49 $17.50 $17.50 $22.96 $22.96 $8.75 $11.25 $11.89 $11.25 $8.49 $1.69 $1.09 $8.99 $8.99 $9.25 $8.75 $9.25 $2.95 $8.49 $3.99 $8.99 $8.49 $7.17 $7.17 $7.17 $8.49 $8.99 $17.50 $17.50 $9.25 $9.25 $11.25 $1.25 $8.99 $1.09 $8.75 $4.45 $11.25 $2.15 $11.75 $11.25 $11.25 $8.75 $8.75 $4.45 $1.25 $11.75 $11.75 $2.50 $2.50 $8.49 $8.99 $2.18 $2.18 $11.25 $4.45 $11.25 $11.75 $8.49 $8.99 $1.69 $1.09 $8.99 $8.99 $11.25 $6.49 $11.25 $8.75 $4.45 $8.99 $1.69 $11.48 $11.75 $2.50 $2.50 $8.49 $1.09 $1.09 $1.69 $8.49 $2.39 $11.75 $1.25 $8.49 $1.69 $8.49 $1.69 $11.75 $4.45 $8.75 $8.75 $4.45 $8.75 $11.25 $11.25 $8.75 $7.98 $7.98 $8.49 $1.09 $8.49 $3.99 $8.49 $3.99 $8.99 $3.99 $11.25 $4.45 $8.49 $2.39 $8.49 $2.39 $3.99 $8.49 $1.25 $11.25 $4.45 $9.25 $4.45 $1.09 $8.99 $3.99 $11.25 $8.90 $8.90 $9.25 $11.25 $8.75 $11.25 $11.25 $11.25 $11.25 $11.25 $8.99 $8.49 $8.75 $8.75 $4.45 $16.98 $16.98 $11.75 $11.25 $9.25 $4.45 $9.25 $2.95 $8.49 $1.69 $3.75 $3.75 $3.75 $4.45 $9.25 $1.50 $11.25 $11.48 $11.25 $2.15 $8.75 $9.39 $8.49 $3.99 $8.19 $2.29 $11.48 $1.69 $11.48 $3.99 $8.49 $1.69 $9.25 $2.95 $8.49 $1.69 $11.25 $4.45 $9.39 $9.25 $8.75 $8.75 $4.45 $11.89 $4.45 $4.45 $8.75 $8.75 $8.75 $2.15 $8.75 $3.75 $3.75 $3.75 $9.25 $11.25 $4.45 $6.49 $16.98 $16.98 $18.50 $18.50 $2.50 $2.50 $2.95 $3.99 $8.49 $8.19 $11.08 $6.49 $11.75 $2.39 $8.99 $1.09 $11.25 $4.45 $11.25 $8.99 $1.69 $21.96 $21.96 $2.18 $2.18 $8.99 $8.99 $2.39 $8.69 $1.69 $8.90 $8.90 $2.50 $2.50 $8.75 $8.99 $1.09 $8.49 $8.49 $8.75 $4.45 $17.50 $17.50 $8.75 $9.25 $8.49 $2.39 $8.75 $4.45 $11.25 $11.25 $11.75 $8.75 $8.49 $8.49 $8.49 $8.99 $8.75 $4.45 $11.48 $8.75 $1.25 $2.15 $9.25 $4.45 $11.75 $2.15 $11.25 $8.99 $2.39 $8.69 $8.69 $11.75 $2.95 $11.75 $1.50 $9.25 $4.45 $1.50 $11.48 $8.99 $2.39 $11.25 $11.89 $2.15 $1.25 $11.75 $4.45 $8.75 $8.75 $11.25 $4.45 $11.25 $2.15 $4.45 $8.49 $1.09 $3.99 $11.25 $11.25 $8.49 $2.39 $8.99 $2.39 $11.25 $2.15 $8.75 $2.95 $1.25 $8.75 $11.25 $17.50 $17.50 $11.75 $11.75 $11.25 $11.25 $4.45 $2.50 $2.50 $8.75 $8.99 $8.99 $1.69 $8.99 $1.69 $11.25 $1.25 $11.08 $8.69 $8.99 $1.09 $11.25 $11.25 $2.95 $1.25 $8.75 $1.25 $8.75 $8.75 $2.15 $1.25 $8.49 $3.99 $8.49 $2.39 $8.49 $7.17 $7.17 $7.17 $8.75 $4.45 $11.48 $8.75 $8.75 $11.48 $8.75 $9.25 $8.49 $3.99 $1.50 $11.25 $11.25 $8.75 $8.75 $4.45 $9.25 $4.45 $8.75 $8.75 $4.30 $4.30 $2.95 $8.75 $4.50 $4.50 $4.50 $9.25 $11.25 $4.45 $11.25 $11.25 $8.75 $9.25 $8.75 $2.15 $1.25 $8.75 $2.15 $1.25 $8.99 $8.49 $8.75 $8.75 $1.25 $11.75 $4.50 $4.50 $4.50 $8.75 $8.75 $3.99 $3.39 $8.49 $2.39 $8.99 $1.50 $11.25 $11.25 $8.75 $8.75 $2.15 $8.75 $2.15 $1.25 $21.96 $21.96 $8.49 $1.69 $26.07 $26.07 $26.07 $11.75 $1.50 $8.99 $8.99 $11.48 $9.25 $9.25 $8.75 $8.75 $8.75 $9.25 $8.75 $8.75 $2.15 $1.25 $11.89 $8.75 $11.75 $4.45 $18.50 $18.50 $9.25 $9.39 $8.49 $2.39 $8.49 $1.69 $1.09 $8.99 $8.49 $2.18 $2.18 $11.25 $1.25 $8.49 $3.39 $8.49 $3.99 $11.25 $8.75 $8.49 $1.69 $16.98 $16.98 $9.25 $9.25 $11.75 $1.25 $11.25 $8.75 $8.49 $8.49 $8.75 $1.25 $1.25 $1.25 $11.25 $12.98 $12.98 $11.75 $11.75 $4.45 $11.25 $11.75 $10.98 $8.49 $8.49 $2.39 $9.25 $11.25 $8.75 $2.95 $1.50 $11.25 $2.95 $9.25 $2.95 $9.25 $8.75 $11.25 $8.75 $8.75 $4.45 $11.25 $1.25 $8.75 $2.95 $2.50 $2.50 $9.25 $9.25 $9.25 $6.49 $17.50 $17.50 $8.49 $1.69 $8.49 $3.99 $8.75 $2.95 $2.95 $8.49 $8.99 $8.99 $1.09 $8.75 $4.45 $1.25 $11.25 $11.75 $11.25 $9.25 $11.25 $1.50 $11.25 $2.15 $10.98 $8.75 $11.75 $2.95 $11.25 $11.25 $9.25 $8.75 $9.25 $8.75 $8.75 $8.75 $1.25 $11.25 $1.50 $2.15 $8.75 $8.75 $11.25 $8.75 $8.75 $11.25 $4.45 $8.49 $8.49 $8.49 $8.49 $8.99 $1.69 $2.39 $1.09 $1.09 $11.25 $2.95 $35.25 $35.25 $35.25 $8.75 $2.95 $1.25 $11.25 $2.15 $9.25 $4.45 $8.75 $8.75 $8.75 $4.45 $1.25 $11.89 $8.75 $2.15 $1.25 $8.49 $1.09 $1.09 $1.69 $8.69 $8.69 $9.25 $2.95 $10.98 $2.39 $22.50 $22.50 $21.96 $21.96 $10.98 $8.49 $1.69 $11.75 $2.95 $8.75 $11.25 $8.75 $9.25 $8.75 $8.19 $10.58 $8.75 $2.95 $1.50 $2.50 $2.50 $9.25 $4.45 $9.25 $11.25 $8.69 $8.69 $3.89 $8.69 $1.69 $4.45 $9.25 $11.25 $4.45 $2.15 $8.19 $8.69 $4.45 $11.25 $1.25 $11.25 $8.75 $11.89 $11.75 $11.75 $9.25 $8.75 $2.15 $1.50 $11.75 $4.45 $3.99 $8.99 $10.98 $2.39 $1.25 $2.95 $8.75 $2.95 $9.25 $9.25 $9.25 $8.75 $2.15 $9.25 $9.25 $3.39 $8.49 $8.49 $2.39 $10.98 $1.09 $1.09 $8.49 $11.25 $1.25 $8.99 $1.09 $8.75 $2.15 $1.50 $3.99 $8.49 $8.75 $2.15 $1.50 $8.49 $10.98 $2.18 $2.18 $8.75 $2.15 $1.50 $4.45 $9.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $10.50 $10.50 $10.50 $10.50 $10.50 $10.50 $10.50 $6.49 $33.75 $33.75 $33.75 $35.00 $35.00 $35.00 $35.00 $27.75 $27.75 $27.75 $3.00 $3.00 $11.25 $11.75 $10.98 $2.39 $2.50 $2.50 $8.75 $4.45 $16.98 $16.98 $8.75 $6.49 $16.98 $16.98 $17.98 $17.98 $16.98 $16.98 $16.98 $16.98 $8.99 $8.99 $8.49 $9.25 $8.75 $2.95 $11.48 $2.39 $8.99 $2.39 $11.25 $4.45 $8.75 $9.25 $6.49 $26.25 $26.25 $26.25 $8.75 $26.25 $26.25 $26.25 $8.75 $8.75 $11.25 $11.25 $2.15 $1.25 $11.75 $8.75 $2.15 $1.50 $11.25 $2.15 $8.99 $2.39 $11.25 $11.25 $2.15 $11.25 $11.25 $8.75 $4.78 $4.78 $21.96 $21.96 $8.49 $2.39 $9.25 $2.95 $16.98 $16.98 $8.19 $3.89 $8.99 $1.09 $8.99 $3.39 $9.25 $4.45 $10.98 $10.98 $17.50 $17.50 $11.25 $1.25 $8.75 $11.75 $4.45 $11.25 $11.25 $8.99 $1.09 $10.98 $8.49 $1.69 $11.25 $9.25 $16.98 $16.98 $8.75 $4.45 $11.25 $6.49 $11.75 $9.25 $9.25 $8.75 $4.45 $2.50 $2.50 $8.75 $11.75 $8.75 $9.25 $11.75 $9.25 $8.75 $9.25 $8.75 $11.25 $11.75 $9.25 $8.75 $11.75 $8.49 $1.09 $1.09 $8.49 $1.09 $1.69 $11.25 $1.25 $8.75 $2.15 $1.50 $8.49 $1.69 $1.25 $8.75 $2.95 $8.49 $3.99 $8.49 $8.49 $8.75 $11.25 $2.15 $1.50 $11.75 $8.99 $1.09 $10.98 $10.98 $11.25 $1.25 $8.75 $4.45 $4.45 $1.25 $11.89 $8.99 $8.99 $11.25 $4.45 $23.50 $23.50 $8.49 $3.99 $9.25 $4.45 $4.45 $9.25 $8.75 $4.45 $8.75 $8.75 $11.75 $6.49 $17.50 $17.50 $4.45 $8.75 $2.95 $1.50 $8.75 $8.75 $8.75 $4.45 $11.25 $11.25 $11.75 $11.25 $2.95 $11.25 $4.45 $3.00 $3.00 $1.25 $2.95 $9.25 $8.99 $2.39 $6.49 $8.75 $8.90 $8.90 $11.48 $1.09 $10.98 $9.25 $9.25 $11.25 $8.75 $11.75 $11.25 $11.25 $1.25 $9.25 $4.45 $9.25 $6.49 $11.75 $11.75 $8.99 $2.39 $8.49 $8.49 $9.25 $9.25 $1.25 $8.75 $2.95 $11.75 $2.15 $8.49 $8.49 $8.69 $16.38 $16.38 $8.19 $3.89 $2.29 $11.75 $8.75 $8.75 $8.75 $4.45 $8.49 $8.49 $9.25 $8.75 $6.49 $2.95 $11.25 $11.25 $2.15 $9.25 $11.75 $21.96 $21.96 $8.49 $3.39 $1.69 $8.49 $8.75 $4.45 $8.49 $3.99 $11.25 $8.75 $11.25 $2.15 $11.75 $4.45 $11.25 $9.25 $8.75 $18.50 $18.50 $1.50 $8.75 $2.15 $11.48 $2.18 $2.18 $3.99 $11.25 $1.50 $8.99 $2.39 $11.75 $1.50 $11.25 $6.49 $4.45 $11.25 $8.49 $3.99 $2.50 $2.50 $8.75 $9.25 $3.99 $8.99 $8.75 $6.49 $13.52 $13.52 $13.52 $13.52 $13.52 $13.52 $13.52 $13.52 $16.98 $16.98 $16.98 $16.98 $17.98 $17.98 $16.98 $16.98 $8.75 $8.75 $11.25 $11.25 $8.49 $1.09 $1.69 $1.25 $9.25 $2.95 $8.69 $8.19 $8.49 $2.39 $8.49 $2.39 $10.98 $8.99 $8.99 $1.69 $8.49 $8.75 $8.75 $11.25 $4.45 $4.45 $17.50 $17.50 $8.75 $4.45 $8.75 $2.15 $1.50 $1.50 $8.99 $1.09 $8.75 $4.45 $8.75 $8.75 $11.25 $4.30 $4.30 $8.49 $1.69 $1.09 $1.09 $8.75 $2.15 $1.50 $8.99 $8.49 $3.99 $8.75 $2.15 $1.25 $9.25 $2.95 $11.25 $4.45 $9.25 $2.95 $3.99 $8.99 $8.49 $8.75 $8.75 $11.25 $9.25 $8.75 $4.45 $11.25 $1.25 $9.25 $11.25 $4.45 $2.95 $10.98 $8.75 $8.75 $18.50 $18.50 $9.25 $9.25 $5.00 $5.00 $5.00 $5.00 $8.75 $2.95 $16.98 $16.98 $11.25 $2.95 $8.75 $2.15 $1.50 $8.49 $2.39 $9.25 $2.15 $1.25 $8.19 $8.69 $8.19 $8.19 $8.75 $2.95 $1.25 $9.25 $2.95 $11.25 $8.75 $11.25 $11.25 $8.99 $1.09 $9.25 $9.25 $4.45 $8.49 $3.99 $2.39 $1.09 $8.99 $8.49 $8.75 $8.75 $11.25 $11.75 $4.45 $2.50 $2.50 $8.75 $8.49 $3.39 $8.75 $9.25 $4.45 $1.25 $11.25 $2.15 $4.45 $2.50 $2.50 $8.99 $3.99 $8.75 $2.15 $11.75 $11.75 $1.25 $8.75 $9.39 $11.25 $9.25 $9.25 $2.95 $9.25 $4.45 $1.25 $9.25 $8.75 $11.75 $1.50 $8.75 $4.45 $8.99 $1.09 $9.25 $2.95 $8.99 $1.69 $8.69 $1.69 $11.25 $4.45 $8.75 $8.75 $4.45 $11.25 $8.75 $2.95 $1.50 $8.19 $8.69 $1.09 $1.69 $8.49 $8.75 $2.95 $1.25 $8.49 $3.99 $10.98 $3.39 $11.25 $11.25 $2.15 $18.50 $18.50 $8.49 $8.49 $11.25 $1.50 $8.49 $2.39 $8.99 $2.39 $11.75 $4.45 $17.50 $17.50 $9.25 $9.25 $8.75 $4.45 $3.75 $3.75 $3.75 $8.75 $4.45 $11.75 $2.95 $1.25 $4.45 $8.75 $1.25 $1.50 $9.25 $11.25 $11.25 $11.25 $11.25 $9.25 $11.25 $4.45 $8.75 $9.25 $8.75 $8.75 $4.45 $8.75 $1.25 $2.15 $8.75 $8.75 $4.30 $4.30 $8.75 $1.25 $2.95 $9.25 $2.95 $4.45 $11.25 $11.25 $9.25 $9.25 $4.50 $4.50 $4.50 $11.75 $1.25 $11.75 $11.75 $1.25 $1.25 $9.25 $4.45 $11.25 $11.75 $17.50 $17.50 $2.15 $1.25 $11.25 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $11.25 $4.45 $4.45 $2.95 $11.25 $2.15 $1.25 $1.50 $8.75 $11.25 $2.95 $11.25 $1.25 $2.15 $11.25 $9.25 $6.49 $1.25 $8.75 $2.15 $8.75 $6.49 $11.25 $1.50 $8.75 $4.45 $8.75 $4.45 $9.25 $9.25 $1.25 $1.25 $8.75 $4.50 $4.50 $4.50 $11.25 $1.25 $1.50 $9.25 $2.15 $11.25 $4.45 $11.25 $4.45 $8.75 $4.45 $9.25 $4.45 $1.25 $11.25 $4.45 $8.75 $4.45 $8.75 $2.15 $8.75 $4.45 $8.75 $11.75 $1.50 $11.25 $4.45 $8.75 $2.15 $1.50 $8.75 $4.45 $8.75 $11.75 $8.75 $8.75 $11.25 $11.25 $1.50 $8.75 $2.15 $11.75 $2.15 $9.25 $2.95 $18.50 $18.50 $1.25 $4.45 $8.50 $8.50 $8.50 $8.50 $11.25 $11.89 $1.25 $9.39 $4.45 $8.75 $2.15 $1.50 $11.75 $8.75 $9.25 $9.25 $4.45 $1.25 $11.25 $9.25 $2.95 $8.75 $8.75 $2.15 $8.75 $11.25 $11.25 $11.25 $11.75 $11.25 $2.15 $11.25 $2.15 $8.99 $8.99 $8.75 $9.25 $9.25 $11.25 $8.75 $4.45 $8.75 $1.25 $4.45 $11.25 $1.25 $8.75 $8.75 $11.25 $8.75 $1.25 $1.25 $1.25 $9.25 $11.75 $2.15 $8.75 $4.45 $8.75 $4.45 $11.25 $9.25 $8.75 $9.25 $4.45 $11.75 $4.45 $1.25 $4.45 $11.75 $9.25 $11.25 $2.15 $23.50 $23.50 $9.25 $2.15 $18.50 $18.50 $8.75 $5.90 $5.90 $11.89 $4.45 $8.75 $4.45 $9.25 $2.95 $11.25 $2.95 $11.25 $11.25 $11.25 $2.95 $11.75 $9.25 $9.25 $2.95 $11.25 $2.15 $9.25 $8.90 $8.90 $8.75 $11.25 $11.25 $11.25 $8.75 $2.15 $1.25 $11.25 $1.25 $8.75 $4.45 $1.25 $11.25 $11.25 $11.75 $1.25 $11.25 $11.25 $11.25 $8.75 $8.75 $18.50 $18.50 $11.75 $1.25 $4.45 $9.25 $6.49 $4.45 $8.75 $11.25 $6.49 $11.75 $8.75 $9.25 $11.25 $2.15 $8.75 $4.45 $11.25 $4.45 $8.75 $9.25 $4.45 $1.25 $1.25 $8.75 $11.25 $11.75 $2.15 $11.75 $4.45 $11.75 $1.25 $11.75 $11.75 $11.25 $4.30 $4.30 $9.39 $9.39 $8.75 $1.25 $9.25 $4.45 $11.25 $1.25 $8.75 $1.25 $2.95 $11.25 $4.45 $8.75 $1.50 $4.45 $4.45 $9.25 $8.75 $2.95 $1.25 $11.25 $2.95 $8.75 $8.75 $8.75 $8.75 $4.30 $4.30 $9.25 $9.39 $4.45 $9.25 $1.25 $22.50 $22.50 $4.45 $2.95 $2.15 $23.50 $23.50 $11.75 $2.15 $1.25 $9.25 $4.45 $11.25 $11.75 $17.50 $17.50 $8.75 $11.75 $11.25 $8.75 $4.45 $11.75 $1.50 $8.75 $8.75 $11.75 $9.25 $11.25 $4.45 $11.75 $9.25 $4.45 $11.25 $8.75 $8.75 $2.15 $1.50 $8.75 $4.45 $9.25 $8.75 $1.50 $1.25 $1.25 $1.25 $8.75 $2.95 $11.25 $11.25 $1.50 $11.75 $11.25 $2.15 $9.25 $8.75 $11.75 $2.95 $1.50 $8.75 $1.50 $1.25 $8.75 $11.75 $11.25 $11.25 $11.75 $11.25 $11.75 $8.75 $17.80 $17.80 $17.80 $17.80 $5.00 $5.00 $5.00 $5.00 $5.00 $5.00 $5.00 $5.00 $8.75 $2.95 $1.25 $11.25 $1.25 $2.15 $11.25 $2.50 $2.50 $9.25 $1.25 $11.25 $2.95 $11.75 $2.15 $11.25 $1.50 $8.99 $1.99 $11.49 $8.75 $4.45 $1.25 $8.75 $4.45 $1.25 $1.50 $11.75 $8.75 $8.75 $11.25 $6.49 $11.75 $8.75 $2.15 $1.25 $6.49 $8.75 $4.45 $8.75 $4.45 $8.75 $11.25 $4.45 $6.49 $9.25 $8.75 $1.25 $4.45 $11.25 $8.75 $1.50 $8.75 $1.50 $1.25 $9.25 $9.39 $4.45 $9.25 $8.75 $4.45 $1.25 $11.25 $11.75 $8.75 $11.25 $9.25 $8.75 $11.25 $2.50 $2.50 $17.50 $17.50 $9.25 $4.45 $11.25 $1.25 $8.75 $4.45 $1.50 $8.75 $1.50 $1.25 $9.39 $8.75 $8.75 $4.45 $11.25 $1.25 $9.25 $4.45 $11.25 $8.75 $3.00 $3.00 $8.75 $2.15 $1.25 $11.25 $11.25 $4.45 $11.25 $11.25 $8.75 $11.75 $11.75 $11.75 $8.75 $4.45 $1.25 $1.50 $8.75 $4.45 $1.25 $9.25 $9.25 $8.75 $4.45 $1.25 $11.75 $11.25 $1.25 $11.75 $11.25 $9.25 $2.15 $1.50 $8.75 $4.45 $11.75 $11.75 $11.25 $8.75 $8.75 ' to numeric\n\n\n\n\n\nStep 17. How many different items are sold?\n\nchipo.item_name.value_counts().count()\n\n50"
  },
  {
    "objectID": "labs/Labexercises/01World-Food-Facts-Exercises-with-solutions.html",
    "href": "labs/Labexercises/01World-Food-Facts-Exercises-with-solutions.html",
    "title": "Exercise 1",
    "section": "",
    "text": "Step 1. Go to https://www.kaggle.com/openfoodfacts/world-food-facts/data\n\n\nStep 2. Download the dataset to your computer and unzip it.\n\nimport pandas as pd\nimport numpy as np\n\n\n\nStep 3. Use the tsv file and assign it to a dataframe called food\n\nfood = pd.read_csv('E:\\Yang Fan\\Lab 1\\en.openfoodfacts.org.products.tsv', sep='\\t')\n\n\n\nStep 4. See the first 5 entries\n\nfood.head()\n\n\n\n\n\n\n\n\ncode\nurl\ncreator\ncreated_t\ncreated_datetime\nlast_modified_t\nlast_modified_datetime\nproduct_name\ngeneric_name\nquantity\n...\nfruits-vegetables-nuts_100g\nfruits-vegetables-nuts-estimate_100g\ncollagen-meat-protein-ratio_100g\ncocoa_100g\nchlorophyl_100g\ncarbon-footprint_100g\nnutrition-score-fr_100g\nnutrition-score-uk_100g\nglycemic-index_100g\nwater-hardness_100g\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000...\nopenfoodfacts-contributors\n1474103866\n2016-09-17T09:17:46Z\n1474103893\n2016-09-17T09:18:13Z\nFarine de blé noir\nNaN\n1kg\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000...\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nBanana Chips Sweetened (Whole)\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n14.0\n14.0\nNaN\nNaN\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000...\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nPeanuts\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.0\n0.0\nNaN\nNaN\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000...\nusda-ndb-import\n1489055731\n2017-03-09T10:35:31Z\n1489055731\n2017-03-09T10:35:31Z\nOrganic Salted Nut Mix\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n12.0\n12.0\nNaN\nNaN\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000...\nusda-ndb-import\n1489055653\n2017-03-09T10:34:13Z\n1489055653\n2017-03-09T10:34:13Z\nOrganic Polenta\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 163 columns\n\n\n\n\n\nStep 5. What is the number of observations in the dataset?\n\nfood.shape\n\n(356027, 163)\n\n\n\nfood.shape[0]\n\n356027\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\nprint(food.shape) \nprint(food.shape[1]) \n\n#OR\n\nfood.info() \n\n(356027, 163)\n163\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 356027 entries, 0 to 356026\nColumns: 163 entries, code to water-hardness_100g\ndtypes: float64(107), object(56)\nmemory usage: 442.8+ MB\n\n\n\n\nStep 7. Print the name of all the columns.\n\nfood.columns\n\nIndex(['code', 'url', 'creator', 'created_t', 'created_datetime',\n       'last_modified_t', 'last_modified_datetime', 'product_name',\n       'generic_name', 'quantity',\n       ...\n       'fruits-vegetables-nuts_100g', 'fruits-vegetables-nuts-estimate_100g',\n       'collagen-meat-protein-ratio_100g', 'cocoa_100g', 'chlorophyl_100g',\n       'carbon-footprint_100g', 'nutrition-score-fr_100g',\n       'nutrition-score-uk_100g', 'glycemic-index_100g',\n       'water-hardness_100g'],\n      dtype='object', length=163)\n\n\n\n\nStep 8. What is the name of 105th column?\n\nfood.columns[104]\n\n'-glucose_100g'\n\n\n\n\nStep 9. What is the type of the observations of the 105th column?\n\nfood.dtypes['-glucose_100g']\n\ndtype('float64')\n\n\n\n\nStep 10. How is the dataset indexed?\n\nfood.index\n\nRangeIndex(start=0, stop=356027, step=1)\n\n\n\n\nStep 11. What is the product name of the 19th observation?\n\nfood.values[18][7]\n\n'Lotus Organic Brown Jasmine Rice'"
  },
  {
    "objectID": "labs/Labexercises/02Euro12-Exercises-with-solutions.html",
    "href": "labs/Labexercises/02Euro12-Exercises-with-solutions.html",
    "title": "Ex2 - Filtering and Sorting Data",
    "section": "",
    "text": "This time we are going to pull data directly from the internet.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called euro12.\n\neuro12 = pd.read_csv('https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_%26_Sorting/Euro12/Euro_2012_stats_TEAM.csv', sep=',')\neuro12\n\n\n\n\n\n\n\n\nTeam\nGoals\nShots on target\nShots off target\nShooting Accuracy\n% Goals-to-shots\nTotal shots (inc. Blocked)\nHit Woodwork\nPenalty goals\nPenalties not scored\n...\nSaves made\nSaves-to-shots ratio\nFouls Won\nFouls Conceded\nOffsides\nYellow Cards\nRed Cards\nSubs on\nSubs off\nPlayers Used\n\n\n\n\n0\nCroatia\n4\n13\n12\n51.9%\n16.0%\n32\n0\n0\n0\n...\n13\n81.3%\n41\n62\n2\n9\n0\n9\n9\n16\n\n\n1\nCzech Republic\n4\n13\n18\n41.9%\n12.9%\n39\n0\n0\n0\n...\n9\n60.1%\n53\n73\n8\n7\n0\n11\n11\n19\n\n\n2\nDenmark\n4\n10\n10\n50.0%\n20.0%\n27\n1\n0\n0\n...\n10\n66.7%\n25\n38\n8\n4\n0\n7\n7\n15\n\n\n3\nEngland\n5\n11\n18\n50.0%\n17.2%\n40\n0\n0\n0\n...\n22\n88.1%\n43\n45\n6\n5\n0\n11\n11\n16\n\n\n4\nFrance\n3\n22\n24\n37.9%\n6.5%\n65\n1\n0\n0\n...\n6\n54.6%\n36\n51\n5\n6\n0\n11\n11\n19\n\n\n5\nGermany\n10\n32\n32\n47.8%\n15.6%\n80\n2\n1\n0\n...\n10\n62.6%\n63\n49\n12\n4\n0\n15\n15\n17\n\n\n6\nGreece\n5\n8\n18\n30.7%\n19.2%\n32\n1\n1\n1\n...\n13\n65.1%\n67\n48\n12\n9\n1\n12\n12\n20\n\n\n7\nItaly\n6\n34\n45\n43.0%\n7.5%\n110\n2\n0\n0\n...\n20\n74.1%\n101\n89\n16\n16\n0\n18\n18\n19\n\n\n8\nNetherlands\n2\n12\n36\n25.0%\n4.1%\n60\n2\n0\n0\n...\n12\n70.6%\n35\n30\n3\n5\n0\n7\n7\n15\n\n\n9\nPoland\n2\n15\n23\n39.4%\n5.2%\n48\n0\n0\n0\n...\n6\n66.7%\n48\n56\n3\n7\n1\n7\n7\n17\n\n\n10\nPortugal\n6\n22\n42\n34.3%\n9.3%\n82\n6\n0\n0\n...\n10\n71.5%\n73\n90\n10\n12\n0\n14\n14\n16\n\n\n11\nRepublic of Ireland\n1\n7\n12\n36.8%\n5.2%\n28\n0\n0\n0\n...\n17\n65.4%\n43\n51\n11\n6\n1\n10\n10\n17\n\n\n12\nRussia\n5\n9\n31\n22.5%\n12.5%\n59\n2\n0\n0\n...\n10\n77.0%\n34\n43\n4\n6\n0\n7\n7\n16\n\n\n13\nSpain\n12\n42\n33\n55.9%\n16.0%\n100\n0\n1\n0\n...\n15\n93.8%\n102\n83\n19\n11\n0\n17\n17\n18\n\n\n14\nSweden\n5\n17\n19\n47.2%\n13.8%\n39\n3\n0\n0\n...\n8\n61.6%\n35\n51\n7\n7\n0\n9\n9\n18\n\n\n15\nUkraine\n2\n7\n26\n21.2%\n6.0%\n38\n0\n0\n0\n...\n13\n76.5%\n48\n31\n4\n5\n0\n9\n9\n18\n\n\n\n\n16 rows × 35 columns\n\n\n\n\n\nStep 4. Select only the Goal column.\n\neuro12.Goals\n\n0      4\n1      4\n2      4\n3      5\n4      3\n5     10\n6      5\n7      6\n8      2\n9      2\n10     6\n11     1\n12     5\n13    12\n14     5\n15     2\nName: Goals, dtype: int64\n\n\n\n\nStep 5. How many team participated in the Euro2012?\n\neuro12.shape[0]\n\n16\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\neuro12.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 16 entries, 0 to 15\nData columns (total 35 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   Team                        16 non-null     object \n 1   Goals                       16 non-null     int64  \n 2   Shots on target             16 non-null     int64  \n 3   Shots off target            16 non-null     int64  \n 4   Shooting Accuracy           16 non-null     object \n 5   % Goals-to-shots            16 non-null     object \n 6   Total shots (inc. Blocked)  16 non-null     int64  \n 7   Hit Woodwork                16 non-null     int64  \n 8   Penalty goals               16 non-null     int64  \n 9   Penalties not scored        16 non-null     int64  \n 10  Headed goals                16 non-null     int64  \n 11  Passes                      16 non-null     int64  \n 12  Passes completed            16 non-null     int64  \n 13  Passing Accuracy            16 non-null     object \n 14  Touches                     16 non-null     int64  \n 15  Crosses                     16 non-null     int64  \n 16  Dribbles                    16 non-null     int64  \n 17  Corners Taken               16 non-null     int64  \n 18  Tackles                     16 non-null     int64  \n 19  Clearances                  16 non-null     int64  \n 20  Interceptions               16 non-null     int64  \n 21  Clearances off line         15 non-null     float64\n 22  Clean Sheets                16 non-null     int64  \n 23  Blocks                      16 non-null     int64  \n 24  Goals conceded              16 non-null     int64  \n 25  Saves made                  16 non-null     int64  \n 26  Saves-to-shots ratio        16 non-null     object \n 27  Fouls Won                   16 non-null     int64  \n 28  Fouls Conceded              16 non-null     int64  \n 29  Offsides                    16 non-null     int64  \n 30  Yellow Cards                16 non-null     int64  \n 31  Red Cards                   16 non-null     int64  \n 32  Subs on                     16 non-null     int64  \n 33  Subs off                    16 non-null     int64  \n 34  Players Used                16 non-null     int64  \ndtypes: float64(1), int64(29), object(5)\nmemory usage: 4.5+ KB\n\n\n\n\nStep 7. View only the columns Team, Yellow Cards and Red Cards and assign them to a dataframe called discipline\n\ndiscipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\ndiscipline\n\n\n\n\n\n\n\n\nTeam\nYellow Cards\nRed Cards\n\n\n\n\n0\nCroatia\n9\n0\n\n\n1\nCzech Republic\n7\n0\n\n\n2\nDenmark\n4\n0\n\n\n3\nEngland\n5\n0\n\n\n4\nFrance\n6\n0\n\n\n5\nGermany\n4\n0\n\n\n6\nGreece\n9\n1\n\n\n7\nItaly\n16\n0\n\n\n8\nNetherlands\n5\n0\n\n\n9\nPoland\n7\n1\n\n\n10\nPortugal\n12\n0\n\n\n11\nRepublic of Ireland\n6\n1\n\n\n12\nRussia\n6\n0\n\n\n13\nSpain\n11\n0\n\n\n14\nSweden\n7\n0\n\n\n15\nUkraine\n5\n0\n\n\n\n\n\n\n\n\n\nStep 8. Sort the teams by Red Cards, then to Yellow Cards\n\ndiscipline.sort_values(['Red Cards', 'Yellow Cards'], ascending = False)\n\n\n\n\n\n\n\n\nTeam\nYellow Cards\nRed Cards\n\n\n\n\n6\nGreece\n9\n1\n\n\n9\nPoland\n7\n1\n\n\n11\nRepublic of Ireland\n6\n1\n\n\n7\nItaly\n16\n0\n\n\n10\nPortugal\n12\n0\n\n\n13\nSpain\n11\n0\n\n\n0\nCroatia\n9\n0\n\n\n1\nCzech Republic\n7\n0\n\n\n14\nSweden\n7\n0\n\n\n4\nFrance\n6\n0\n\n\n12\nRussia\n6\n0\n\n\n3\nEngland\n5\n0\n\n\n8\nNetherlands\n5\n0\n\n\n15\nUkraine\n5\n0\n\n\n2\nDenmark\n4\n0\n\n\n5\nGermany\n4\n0\n\n\n\n\n\n\n\n\n\nStep 9. Calculate the mean Yellow Cards given per Team\n\n\nround(discipline['Yellow Cards'].mean())\n\n7\n\n\n\n\nStep 10. Filter teams that scored more than 6 goals\n\neuro12[euro12.Goals &gt; 6]\n\n\n\n\n\n\n\n\nTeam\nGoals\nShots on target\nShots off target\nShooting Accuracy\n% Goals-to-shots\nTotal shots (inc. Blocked)\nHit Woodwork\nPenalty goals\nPenalties not scored\n...\nSaves made\nSaves-to-shots ratio\nFouls Won\nFouls Conceded\nOffsides\nYellow Cards\nRed Cards\nSubs on\nSubs off\nPlayers Used\n\n\n\n\n5\nGermany\n10\n32\n32\n47.8%\n15.6%\n80\n2\n1\n0\n...\n10\n62.6%\n63\n49\n12\n4\n0\n15\n15\n17\n\n\n13\nSpain\n12\n42\n33\n55.9%\n16.0%\n100\n0\n1\n0\n...\n15\n93.8%\n102\n83\n19\n11\n0\n17\n17\n18\n\n\n\n\n2 rows × 35 columns\n\n\n\n\n\nStep 11. Select the teams that start with G\n\neuro12[euro12.Team.str.startswith('G')]\n\n\n\n\n\n\n\n\nTeam\nGoals\nShots on target\nShots off target\nShooting Accuracy\n% Goals-to-shots\nTotal shots (inc. Blocked)\nHit Woodwork\nPenalty goals\nPenalties not scored\n...\nSaves made\nSaves-to-shots ratio\nFouls Won\nFouls Conceded\nOffsides\nYellow Cards\nRed Cards\nSubs on\nSubs off\nPlayers Used\n\n\n\n\n5\nGermany\n10\n32\n32\n47.8%\n15.6%\n80\n2\n1\n0\n...\n10\n62.6%\n63\n49\n12\n4\n0\n15\n15\n17\n\n\n6\nGreece\n5\n8\n18\n30.7%\n19.2%\n32\n1\n1\n1\n...\n13\n65.1%\n67\n48\n12\n9\n1\n12\n12\n20\n\n\n\n\n2 rows × 35 columns\n\n\n\n\n\nStep 12. Select the first 7 columns\n\neuro12.iloc[: , 0:7]\n\n\n\n\n\n\n\n\nTeam\nGoals\nShots on target\nShots off target\nShooting Accuracy\n% Goals-to-shots\nTotal shots (inc. Blocked)\n\n\n\n\n0\nCroatia\n4\n13\n12\n51.9%\n16.0%\n32\n\n\n1\nCzech Republic\n4\n13\n18\n41.9%\n12.9%\n39\n\n\n2\nDenmark\n4\n10\n10\n50.0%\n20.0%\n27\n\n\n3\nEngland\n5\n11\n18\n50.0%\n17.2%\n40\n\n\n4\nFrance\n3\n22\n24\n37.9%\n6.5%\n65\n\n\n5\nGermany\n10\n32\n32\n47.8%\n15.6%\n80\n\n\n6\nGreece\n5\n8\n18\n30.7%\n19.2%\n32\n\n\n7\nItaly\n6\n34\n45\n43.0%\n7.5%\n110\n\n\n8\nNetherlands\n2\n12\n36\n25.0%\n4.1%\n60\n\n\n9\nPoland\n2\n15\n23\n39.4%\n5.2%\n48\n\n\n10\nPortugal\n6\n22\n42\n34.3%\n9.3%\n82\n\n\n11\nRepublic of Ireland\n1\n7\n12\n36.8%\n5.2%\n28\n\n\n12\nRussia\n5\n9\n31\n22.5%\n12.5%\n59\n\n\n13\nSpain\n12\n42\n33\n55.9%\n16.0%\n100\n\n\n14\nSweden\n5\n17\n19\n47.2%\n13.8%\n39\n\n\n15\nUkraine\n2\n7\n26\n21.2%\n6.0%\n38\n\n\n\n\n\n\n\n\n\nStep 13. Select all columns except the last 3.\n\neuro12.iloc[: , :-3]\n\n\n\n\n\n\n\n\nTeam\nGoals\nShots on target\nShots off target\nShooting Accuracy\n% Goals-to-shots\nTotal shots (inc. Blocked)\nHit Woodwork\nPenalty goals\nPenalties not scored\n...\nClean Sheets\nBlocks\nGoals conceded\nSaves made\nSaves-to-shots ratio\nFouls Won\nFouls Conceded\nOffsides\nYellow Cards\nRed Cards\n\n\n\n\n0\nCroatia\n4\n13\n12\n51.9%\n16.0%\n32\n0\n0\n0\n...\n0\n10\n3\n13\n81.3%\n41\n62\n2\n9\n0\n\n\n1\nCzech Republic\n4\n13\n18\n41.9%\n12.9%\n39\n0\n0\n0\n...\n1\n10\n6\n9\n60.1%\n53\n73\n8\n7\n0\n\n\n2\nDenmark\n4\n10\n10\n50.0%\n20.0%\n27\n1\n0\n0\n...\n1\n10\n5\n10\n66.7%\n25\n38\n8\n4\n0\n\n\n3\nEngland\n5\n11\n18\n50.0%\n17.2%\n40\n0\n0\n0\n...\n2\n29\n3\n22\n88.1%\n43\n45\n6\n5\n0\n\n\n4\nFrance\n3\n22\n24\n37.9%\n6.5%\n65\n1\n0\n0\n...\n1\n7\n5\n6\n54.6%\n36\n51\n5\n6\n0\n\n\n5\nGermany\n10\n32\n32\n47.8%\n15.6%\n80\n2\n1\n0\n...\n1\n11\n6\n10\n62.6%\n63\n49\n12\n4\n0\n\n\n6\nGreece\n5\n8\n18\n30.7%\n19.2%\n32\n1\n1\n1\n...\n1\n23\n7\n13\n65.1%\n67\n48\n12\n9\n1\n\n\n7\nItaly\n6\n34\n45\n43.0%\n7.5%\n110\n2\n0\n0\n...\n2\n18\n7\n20\n74.1%\n101\n89\n16\n16\n0\n\n\n8\nNetherlands\n2\n12\n36\n25.0%\n4.1%\n60\n2\n0\n0\n...\n0\n9\n5\n12\n70.6%\n35\n30\n3\n5\n0\n\n\n9\nPoland\n2\n15\n23\n39.4%\n5.2%\n48\n0\n0\n0\n...\n0\n8\n3\n6\n66.7%\n48\n56\n3\n7\n1\n\n\n10\nPortugal\n6\n22\n42\n34.3%\n9.3%\n82\n6\n0\n0\n...\n2\n11\n4\n10\n71.5%\n73\n90\n10\n12\n0\n\n\n11\nRepublic of Ireland\n1\n7\n12\n36.8%\n5.2%\n28\n0\n0\n0\n...\n0\n23\n9\n17\n65.4%\n43\n51\n11\n6\n1\n\n\n12\nRussia\n5\n9\n31\n22.5%\n12.5%\n59\n2\n0\n0\n...\n0\n8\n3\n10\n77.0%\n34\n43\n4\n6\n0\n\n\n13\nSpain\n12\n42\n33\n55.9%\n16.0%\n100\n0\n1\n0\n...\n5\n8\n1\n15\n93.8%\n102\n83\n19\n11\n0\n\n\n14\nSweden\n5\n17\n19\n47.2%\n13.8%\n39\n3\n0\n0\n...\n1\n12\n5\n8\n61.6%\n35\n51\n7\n7\n0\n\n\n15\nUkraine\n2\n7\n26\n21.2%\n6.0%\n38\n0\n0\n0\n...\n0\n4\n4\n13\n76.5%\n48\n31\n4\n5\n0\n\n\n\n\n16 rows × 32 columns\n\n\n\n\n\nStep 14. Present only the Shooting Accuracy from England, Italy and Russia\n\neuro12.loc[euro12.Team.isin(['England', 'Italy', 'Russia']), ['Team','Shooting Accuracy']]\n\n\n\n\n\n\n\n\nTeam\nShooting Accuracy\n\n\n\n\n3\nEngland\n50.0%\n\n\n7\nItaly\n43.0%\n\n\n12\nRussia\n22.5%"
  },
  {
    "objectID": "labs/Labexercises/03Scores-Exercises-with-solutions.html",
    "href": "labs/Labexercises/03Scores-Exercises-with-solutions.html",
    "title": "Scores",
    "section": "",
    "text": "Introduction:\nThis time you will create the data.\nExercise based on Chris Albon work, the credits belong to him.\n\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n%matplotlib inline\n\n\n\nStep 2. Create the DataFrame that should look like the one below.\n\nraw_data = {'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n            'last_name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze'], \n            'female': [0, 1, 1, 0, 1],\n            'age': [42, 52, 36, 24, 73], \n            'preTestScore': [4, 24, 31, 2, 3],\n            'postTestScore': [25, 94, 57, 62, 70]}\n\ndf = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'female', 'preTestScore', 'postTestScore'])\n\ndf\n\n\n\n\n\n\n\n\nfirst_name\nlast_name\nage\nfemale\npreTestScore\npostTestScore\n\n\n\n\n0\nJason\nMiller\n42\n0\n4\n25\n\n\n1\nMolly\nJacobson\n52\n1\n24\n94\n\n\n2\nTina\nAli\n36\n1\n31\n57\n\n\n3\nJake\nMilner\n24\n0\n2\n62\n\n\n4\nAmy\nCooze\n73\n1\n3\n70\n\n\n\n\n\n\n\n\n\nStep 3. Create a Scatterplot of preTestScore and postTestScore, with the size of each point determined by age\n\nHint: Don’t forget to place the labels\n\nplt.scatter(df.preTestScore, df.postTestScore, s=df.age)\n\n#set labels and titles\nplt.title(\"preTestScore x postTestScore\")\nplt.xlabel('preTestScore')\nplt.ylabel('preTestScore')\n\nText(0, 0.5, 'preTestScore')\n\n\n\n\n\nStep 4. Create a Scatterplot of preTestScore and postTestScore.\n\n\nThis time the size should be 4.5 times the postTestScore and the color determined by sex\n\nplt.scatter(df.preTestScore, df.postTestScore, s= df.postTestScore * 4.5, c = df.female)\n\n#set labels and titles\nplt.title(\"preTestScore x postTestScore\")\nplt.xlabel('preTestScore')\nplt.ylabel('preTestScore')\n\nText(46.972222222222214, 0.5, 'preTestScore')\n\n\n\n\nBONUS: Create your own question and answer it."
  },
  {
    "objectID": "labs/Practice/Practice2-Collecting-and-analysing-data-from-experiments.html",
    "href": "labs/Practice/Practice2-Collecting-and-analysing-data-from-experiments.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nfrom lets_plot import *\n\n\nLetsPlot.setup_html(no_js=True)\n\n\nplt.style.use(\n\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\n\n\ndata_np = pd.read_excel(\n    \"data/doing-economics-datafile-working-in-excel-project-2.xlsx\",\n    usecols=\"A:Q\",\n    header=1,\n    index_col=\"Period\",\n)\ndata_n = data_np.iloc[:10, :].copy()\ndata_p = data_np.iloc[14:24, :].copy()\n\n\ntest_data = {\n    \"City A\": [14.1, 14.1, 13.7],\n    \"City B\": [11.0, 12.6, 12.1],\n}\n\n\n# Original dataframe\ntest_df = pd.DataFrame.from_dict(test_data)\n# A copy of the dataframe\ntest_copy = test_df.copy()\n# A pointer to the dataframe\ntest_pointer = test_df\n\n\ntest_pointer.iloc[1, 1] = 99\n\n\nprint(\"test_df=\")\nprint(f\"{test_df}\\n\")\nprint(\"test_copy=\")\nprint(f\"{test_copy}\\n\")\n\ntest_df=\n   City A  City B\n0    14.1    11.0\n1    14.1    99.0\n2    13.7    12.1\n\ntest_copy=\n   City A  City B\n0    14.1    11.0\n1    14.1    12.6\n2    13.7    12.1\n\n\n\n\ndata_n.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 10 entries, 1 to 10\nData columns (total 16 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   Copenhagen       10 non-null     object\n 1   Dnipropetrovs’k  10 non-null     object\n 2   Minsk            10 non-null     object\n 3   St. Gallen       10 non-null     object\n 4   Muscat           10 non-null     object\n 5   Samara           10 non-null     object\n 6   Zurich           10 non-null     object\n 7   Boston           10 non-null     object\n 8   Bonn             10 non-null     object\n 9   Chengdu          10 non-null     object\n 10  Seoul            10 non-null     object\n 11  Riyadh           10 non-null     object\n 12  Nottingham       10 non-null     object\n 13  Athens           10 non-null     object\n 14  Istanbul         10 non-null     object\n 15  Melbourne        10 non-null     object\ndtypes: object(16)\nmemory usage: 1.3+ KB\n\n\n\ndata_n = data_n.astype(\"double\")\ndata_p = data_p.astype(\"double\")\n\n\nmean_n_c = data_n.mean(axis=1)\nmean_p_c = data_p.agg(np.mean, axis=1)\n\n\nfig, ax = plt.subplots()\nmean_n_c.plot(ax=ax, label=\"Without punishment\")\nmean_p_c.plot(ax=ax, label=\"With punishment\")\nax.set_title(\"Average contributions to the public goods game\")\nax.set_ylabel(\"Average contribution\")\nax.legend();\n\n\n\n\n\n\n\n\n\npartial_names_list = [\"F. Kennedy\", \"Lennon\", \"Maynard Keynes\", \"Wayne\"]\n[\"John \" + name for name in partial_names_list]\n\n['John F. Kennedy', 'John Lennon', 'John Maynard Keynes', 'John Wayne']\n\n\n\n# Create new dataframe with bars in\ncompare_grps = pd.DataFrame(\n    [mean_n_c.loc[[1, 10]], mean_p_c.loc[[1, 10]]],\n    index=[\"Without punishment\", \"With punishment\"],\n)\n# Rename columns to have 'round' in them\ncompare_grps.columns = [\"Round \" + str(i) for i in compare_grps.columns]\n# Swap the column and index variables around with the transpose function, ready for plotting (.T is transpose)\ncompare_grps = compare_grps.T\n# Make a bar chart\ncompare_grps.plot.bar(rot=0);\n\n\n\n\n\n\n\n\n\nn_c = data_n.agg([\"std\", \"var\", \"mean\"], 1)\nn_c\n\n\n\n\n\n\n\n\nstd\nvar\nmean\n\n\nPeriod\n\n\n\n\n\n\n\n1\n2.020724\n4.083325\n10.578313\n\n\n2\n2.238129\n5.009220\n10.628398\n\n\n3\n2.329569\n5.426891\n10.407079\n\n\n4\n2.068213\n4.277504\n9.813033\n\n\n5\n2.108329\n4.445049\n9.305433\n\n\n6\n2.240881\n5.021549\n8.454844\n\n\n7\n2.136614\n4.565117\n7.837568\n\n\n8\n2.349442\n5.519880\n7.376388\n\n\n9\n2.413845\n5.826645\n6.392985\n\n\n10\n2.187126\n4.783520\n4.383769\n\n\n\n\n\n\n\n\np_c = data_p.agg([\"std\", \"var\", \"mean\"], 1)\n\n\nfig, ax = plt.subplots()\nn_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 standard deviations\n(n_c[\"mean\"] + 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 standard deviations\n(n_c[\"mean\"] - 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_n.columns)):\n    ax.scatter(x=data_n.index, y=data_n.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game without punishment\")\nplt.show();\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\np_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 sd\n(p_c[\"mean\"] + 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 sd\n(p_c[\"mean\"] - 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_p.columns)):\n    ax.scatter(x=data_p.index, y=data_p.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game with punishment\")\nplt.show();\n\n\n\n\n\n\n\n\n\ndata_p.apply(lambda x: x.max() - x.min(), axis=1)\n\nPeriod\n1     10.199675\n2     12.185065\n3     12.689935\n4     12.625000\n5     12.140375\n6     12.827541\n7     13.098931\n8     13.482621\n9     13.496754\n10    11.307360\ndtype: float64\n\n\n\n# A lambda function accepting three inputs, a, b, and c, and calculating the sum of the squares\ntest_function = lambda a, b, c: a**2 + b**2 + c**2\n\n\n# Now we apply the function by handing over (in parenthesis) the following inputs: a=3, b=4 and c=5\ntest_function(3, 4, 5)\n\n50\n\n\n\nrange_function = lambda x: x.max() - x.min()\nrange_p = data_p.apply(range_function, axis=1)\nrange_n = data_n.apply(range_function, axis=1)\n\n\nfig, ax = plt.subplots()\nrange_p.plot(ax=ax, label=\"With punishment\")\nrange_n.plot(ax=ax, label=\"Without punishment\")\nax.set_ylim(0, None)\nax.legend()\nax.set_title(\"Range of contributions to the public goods game\")\nplt.show();\n\n\n\n\n\n\n\n\n\nfuncs_to_apply = [range_function, \"max\", \"min\", \"std\", \"mean\"]\nsumm_p = data_p.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\nsumm_n = data_n.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\n\n\nsumm_n.loc[[1, 10], :].round(2)\n\n\n\n\n\n\n\n\nrange\nmax\nmin\nstd\nmean\n\n\nPeriod\n\n\n\n\n\n\n\n\n\n1\n6.14\n14.10\n7.96\n2.02\n10.58\n\n\n10\n7.38\n8.68\n1.30\n2.19\n4.38\n\n\n\n\n\n\n\n\nsumm_p.loc[[1, 10], :].round(2)\n\n\n\n\n\n\n\n\nrange\nmax\nmin\nstd\nmean\n\n\nPeriod\n\n\n\n\n\n\n\n\n\n1\n10.20\n16.02\n5.82\n3.21\n10.64\n\n\n10\n11.31\n17.51\n6.20\n3.90\n12.87\n\n\n\n\n\n\n\n\n%pip install pingouin\n\nCollecting pingouin\n  Downloading pingouin-0.5.5-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (3.9.2)\nRequirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (1.26.4)\nRequirement already satisfied: pandas&gt;=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (2.2.2)\nCollecting pandas-flavor (from pingouin)\n  Downloading pandas_flavor-0.6.0-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: scikit-learn&gt;=1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (1.5.1)\nRequirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (1.13.1)\nRequirement already satisfied: seaborn in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (0.13.2)\nRequirement already satisfied: statsmodels in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (0.14.2)\nRequirement already satisfied: tabulate in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pingouin) (0.9.0)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas&gt;=1.5-&gt;pingouin) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas&gt;=1.5-&gt;pingouin) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas&gt;=1.5-&gt;pingouin) (2023.3)\nRequirement already satisfied: joblib&gt;=1.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn&gt;=1.2-&gt;pingouin) (1.4.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn&gt;=1.2-&gt;pingouin) (3.5.0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib-&gt;pingouin) (1.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib-&gt;pingouin) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib-&gt;pingouin) (4.51.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib-&gt;pingouin) (1.4.4)\nRequirement already satisfied: packaging&gt;=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib-&gt;pingouin) (24.1)\nRequirement already satisfied: pillow&gt;=8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib-&gt;pingouin) (10.4.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib-&gt;pingouin) (3.1.2)\nRequirement already satisfied: xarray in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas-flavor-&gt;pingouin) (2023.6.0)\nRequirement already satisfied: patsy&gt;=0.5.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from statsmodels-&gt;pingouin) (0.5.6)\nRequirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from patsy&gt;=0.5.6-&gt;statsmodels-&gt;pingouin) (1.16.0)\nDownloading pingouin-0.5.5-py3-none-any.whl (204 kB)\nDownloading pandas_flavor-0.6.0-py3-none-any.whl (7.2 kB)\nInstalling collected packages: pandas-flavor, pingouin\nSuccessfully installed pandas-flavor-0.6.0 pingouin-0.5.5\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport pingouin as pg\n\n\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :])\n\n\n\n\n\n\n\n\nT\ndof\nalternative\np-val\nCI95%\ncohen-d\nBF10\npower\n\n\n\n\nT-test\n-0.063782\n30\ntwo-sided\n0.949567\n[-2.0, 1.87]\n0.02255\n0.337\n0.050437\n\n\n\n\n\n\n\n\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :], paired=True)\n\n\n\n\n\n\n\n\nT\ndof\nalternative\np-val\nCI95%\ncohen-d\nBF10\npower\n\n\n\n\nT-test\n-0.149959\n15\ntwo-sided\n0.882795\n[-0.92, 0.8]\n0.02255\n0.258\n0.05082"
  },
  {
    "objectID": "labs/Practice/Practice3-DouBan-top250-visualizations.html",
    "href": "labs/Practice/Practice3-DouBan-top250-visualizations.html",
    "title": "",
    "section": "",
    "text": "%pip install requests beautifulsoup4\n\nRequirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.32.3)\nRequirement already satisfied: beautifulsoup4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.12.3)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (3.7)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\nRequirement already satisfied: soupsieve&gt;1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport requests\n \n# 定义请求的 URL 和 headers\nurl = \"https://movie.douban.com/top250\"\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n}\n \n# 发送 GET 请求\nresponse = requests.get(url, headers=headers)\nresponse.encoding = 'utf-8'  # 设置编码方式\nhtml_content = response.text  # 获取网页的 HTML 内容\nprint(\"网页内容加载成功！\")\n\n网页内容加载成功！\n\n\n\nfrom bs4 import BeautifulSoup\n \n# 使用 Beautiful Soup 解析 HTML\nsoup = BeautifulSoup(html_content, 'html.parser')\n \n# 提取电影名称、描述、评分和评价人数\nmovies = []\nfor item in soup.find_all('div', class_='item'):\n    title = item.find('span', class_='title').get_text()  # 电影名称\n    description = item.find('span', class_='inq')  # 电影描述\n    rating = item.find('span', class_='rating_num').get_text()  # 评分\n    votes = item.find('div', class_='star').find_all('span')[3].get_text()  # 评价人数\n    \n    # 如果没有描述，将其置为空字符串\n    if description:\n        description = description.get_text()\n    else:\n        description = ''\n    \n    movie = {\n        \"title\": title,\n        \"description\": description,\n        \"rating\": rating,\n        \"votes\": votes.replace('人评价', '').strip()\n    }\n    movies.append(movie)\n \nprint(\"数据提取成功！\")\n\n数据提取成功！\n\n\n\nimport csv\n \n# 将数据保存到 CSV 文件\nwith open('douban_top250.csv', 'w', newline='', encoding='utf-8') as csvfile:\n    fieldnames = ['title', 'description', 'rating', 'votes']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n \n    writer.writeheader()  # 写入表头\n    for movie in movies:\n        writer.writerow(movie)  # 写入每一行数据\n \nprint(\"数据已成功保存到 douban_top250.csv\")\n\n数据已成功保存到 douban_top250.csv"
  },
  {
    "objectID": "labs/Practice/Practice3-scrape-imdb-movie-rating-and-details.html",
    "href": "labs/Practice/Practice3-scrape-imdb-movie-rating-and-details.html",
    "title": "",
    "section": "",
    "text": "from bs4 import BeautifulSoup\nimport requests\nimport re\nimport pandas as pd\n\n\n# Downloading imdb top 250 movie's data\nurl = 'http://www.imdb.com/chart/top'\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.text, \"html.parser\")\n\n\nmovies = soup.select('td.titleColumn')\ncrew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\nratings = [b.attrs.get('data-value')\n        for b in soup.select('td.posterColumn span[name=ir]')]\n\n\n# create a empty list for storing\n# movie information\nlist = []\n\n# Iterating over movies to extract\n# each movie's details\nfor index in range(0, len(movies)):\n    \n    # Separating movie into: 'place',\n    # 'title', 'year'\n    movie_string = movies[index].get_text()\n    movie = (' '.join(movie_string.split()).replace('.', ''))\n    movie_title = movie[len(str(index))+1:-7]\n    year = re.search('\\((.*?)\\)', movie_string).group(1)\n    place = movie[:len(str(index))-(len(movie))]\n    data = {\"place\": place,\n            \"movie_title\": movie_title,\n            \"rating\": ratings[index],\n            \"year\": year,\n            \"star_cast\": crew[index],\n            }\n    list.append(data)\n\n\nfor movie in list:\n    print(movie['place'], '-', movie['movie_title'], '('+movie['year'] +\n        ') -', 'Starring:', movie['star_cast'], movie['rating'])\n\n\n#saving the list as dataframe\n#then converting into .csv file\ndf = pd.DataFrame(list)\ndf.to_csv('imdb_top_250_movies.csv',index=False)\n\n\nfrom bs4 import BeautifulSoup\nimport requests\nimport re\nimport pandas as pd\n\n\n# Downloading imdb top 250 movie's data\nurl = 'http://www.imdb.com/chart/top'\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.text, \"html.parser\")\nmovies = soup.select('td.titleColumn')\ncrew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\nratings = [b.attrs.get('data-value')\n        for b in soup.select('td.posterColumn span[name=ir]')]\n\n\n\n\n# create a empty list for storing\n# movie information\nlist = []\n\n# Iterating over movies to extract\n# each movie's details\nfor index in range(0, len(movies)):\n    \n    # Separating movie into: 'place',\n    # 'title', 'year'\n    movie_string = movies[index].get_text()\n    movie = (' '.join(movie_string.split()).replace('.', ''))\n    movie_title = movie[len(str(index))+1:-7]\n    year = re.search('\\((.*?)\\)', movie_string).group(1)\n    place = movie[:len(str(index))-(len(movie))]\n    data = {\"place\": place,\n            \"movie_title\": movie_title,\n            \"rating\": ratings[index],\n            \"year\": year,\n            \"star_cast\": crew[index],\n            }\n    list.append(data)\n\n# printing movie details with its rating.\nfor movie in list:\n    print(movie['place'], '-', movie['movie_title'], '('+movie['year'] +\n        ') -', 'Starring:', movie['star_cast'], movie['rating'])\n\n\n##.......##\ndf = pd.DataFrame(list)\ndf.to_csv('imdb_top_250_movies.csv',index=False)"
  },
  {
    "objectID": "labs.html",
    "href": "labs.html",
    "title": "01Chipotle-Exercises-with-solutions",
    "section": "",
    "text": "01Chipotle-Exercises-with-solutions\n\n\nEx2 - Getting and Knowing your Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport numpy as np\n\n\n\nStep 2. Import the dataset from this address.\n\nchipo = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv', sep= '\\t')\n\n\n\nStep 3. Assign it to a variable called chipo.\n\nchipo = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv', sep= '\\t')\n\n\n\nStep 4. See the first 10 entries\n\nchipo.head(10)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n0\n1\n1\nChips and Fresh Tomato Salsa\nNaN\n$2.39\n\n\n1\n1\n1\nIzze\n[Clementine]\n$3.39\n\n\n2\n1\n1\nNantucket Nectar\n[Apple]\n$3.39\n\n\n3\n1\n1\nChips and Tomatillo-Green Chili Salsa\nNaN\n$2.39\n\n\n4\n2\n2\nChicken Bowl\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98\n\n\n5\n3\n1\nChicken Bowl\n[Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...\n$10.98\n\n\n6\n3\n1\nSide of Chips\nNaN\n$1.69\n\n\n7\n4\n1\nSteak Burrito\n[Tomatillo Red Chili Salsa, [Fajita Vegetables...\n$11.75\n\n\n8\n4\n1\nSteak Soft Tacos\n[Tomatillo Green Chili Salsa, [Pinto Beans, Ch...\n$9.25\n\n\n9\n5\n1\nSteak Burrito\n[Fresh Tomato Salsa, [Rice, Black Beans, Pinto...\n$9.25\n\n\n\n\n\n\n\n\n\nStep 5. What is the number of observations in the dataset?\n\n# Solution 1\n\nchipo.shape\n\n(4622, 5)\n\n\n\n# Solution 2\n\nchipo.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 4622 entries, 0 to 4621\nData columns (total 5 columns):\n #   Column              Non-Null Count  Dtype \n---  ------              --------------  ----- \n 0   order_id            4622 non-null   int64 \n 1   quantity            4622 non-null   int64 \n 2   item_name           4622 non-null   object\n 3   choice_description  3376 non-null   object\n 4   item_price          4622 non-null   object\ndtypes: int64(2), object(3)\nmemory usage: 180.7+ KB\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\nchipo.shape[1]\n\n5\n\n\n\n\nStep 7. Print the name of all the columns.\n\nchipo.columns\n\nIndex(['order_id', 'quantity', 'item_name', 'choice_description',\n       'item_price'],\n      dtype='object')\n\n\n\n\nStep 8. How is the dataset indexed?\n\nchipo.index\n\nRangeIndex(start=0, stop=4622, step=1)\n\n\n\n\nStep 9. Which was the most-ordered item?\n\nchipo.groupby(by=\"item_name\").sum().sort_values('quantity',ascending=False).head(1)\n\n\n\n\n\n\n\n\norder_id\nquantity\nchoice_description\nitem_price\n\n\nitem_name\n\n\n\n\n\n\n\n\nChicken Bowl\n713926\n761\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98 $10.98 $11.25 $8.75 $8.49 $11.25 $8.75 ...\n\n\n\n\n\n\n\n\n\nStep 10. For the most-ordered item, how many items were ordered?\n\nchipo.groupby(by=\"item_name\").sum().sort_values('quantity',ascending=False).head(1)\n\n\n\n\n\n\n\n\norder_id\nquantity\nchoice_description\nitem_price\n\n\nitem_name\n\n\n\n\n\n\n\n\nChicken Bowl\n713926\n761\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98 $10.98 $11.25 $8.75 $8.49 $11.25 $8.75 ...\n\n\n\n\n\n\n\n\n\nStep 11. What was the most ordered item in the choice_description column?\n\nchipo.groupby(by=\"choice_description\").sum().sort_values('quantity',ascending=False).head(1)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nitem_price\n\n\nchoice_description\n\n\n\n\n\n\n\n\n[Diet Coke]\n123455\n159\nCanned SodaCanned SodaCanned Soda6 Pack Soft D...\n$2.18 $1.09 $1.09 $6.49 $2.18 $1.25 $1.09 $6.4...\n\n\n\n\n\n\n\n\n\nStep 12. How many items were orderd in total?\n\nchipo.item_name.count()\n\n4622\n\n\n\n\nStep 13. Turn the item price into a float\n\nStep 13.a. Check the item price type\n\nchipo.item_price.dtype\n\ndtype('O')\n\n\n\n\nStep 13.b. Create a lambda function and change the type of item price\n\ndollarizer = lambda x: float(x[1:-1])\nchipo.item_price = chipo.item_price.apply(dollarizer)\n\n\n\nStep 13.c. Check the item price type\n\nchipo.item_price.dtype\n\ndtype('float64')\n\n\n\n\n\nStep 14. How much was the revenue for the period in the dataset?\n\nrevenue =  (chipo.item_price * chipo.quantity).sum()\nprint('Revenue is : $ '+ str(revenue))\n\nRevenue is : $ 39237.02\n\n\n\n\nStep 15. How many orders were made in the period?\n\nchipo.order_id.value_counts().count()\n\n1834\n\n\n\n\nStep 16. What is the average revenue amount per order?\n\n# Solution 1\nchipo['revenue'] = chipo['quantity'] * chipo['item_price']\norder_grouped = chipo.groupby(by=['order_id']).sum()\norder_grouped['revenue'].mean()\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[8], line 4\n      2 chipo['revenue'] = chipo['quantity'] * chipo['item_price']\n      3 order_grouped = chipo.groupby(by=['order_id']).sum()\n----&gt; 4 order_grouped['revenue'].mean()\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6549, in Series.mean(self, axis, skipna, numeric_only, **kwargs)\n   6541 @doc(make_doc(\"mean\", ndim=1))\n   6542 def mean(\n   6543     self,\n   (...)\n   6547     **kwargs,\n   6548 ):\n-&gt; 6549     return NDFrame.mean(self, axis, skipna, numeric_only, **kwargs)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12420, in NDFrame.mean(self, axis, skipna, numeric_only, **kwargs)\n  12413 def mean(\n  12414     self,\n  12415     axis: Axis | None = 0,\n   (...)\n  12418     **kwargs,\n  12419 ) -&gt; Series | float:\n&gt; 12420     return self._stat_function(\n  12421         \"mean\", nanops.nanmean, axis, skipna, numeric_only, **kwargs\n  12422     )\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12377, in NDFrame._stat_function(self, name, func, axis, skipna, numeric_only, **kwargs)\n  12373 nv.validate_func(name, (), kwargs)\n  12375 validate_bool_kwarg(skipna, \"skipna\", none_allowed=False)\n&gt; 12377 return self._reduce(\n  12378     func, name=name, axis=axis, skipna=skipna, numeric_only=numeric_only\n  12379 )\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6457, in Series._reduce(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\n   6452     # GH#47500 - change to TypeError to match other methods\n   6453     raise TypeError(\n   6454         f\"Series.{name} does not allow {kwd_name}={numeric_only} \"\n   6455         \"with non-numeric dtypes.\"\n   6456     )\n-&gt; 6457 return op(delegate, skipna=skipna, **kwds)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147, in bottleneck_switch.__call__.&lt;locals&gt;.f(values, axis, skipna, **kwds)\n    145         result = alt(values, axis=axis, skipna=skipna, **kwds)\n    146 else:\n--&gt; 147     result = alt(values, axis=axis, skipna=skipna, **kwds)\n    149 return result\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404, in _datetimelike_compat.&lt;locals&gt;.new_func(values, axis, skipna, mask, **kwargs)\n    401 if datetimelike and mask is None:\n    402     mask = isna(values)\n--&gt; 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)\n    406 if datetimelike:\n    407     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:720, in nanmean(values, axis, skipna, mask)\n    718 count = _get_counts(values.shape, mask, axis, dtype=dtype_count)\n    719 the_sum = values.sum(axis, dtype=dtype_sum)\n--&gt; 720 the_sum = _ensure_numeric(the_sum)\n    722 if axis is not None and getattr(the_sum, \"ndim\", False):\n    723     count = cast(np.ndarray, count)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1701, in _ensure_numeric(x)\n   1698 elif not (is_float(x) or is_integer(x) or is_complex(x)):\n   1699     if isinstance(x, str):\n   1700         # GH#44008, GH#36703 avoid casting e.g. strings to numeric\n-&gt; 1701         raise TypeError(f\"Could not convert string '{x}' to numeric\")\n   1702     try:\n   1703         x = float(x)\n\nTypeError: Could not convert string '$2.39 $3.39 $3.39 $2.39 $16.98 $16.98 $10.98 $1.69 $11.75 $9.25 $9.25 $4.45 $8.75 $8.75 $11.25 $4.45 $2.39 $8.49 $8.49 $2.18 $2.18 $8.75 $4.45 $8.99 $3.39 $10.98 $3.39 $2.39 $8.49 $8.99 $1.09 $8.49 $2.39 $8.99 $1.69 $8.99 $1.09 $8.75 $8.75 $4.45 $2.95 $11.75 $2.15 $4.45 $11.25 $11.75 $8.75 $10.98 $8.99 $3.39 $8.99 $3.99 $8.99 $2.18 $2.18 $10.98 $1.09 $8.99 $2.39 $9.25 $11.25 $11.75 $2.15 $4.45 $9.25 $11.25 $8.75 $8.99 $8.99 $3.39 $8.99 $10.98 $8.99 $1.69 $8.99 $3.99 $8.75 $4.45 $8.75 $8.75 $2.15 $8.75 $11.25 $2.15 $9.25 $8.75 $8.75 $9.25 $8.49 $8.99 $1.09 $9.25 $2.95 $11.75 $11.75 $9.25 $11.75 $4.45 $9.25 $4.45 $11.75 $8.75 $8.75 $4.45 $8.99 $8.99 $3.99 $8.49 $3.39 $8.99 $1.09 $9.25 $4.45 $8.75 $2.95 $4.45 $2.39 $8.49 $8.99 $8.49 $1.09 $8.99 $3.99 $8.75 $9.25 $4.45 $11.25 $4.45 $8.99 $1.09 $9.25 $2.95 $4.45 $11.75 $4.45 $8.49 $2.39 $10.98 $22.50 $22.50 $11.75 $4.45 $11.25 $4.45 $11.25 $4.45 $11.25 $11.25 $11.75 $9.25 $4.45 $11.48 $17.98 $17.98 $1.69 $17.50 $17.50 $4.45 $8.49 $2.39 $17.50 $17.50 $4.45 $4.45 $11.25 $11.75 $10.98 $8.49 $10.98 $2.18 $2.18 $11.48 $8.49 $2.39 $4.45 $11.25 $11.75 $8.75 $8.49 $2.18 $2.18 $8.49 $3.39 $8.49 $8.99 $10.98 $11.48 $8.49 $1.09 $1.09 $9.25 $8.75 $2.95 $9.25 $4.45 $11.25 $11.48 $8.49 $8.49 $8.99 $2.39 $11.25 $8.75 $2.95 $1.09 $8.99 $8.49 $2.39 $10.98 $1.09 $3.99 $11.25 $8.75 $8.49 $3.39 $8.75 $9.25 $2.15 $11.25 $11.25 $11.25 $4.45 $22.50 $22.50 $4.45 $11.75 $8.75 $17.50 $17.50 $8.75 $9.25 $8.75 $2.15 $9.25 $4.30 $4.30 $8.75 $11.25 $2.15 $8.99 $1.09 $8.99 $3.99 $8.75 $2.95 $2.95 $11.75 $5.90 $5.90 $9.25 $9.25 $11.75 $9.25 $2.95 $17.50 $17.50 $8.75 $9.25 $10.98 $8.99 $1.09 $1.09 $1.09 $8.99 $10.98 $1.09 $8.75 $8.75 $9.25 $9.25 $8.75 $8.75 $8.99 $8.99 $8.99 $1.09 $11.75 $1.25 $8.99 $2.39 $9.25 $2.95 $8.99 $3.99 $8.49 $2.39 $8.49 $8.49 $8.49 $1.69 $8.49 $3.99 $8.99 $1.69 $1.09 $23.78 $23.78 $17.50 $17.50 $2.15 $8.75 $9.25 $9.25 $8.75 $4.45 $8.75 $11.25 $11.25 $1.25 $9.25 $4.45 $11.25 $11.75 $11.75 $6.49 $8.99 $2.39 $8.49 $2.39 $11.25 $8.75 $2.15 $8.99 $1.69 $8.75 $11.25 $2.15 $4.45 $8.75 $8.49 $8.99 $17.50 $17.50 $8.49 $1.09 $1.09 $8.75 $1.25 $2.15 $11.08 $8.49 $8.49 $8.99 $2.39 $8.75 $2.15 $1.50 $11.25 $2.15 $8.49 $8.49 $11.75 $9.25 $11.75 $1.25 $11.25 $8.75 $4.45 $6.49 $9.25 $2.95 $11.25 $4.45 $1.25 $1.25 $8.49 $2.39 $2.18 $2.18 $8.49 $2.18 $2.18 $22.16 $22.16 $17.50 $17.50 $8.75 $2.95 $6.49 $8.99 $3.39 $3.39 $8.99 $8.49 $11.25 $2.15 $11.25 $2.95 $11.25 $1.25 $8.99 $1.09 $8.75 $8.75 $9.25 $2.95 $11.75 $1.50 $8.99 $1.09 $11.25 $1.25 $1.25 $11.25 $11.75 $2.15 $8.99 $1.69 $11.75 $6.49 $8.75 $9.25 $11.25 $4.45 $1.25 $11.25 $4.45 $8.49 $8.99 $8.49 $8.99 $11.25 $1.25 $11.75 $1.25 $11.75 $9.25 $4.45 $11.25 $2.15 $32.94 $32.94 $32.94 $1.25 $11.25 $11.48 $1.69 $1.09 $17.50 $17.50 $4.45 $6.49 $9.25 $8.75 $9.25 $9.25 $8.75 $8.75 $2.15 $2.95 $17.50 $17.50 $10.98 $11.48 $11.48 $3.39 $8.99 $1.69 $8.99 $1.09 $10.98 $3.39 $8.99 $1.09 $9.25 $8.75 $11.25 $4.45 $2.95 $9.25 $22.20 $22.20 $22.20 $8.49 $8.99 $8.75 $8.75 $11.75 $8.75 $11.25 $9.25 $11.25 $11.25 $8.75 $11.25 $2.95 $1.25 $8.49 $1.69 $11.75 $11.25 $8.75 $8.75 $4.45 $8.49 $3.99 $8.49 $3.99 $11.48 $1.69 $1.09 $11.25 $1.50 $10.58 $1.69 $9.25 $11.25 $8.75 $9.25 $11.25 $11.25 $8.75 $11.75 $8.75 $8.75 $8.75 $2.15 $11.25 $11.75 $2.50 $2.50 $4.45 $9.25 $4.45 $11.25 $8.49 $3.99 $9.25 $9.25 $11.25 $9.25 $11.75 $11.25 $1.25 $23.50 $23.50 $1.25 $8.99 $8.49 $7.40 $7.40 $8.75 $1.25 $4.45 $8.75 $2.15 $8.75 $4.45 $7.40 $7.40 $7.40 $8.99 $3.99 $8.99 $1.69 $8.75 $8.75 $8.75 $8.75 $11.25 $11.25 $2.95 $8.75 $18.50 $18.50 $8.49 $3.99 $2.95 $9.25 $9.25 $3.00 $3.00 $1.25 $8.75 $9.25 $4.45 $8.75 $11.25 $4.45 $10.98 $22.16 $22.16 $4.45 $8.75 $9.25 $6.49 $9.25 $11.25 $8.75 $9.25 $2.15 $9.25 $4.45 $9.25 $2.95 $9.25 $8.75 $9.25 $1.25 $1.25 $8.75 $8.75 $9.25 $4.45 $11.75 $11.75 $11.75 $9.25 $9.25 $16.98 $16.98 $2.39 $3.39 $3.39 $9.25 $11.75 $11.25 $2.15 $8.75 $9.25 $4.45 $10.98 $11.25 $9.25 $22.50 $22.50 $9.25 $2.95 $1.50 $11.48 $8.49 $1.69 $8.49 $8.49 $8.49 $6.78 $6.78 $11.75 $4.45 $8.75 $4.45 $11.89 $9.39 $8.75 $2.95 $1.25 $9.25 $8.75 $23.78 $23.78 $8.75 $9.25 $2.15 $2.15 $1.25 $8.49 $3.99 $10.98 $1.09 $8.75 $4.45 $8.75 $11.75 $2.95 $4.45 $9.25 $8.75 $8.49 $3.99 $22.50 $22.50 $11.25 $1.25 $8.75 $8.75 $18.50 $18.50 $6.49 $8.75 $8.75 $4.45 $8.49 $3.99 $8.99 $1.09 $8.49 $2.39 $11.48 $1.69 $2.50 $2.50 $9.25 $1.50 $17.50 $17.50 $2.95 $8.75 $4.45 $11.75 $8.75 $8.49 $1.69 $8.49 $3.99 $8.99 $8.99 $3.99 $8.99 $11.25 $4.45 $1.25 $3.99 $10.98 $7.40 $3.00 $7.40 $4.00 $8.49 $3.99 $9.25 $4.45 $11.25 $1.25 $11.75 $1.25 $11.25 $2.15 $11.25 $4.45 $3.75 $3.75 $3.75 $11.75 $8.99 $2.39 $8.75 $4.45 $1.25 $8.99 $8.49 $2.18 $2.18 $8.49 $2.18 $2.18 $1.09 $8.75 $2.95 $1.25 $1.50 $11.25 $9.25 $2.95 $1.25 $8.49 $3.99 $11.48 $3.99 $8.49 $11.25 $1.25 $8.99 $1.69 $11.25 $1.25 $6.49 $8.75 $9.25 $8.75 $2.95 $8.75 $11.75 $8.69 $8.69 $2.29 $3.99 $8.49 $8.75 $8.75 $1.25 $11.75 $11.25 $11.25 $11.25 $1.25 $9.25 $11.75 $6.49 $3.99 $8.49 $11.25 $2.15 $11.25 $11.89 $8.99 $1.69 $8.99 $8.99 $3.99 $8.99 $9.25 $9.25 $2.15 $7.40 $7.40 $8.75 $8.75 $9.25 $4.45 $11.25 $1.25 $11.75 $11.25 $1.25 $3.99 $8.49 $8.49 $8.49 $8.99 $8.75 $2.15 $1.25 $8.49 $1.09 $1.09 $8.75 $2.95 $1.25 $9.25 $1.25 $2.15 $11.25 $1.25 $4.45 $8.75 $2.50 $2.50 $8.90 $8.90 $8.75 $8.75 $8.75 $11.25 $11.25 $10.98 $3.99 $10.98 $3.99 $1.69 $8.99 $9.25 $8.75 $8.99 $1.09 $9.25 $2.95 $8.75 $9.25 $3.99 $8.49 $8.75 $8.75 $22.50 $22.50 $10.98 $3.27 $3.27 $3.27 $3.99 $8.99 $1.09 $11.08 $8.75 $4.45 $11.08 $3.99 $8.49 $4.30 $4.30 $9.25 $8.75 $11.25 $11.25 $9.25 $8.49 $8.99 $8.49 $8.75 $2.95 $4.45 $9.25 $2.95 $9.25 $8.75 $11.25 $4.45 $16.98 $16.98 $8.49 $2.39 $11.25 $3.75 $3.75 $3.75 $9.25 $4.45 $9.25 $9.25 $4.45 $8.75 $9.25 $8.75 $9.25 $9.25 $9.25 $11.48 $8.99 $22.50 $22.50 $11.75 $11.25 $1.25 $8.75 $2.15 $1.25 $11.25 $8.75 $1.25 $11.25 $1.50 $11.25 $11.25 $9.25 $6.49 $8.90 $8.90 $8.75 $4.45 $11.25 $1.25 $17.50 $17.50 $9.25 $8.75 $11.75 $3.00 $3.00 $8.49 $8.49 $10.98 $8.99 $3.99 $8.75 $4.45 $8.99 $1.69 $11.75 $8.75 $11.25 $4.45 $11.75 $1.25 $11.75 $2.95 $8.99 $8.99 $2.18 $2.18 $17.98 $17.98 $8.99 $8.49 $1.69 $11.75 $11.25 $2.95 $3.75 $3.75 $3.75 $9.25 $11.75 $8.75 $2.15 $1.50 $8.49 $8.49 $3.39 $8.69 $3.89 $8.75 $4.45 $8.75 $11.25 $2.15 $8.75 $8.49 $1.69 $8.49 $8.49 $1.25 $8.75 $11.75 $11.75 $8.99 $1.09 $8.75 $4.45 $8.75 $2.95 $8.75 $2.15 $3.99 $8.49 $8.99 $3.99 $8.49 $1.69 $1.09 $8.99 $1.09 $9.25 $8.75 $8.99 $2.39 $1.25 $1.25 $11.25 $11.25 $9.25 $9.25 $11.25 $1.50 $3.99 $8.49 $11.25 $9.25 $11.25 $17.50 $17.50 $8.75 $8.90 $8.90 $8.75 $8.75 $8.99 $2.39 $11.25 $9.25 $2.15 $11.25 $1.25 $11.75 $1.25 $11.25 $11.75 $1.25 $11.25 $11.25 $8.49 $10.98 $8.75 $1.25 $8.75 $8.49 $8.49 $1.50 $1.50 $8.75 $4.45 $11.25 $1.25 $11.75 $8.49 $2.39 $9.25 $4.45 $9.25 $8.75 $8.99 $1.69 $17.50 $17.50 $2.39 $8.99 $8.99 $11.25 $4.45 $8.75 $4.45 $9.25 $6.49 $10.98 $8.49 $8.49 $1.09 $1.69 $9.25 $4.45 $8.75 $1.25 $2.95 $3.99 $8.49 $11.75 $11.75 $2.15 $11.48 $8.75 $2.15 $1.25 $11.25 $2.15 $1.25 $8.75 $8.75 $6.49 $1.69 $8.99 $8.75 $11.75 $10.98 $1.09 $8.49 $3.39 $8.75 $2.15 $1.25 $11.48 $10.98 $10.98 $8.49 $2.95 $9.25 $9.25 $11.75 $4.45 $11.48 $11.25 $8.75 $4.45 $1.69 $8.99 $8.75 $4.45 $1.50 $11.75 $2.15 $8.99 $2.39 $8.75 $2.95 $1.25 $8.75 $2.15 $1.25 $2.18 $2.18 $2.18 $2.18 $11.48 $8.75 $2.95 $11.75 $11.75 $1.25 $10.58 $8.99 $2.39 $11.75 $4.45 $11.25 $11.25 $17.50 $17.50 $8.75 $8.75 $8.75 $22.50 $22.50 $9.25 $8.75 $4.45 $11.75 $1.25 $11.25 $11.25 $2.95 $8.99 $1.69 $11.25 $4.45 $8.75 $6.49 $8.75 $4.45 $9.25 $4.45 $11.75 $11.75 $4.45 $11.89 $11.75 $11.25 $2.95 $1.50 $4.45 $8.75 $8.99 $1.09 $8.99 $1.09 $3.99 $11.48 $8.49 $9.25 $4.45 $11.48 $9.25 $2.95 $9.25 $8.49 $8.99 $8.99 $8.49 $8.75 $2.95 $4.45 $11.89 $10.58 $8.19 $1.69 $8.75 $2.15 $1.25 $17.50 $17.50 $6.49 $9.25 $2.15 $8.75 $4.45 $8.75 $1.25 $11.48 $11.48 $8.99 $2.18 $2.18 $8.49 $8.99 $2.39 $2.39 $2.18 $2.18 $8.75 $4.45 $11.25 $9.25 $9.25 $11.25 $11.25 $4.45 $2.95 $11.75 $8.49 $8.49 $8.99 $1.69 $9.25 $11.25 $11.75 $9.25 $8.75 $11.75 $8.75 $8.75 $11.25 $11.25 $10.98 $11.25 $4.45 $10.98 $8.49 $8.99 $3.39 $3.99 $8.99 $1.09 $1.09 $2.39 $17.50 $17.50 $4.45 $11.25 $11.25 $4.45 $9.25 $4.45 $8.75 $2.15 $1.25 $11.89 $2.95 $11.75 $1.25 $11.25 $4.45 $11.48 $11.48 $2.95 $9.25 $8.75 $9.25 $2.95 $11.25 $1.25 $11.75 $1.25 $8.99 $2.39 $1.25 $11.25 $1.25 $11.25 $8.49 $3.99 $35.00 $35.00 $35.00 $35.00 $27.75 $27.75 $27.75 $8.75 $11.80 $11.80 $11.80 $11.80 $8.90 $8.90 $5.90 $5.90 $6.49 $10.98 $17.98 $17.98 $2.39 $9.25 $8.75 $2.15 $8.75 $4.45 $8.49 $1.69 $8.19 $8.69 $10.98 $3.99 $11.48 $11.48 $4.45 $8.75 $6.49 $8.75 $8.75 $9.25 $1.25 $4.45 $8.49 $1.69 $9.25 $4.45 $8.99 $1.09 $11.25 $2.95 $11.08 $11.08 $3.89 $10.98 $11.25 $8.75 $11.25 $9.25 $4.30 $4.30 $8.75 $8.49 $3.99 $1.69 $8.99 $8.49 $1.69 $11.75 $11.25 $11.89 $9.25 $2.95 $9.25 $2.95 $8.75 $4.45 $4.45 $8.75 $10.98 $11.48 $8.49 $9.25 $4.45 $11.75 $11.89 $8.99 $8.49 $8.75 $9.25 $8.75 $8.75 $11.75 $11.75 $4.45 $11.25 $11.75 $2.50 $2.50 $8.99 $1.69 $11.75 $2.15 $1.25 $9.25 $8.75 $8.90 $8.90 $9.25 $2.95 $8.75 $11.25 $8.90 $8.90 $11.25 $11.75 $11.48 $1.69 $3.39 $9.25 $2.95 $8.99 $1.69 $8.49 $10.98 $11.25 $2.95 $8.99 $1.69 $8.75 $2.15 $1.25 $8.75 $2.95 $9.25 $2.50 $2.50 $11.25 $1.25 $11.75 $2.50 $2.50 $11.25 $1.50 $8.75 $1.25 $2.95 $11.48 $11.48 $8.75 $8.75 $2.15 $11.75 $1.25 $9.25 $9.25 $6.49 $11.75 $8.49 $8.49 $1.09 $10.98 $8.75 $1.25 $2.15 $11.25 $1.50 $11.25 $11.25 $8.49 $8.49 $8.75 $1.50 $1.25 $1.50 $8.75 $2.50 $2.50 $2.15 $7.40 $7.40 $4.00 $9.25 $9.39 $9.25 $9.25 $9.39 $11.25 $8.90 $8.90 $11.25 $6.00 $6.00 $6.00 $6.00 $11.25 $11.25 $11.25 $22.50 $22.50 $11.48 $1.09 $8.49 $8.49 $17.50 $17.50 $11.25 $1.50 $9.25 $8.75 $3.99 $8.49 $8.75 $8.75 $8.75 $8.75 $8.75 $11.75 $1.50 $11.25 $11.25 $2.95 $8.99 $10.98 $9.25 $8.75 $4.45 $8.49 $1.09 $2.39 $8.75 $8.75 $11.48 $8.99 $8.49 $8.49 $2.39 $10.98 $8.49 $3.99 $11.75 $4.45 $8.75 $2.15 $1.25 $10.98 $8.99 $11.25 $1.50 $8.75 $2.15 $1.25 $8.75 $9.25 $8.75 $11.25 $1.50 $8.75 $1.25 $4.45 $10.98 $8.75 $2.95 $1.25 $8.75 $2.95 $1.25 $8.49 $8.49 $2.39 $11.25 $1.25 $8.75 $8.75 $9.25 $8.75 $11.89 $1.25 $8.75 $2.15 $1.25 $8.99 $1.09 $8.75 $4.45 $26.25 $26.25 $26.25 $8.75 $4.45 $11.75 $2.95 $8.75 $8.75 $11.75 $8.75 $11.25 $11.25 $11.25 $4.45 $1.25 $8.49 $8.49 $8.49 $8.99 $8.99 $2.39 $2.39 $3.99 $8.75 $4.45 $2.15 $9.25 $1.25 $11.25 $11.75 $8.75 $4.45 $11.25 $2.15 $8.75 $4.45 $8.75 $8.75 $1.25 $11.25 $2.15 $8.75 $5.90 $5.90 $11.75 $1.25 $9.25 $3.75 $3.75 $3.75 $8.75 $1.25 $4.45 $11.75 $4.45 $8.75 $23.50 $23.50 $8.75 $2.95 $8.75 $8.75 $11.89 $4.45 $2.95 $1.25 $8.75 $4.45 $2.95 $1.25 $8.75 $2.15 $1.25 $11.75 $2.95 $8.99 $3.39 $9.25 $9.25 $17.50 $17.50 $2.95 $11.89 $1.50 $11.25 $2.95 $9.25 $11.25 $11.25 $2.95 $8.75 $9.25 $4.30 $4.30 $8.75 $8.75 $11.25 $8.75 $4.30 $4.30 $8.75 $1.25 $2.15 $8.49 $8.49 $3.39 $3.39 $10.98 $10.98 $2.39 $11.25 $11.75 $11.75 $1.25 $5.90 $5.90 $8.75 $11.25 $9.25 $4.45 $1.50 $3.39 $8.99 $2.39 $11.25 $2.15 $11.25 $11.75 $11.75 $4.45 $11.75 $4.45 $9.25 $8.75 $8.49 $8.99 $8.49 $8.99 $11.75 $8.75 $8.49 $3.99 $3.89 $11.08 $8.49 $8.99 $8.49 $8.49 $8.49 $11.25 $2.15 $17.50 $17.50 $8.75 $2.95 $8.49 $8.49 $10.98 $1.09 $11.25 $2.15 $2.95 $1.25 $8.75 $9.25 $9.25 $9.25 $2.95 $8.75 $2.15 $1.25 $8.99 $3.99 $11.75 $2.15 $8.99 $3.39 $9.25 $8.75 $11.25 $11.25 $4.45 $8.75 $2.15 $1.25 $11.75 $4.45 $9.25 $2.95 $8.49 $8.49 $11.25 $8.75 $4.45 $11.25 $11.25 $11.25 $11.25 $4.45 $8.49 $1.69 $8.49 $3.39 $8.75 $11.25 $9.25 $8.75 $11.25 $11.25 $11.75 $11.25 $11.75 $11.25 $11.75 $21.96 $21.96 $10.98 $1.69 $11.48 $8.99 $8.49 $1.69 $9.25 $2.15 $1.50 $11.25 $1.50 $8.75 $8.75 $2.95 $8.49 $1.69 $8.75 $2.95 $1.25 $11.25 $2.15 $11.08 $8.49 $8.49 $8.49 $11.75 $1.25 $11.75 $8.75 $8.75 $8.75 $4.45 $11.25 $1.50 $23.50 $23.50 $11.75 $6.49 $8.75 $4.45 $6.49 $8.75 $2.50 $2.50 $2.15 $8.49 $2.39 $8.75 $11.75 $4.45 $8.99 $10.98 $9.25 $2.95 $9.25 $9.25 $11.75 $8.75 $8.75 $8.75 $10.98 $11.25 $9.25 $8.75 $8.75 $2.15 $11.25 $2.15 $4.45 $11.75 $8.49 $2.39 $9.25 $1.25 $1.25 $1.25 $1.25 $8.75 $2.15 $8.49 $1.69 $11.25 $1.50 $8.75 $8.75 $8.49 $3.99 $8.99 $1.09 $11.25 $1.25 $8.49 $2.39 $8.49 $8.75 $9.25 $11.25 $4.45 $11.25 $11.89 $8.99 $8.49 $8.75 $4.45 $8.75 $11.75 $11.75 $8.90 $8.90 $9.39 $2.95 $8.49 $3.99 $8.75 $2.15 $1.25 $21.96 $21.96 $8.49 $1.69 $8.75 $4.45 $8.49 $8.99 $8.49 $3.99 $8.75 $8.75 $2.95 $8.75 $17.50 $17.50 $9.25 $2.95 $8.75 $6.49 $4.30 $4.30 $8.75 $8.75 $2.15 $1.50 $8.49 $8.49 $2.39 $9.25 $4.45 $6.49 $11.75 $4.45 $10.98 $1.69 $9.39 $9.25 $9.25 $2.95 $8.75 $2.15 $1.25 $11.25 $9.25 $8.75 $11.25 $8.75 $11.25 $2.50 $2.50 $2.50 $2.50 $6.00 $6.00 $6.00 $6.00 $8.90 $8.90 $5.90 $5.90 $11.25 $11.25 $8.49 $10.98 $8.75 $2.15 $1.50 $9.25 $1.25 $1.50 $2.15 $1.25 $8.75 $2.95 $8.49 $3.99 $11.25 $4.30 $4.30 $11.75 $2.15 $18.50 $18.50 $8.49 $2.39 $8.75 $4.45 $11.75 $8.99 $3.99 $9.25 $9.25 $1.50 $8.75 $2.95 $6.49 $11.75 $8.49 $8.99 $8.75 $4.45 $6.49 $22.50 $22.50 $9.25 $2.95 $8.49 $1.69 $10.98 $8.75 $4.45 $11.25 $2.95 $8.99 $8.49 $2.39 $11.75 $6.49 $11.25 $11.75 $2.95 $8.99 $1.69 $8.99 $2.18 $2.18 $1.09 $8.99 $8.99 $1.09 $8.99 $8.99 $8.49 $10.98 $1.09 $11.75 $9.25 $11.25 $11.25 $2.15 $11.25 $8.75 $4.45 $2.95 $11.75 $1.50 $8.99 $10.98 $2.39 $8.75 $2.15 $9.25 $1.50 $8.75 $2.15 $3.99 $8.99 $6.49 $8.75 $8.90 $8.90 $8.99 $3.99 $17.50 $17.50 $11.25 $1.25 $10.98 $9.25 $4.45 $1.25 $3.00 $3.00 $11.25 $4.45 $4.45 $2.95 $9.25 $11.25 $2.15 $11.25 $11.25 $4.45 $2.95 $9.25 $11.25 $1.25 $8.75 $2.95 $1.25 $8.75 $4.45 $11.48 $11.48 $8.49 $2.39 $11.25 $11.75 $2.15 $1.50 $2.15 $8.75 $11.25 $8.90 $8.90 $11.25 $11.25 $1.25 $4.45 $9.25 $9.25 $8.75 $9.25 $8.75 $8.75 $9.25 $8.75 $11.75 $11.75 $8.75 $8.75 $8.90 $8.90 $2.95 $10.98 $8.49 $8.49 $10.98 $8.99 $8.99 $11.75 $17.50 $17.50 $11.75 $3.99 $8.49 $10.98 $1.69 $17.50 $17.50 $8.99 $2.39 $8.99 $2.39 $1.25 $8.75 $2.95 $11.75 $11.25 $17.50 $17.50 $8.49 $8.49 $2.39 $11.25 $1.50 $8.75 $3.00 $3.00 $1.25 $8.75 $4.45 $11.75 $11.75 $4.45 $21.96 $21.96 $8.75 $4.45 $8.75 $11.25 $9.25 $8.99 $2.39 $9.25 $8.75 $10.98 $8.49 $3.99 $3.39 $11.75 $1.50 $4.45 $9.25 $8.75 $1.25 $11.75 $8.75 $1.50 $8.75 $8.75 $2.15 $1.50 $8.75 $2.95 $8.75 $8.75 $17.50 $17.50 $8.75 $6.49 $4.45 $11.25 $11.25 $4.30 $4.30 $8.75 $11.25 $4.45 $8.99 $2.39 $9.25 $9.25 $9.25 $4.45 $11.75 $11.25 $2.95 $2.15 $11.25 $11.25 $8.75 $2.15 $1.50 $9.25 $4.45 $10.98 $8.99 $2.18 $2.18 $8.75 $4.45 $1.25 $8.99 $2.39 $4.45 $8.75 $10.98 $11.75 $1.50 $10.98 $8.99 $8.49 $3.99 $8.99 $8.49 $3.99 $8.49 $8.49 $8.99 $11.25 $11.25 $10.98 $10.98 $10.98 $2.39 $3.39 $8.75 $1.25 $2.95 $11.75 $1.50 $10.98 $1.69 $4.45 $8.75 $8.75 $8.75 $8.75 $4.45 $9.25 $8.75 $11.25 $8.75 $3.99 $8.99 $8.49 $11.25 $11.25 $8.75 $4.45 $8.75 $4.45 $1.25 $8.75 $8.75 $1.50 $2.15 $11.75 $11.75 $11.75 $11.75 $11.75 $1.50 $8.75 $9.25 $1.25 $8.75 $2.15 $8.99 $1.09 $4.45 $11.25 $11.75 $2.15 $8.75 $8.75 $1.25 $9.25 $2.15 $11.75 $11.25 $8.75 $11.25 $4.45 $8.49 $1.69 $8.75 $8.75 $8.99 $8.49 $9.25 $11.25 $2.95 $4.45 $11.75 $6.49 $11.48 $8.99 $4.36 $4.36 $4.36 $4.36 $11.48 $8.99 $8.49 $11.48 $8.75 $2.15 $1.50 $8.99 $1.69 $11.25 $1.25 $9.25 $9.25 $8.75 $9.25 $8.90 $8.90 $2.15 $9.25 $10.98 $8.49 $8.75 $9.25 $4.30 $4.30 $9.25 $8.75 $8.75 $2.15 $1.25 $8.75 $1.25 $8.75 $5.90 $5.90 $9.25 $8.75 $9.25 $4.45 $9.25 $11.75 $2.50 $2.50 $9.25 $2.15 $9.25 $1.50 $1.25 $11.25 $2.95 $8.75 $8.75 $8.75 $10.98 $8.75 $8.75 $8.75 $2.15 $1.25 $10.98 $8.75 $2.15 $1.50 $8.75 $2.95 $1.25 $9.25 $9.25 $8.49 $2.39 $8.75 $4.45 $9.25 $8.75 $8.75 $8.75 $9.25 $8.75 $9.25 $8.75 $8.75 $8.75 $8.75 $9.25 $8.75 $9.25 $8.75 $9.25 $8.75 $8.75 $8.75 $9.25 $8.75 $9.25 $8.75 $8.99 $8.99 $8.75 $2.95 $1.25 $11.75 $1.50 $11.25 $11.25 $8.75 $1.50 $2.15 $16.98 $16.98 $11.75 $1.50 $8.75 $4.30 $4.30 $1.50 $8.75 $2.95 $1.25 $1.25 $9.25 $4.45 $11.25 $8.75 $4.45 $8.75 $2.15 $1.25 $10.98 $1.69 $8.75 $1.25 $8.75 $1.25 $11.25 $8.75 $8.75 $8.49 $1.69 $9.25 $11.75 $8.49 $2.39 $9.25 $2.95 $6.49 $8.75 $8.75 $9.25 $8.75 $6.78 $6.78 $17.98 $17.98 $3.39 $11.75 $11.25 $8.75 $4.45 $11.75 $9.25 $8.75 $6.49 $8.99 $2.39 $8.75 $11.25 $11.75 $4.45 $8.75 $2.15 $9.25 $9.25 $9.25 $11.89 $11.75 $11.25 $9.25 $9.25 $8.75 $8.75 $8.49 $1.69 $1.09 $11.25 $1.50 $11.25 $11.25 $11.75 $1.50 $8.49 $8.99 $22.50 $22.50 $8.75 $4.30 $4.30 $8.75 $11.25 $2.15 $11.25 $2.95 $4.45 $11.25 $8.49 $3.39 $2.39 $11.75 $2.15 $11.75 $8.99 $2.39 $8.75 $11.75 $11.89 $1.25 $7.50 $7.50 $7.50 $7.50 $7.50 $11.89 $1.09 $8.49 $2.39 $8.75 $8.75 $8.75 $8.75 $9.25 $11.25 $8.75 $8.90 $8.90 $9.25 $8.75 $8.75 $11.75 $3.00 $3.00 $1.50 $11.25 $11.75 $8.99 $10.98 $4.45 $8.75 $2.15 $9.25 $11.25 $4.45 $1.69 $10.98 $9.25 $11.75 $9.25 $4.45 $10.98 $3.99 $8.49 $1.25 $9.25 $4.45 $10.98 $8.75 $8.75 $11.75 $11.25 $8.49 $11.48 $4.45 $1.25 $11.25 $8.99 $1.09 $2.39 $11.25 $2.15 $8.75 $4.45 $8.49 $1.69 $10.98 $1.69 $9.25 $4.45 $11.25 $8.75 $11.25 $11.75 $11.25 $22.50 $22.50 $8.49 $2.39 $2.50 $2.50 $8.75 $8.75 $9.25 $9.25 $11.25 $8.99 $1.09 $8.99 $1.69 $11.75 $1.25 $21.96 $21.96 $8.75 $2.15 $1.25 $8.75 $11.25 $9.25 $11.25 $8.75 $8.75 $11.25 $2.15 $8.99 $1.09 $1.69 $8.75 $2.15 $1.25 $8.49 $1.09 $1.09 $1.69 $11.48 $8.49 $8.49 $4.78 $4.78 $9.25 $1.25 $1.25 $1.25 $11.25 $11.25 $11.75 $4.45 $11.25 $4.45 $8.99 $1.09 $11.25 $2.15 $11.25 $9.25 $11.75 $11.25 $11.25 $9.25 $2.95 $11.25 $4.45 $8.75 $2.95 $2.95 $11.25 $1.50 $10.98 $16.98 $16.98 $18.50 $18.50 $10.98 $3.99 $1.09 $9.25 $9.25 $8.75 $4.45 $17.50 $17.50 $8.75 $4.45 $8.75 $1.25 $4.45 $9.25 $8.75 $8.75 $17.50 $17.50 $4.45 $9.39 $1.25 $2.95 $11.25 $8.75 $8.75 $11.25 $2.15 $8.90 $8.90 $11.25 $11.89 $10.98 $11.25 $4.45 $11.25 $11.25 $8.49 $10.98 $8.49 $3.39 $9.25 $8.75 $2.95 $3.00 $3.00 $9.39 $11.75 $2.95 $1.50 $11.25 $11.75 $8.75 $2.15 $1.50 $8.49 $3.39 $11.75 $1.25 $17.50 $17.50 $11.25 $1.25 $8.75 $2.95 $1.25 $11.25 $11.75 $13.35 $13.35 $13.35 $11.25 $11.75 $11.25 $11.25 $4.45 $11.25 $8.49 $3.39 $9.25 $2.95 $4.78 $4.78 $2.39 $3.99 $8.99 $8.99 $11.25 $11.25 $8.75 $11.25 $2.95 $4.45 $9.25 $8.75 $4.45 $8.49 $8.49 $10.98 $10.98 $3.99 $11.75 $8.75 $11.75 $4.45 $1.50 $1.25 $8.49 $8.49 $8.75 $8.75 $8.75 $9.25 $8.75 $2.95 $1.25 $11.25 $1.50 $11.25 $4.45 $9.25 $8.75 $8.75 $9.25 $8.75 $4.45 $1.50 $8.75 $8.75 $8.49 $1.69 $8.75 $2.15 $9.25 $2.15 $1.50 $11.25 $11.75 $2.15 $6.49 $9.25 $9.25 $11.25 $11.25 $11.75 $11.75 $11.75 $11.25 $8.75 $2.15 $1.25 $11.75 $9.25 $11.25 $8.75 $5.90 $5.90 $8.75 $4.45 $9.25 $9.25 $4.45 $11.25 $4.45 $11.25 $8.75 $2.15 $11.89 $11.25 $8.75 $2.95 $1.50 $8.75 $4.30 $4.30 $8.75 $11.25 $11.75 $11.75 $2.15 $11.25 $8.99 $1.09 $8.49 $8.49 $8.49 $3.39 $8.99 $10.98 $3.99 $11.75 $2.15 $8.75 $4.45 $2.50 $2.50 $11.48 $1.09 $8.49 $8.49 $16.98 $16.98 $3.99 $10.98 $1.09 $8.75 $2.95 $8.75 $8.75 $2.95 $9.25 $11.25 $2.15 $9.25 $4.45 $4.45 $9.25 $11.75 $11.75 $2.15 $9.25 $8.75 $11.25 $6.49 $8.75 $11.25 $2.95 $10.98 $3.99 $1.50 $9.25 $2.15 $8.75 $11.25 $11.89 $4.45 $1.50 $1.25 $8.75 $8.75 $4.45 $11.25 $11.75 $8.49 $1.09 $1.09 $1.69 $8.99 $3.39 $8.99 $1.69 $8.49 $8.99 $3.27 $3.27 $3.27 $8.99 $8.99 $1.09 $10.98 $1.69 $3.99 $8.49 $1.09 $8.75 $8.75 $11.75 $8.75 $9.25 $8.75 $3.39 $8.99 $8.99 $2.39 $9.25 $8.75 $9.25 $9.25 $8.99 $3.99 $2.39 $8.49 $1.09 $8.49 $8.99 $3.39 $11.25 $1.25 $8.99 $3.99 $8.75 $8.90 $8.90 $6.49 $8.75 $9.25 $11.25 $11.25 $11.25 $1.25 $8.75 $9.25 $4.45 $1.25 $8.75 $1.25 $2.15 $17.98 $17.98 $8.99 $8.75 $2.95 $1.25 $11.75 $1.50 $1.50 $8.75 $8.75 $11.08 $8.99 $1.69 $8.99 $1.69 $10.98 $3.99 $3.39 $11.75 $2.15 $11.75 $2.95 $8.75 $8.75 $11.75 $11.25 $11.75 $11.25 $4.45 $11.25 $1.25 $2.18 $2.18 $2.18 $2.18 $2.39 $8.49 $8.99 $2.39 $11.25 $8.75 $11.75 $11.75 $11.25 $4.45 $2.15 $8.19 $10.58 $4.45 $9.25 $1.09 $8.99 $11.25 $1.50 $8.99 $3.99 $4.45 $11.75 $2.15 $11.25 $8.75 $4.45 $8.75 $9.25 $6.45 $6.45 $6.45 $8.75 $11.25 $11.25 $8.75 $11.75 $21.96 $21.96 $8.99 $5.07 $5.07 $5.07 $8.49 $9.25 $11.25 $4.45 $3.39 $8.49 $8.99 $8.49 $17.50 $17.50 $22.96 $22.96 $8.75 $11.25 $11.89 $11.25 $8.49 $1.69 $1.09 $8.99 $8.99 $9.25 $8.75 $9.25 $2.95 $8.49 $3.99 $8.99 $8.49 $7.17 $7.17 $7.17 $8.49 $8.99 $17.50 $17.50 $9.25 $9.25 $11.25 $1.25 $8.99 $1.09 $8.75 $4.45 $11.25 $2.15 $11.75 $11.25 $11.25 $8.75 $8.75 $4.45 $1.25 $11.75 $11.75 $2.50 $2.50 $8.49 $8.99 $2.18 $2.18 $11.25 $4.45 $11.25 $11.75 $8.49 $8.99 $1.69 $1.09 $8.99 $8.99 $11.25 $6.49 $11.25 $8.75 $4.45 $8.99 $1.69 $11.48 $11.75 $2.50 $2.50 $8.49 $1.09 $1.09 $1.69 $8.49 $2.39 $11.75 $1.25 $8.49 $1.69 $8.49 $1.69 $11.75 $4.45 $8.75 $8.75 $4.45 $8.75 $11.25 $11.25 $8.75 $7.98 $7.98 $8.49 $1.09 $8.49 $3.99 $8.49 $3.99 $8.99 $3.99 $11.25 $4.45 $8.49 $2.39 $8.49 $2.39 $3.99 $8.49 $1.25 $11.25 $4.45 $9.25 $4.45 $1.09 $8.99 $3.99 $11.25 $8.90 $8.90 $9.25 $11.25 $8.75 $11.25 $11.25 $11.25 $11.25 $11.25 $8.99 $8.49 $8.75 $8.75 $4.45 $16.98 $16.98 $11.75 $11.25 $9.25 $4.45 $9.25 $2.95 $8.49 $1.69 $3.75 $3.75 $3.75 $4.45 $9.25 $1.50 $11.25 $11.48 $11.25 $2.15 $8.75 $9.39 $8.49 $3.99 $8.19 $2.29 $11.48 $1.69 $11.48 $3.99 $8.49 $1.69 $9.25 $2.95 $8.49 $1.69 $11.25 $4.45 $9.39 $9.25 $8.75 $8.75 $4.45 $11.89 $4.45 $4.45 $8.75 $8.75 $8.75 $2.15 $8.75 $3.75 $3.75 $3.75 $9.25 $11.25 $4.45 $6.49 $16.98 $16.98 $18.50 $18.50 $2.50 $2.50 $2.95 $3.99 $8.49 $8.19 $11.08 $6.49 $11.75 $2.39 $8.99 $1.09 $11.25 $4.45 $11.25 $8.99 $1.69 $21.96 $21.96 $2.18 $2.18 $8.99 $8.99 $2.39 $8.69 $1.69 $8.90 $8.90 $2.50 $2.50 $8.75 $8.99 $1.09 $8.49 $8.49 $8.75 $4.45 $17.50 $17.50 $8.75 $9.25 $8.49 $2.39 $8.75 $4.45 $11.25 $11.25 $11.75 $8.75 $8.49 $8.49 $8.49 $8.99 $8.75 $4.45 $11.48 $8.75 $1.25 $2.15 $9.25 $4.45 $11.75 $2.15 $11.25 $8.99 $2.39 $8.69 $8.69 $11.75 $2.95 $11.75 $1.50 $9.25 $4.45 $1.50 $11.48 $8.99 $2.39 $11.25 $11.89 $2.15 $1.25 $11.75 $4.45 $8.75 $8.75 $11.25 $4.45 $11.25 $2.15 $4.45 $8.49 $1.09 $3.99 $11.25 $11.25 $8.49 $2.39 $8.99 $2.39 $11.25 $2.15 $8.75 $2.95 $1.25 $8.75 $11.25 $17.50 $17.50 $11.75 $11.75 $11.25 $11.25 $4.45 $2.50 $2.50 $8.75 $8.99 $8.99 $1.69 $8.99 $1.69 $11.25 $1.25 $11.08 $8.69 $8.99 $1.09 $11.25 $11.25 $2.95 $1.25 $8.75 $1.25 $8.75 $8.75 $2.15 $1.25 $8.49 $3.99 $8.49 $2.39 $8.49 $7.17 $7.17 $7.17 $8.75 $4.45 $11.48 $8.75 $8.75 $11.48 $8.75 $9.25 $8.49 $3.99 $1.50 $11.25 $11.25 $8.75 $8.75 $4.45 $9.25 $4.45 $8.75 $8.75 $4.30 $4.30 $2.95 $8.75 $4.50 $4.50 $4.50 $9.25 $11.25 $4.45 $11.25 $11.25 $8.75 $9.25 $8.75 $2.15 $1.25 $8.75 $2.15 $1.25 $8.99 $8.49 $8.75 $8.75 $1.25 $11.75 $4.50 $4.50 $4.50 $8.75 $8.75 $3.99 $3.39 $8.49 $2.39 $8.99 $1.50 $11.25 $11.25 $8.75 $8.75 $2.15 $8.75 $2.15 $1.25 $21.96 $21.96 $8.49 $1.69 $26.07 $26.07 $26.07 $11.75 $1.50 $8.99 $8.99 $11.48 $9.25 $9.25 $8.75 $8.75 $8.75 $9.25 $8.75 $8.75 $2.15 $1.25 $11.89 $8.75 $11.75 $4.45 $18.50 $18.50 $9.25 $9.39 $8.49 $2.39 $8.49 $1.69 $1.09 $8.99 $8.49 $2.18 $2.18 $11.25 $1.25 $8.49 $3.39 $8.49 $3.99 $11.25 $8.75 $8.49 $1.69 $16.98 $16.98 $9.25 $9.25 $11.75 $1.25 $11.25 $8.75 $8.49 $8.49 $8.75 $1.25 $1.25 $1.25 $11.25 $12.98 $12.98 $11.75 $11.75 $4.45 $11.25 $11.75 $10.98 $8.49 $8.49 $2.39 $9.25 $11.25 $8.75 $2.95 $1.50 $11.25 $2.95 $9.25 $2.95 $9.25 $8.75 $11.25 $8.75 $8.75 $4.45 $11.25 $1.25 $8.75 $2.95 $2.50 $2.50 $9.25 $9.25 $9.25 $6.49 $17.50 $17.50 $8.49 $1.69 $8.49 $3.99 $8.75 $2.95 $2.95 $8.49 $8.99 $8.99 $1.09 $8.75 $4.45 $1.25 $11.25 $11.75 $11.25 $9.25 $11.25 $1.50 $11.25 $2.15 $10.98 $8.75 $11.75 $2.95 $11.25 $11.25 $9.25 $8.75 $9.25 $8.75 $8.75 $8.75 $1.25 $11.25 $1.50 $2.15 $8.75 $8.75 $11.25 $8.75 $8.75 $11.25 $4.45 $8.49 $8.49 $8.49 $8.49 $8.99 $1.69 $2.39 $1.09 $1.09 $11.25 $2.95 $35.25 $35.25 $35.25 $8.75 $2.95 $1.25 $11.25 $2.15 $9.25 $4.45 $8.75 $8.75 $8.75 $4.45 $1.25 $11.89 $8.75 $2.15 $1.25 $8.49 $1.09 $1.09 $1.69 $8.69 $8.69 $9.25 $2.95 $10.98 $2.39 $22.50 $22.50 $21.96 $21.96 $10.98 $8.49 $1.69 $11.75 $2.95 $8.75 $11.25 $8.75 $9.25 $8.75 $8.19 $10.58 $8.75 $2.95 $1.50 $2.50 $2.50 $9.25 $4.45 $9.25 $11.25 $8.69 $8.69 $3.89 $8.69 $1.69 $4.45 $9.25 $11.25 $4.45 $2.15 $8.19 $8.69 $4.45 $11.25 $1.25 $11.25 $8.75 $11.89 $11.75 $11.75 $9.25 $8.75 $2.15 $1.50 $11.75 $4.45 $3.99 $8.99 $10.98 $2.39 $1.25 $2.95 $8.75 $2.95 $9.25 $9.25 $9.25 $8.75 $2.15 $9.25 $9.25 $3.39 $8.49 $8.49 $2.39 $10.98 $1.09 $1.09 $8.49 $11.25 $1.25 $8.99 $1.09 $8.75 $2.15 $1.50 $3.99 $8.49 $8.75 $2.15 $1.50 $8.49 $10.98 $2.18 $2.18 $8.75 $2.15 $1.50 $4.45 $9.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $10.50 $10.50 $10.50 $10.50 $10.50 $10.50 $10.50 $6.49 $33.75 $33.75 $33.75 $35.00 $35.00 $35.00 $35.00 $27.75 $27.75 $27.75 $3.00 $3.00 $11.25 $11.75 $10.98 $2.39 $2.50 $2.50 $8.75 $4.45 $16.98 $16.98 $8.75 $6.49 $16.98 $16.98 $17.98 $17.98 $16.98 $16.98 $16.98 $16.98 $8.99 $8.99 $8.49 $9.25 $8.75 $2.95 $11.48 $2.39 $8.99 $2.39 $11.25 $4.45 $8.75 $9.25 $6.49 $26.25 $26.25 $26.25 $8.75 $26.25 $26.25 $26.25 $8.75 $8.75 $11.25 $11.25 $2.15 $1.25 $11.75 $8.75 $2.15 $1.50 $11.25 $2.15 $8.99 $2.39 $11.25 $11.25 $2.15 $11.25 $11.25 $8.75 $4.78 $4.78 $21.96 $21.96 $8.49 $2.39 $9.25 $2.95 $16.98 $16.98 $8.19 $3.89 $8.99 $1.09 $8.99 $3.39 $9.25 $4.45 $10.98 $10.98 $17.50 $17.50 $11.25 $1.25 $8.75 $11.75 $4.45 $11.25 $11.25 $8.99 $1.09 $10.98 $8.49 $1.69 $11.25 $9.25 $16.98 $16.98 $8.75 $4.45 $11.25 $6.49 $11.75 $9.25 $9.25 $8.75 $4.45 $2.50 $2.50 $8.75 $11.75 $8.75 $9.25 $11.75 $9.25 $8.75 $9.25 $8.75 $11.25 $11.75 $9.25 $8.75 $11.75 $8.49 $1.09 $1.09 $8.49 $1.09 $1.69 $11.25 $1.25 $8.75 $2.15 $1.50 $8.49 $1.69 $1.25 $8.75 $2.95 $8.49 $3.99 $8.49 $8.49 $8.75 $11.25 $2.15 $1.50 $11.75 $8.99 $1.09 $10.98 $10.98 $11.25 $1.25 $8.75 $4.45 $4.45 $1.25 $11.89 $8.99 $8.99 $11.25 $4.45 $23.50 $23.50 $8.49 $3.99 $9.25 $4.45 $4.45 $9.25 $8.75 $4.45 $8.75 $8.75 $11.75 $6.49 $17.50 $17.50 $4.45 $8.75 $2.95 $1.50 $8.75 $8.75 $8.75 $4.45 $11.25 $11.25 $11.75 $11.25 $2.95 $11.25 $4.45 $3.00 $3.00 $1.25 $2.95 $9.25 $8.99 $2.39 $6.49 $8.75 $8.90 $8.90 $11.48 $1.09 $10.98 $9.25 $9.25 $11.25 $8.75 $11.75 $11.25 $11.25 $1.25 $9.25 $4.45 $9.25 $6.49 $11.75 $11.75 $8.99 $2.39 $8.49 $8.49 $9.25 $9.25 $1.25 $8.75 $2.95 $11.75 $2.15 $8.49 $8.49 $8.69 $16.38 $16.38 $8.19 $3.89 $2.29 $11.75 $8.75 $8.75 $8.75 $4.45 $8.49 $8.49 $9.25 $8.75 $6.49 $2.95 $11.25 $11.25 $2.15 $9.25 $11.75 $21.96 $21.96 $8.49 $3.39 $1.69 $8.49 $8.75 $4.45 $8.49 $3.99 $11.25 $8.75 $11.25 $2.15 $11.75 $4.45 $11.25 $9.25 $8.75 $18.50 $18.50 $1.50 $8.75 $2.15 $11.48 $2.18 $2.18 $3.99 $11.25 $1.50 $8.99 $2.39 $11.75 $1.50 $11.25 $6.49 $4.45 $11.25 $8.49 $3.99 $2.50 $2.50 $8.75 $9.25 $3.99 $8.99 $8.75 $6.49 $13.52 $13.52 $13.52 $13.52 $13.52 $13.52 $13.52 $13.52 $16.98 $16.98 $16.98 $16.98 $17.98 $17.98 $16.98 $16.98 $8.75 $8.75 $11.25 $11.25 $8.49 $1.09 $1.69 $1.25 $9.25 $2.95 $8.69 $8.19 $8.49 $2.39 $8.49 $2.39 $10.98 $8.99 $8.99 $1.69 $8.49 $8.75 $8.75 $11.25 $4.45 $4.45 $17.50 $17.50 $8.75 $4.45 $8.75 $2.15 $1.50 $1.50 $8.99 $1.09 $8.75 $4.45 $8.75 $8.75 $11.25 $4.30 $4.30 $8.49 $1.69 $1.09 $1.09 $8.75 $2.15 $1.50 $8.99 $8.49 $3.99 $8.75 $2.15 $1.25 $9.25 $2.95 $11.25 $4.45 $9.25 $2.95 $3.99 $8.99 $8.49 $8.75 $8.75 $11.25 $9.25 $8.75 $4.45 $11.25 $1.25 $9.25 $11.25 $4.45 $2.95 $10.98 $8.75 $8.75 $18.50 $18.50 $9.25 $9.25 $5.00 $5.00 $5.00 $5.00 $8.75 $2.95 $16.98 $16.98 $11.25 $2.95 $8.75 $2.15 $1.50 $8.49 $2.39 $9.25 $2.15 $1.25 $8.19 $8.69 $8.19 $8.19 $8.75 $2.95 $1.25 $9.25 $2.95 $11.25 $8.75 $11.25 $11.25 $8.99 $1.09 $9.25 $9.25 $4.45 $8.49 $3.99 $2.39 $1.09 $8.99 $8.49 $8.75 $8.75 $11.25 $11.75 $4.45 $2.50 $2.50 $8.75 $8.49 $3.39 $8.75 $9.25 $4.45 $1.25 $11.25 $2.15 $4.45 $2.50 $2.50 $8.99 $3.99 $8.75 $2.15 $11.75 $11.75 $1.25 $8.75 $9.39 $11.25 $9.25 $9.25 $2.95 $9.25 $4.45 $1.25 $9.25 $8.75 $11.75 $1.50 $8.75 $4.45 $8.99 $1.09 $9.25 $2.95 $8.99 $1.69 $8.69 $1.69 $11.25 $4.45 $8.75 $8.75 $4.45 $11.25 $8.75 $2.95 $1.50 $8.19 $8.69 $1.09 $1.69 $8.49 $8.75 $2.95 $1.25 $8.49 $3.99 $10.98 $3.39 $11.25 $11.25 $2.15 $18.50 $18.50 $8.49 $8.49 $11.25 $1.50 $8.49 $2.39 $8.99 $2.39 $11.75 $4.45 $17.50 $17.50 $9.25 $9.25 $8.75 $4.45 $3.75 $3.75 $3.75 $8.75 $4.45 $11.75 $2.95 $1.25 $4.45 $8.75 $1.25 $1.50 $9.25 $11.25 $11.25 $11.25 $11.25 $9.25 $11.25 $4.45 $8.75 $9.25 $8.75 $8.75 $4.45 $8.75 $1.25 $2.15 $8.75 $8.75 $4.30 $4.30 $8.75 $1.25 $2.95 $9.25 $2.95 $4.45 $11.25 $11.25 $9.25 $9.25 $4.50 $4.50 $4.50 $11.75 $1.25 $11.75 $11.75 $1.25 $1.25 $9.25 $4.45 $11.25 $11.75 $17.50 $17.50 $2.15 $1.25 $11.25 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $11.25 $4.45 $4.45 $2.95 $11.25 $2.15 $1.25 $1.50 $8.75 $11.25 $2.95 $11.25 $1.25 $2.15 $11.25 $9.25 $6.49 $1.25 $8.75 $2.15 $8.75 $6.49 $11.25 $1.50 $8.75 $4.45 $8.75 $4.45 $9.25 $9.25 $1.25 $1.25 $8.75 $4.50 $4.50 $4.50 $11.25 $1.25 $1.50 $9.25 $2.15 $11.25 $4.45 $11.25 $4.45 $8.75 $4.45 $9.25 $4.45 $1.25 $11.25 $4.45 $8.75 $4.45 $8.75 $2.15 $8.75 $4.45 $8.75 $11.75 $1.50 $11.25 $4.45 $8.75 $2.15 $1.50 $8.75 $4.45 $8.75 $11.75 $8.75 $8.75 $11.25 $11.25 $1.50 $8.75 $2.15 $11.75 $2.15 $9.25 $2.95 $18.50 $18.50 $1.25 $4.45 $8.50 $8.50 $8.50 $8.50 $11.25 $11.89 $1.25 $9.39 $4.45 $8.75 $2.15 $1.50 $11.75 $8.75 $9.25 $9.25 $4.45 $1.25 $11.25 $9.25 $2.95 $8.75 $8.75 $2.15 $8.75 $11.25 $11.25 $11.25 $11.75 $11.25 $2.15 $11.25 $2.15 $8.99 $8.99 $8.75 $9.25 $9.25 $11.25 $8.75 $4.45 $8.75 $1.25 $4.45 $11.25 $1.25 $8.75 $8.75 $11.25 $8.75 $1.25 $1.25 $1.25 $9.25 $11.75 $2.15 $8.75 $4.45 $8.75 $4.45 $11.25 $9.25 $8.75 $9.25 $4.45 $11.75 $4.45 $1.25 $4.45 $11.75 $9.25 $11.25 $2.15 $23.50 $23.50 $9.25 $2.15 $18.50 $18.50 $8.75 $5.90 $5.90 $11.89 $4.45 $8.75 $4.45 $9.25 $2.95 $11.25 $2.95 $11.25 $11.25 $11.25 $2.95 $11.75 $9.25 $9.25 $2.95 $11.25 $2.15 $9.25 $8.90 $8.90 $8.75 $11.25 $11.25 $11.25 $8.75 $2.15 $1.25 $11.25 $1.25 $8.75 $4.45 $1.25 $11.25 $11.25 $11.75 $1.25 $11.25 $11.25 $11.25 $8.75 $8.75 $18.50 $18.50 $11.75 $1.25 $4.45 $9.25 $6.49 $4.45 $8.75 $11.25 $6.49 $11.75 $8.75 $9.25 $11.25 $2.15 $8.75 $4.45 $11.25 $4.45 $8.75 $9.25 $4.45 $1.25 $1.25 $8.75 $11.25 $11.75 $2.15 $11.75 $4.45 $11.75 $1.25 $11.75 $11.75 $11.25 $4.30 $4.30 $9.39 $9.39 $8.75 $1.25 $9.25 $4.45 $11.25 $1.25 $8.75 $1.25 $2.95 $11.25 $4.45 $8.75 $1.50 $4.45 $4.45 $9.25 $8.75 $2.95 $1.25 $11.25 $2.95 $8.75 $8.75 $8.75 $8.75 $4.30 $4.30 $9.25 $9.39 $4.45 $9.25 $1.25 $22.50 $22.50 $4.45 $2.95 $2.15 $23.50 $23.50 $11.75 $2.15 $1.25 $9.25 $4.45 $11.25 $11.75 $17.50 $17.50 $8.75 $11.75 $11.25 $8.75 $4.45 $11.75 $1.50 $8.75 $8.75 $11.75 $9.25 $11.25 $4.45 $11.75 $9.25 $4.45 $11.25 $8.75 $8.75 $2.15 $1.50 $8.75 $4.45 $9.25 $8.75 $1.50 $1.25 $1.25 $1.25 $8.75 $2.95 $11.25 $11.25 $1.50 $11.75 $11.25 $2.15 $9.25 $8.75 $11.75 $2.95 $1.50 $8.75 $1.50 $1.25 $8.75 $11.75 $11.25 $11.25 $11.75 $11.25 $11.75 $8.75 $17.80 $17.80 $17.80 $17.80 $5.00 $5.00 $5.00 $5.00 $5.00 $5.00 $5.00 $5.00 $8.75 $2.95 $1.25 $11.25 $1.25 $2.15 $11.25 $2.50 $2.50 $9.25 $1.25 $11.25 $2.95 $11.75 $2.15 $11.25 $1.50 $8.99 $1.99 $11.49 $8.75 $4.45 $1.25 $8.75 $4.45 $1.25 $1.50 $11.75 $8.75 $8.75 $11.25 $6.49 $11.75 $8.75 $2.15 $1.25 $6.49 $8.75 $4.45 $8.75 $4.45 $8.75 $11.25 $4.45 $6.49 $9.25 $8.75 $1.25 $4.45 $11.25 $8.75 $1.50 $8.75 $1.50 $1.25 $9.25 $9.39 $4.45 $9.25 $8.75 $4.45 $1.25 $11.25 $11.75 $8.75 $11.25 $9.25 $8.75 $11.25 $2.50 $2.50 $17.50 $17.50 $9.25 $4.45 $11.25 $1.25 $8.75 $4.45 $1.50 $8.75 $1.50 $1.25 $9.39 $8.75 $8.75 $4.45 $11.25 $1.25 $9.25 $4.45 $11.25 $8.75 $3.00 $3.00 $8.75 $2.15 $1.25 $11.25 $11.25 $4.45 $11.25 $11.25 $8.75 $11.75 $11.75 $11.75 $8.75 $4.45 $1.25 $1.50 $8.75 $4.45 $1.25 $9.25 $9.25 $8.75 $4.45 $1.25 $11.75 $11.25 $1.25 $11.75 $11.25 $9.25 $2.15 $1.50 $8.75 $4.45 $11.75 $11.75 $11.25 $8.75 $8.75 ' to numeric\n\n\n\n\n# Solution 2\n\nchipo.groupby(by=['order_id']).sum()['revenue'].mean()\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[9], line 3\n      1 # Solution 2\n----&gt; 3 chipo.groupby(by=['order_id']).sum()['revenue'].mean()\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6549, in Series.mean(self, axis, skipna, numeric_only, **kwargs)\n   6541 @doc(make_doc(\"mean\", ndim=1))\n   6542 def mean(\n   6543     self,\n   (...)\n   6547     **kwargs,\n   6548 ):\n-&gt; 6549     return NDFrame.mean(self, axis, skipna, numeric_only, **kwargs)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12420, in NDFrame.mean(self, axis, skipna, numeric_only, **kwargs)\n  12413 def mean(\n  12414     self,\n  12415     axis: Axis | None = 0,\n   (...)\n  12418     **kwargs,\n  12419 ) -&gt; Series | float:\n&gt; 12420     return self._stat_function(\n  12421         \"mean\", nanops.nanmean, axis, skipna, numeric_only, **kwargs\n  12422     )\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12377, in NDFrame._stat_function(self, name, func, axis, skipna, numeric_only, **kwargs)\n  12373 nv.validate_func(name, (), kwargs)\n  12375 validate_bool_kwarg(skipna, \"skipna\", none_allowed=False)\n&gt; 12377 return self._reduce(\n  12378     func, name=name, axis=axis, skipna=skipna, numeric_only=numeric_only\n  12379 )\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6457, in Series._reduce(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\n   6452     # GH#47500 - change to TypeError to match other methods\n   6453     raise TypeError(\n   6454         f\"Series.{name} does not allow {kwd_name}={numeric_only} \"\n   6455         \"with non-numeric dtypes.\"\n   6456     )\n-&gt; 6457 return op(delegate, skipna=skipna, **kwds)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147, in bottleneck_switch.__call__.&lt;locals&gt;.f(values, axis, skipna, **kwds)\n    145         result = alt(values, axis=axis, skipna=skipna, **kwds)\n    146 else:\n--&gt; 147     result = alt(values, axis=axis, skipna=skipna, **kwds)\n    149 return result\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404, in _datetimelike_compat.&lt;locals&gt;.new_func(values, axis, skipna, mask, **kwargs)\n    401 if datetimelike and mask is None:\n    402     mask = isna(values)\n--&gt; 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)\n    406 if datetimelike:\n    407     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:720, in nanmean(values, axis, skipna, mask)\n    718 count = _get_counts(values.shape, mask, axis, dtype=dtype_count)\n    719 the_sum = values.sum(axis, dtype=dtype_sum)\n--&gt; 720 the_sum = _ensure_numeric(the_sum)\n    722 if axis is not None and getattr(the_sum, \"ndim\", False):\n    723     count = cast(np.ndarray, count)\n\nFile c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1701, in _ensure_numeric(x)\n   1698 elif not (is_float(x) or is_integer(x) or is_complex(x)):\n   1699     if isinstance(x, str):\n   1700         # GH#44008, GH#36703 avoid casting e.g. strings to numeric\n-&gt; 1701         raise TypeError(f\"Could not convert string '{x}' to numeric\")\n   1702     try:\n   1703         x = float(x)\n\nTypeError: Could not convert string '$2.39 $3.39 $3.39 $2.39 $16.98 $16.98 $10.98 $1.69 $11.75 $9.25 $9.25 $4.45 $8.75 $8.75 $11.25 $4.45 $2.39 $8.49 $8.49 $2.18 $2.18 $8.75 $4.45 $8.99 $3.39 $10.98 $3.39 $2.39 $8.49 $8.99 $1.09 $8.49 $2.39 $8.99 $1.69 $8.99 $1.09 $8.75 $8.75 $4.45 $2.95 $11.75 $2.15 $4.45 $11.25 $11.75 $8.75 $10.98 $8.99 $3.39 $8.99 $3.99 $8.99 $2.18 $2.18 $10.98 $1.09 $8.99 $2.39 $9.25 $11.25 $11.75 $2.15 $4.45 $9.25 $11.25 $8.75 $8.99 $8.99 $3.39 $8.99 $10.98 $8.99 $1.69 $8.99 $3.99 $8.75 $4.45 $8.75 $8.75 $2.15 $8.75 $11.25 $2.15 $9.25 $8.75 $8.75 $9.25 $8.49 $8.99 $1.09 $9.25 $2.95 $11.75 $11.75 $9.25 $11.75 $4.45 $9.25 $4.45 $11.75 $8.75 $8.75 $4.45 $8.99 $8.99 $3.99 $8.49 $3.39 $8.99 $1.09 $9.25 $4.45 $8.75 $2.95 $4.45 $2.39 $8.49 $8.99 $8.49 $1.09 $8.99 $3.99 $8.75 $9.25 $4.45 $11.25 $4.45 $8.99 $1.09 $9.25 $2.95 $4.45 $11.75 $4.45 $8.49 $2.39 $10.98 $22.50 $22.50 $11.75 $4.45 $11.25 $4.45 $11.25 $4.45 $11.25 $11.25 $11.75 $9.25 $4.45 $11.48 $17.98 $17.98 $1.69 $17.50 $17.50 $4.45 $8.49 $2.39 $17.50 $17.50 $4.45 $4.45 $11.25 $11.75 $10.98 $8.49 $10.98 $2.18 $2.18 $11.48 $8.49 $2.39 $4.45 $11.25 $11.75 $8.75 $8.49 $2.18 $2.18 $8.49 $3.39 $8.49 $8.99 $10.98 $11.48 $8.49 $1.09 $1.09 $9.25 $8.75 $2.95 $9.25 $4.45 $11.25 $11.48 $8.49 $8.49 $8.99 $2.39 $11.25 $8.75 $2.95 $1.09 $8.99 $8.49 $2.39 $10.98 $1.09 $3.99 $11.25 $8.75 $8.49 $3.39 $8.75 $9.25 $2.15 $11.25 $11.25 $11.25 $4.45 $22.50 $22.50 $4.45 $11.75 $8.75 $17.50 $17.50 $8.75 $9.25 $8.75 $2.15 $9.25 $4.30 $4.30 $8.75 $11.25 $2.15 $8.99 $1.09 $8.99 $3.99 $8.75 $2.95 $2.95 $11.75 $5.90 $5.90 $9.25 $9.25 $11.75 $9.25 $2.95 $17.50 $17.50 $8.75 $9.25 $10.98 $8.99 $1.09 $1.09 $1.09 $8.99 $10.98 $1.09 $8.75 $8.75 $9.25 $9.25 $8.75 $8.75 $8.99 $8.99 $8.99 $1.09 $11.75 $1.25 $8.99 $2.39 $9.25 $2.95 $8.99 $3.99 $8.49 $2.39 $8.49 $8.49 $8.49 $1.69 $8.49 $3.99 $8.99 $1.69 $1.09 $23.78 $23.78 $17.50 $17.50 $2.15 $8.75 $9.25 $9.25 $8.75 $4.45 $8.75 $11.25 $11.25 $1.25 $9.25 $4.45 $11.25 $11.75 $11.75 $6.49 $8.99 $2.39 $8.49 $2.39 $11.25 $8.75 $2.15 $8.99 $1.69 $8.75 $11.25 $2.15 $4.45 $8.75 $8.49 $8.99 $17.50 $17.50 $8.49 $1.09 $1.09 $8.75 $1.25 $2.15 $11.08 $8.49 $8.49 $8.99 $2.39 $8.75 $2.15 $1.50 $11.25 $2.15 $8.49 $8.49 $11.75 $9.25 $11.75 $1.25 $11.25 $8.75 $4.45 $6.49 $9.25 $2.95 $11.25 $4.45 $1.25 $1.25 $8.49 $2.39 $2.18 $2.18 $8.49 $2.18 $2.18 $22.16 $22.16 $17.50 $17.50 $8.75 $2.95 $6.49 $8.99 $3.39 $3.39 $8.99 $8.49 $11.25 $2.15 $11.25 $2.95 $11.25 $1.25 $8.99 $1.09 $8.75 $8.75 $9.25 $2.95 $11.75 $1.50 $8.99 $1.09 $11.25 $1.25 $1.25 $11.25 $11.75 $2.15 $8.99 $1.69 $11.75 $6.49 $8.75 $9.25 $11.25 $4.45 $1.25 $11.25 $4.45 $8.49 $8.99 $8.49 $8.99 $11.25 $1.25 $11.75 $1.25 $11.75 $9.25 $4.45 $11.25 $2.15 $32.94 $32.94 $32.94 $1.25 $11.25 $11.48 $1.69 $1.09 $17.50 $17.50 $4.45 $6.49 $9.25 $8.75 $9.25 $9.25 $8.75 $8.75 $2.15 $2.95 $17.50 $17.50 $10.98 $11.48 $11.48 $3.39 $8.99 $1.69 $8.99 $1.09 $10.98 $3.39 $8.99 $1.09 $9.25 $8.75 $11.25 $4.45 $2.95 $9.25 $22.20 $22.20 $22.20 $8.49 $8.99 $8.75 $8.75 $11.75 $8.75 $11.25 $9.25 $11.25 $11.25 $8.75 $11.25 $2.95 $1.25 $8.49 $1.69 $11.75 $11.25 $8.75 $8.75 $4.45 $8.49 $3.99 $8.49 $3.99 $11.48 $1.69 $1.09 $11.25 $1.50 $10.58 $1.69 $9.25 $11.25 $8.75 $9.25 $11.25 $11.25 $8.75 $11.75 $8.75 $8.75 $8.75 $2.15 $11.25 $11.75 $2.50 $2.50 $4.45 $9.25 $4.45 $11.25 $8.49 $3.99 $9.25 $9.25 $11.25 $9.25 $11.75 $11.25 $1.25 $23.50 $23.50 $1.25 $8.99 $8.49 $7.40 $7.40 $8.75 $1.25 $4.45 $8.75 $2.15 $8.75 $4.45 $7.40 $7.40 $7.40 $8.99 $3.99 $8.99 $1.69 $8.75 $8.75 $8.75 $8.75 $11.25 $11.25 $2.95 $8.75 $18.50 $18.50 $8.49 $3.99 $2.95 $9.25 $9.25 $3.00 $3.00 $1.25 $8.75 $9.25 $4.45 $8.75 $11.25 $4.45 $10.98 $22.16 $22.16 $4.45 $8.75 $9.25 $6.49 $9.25 $11.25 $8.75 $9.25 $2.15 $9.25 $4.45 $9.25 $2.95 $9.25 $8.75 $9.25 $1.25 $1.25 $8.75 $8.75 $9.25 $4.45 $11.75 $11.75 $11.75 $9.25 $9.25 $16.98 $16.98 $2.39 $3.39 $3.39 $9.25 $11.75 $11.25 $2.15 $8.75 $9.25 $4.45 $10.98 $11.25 $9.25 $22.50 $22.50 $9.25 $2.95 $1.50 $11.48 $8.49 $1.69 $8.49 $8.49 $8.49 $6.78 $6.78 $11.75 $4.45 $8.75 $4.45 $11.89 $9.39 $8.75 $2.95 $1.25 $9.25 $8.75 $23.78 $23.78 $8.75 $9.25 $2.15 $2.15 $1.25 $8.49 $3.99 $10.98 $1.09 $8.75 $4.45 $8.75 $11.75 $2.95 $4.45 $9.25 $8.75 $8.49 $3.99 $22.50 $22.50 $11.25 $1.25 $8.75 $8.75 $18.50 $18.50 $6.49 $8.75 $8.75 $4.45 $8.49 $3.99 $8.99 $1.09 $8.49 $2.39 $11.48 $1.69 $2.50 $2.50 $9.25 $1.50 $17.50 $17.50 $2.95 $8.75 $4.45 $11.75 $8.75 $8.49 $1.69 $8.49 $3.99 $8.99 $8.99 $3.99 $8.99 $11.25 $4.45 $1.25 $3.99 $10.98 $7.40 $3.00 $7.40 $4.00 $8.49 $3.99 $9.25 $4.45 $11.25 $1.25 $11.75 $1.25 $11.25 $2.15 $11.25 $4.45 $3.75 $3.75 $3.75 $11.75 $8.99 $2.39 $8.75 $4.45 $1.25 $8.99 $8.49 $2.18 $2.18 $8.49 $2.18 $2.18 $1.09 $8.75 $2.95 $1.25 $1.50 $11.25 $9.25 $2.95 $1.25 $8.49 $3.99 $11.48 $3.99 $8.49 $11.25 $1.25 $8.99 $1.69 $11.25 $1.25 $6.49 $8.75 $9.25 $8.75 $2.95 $8.75 $11.75 $8.69 $8.69 $2.29 $3.99 $8.49 $8.75 $8.75 $1.25 $11.75 $11.25 $11.25 $11.25 $1.25 $9.25 $11.75 $6.49 $3.99 $8.49 $11.25 $2.15 $11.25 $11.89 $8.99 $1.69 $8.99 $8.99 $3.99 $8.99 $9.25 $9.25 $2.15 $7.40 $7.40 $8.75 $8.75 $9.25 $4.45 $11.25 $1.25 $11.75 $11.25 $1.25 $3.99 $8.49 $8.49 $8.49 $8.99 $8.75 $2.15 $1.25 $8.49 $1.09 $1.09 $8.75 $2.95 $1.25 $9.25 $1.25 $2.15 $11.25 $1.25 $4.45 $8.75 $2.50 $2.50 $8.90 $8.90 $8.75 $8.75 $8.75 $11.25 $11.25 $10.98 $3.99 $10.98 $3.99 $1.69 $8.99 $9.25 $8.75 $8.99 $1.09 $9.25 $2.95 $8.75 $9.25 $3.99 $8.49 $8.75 $8.75 $22.50 $22.50 $10.98 $3.27 $3.27 $3.27 $3.99 $8.99 $1.09 $11.08 $8.75 $4.45 $11.08 $3.99 $8.49 $4.30 $4.30 $9.25 $8.75 $11.25 $11.25 $9.25 $8.49 $8.99 $8.49 $8.75 $2.95 $4.45 $9.25 $2.95 $9.25 $8.75 $11.25 $4.45 $16.98 $16.98 $8.49 $2.39 $11.25 $3.75 $3.75 $3.75 $9.25 $4.45 $9.25 $9.25 $4.45 $8.75 $9.25 $8.75 $9.25 $9.25 $9.25 $11.48 $8.99 $22.50 $22.50 $11.75 $11.25 $1.25 $8.75 $2.15 $1.25 $11.25 $8.75 $1.25 $11.25 $1.50 $11.25 $11.25 $9.25 $6.49 $8.90 $8.90 $8.75 $4.45 $11.25 $1.25 $17.50 $17.50 $9.25 $8.75 $11.75 $3.00 $3.00 $8.49 $8.49 $10.98 $8.99 $3.99 $8.75 $4.45 $8.99 $1.69 $11.75 $8.75 $11.25 $4.45 $11.75 $1.25 $11.75 $2.95 $8.99 $8.99 $2.18 $2.18 $17.98 $17.98 $8.99 $8.49 $1.69 $11.75 $11.25 $2.95 $3.75 $3.75 $3.75 $9.25 $11.75 $8.75 $2.15 $1.50 $8.49 $8.49 $3.39 $8.69 $3.89 $8.75 $4.45 $8.75 $11.25 $2.15 $8.75 $8.49 $1.69 $8.49 $8.49 $1.25 $8.75 $11.75 $11.75 $8.99 $1.09 $8.75 $4.45 $8.75 $2.95 $8.75 $2.15 $3.99 $8.49 $8.99 $3.99 $8.49 $1.69 $1.09 $8.99 $1.09 $9.25 $8.75 $8.99 $2.39 $1.25 $1.25 $11.25 $11.25 $9.25 $9.25 $11.25 $1.50 $3.99 $8.49 $11.25 $9.25 $11.25 $17.50 $17.50 $8.75 $8.90 $8.90 $8.75 $8.75 $8.99 $2.39 $11.25 $9.25 $2.15 $11.25 $1.25 $11.75 $1.25 $11.25 $11.75 $1.25 $11.25 $11.25 $8.49 $10.98 $8.75 $1.25 $8.75 $8.49 $8.49 $1.50 $1.50 $8.75 $4.45 $11.25 $1.25 $11.75 $8.49 $2.39 $9.25 $4.45 $9.25 $8.75 $8.99 $1.69 $17.50 $17.50 $2.39 $8.99 $8.99 $11.25 $4.45 $8.75 $4.45 $9.25 $6.49 $10.98 $8.49 $8.49 $1.09 $1.69 $9.25 $4.45 $8.75 $1.25 $2.95 $3.99 $8.49 $11.75 $11.75 $2.15 $11.48 $8.75 $2.15 $1.25 $11.25 $2.15 $1.25 $8.75 $8.75 $6.49 $1.69 $8.99 $8.75 $11.75 $10.98 $1.09 $8.49 $3.39 $8.75 $2.15 $1.25 $11.48 $10.98 $10.98 $8.49 $2.95 $9.25 $9.25 $11.75 $4.45 $11.48 $11.25 $8.75 $4.45 $1.69 $8.99 $8.75 $4.45 $1.50 $11.75 $2.15 $8.99 $2.39 $8.75 $2.95 $1.25 $8.75 $2.15 $1.25 $2.18 $2.18 $2.18 $2.18 $11.48 $8.75 $2.95 $11.75 $11.75 $1.25 $10.58 $8.99 $2.39 $11.75 $4.45 $11.25 $11.25 $17.50 $17.50 $8.75 $8.75 $8.75 $22.50 $22.50 $9.25 $8.75 $4.45 $11.75 $1.25 $11.25 $11.25 $2.95 $8.99 $1.69 $11.25 $4.45 $8.75 $6.49 $8.75 $4.45 $9.25 $4.45 $11.75 $11.75 $4.45 $11.89 $11.75 $11.25 $2.95 $1.50 $4.45 $8.75 $8.99 $1.09 $8.99 $1.09 $3.99 $11.48 $8.49 $9.25 $4.45 $11.48 $9.25 $2.95 $9.25 $8.49 $8.99 $8.99 $8.49 $8.75 $2.95 $4.45 $11.89 $10.58 $8.19 $1.69 $8.75 $2.15 $1.25 $17.50 $17.50 $6.49 $9.25 $2.15 $8.75 $4.45 $8.75 $1.25 $11.48 $11.48 $8.99 $2.18 $2.18 $8.49 $8.99 $2.39 $2.39 $2.18 $2.18 $8.75 $4.45 $11.25 $9.25 $9.25 $11.25 $11.25 $4.45 $2.95 $11.75 $8.49 $8.49 $8.99 $1.69 $9.25 $11.25 $11.75 $9.25 $8.75 $11.75 $8.75 $8.75 $11.25 $11.25 $10.98 $11.25 $4.45 $10.98 $8.49 $8.99 $3.39 $3.99 $8.99 $1.09 $1.09 $2.39 $17.50 $17.50 $4.45 $11.25 $11.25 $4.45 $9.25 $4.45 $8.75 $2.15 $1.25 $11.89 $2.95 $11.75 $1.25 $11.25 $4.45 $11.48 $11.48 $2.95 $9.25 $8.75 $9.25 $2.95 $11.25 $1.25 $11.75 $1.25 $8.99 $2.39 $1.25 $11.25 $1.25 $11.25 $8.49 $3.99 $35.00 $35.00 $35.00 $35.00 $27.75 $27.75 $27.75 $8.75 $11.80 $11.80 $11.80 $11.80 $8.90 $8.90 $5.90 $5.90 $6.49 $10.98 $17.98 $17.98 $2.39 $9.25 $8.75 $2.15 $8.75 $4.45 $8.49 $1.69 $8.19 $8.69 $10.98 $3.99 $11.48 $11.48 $4.45 $8.75 $6.49 $8.75 $8.75 $9.25 $1.25 $4.45 $8.49 $1.69 $9.25 $4.45 $8.99 $1.09 $11.25 $2.95 $11.08 $11.08 $3.89 $10.98 $11.25 $8.75 $11.25 $9.25 $4.30 $4.30 $8.75 $8.49 $3.99 $1.69 $8.99 $8.49 $1.69 $11.75 $11.25 $11.89 $9.25 $2.95 $9.25 $2.95 $8.75 $4.45 $4.45 $8.75 $10.98 $11.48 $8.49 $9.25 $4.45 $11.75 $11.89 $8.99 $8.49 $8.75 $9.25 $8.75 $8.75 $11.75 $11.75 $4.45 $11.25 $11.75 $2.50 $2.50 $8.99 $1.69 $11.75 $2.15 $1.25 $9.25 $8.75 $8.90 $8.90 $9.25 $2.95 $8.75 $11.25 $8.90 $8.90 $11.25 $11.75 $11.48 $1.69 $3.39 $9.25 $2.95 $8.99 $1.69 $8.49 $10.98 $11.25 $2.95 $8.99 $1.69 $8.75 $2.15 $1.25 $8.75 $2.95 $9.25 $2.50 $2.50 $11.25 $1.25 $11.75 $2.50 $2.50 $11.25 $1.50 $8.75 $1.25 $2.95 $11.48 $11.48 $8.75 $8.75 $2.15 $11.75 $1.25 $9.25 $9.25 $6.49 $11.75 $8.49 $8.49 $1.09 $10.98 $8.75 $1.25 $2.15 $11.25 $1.50 $11.25 $11.25 $8.49 $8.49 $8.75 $1.50 $1.25 $1.50 $8.75 $2.50 $2.50 $2.15 $7.40 $7.40 $4.00 $9.25 $9.39 $9.25 $9.25 $9.39 $11.25 $8.90 $8.90 $11.25 $6.00 $6.00 $6.00 $6.00 $11.25 $11.25 $11.25 $22.50 $22.50 $11.48 $1.09 $8.49 $8.49 $17.50 $17.50 $11.25 $1.50 $9.25 $8.75 $3.99 $8.49 $8.75 $8.75 $8.75 $8.75 $8.75 $11.75 $1.50 $11.25 $11.25 $2.95 $8.99 $10.98 $9.25 $8.75 $4.45 $8.49 $1.09 $2.39 $8.75 $8.75 $11.48 $8.99 $8.49 $8.49 $2.39 $10.98 $8.49 $3.99 $11.75 $4.45 $8.75 $2.15 $1.25 $10.98 $8.99 $11.25 $1.50 $8.75 $2.15 $1.25 $8.75 $9.25 $8.75 $11.25 $1.50 $8.75 $1.25 $4.45 $10.98 $8.75 $2.95 $1.25 $8.75 $2.95 $1.25 $8.49 $8.49 $2.39 $11.25 $1.25 $8.75 $8.75 $9.25 $8.75 $11.89 $1.25 $8.75 $2.15 $1.25 $8.99 $1.09 $8.75 $4.45 $26.25 $26.25 $26.25 $8.75 $4.45 $11.75 $2.95 $8.75 $8.75 $11.75 $8.75 $11.25 $11.25 $11.25 $4.45 $1.25 $8.49 $8.49 $8.49 $8.99 $8.99 $2.39 $2.39 $3.99 $8.75 $4.45 $2.15 $9.25 $1.25 $11.25 $11.75 $8.75 $4.45 $11.25 $2.15 $8.75 $4.45 $8.75 $8.75 $1.25 $11.25 $2.15 $8.75 $5.90 $5.90 $11.75 $1.25 $9.25 $3.75 $3.75 $3.75 $8.75 $1.25 $4.45 $11.75 $4.45 $8.75 $23.50 $23.50 $8.75 $2.95 $8.75 $8.75 $11.89 $4.45 $2.95 $1.25 $8.75 $4.45 $2.95 $1.25 $8.75 $2.15 $1.25 $11.75 $2.95 $8.99 $3.39 $9.25 $9.25 $17.50 $17.50 $2.95 $11.89 $1.50 $11.25 $2.95 $9.25 $11.25 $11.25 $2.95 $8.75 $9.25 $4.30 $4.30 $8.75 $8.75 $11.25 $8.75 $4.30 $4.30 $8.75 $1.25 $2.15 $8.49 $8.49 $3.39 $3.39 $10.98 $10.98 $2.39 $11.25 $11.75 $11.75 $1.25 $5.90 $5.90 $8.75 $11.25 $9.25 $4.45 $1.50 $3.39 $8.99 $2.39 $11.25 $2.15 $11.25 $11.75 $11.75 $4.45 $11.75 $4.45 $9.25 $8.75 $8.49 $8.99 $8.49 $8.99 $11.75 $8.75 $8.49 $3.99 $3.89 $11.08 $8.49 $8.99 $8.49 $8.49 $8.49 $11.25 $2.15 $17.50 $17.50 $8.75 $2.95 $8.49 $8.49 $10.98 $1.09 $11.25 $2.15 $2.95 $1.25 $8.75 $9.25 $9.25 $9.25 $2.95 $8.75 $2.15 $1.25 $8.99 $3.99 $11.75 $2.15 $8.99 $3.39 $9.25 $8.75 $11.25 $11.25 $4.45 $8.75 $2.15 $1.25 $11.75 $4.45 $9.25 $2.95 $8.49 $8.49 $11.25 $8.75 $4.45 $11.25 $11.25 $11.25 $11.25 $4.45 $8.49 $1.69 $8.49 $3.39 $8.75 $11.25 $9.25 $8.75 $11.25 $11.25 $11.75 $11.25 $11.75 $11.25 $11.75 $21.96 $21.96 $10.98 $1.69 $11.48 $8.99 $8.49 $1.69 $9.25 $2.15 $1.50 $11.25 $1.50 $8.75 $8.75 $2.95 $8.49 $1.69 $8.75 $2.95 $1.25 $11.25 $2.15 $11.08 $8.49 $8.49 $8.49 $11.75 $1.25 $11.75 $8.75 $8.75 $8.75 $4.45 $11.25 $1.50 $23.50 $23.50 $11.75 $6.49 $8.75 $4.45 $6.49 $8.75 $2.50 $2.50 $2.15 $8.49 $2.39 $8.75 $11.75 $4.45 $8.99 $10.98 $9.25 $2.95 $9.25 $9.25 $11.75 $8.75 $8.75 $8.75 $10.98 $11.25 $9.25 $8.75 $8.75 $2.15 $11.25 $2.15 $4.45 $11.75 $8.49 $2.39 $9.25 $1.25 $1.25 $1.25 $1.25 $8.75 $2.15 $8.49 $1.69 $11.25 $1.50 $8.75 $8.75 $8.49 $3.99 $8.99 $1.09 $11.25 $1.25 $8.49 $2.39 $8.49 $8.75 $9.25 $11.25 $4.45 $11.25 $11.89 $8.99 $8.49 $8.75 $4.45 $8.75 $11.75 $11.75 $8.90 $8.90 $9.39 $2.95 $8.49 $3.99 $8.75 $2.15 $1.25 $21.96 $21.96 $8.49 $1.69 $8.75 $4.45 $8.49 $8.99 $8.49 $3.99 $8.75 $8.75 $2.95 $8.75 $17.50 $17.50 $9.25 $2.95 $8.75 $6.49 $4.30 $4.30 $8.75 $8.75 $2.15 $1.50 $8.49 $8.49 $2.39 $9.25 $4.45 $6.49 $11.75 $4.45 $10.98 $1.69 $9.39 $9.25 $9.25 $2.95 $8.75 $2.15 $1.25 $11.25 $9.25 $8.75 $11.25 $8.75 $11.25 $2.50 $2.50 $2.50 $2.50 $6.00 $6.00 $6.00 $6.00 $8.90 $8.90 $5.90 $5.90 $11.25 $11.25 $8.49 $10.98 $8.75 $2.15 $1.50 $9.25 $1.25 $1.50 $2.15 $1.25 $8.75 $2.95 $8.49 $3.99 $11.25 $4.30 $4.30 $11.75 $2.15 $18.50 $18.50 $8.49 $2.39 $8.75 $4.45 $11.75 $8.99 $3.99 $9.25 $9.25 $1.50 $8.75 $2.95 $6.49 $11.75 $8.49 $8.99 $8.75 $4.45 $6.49 $22.50 $22.50 $9.25 $2.95 $8.49 $1.69 $10.98 $8.75 $4.45 $11.25 $2.95 $8.99 $8.49 $2.39 $11.75 $6.49 $11.25 $11.75 $2.95 $8.99 $1.69 $8.99 $2.18 $2.18 $1.09 $8.99 $8.99 $1.09 $8.99 $8.99 $8.49 $10.98 $1.09 $11.75 $9.25 $11.25 $11.25 $2.15 $11.25 $8.75 $4.45 $2.95 $11.75 $1.50 $8.99 $10.98 $2.39 $8.75 $2.15 $9.25 $1.50 $8.75 $2.15 $3.99 $8.99 $6.49 $8.75 $8.90 $8.90 $8.99 $3.99 $17.50 $17.50 $11.25 $1.25 $10.98 $9.25 $4.45 $1.25 $3.00 $3.00 $11.25 $4.45 $4.45 $2.95 $9.25 $11.25 $2.15 $11.25 $11.25 $4.45 $2.95 $9.25 $11.25 $1.25 $8.75 $2.95 $1.25 $8.75 $4.45 $11.48 $11.48 $8.49 $2.39 $11.25 $11.75 $2.15 $1.50 $2.15 $8.75 $11.25 $8.90 $8.90 $11.25 $11.25 $1.25 $4.45 $9.25 $9.25 $8.75 $9.25 $8.75 $8.75 $9.25 $8.75 $11.75 $11.75 $8.75 $8.75 $8.90 $8.90 $2.95 $10.98 $8.49 $8.49 $10.98 $8.99 $8.99 $11.75 $17.50 $17.50 $11.75 $3.99 $8.49 $10.98 $1.69 $17.50 $17.50 $8.99 $2.39 $8.99 $2.39 $1.25 $8.75 $2.95 $11.75 $11.25 $17.50 $17.50 $8.49 $8.49 $2.39 $11.25 $1.50 $8.75 $3.00 $3.00 $1.25 $8.75 $4.45 $11.75 $11.75 $4.45 $21.96 $21.96 $8.75 $4.45 $8.75 $11.25 $9.25 $8.99 $2.39 $9.25 $8.75 $10.98 $8.49 $3.99 $3.39 $11.75 $1.50 $4.45 $9.25 $8.75 $1.25 $11.75 $8.75 $1.50 $8.75 $8.75 $2.15 $1.50 $8.75 $2.95 $8.75 $8.75 $17.50 $17.50 $8.75 $6.49 $4.45 $11.25 $11.25 $4.30 $4.30 $8.75 $11.25 $4.45 $8.99 $2.39 $9.25 $9.25 $9.25 $4.45 $11.75 $11.25 $2.95 $2.15 $11.25 $11.25 $8.75 $2.15 $1.50 $9.25 $4.45 $10.98 $8.99 $2.18 $2.18 $8.75 $4.45 $1.25 $8.99 $2.39 $4.45 $8.75 $10.98 $11.75 $1.50 $10.98 $8.99 $8.49 $3.99 $8.99 $8.49 $3.99 $8.49 $8.49 $8.99 $11.25 $11.25 $10.98 $10.98 $10.98 $2.39 $3.39 $8.75 $1.25 $2.95 $11.75 $1.50 $10.98 $1.69 $4.45 $8.75 $8.75 $8.75 $8.75 $4.45 $9.25 $8.75 $11.25 $8.75 $3.99 $8.99 $8.49 $11.25 $11.25 $8.75 $4.45 $8.75 $4.45 $1.25 $8.75 $8.75 $1.50 $2.15 $11.75 $11.75 $11.75 $11.75 $11.75 $1.50 $8.75 $9.25 $1.25 $8.75 $2.15 $8.99 $1.09 $4.45 $11.25 $11.75 $2.15 $8.75 $8.75 $1.25 $9.25 $2.15 $11.75 $11.25 $8.75 $11.25 $4.45 $8.49 $1.69 $8.75 $8.75 $8.99 $8.49 $9.25 $11.25 $2.95 $4.45 $11.75 $6.49 $11.48 $8.99 $4.36 $4.36 $4.36 $4.36 $11.48 $8.99 $8.49 $11.48 $8.75 $2.15 $1.50 $8.99 $1.69 $11.25 $1.25 $9.25 $9.25 $8.75 $9.25 $8.90 $8.90 $2.15 $9.25 $10.98 $8.49 $8.75 $9.25 $4.30 $4.30 $9.25 $8.75 $8.75 $2.15 $1.25 $8.75 $1.25 $8.75 $5.90 $5.90 $9.25 $8.75 $9.25 $4.45 $9.25 $11.75 $2.50 $2.50 $9.25 $2.15 $9.25 $1.50 $1.25 $11.25 $2.95 $8.75 $8.75 $8.75 $10.98 $8.75 $8.75 $8.75 $2.15 $1.25 $10.98 $8.75 $2.15 $1.50 $8.75 $2.95 $1.25 $9.25 $9.25 $8.49 $2.39 $8.75 $4.45 $9.25 $8.75 $8.75 $8.75 $9.25 $8.75 $9.25 $8.75 $8.75 $8.75 $8.75 $9.25 $8.75 $9.25 $8.75 $9.25 $8.75 $8.75 $8.75 $9.25 $8.75 $9.25 $8.75 $8.99 $8.99 $8.75 $2.95 $1.25 $11.75 $1.50 $11.25 $11.25 $8.75 $1.50 $2.15 $16.98 $16.98 $11.75 $1.50 $8.75 $4.30 $4.30 $1.50 $8.75 $2.95 $1.25 $1.25 $9.25 $4.45 $11.25 $8.75 $4.45 $8.75 $2.15 $1.25 $10.98 $1.69 $8.75 $1.25 $8.75 $1.25 $11.25 $8.75 $8.75 $8.49 $1.69 $9.25 $11.75 $8.49 $2.39 $9.25 $2.95 $6.49 $8.75 $8.75 $9.25 $8.75 $6.78 $6.78 $17.98 $17.98 $3.39 $11.75 $11.25 $8.75 $4.45 $11.75 $9.25 $8.75 $6.49 $8.99 $2.39 $8.75 $11.25 $11.75 $4.45 $8.75 $2.15 $9.25 $9.25 $9.25 $11.89 $11.75 $11.25 $9.25 $9.25 $8.75 $8.75 $8.49 $1.69 $1.09 $11.25 $1.50 $11.25 $11.25 $11.75 $1.50 $8.49 $8.99 $22.50 $22.50 $8.75 $4.30 $4.30 $8.75 $11.25 $2.15 $11.25 $2.95 $4.45 $11.25 $8.49 $3.39 $2.39 $11.75 $2.15 $11.75 $8.99 $2.39 $8.75 $11.75 $11.89 $1.25 $7.50 $7.50 $7.50 $7.50 $7.50 $11.89 $1.09 $8.49 $2.39 $8.75 $8.75 $8.75 $8.75 $9.25 $11.25 $8.75 $8.90 $8.90 $9.25 $8.75 $8.75 $11.75 $3.00 $3.00 $1.50 $11.25 $11.75 $8.99 $10.98 $4.45 $8.75 $2.15 $9.25 $11.25 $4.45 $1.69 $10.98 $9.25 $11.75 $9.25 $4.45 $10.98 $3.99 $8.49 $1.25 $9.25 $4.45 $10.98 $8.75 $8.75 $11.75 $11.25 $8.49 $11.48 $4.45 $1.25 $11.25 $8.99 $1.09 $2.39 $11.25 $2.15 $8.75 $4.45 $8.49 $1.69 $10.98 $1.69 $9.25 $4.45 $11.25 $8.75 $11.25 $11.75 $11.25 $22.50 $22.50 $8.49 $2.39 $2.50 $2.50 $8.75 $8.75 $9.25 $9.25 $11.25 $8.99 $1.09 $8.99 $1.69 $11.75 $1.25 $21.96 $21.96 $8.75 $2.15 $1.25 $8.75 $11.25 $9.25 $11.25 $8.75 $8.75 $11.25 $2.15 $8.99 $1.09 $1.69 $8.75 $2.15 $1.25 $8.49 $1.09 $1.09 $1.69 $11.48 $8.49 $8.49 $4.78 $4.78 $9.25 $1.25 $1.25 $1.25 $11.25 $11.25 $11.75 $4.45 $11.25 $4.45 $8.99 $1.09 $11.25 $2.15 $11.25 $9.25 $11.75 $11.25 $11.25 $9.25 $2.95 $11.25 $4.45 $8.75 $2.95 $2.95 $11.25 $1.50 $10.98 $16.98 $16.98 $18.50 $18.50 $10.98 $3.99 $1.09 $9.25 $9.25 $8.75 $4.45 $17.50 $17.50 $8.75 $4.45 $8.75 $1.25 $4.45 $9.25 $8.75 $8.75 $17.50 $17.50 $4.45 $9.39 $1.25 $2.95 $11.25 $8.75 $8.75 $11.25 $2.15 $8.90 $8.90 $11.25 $11.89 $10.98 $11.25 $4.45 $11.25 $11.25 $8.49 $10.98 $8.49 $3.39 $9.25 $8.75 $2.95 $3.00 $3.00 $9.39 $11.75 $2.95 $1.50 $11.25 $11.75 $8.75 $2.15 $1.50 $8.49 $3.39 $11.75 $1.25 $17.50 $17.50 $11.25 $1.25 $8.75 $2.95 $1.25 $11.25 $11.75 $13.35 $13.35 $13.35 $11.25 $11.75 $11.25 $11.25 $4.45 $11.25 $8.49 $3.39 $9.25 $2.95 $4.78 $4.78 $2.39 $3.99 $8.99 $8.99 $11.25 $11.25 $8.75 $11.25 $2.95 $4.45 $9.25 $8.75 $4.45 $8.49 $8.49 $10.98 $10.98 $3.99 $11.75 $8.75 $11.75 $4.45 $1.50 $1.25 $8.49 $8.49 $8.75 $8.75 $8.75 $9.25 $8.75 $2.95 $1.25 $11.25 $1.50 $11.25 $4.45 $9.25 $8.75 $8.75 $9.25 $8.75 $4.45 $1.50 $8.75 $8.75 $8.49 $1.69 $8.75 $2.15 $9.25 $2.15 $1.50 $11.25 $11.75 $2.15 $6.49 $9.25 $9.25 $11.25 $11.25 $11.75 $11.75 $11.75 $11.25 $8.75 $2.15 $1.25 $11.75 $9.25 $11.25 $8.75 $5.90 $5.90 $8.75 $4.45 $9.25 $9.25 $4.45 $11.25 $4.45 $11.25 $8.75 $2.15 $11.89 $11.25 $8.75 $2.95 $1.50 $8.75 $4.30 $4.30 $8.75 $11.25 $11.75 $11.75 $2.15 $11.25 $8.99 $1.09 $8.49 $8.49 $8.49 $3.39 $8.99 $10.98 $3.99 $11.75 $2.15 $8.75 $4.45 $2.50 $2.50 $11.48 $1.09 $8.49 $8.49 $16.98 $16.98 $3.99 $10.98 $1.09 $8.75 $2.95 $8.75 $8.75 $2.95 $9.25 $11.25 $2.15 $9.25 $4.45 $4.45 $9.25 $11.75 $11.75 $2.15 $9.25 $8.75 $11.25 $6.49 $8.75 $11.25 $2.95 $10.98 $3.99 $1.50 $9.25 $2.15 $8.75 $11.25 $11.89 $4.45 $1.50 $1.25 $8.75 $8.75 $4.45 $11.25 $11.75 $8.49 $1.09 $1.09 $1.69 $8.99 $3.39 $8.99 $1.69 $8.49 $8.99 $3.27 $3.27 $3.27 $8.99 $8.99 $1.09 $10.98 $1.69 $3.99 $8.49 $1.09 $8.75 $8.75 $11.75 $8.75 $9.25 $8.75 $3.39 $8.99 $8.99 $2.39 $9.25 $8.75 $9.25 $9.25 $8.99 $3.99 $2.39 $8.49 $1.09 $8.49 $8.99 $3.39 $11.25 $1.25 $8.99 $3.99 $8.75 $8.90 $8.90 $6.49 $8.75 $9.25 $11.25 $11.25 $11.25 $1.25 $8.75 $9.25 $4.45 $1.25 $8.75 $1.25 $2.15 $17.98 $17.98 $8.99 $8.75 $2.95 $1.25 $11.75 $1.50 $1.50 $8.75 $8.75 $11.08 $8.99 $1.69 $8.99 $1.69 $10.98 $3.99 $3.39 $11.75 $2.15 $11.75 $2.95 $8.75 $8.75 $11.75 $11.25 $11.75 $11.25 $4.45 $11.25 $1.25 $2.18 $2.18 $2.18 $2.18 $2.39 $8.49 $8.99 $2.39 $11.25 $8.75 $11.75 $11.75 $11.25 $4.45 $2.15 $8.19 $10.58 $4.45 $9.25 $1.09 $8.99 $11.25 $1.50 $8.99 $3.99 $4.45 $11.75 $2.15 $11.25 $8.75 $4.45 $8.75 $9.25 $6.45 $6.45 $6.45 $8.75 $11.25 $11.25 $8.75 $11.75 $21.96 $21.96 $8.99 $5.07 $5.07 $5.07 $8.49 $9.25 $11.25 $4.45 $3.39 $8.49 $8.99 $8.49 $17.50 $17.50 $22.96 $22.96 $8.75 $11.25 $11.89 $11.25 $8.49 $1.69 $1.09 $8.99 $8.99 $9.25 $8.75 $9.25 $2.95 $8.49 $3.99 $8.99 $8.49 $7.17 $7.17 $7.17 $8.49 $8.99 $17.50 $17.50 $9.25 $9.25 $11.25 $1.25 $8.99 $1.09 $8.75 $4.45 $11.25 $2.15 $11.75 $11.25 $11.25 $8.75 $8.75 $4.45 $1.25 $11.75 $11.75 $2.50 $2.50 $8.49 $8.99 $2.18 $2.18 $11.25 $4.45 $11.25 $11.75 $8.49 $8.99 $1.69 $1.09 $8.99 $8.99 $11.25 $6.49 $11.25 $8.75 $4.45 $8.99 $1.69 $11.48 $11.75 $2.50 $2.50 $8.49 $1.09 $1.09 $1.69 $8.49 $2.39 $11.75 $1.25 $8.49 $1.69 $8.49 $1.69 $11.75 $4.45 $8.75 $8.75 $4.45 $8.75 $11.25 $11.25 $8.75 $7.98 $7.98 $8.49 $1.09 $8.49 $3.99 $8.49 $3.99 $8.99 $3.99 $11.25 $4.45 $8.49 $2.39 $8.49 $2.39 $3.99 $8.49 $1.25 $11.25 $4.45 $9.25 $4.45 $1.09 $8.99 $3.99 $11.25 $8.90 $8.90 $9.25 $11.25 $8.75 $11.25 $11.25 $11.25 $11.25 $11.25 $8.99 $8.49 $8.75 $8.75 $4.45 $16.98 $16.98 $11.75 $11.25 $9.25 $4.45 $9.25 $2.95 $8.49 $1.69 $3.75 $3.75 $3.75 $4.45 $9.25 $1.50 $11.25 $11.48 $11.25 $2.15 $8.75 $9.39 $8.49 $3.99 $8.19 $2.29 $11.48 $1.69 $11.48 $3.99 $8.49 $1.69 $9.25 $2.95 $8.49 $1.69 $11.25 $4.45 $9.39 $9.25 $8.75 $8.75 $4.45 $11.89 $4.45 $4.45 $8.75 $8.75 $8.75 $2.15 $8.75 $3.75 $3.75 $3.75 $9.25 $11.25 $4.45 $6.49 $16.98 $16.98 $18.50 $18.50 $2.50 $2.50 $2.95 $3.99 $8.49 $8.19 $11.08 $6.49 $11.75 $2.39 $8.99 $1.09 $11.25 $4.45 $11.25 $8.99 $1.69 $21.96 $21.96 $2.18 $2.18 $8.99 $8.99 $2.39 $8.69 $1.69 $8.90 $8.90 $2.50 $2.50 $8.75 $8.99 $1.09 $8.49 $8.49 $8.75 $4.45 $17.50 $17.50 $8.75 $9.25 $8.49 $2.39 $8.75 $4.45 $11.25 $11.25 $11.75 $8.75 $8.49 $8.49 $8.49 $8.99 $8.75 $4.45 $11.48 $8.75 $1.25 $2.15 $9.25 $4.45 $11.75 $2.15 $11.25 $8.99 $2.39 $8.69 $8.69 $11.75 $2.95 $11.75 $1.50 $9.25 $4.45 $1.50 $11.48 $8.99 $2.39 $11.25 $11.89 $2.15 $1.25 $11.75 $4.45 $8.75 $8.75 $11.25 $4.45 $11.25 $2.15 $4.45 $8.49 $1.09 $3.99 $11.25 $11.25 $8.49 $2.39 $8.99 $2.39 $11.25 $2.15 $8.75 $2.95 $1.25 $8.75 $11.25 $17.50 $17.50 $11.75 $11.75 $11.25 $11.25 $4.45 $2.50 $2.50 $8.75 $8.99 $8.99 $1.69 $8.99 $1.69 $11.25 $1.25 $11.08 $8.69 $8.99 $1.09 $11.25 $11.25 $2.95 $1.25 $8.75 $1.25 $8.75 $8.75 $2.15 $1.25 $8.49 $3.99 $8.49 $2.39 $8.49 $7.17 $7.17 $7.17 $8.75 $4.45 $11.48 $8.75 $8.75 $11.48 $8.75 $9.25 $8.49 $3.99 $1.50 $11.25 $11.25 $8.75 $8.75 $4.45 $9.25 $4.45 $8.75 $8.75 $4.30 $4.30 $2.95 $8.75 $4.50 $4.50 $4.50 $9.25 $11.25 $4.45 $11.25 $11.25 $8.75 $9.25 $8.75 $2.15 $1.25 $8.75 $2.15 $1.25 $8.99 $8.49 $8.75 $8.75 $1.25 $11.75 $4.50 $4.50 $4.50 $8.75 $8.75 $3.99 $3.39 $8.49 $2.39 $8.99 $1.50 $11.25 $11.25 $8.75 $8.75 $2.15 $8.75 $2.15 $1.25 $21.96 $21.96 $8.49 $1.69 $26.07 $26.07 $26.07 $11.75 $1.50 $8.99 $8.99 $11.48 $9.25 $9.25 $8.75 $8.75 $8.75 $9.25 $8.75 $8.75 $2.15 $1.25 $11.89 $8.75 $11.75 $4.45 $18.50 $18.50 $9.25 $9.39 $8.49 $2.39 $8.49 $1.69 $1.09 $8.99 $8.49 $2.18 $2.18 $11.25 $1.25 $8.49 $3.39 $8.49 $3.99 $11.25 $8.75 $8.49 $1.69 $16.98 $16.98 $9.25 $9.25 $11.75 $1.25 $11.25 $8.75 $8.49 $8.49 $8.75 $1.25 $1.25 $1.25 $11.25 $12.98 $12.98 $11.75 $11.75 $4.45 $11.25 $11.75 $10.98 $8.49 $8.49 $2.39 $9.25 $11.25 $8.75 $2.95 $1.50 $11.25 $2.95 $9.25 $2.95 $9.25 $8.75 $11.25 $8.75 $8.75 $4.45 $11.25 $1.25 $8.75 $2.95 $2.50 $2.50 $9.25 $9.25 $9.25 $6.49 $17.50 $17.50 $8.49 $1.69 $8.49 $3.99 $8.75 $2.95 $2.95 $8.49 $8.99 $8.99 $1.09 $8.75 $4.45 $1.25 $11.25 $11.75 $11.25 $9.25 $11.25 $1.50 $11.25 $2.15 $10.98 $8.75 $11.75 $2.95 $11.25 $11.25 $9.25 $8.75 $9.25 $8.75 $8.75 $8.75 $1.25 $11.25 $1.50 $2.15 $8.75 $8.75 $11.25 $8.75 $8.75 $11.25 $4.45 $8.49 $8.49 $8.49 $8.49 $8.99 $1.69 $2.39 $1.09 $1.09 $11.25 $2.95 $35.25 $35.25 $35.25 $8.75 $2.95 $1.25 $11.25 $2.15 $9.25 $4.45 $8.75 $8.75 $8.75 $4.45 $1.25 $11.89 $8.75 $2.15 $1.25 $8.49 $1.09 $1.09 $1.69 $8.69 $8.69 $9.25 $2.95 $10.98 $2.39 $22.50 $22.50 $21.96 $21.96 $10.98 $8.49 $1.69 $11.75 $2.95 $8.75 $11.25 $8.75 $9.25 $8.75 $8.19 $10.58 $8.75 $2.95 $1.50 $2.50 $2.50 $9.25 $4.45 $9.25 $11.25 $8.69 $8.69 $3.89 $8.69 $1.69 $4.45 $9.25 $11.25 $4.45 $2.15 $8.19 $8.69 $4.45 $11.25 $1.25 $11.25 $8.75 $11.89 $11.75 $11.75 $9.25 $8.75 $2.15 $1.50 $11.75 $4.45 $3.99 $8.99 $10.98 $2.39 $1.25 $2.95 $8.75 $2.95 $9.25 $9.25 $9.25 $8.75 $2.15 $9.25 $9.25 $3.39 $8.49 $8.49 $2.39 $10.98 $1.09 $1.09 $8.49 $11.25 $1.25 $8.99 $1.09 $8.75 $2.15 $1.50 $3.99 $8.49 $8.75 $2.15 $1.50 $8.49 $10.98 $2.18 $2.18 $8.75 $2.15 $1.50 $4.45 $9.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $44.25 $10.50 $10.50 $10.50 $10.50 $10.50 $10.50 $10.50 $6.49 $33.75 $33.75 $33.75 $35.00 $35.00 $35.00 $35.00 $27.75 $27.75 $27.75 $3.00 $3.00 $11.25 $11.75 $10.98 $2.39 $2.50 $2.50 $8.75 $4.45 $16.98 $16.98 $8.75 $6.49 $16.98 $16.98 $17.98 $17.98 $16.98 $16.98 $16.98 $16.98 $8.99 $8.99 $8.49 $9.25 $8.75 $2.95 $11.48 $2.39 $8.99 $2.39 $11.25 $4.45 $8.75 $9.25 $6.49 $26.25 $26.25 $26.25 $8.75 $26.25 $26.25 $26.25 $8.75 $8.75 $11.25 $11.25 $2.15 $1.25 $11.75 $8.75 $2.15 $1.50 $11.25 $2.15 $8.99 $2.39 $11.25 $11.25 $2.15 $11.25 $11.25 $8.75 $4.78 $4.78 $21.96 $21.96 $8.49 $2.39 $9.25 $2.95 $16.98 $16.98 $8.19 $3.89 $8.99 $1.09 $8.99 $3.39 $9.25 $4.45 $10.98 $10.98 $17.50 $17.50 $11.25 $1.25 $8.75 $11.75 $4.45 $11.25 $11.25 $8.99 $1.09 $10.98 $8.49 $1.69 $11.25 $9.25 $16.98 $16.98 $8.75 $4.45 $11.25 $6.49 $11.75 $9.25 $9.25 $8.75 $4.45 $2.50 $2.50 $8.75 $11.75 $8.75 $9.25 $11.75 $9.25 $8.75 $9.25 $8.75 $11.25 $11.75 $9.25 $8.75 $11.75 $8.49 $1.09 $1.09 $8.49 $1.09 $1.69 $11.25 $1.25 $8.75 $2.15 $1.50 $8.49 $1.69 $1.25 $8.75 $2.95 $8.49 $3.99 $8.49 $8.49 $8.75 $11.25 $2.15 $1.50 $11.75 $8.99 $1.09 $10.98 $10.98 $11.25 $1.25 $8.75 $4.45 $4.45 $1.25 $11.89 $8.99 $8.99 $11.25 $4.45 $23.50 $23.50 $8.49 $3.99 $9.25 $4.45 $4.45 $9.25 $8.75 $4.45 $8.75 $8.75 $11.75 $6.49 $17.50 $17.50 $4.45 $8.75 $2.95 $1.50 $8.75 $8.75 $8.75 $4.45 $11.25 $11.25 $11.75 $11.25 $2.95 $11.25 $4.45 $3.00 $3.00 $1.25 $2.95 $9.25 $8.99 $2.39 $6.49 $8.75 $8.90 $8.90 $11.48 $1.09 $10.98 $9.25 $9.25 $11.25 $8.75 $11.75 $11.25 $11.25 $1.25 $9.25 $4.45 $9.25 $6.49 $11.75 $11.75 $8.99 $2.39 $8.49 $8.49 $9.25 $9.25 $1.25 $8.75 $2.95 $11.75 $2.15 $8.49 $8.49 $8.69 $16.38 $16.38 $8.19 $3.89 $2.29 $11.75 $8.75 $8.75 $8.75 $4.45 $8.49 $8.49 $9.25 $8.75 $6.49 $2.95 $11.25 $11.25 $2.15 $9.25 $11.75 $21.96 $21.96 $8.49 $3.39 $1.69 $8.49 $8.75 $4.45 $8.49 $3.99 $11.25 $8.75 $11.25 $2.15 $11.75 $4.45 $11.25 $9.25 $8.75 $18.50 $18.50 $1.50 $8.75 $2.15 $11.48 $2.18 $2.18 $3.99 $11.25 $1.50 $8.99 $2.39 $11.75 $1.50 $11.25 $6.49 $4.45 $11.25 $8.49 $3.99 $2.50 $2.50 $8.75 $9.25 $3.99 $8.99 $8.75 $6.49 $13.52 $13.52 $13.52 $13.52 $13.52 $13.52 $13.52 $13.52 $16.98 $16.98 $16.98 $16.98 $17.98 $17.98 $16.98 $16.98 $8.75 $8.75 $11.25 $11.25 $8.49 $1.09 $1.69 $1.25 $9.25 $2.95 $8.69 $8.19 $8.49 $2.39 $8.49 $2.39 $10.98 $8.99 $8.99 $1.69 $8.49 $8.75 $8.75 $11.25 $4.45 $4.45 $17.50 $17.50 $8.75 $4.45 $8.75 $2.15 $1.50 $1.50 $8.99 $1.09 $8.75 $4.45 $8.75 $8.75 $11.25 $4.30 $4.30 $8.49 $1.69 $1.09 $1.09 $8.75 $2.15 $1.50 $8.99 $8.49 $3.99 $8.75 $2.15 $1.25 $9.25 $2.95 $11.25 $4.45 $9.25 $2.95 $3.99 $8.99 $8.49 $8.75 $8.75 $11.25 $9.25 $8.75 $4.45 $11.25 $1.25 $9.25 $11.25 $4.45 $2.95 $10.98 $8.75 $8.75 $18.50 $18.50 $9.25 $9.25 $5.00 $5.00 $5.00 $5.00 $8.75 $2.95 $16.98 $16.98 $11.25 $2.95 $8.75 $2.15 $1.50 $8.49 $2.39 $9.25 $2.15 $1.25 $8.19 $8.69 $8.19 $8.19 $8.75 $2.95 $1.25 $9.25 $2.95 $11.25 $8.75 $11.25 $11.25 $8.99 $1.09 $9.25 $9.25 $4.45 $8.49 $3.99 $2.39 $1.09 $8.99 $8.49 $8.75 $8.75 $11.25 $11.75 $4.45 $2.50 $2.50 $8.75 $8.49 $3.39 $8.75 $9.25 $4.45 $1.25 $11.25 $2.15 $4.45 $2.50 $2.50 $8.99 $3.99 $8.75 $2.15 $11.75 $11.75 $1.25 $8.75 $9.39 $11.25 $9.25 $9.25 $2.95 $9.25 $4.45 $1.25 $9.25 $8.75 $11.75 $1.50 $8.75 $4.45 $8.99 $1.09 $9.25 $2.95 $8.99 $1.69 $8.69 $1.69 $11.25 $4.45 $8.75 $8.75 $4.45 $11.25 $8.75 $2.95 $1.50 $8.19 $8.69 $1.09 $1.69 $8.49 $8.75 $2.95 $1.25 $8.49 $3.99 $10.98 $3.39 $11.25 $11.25 $2.15 $18.50 $18.50 $8.49 $8.49 $11.25 $1.50 $8.49 $2.39 $8.99 $2.39 $11.75 $4.45 $17.50 $17.50 $9.25 $9.25 $8.75 $4.45 $3.75 $3.75 $3.75 $8.75 $4.45 $11.75 $2.95 $1.25 $4.45 $8.75 $1.25 $1.50 $9.25 $11.25 $11.25 $11.25 $11.25 $9.25 $11.25 $4.45 $8.75 $9.25 $8.75 $8.75 $4.45 $8.75 $1.25 $2.15 $8.75 $8.75 $4.30 $4.30 $8.75 $1.25 $2.95 $9.25 $2.95 $4.45 $11.25 $11.25 $9.25 $9.25 $4.50 $4.50 $4.50 $11.75 $1.25 $11.75 $11.75 $1.25 $1.25 $9.25 $4.45 $11.25 $11.75 $17.50 $17.50 $2.15 $1.25 $11.25 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $15.00 $11.25 $4.45 $4.45 $2.95 $11.25 $2.15 $1.25 $1.50 $8.75 $11.25 $2.95 $11.25 $1.25 $2.15 $11.25 $9.25 $6.49 $1.25 $8.75 $2.15 $8.75 $6.49 $11.25 $1.50 $8.75 $4.45 $8.75 $4.45 $9.25 $9.25 $1.25 $1.25 $8.75 $4.50 $4.50 $4.50 $11.25 $1.25 $1.50 $9.25 $2.15 $11.25 $4.45 $11.25 $4.45 $8.75 $4.45 $9.25 $4.45 $1.25 $11.25 $4.45 $8.75 $4.45 $8.75 $2.15 $8.75 $4.45 $8.75 $11.75 $1.50 $11.25 $4.45 $8.75 $2.15 $1.50 $8.75 $4.45 $8.75 $11.75 $8.75 $8.75 $11.25 $11.25 $1.50 $8.75 $2.15 $11.75 $2.15 $9.25 $2.95 $18.50 $18.50 $1.25 $4.45 $8.50 $8.50 $8.50 $8.50 $11.25 $11.89 $1.25 $9.39 $4.45 $8.75 $2.15 $1.50 $11.75 $8.75 $9.25 $9.25 $4.45 $1.25 $11.25 $9.25 $2.95 $8.75 $8.75 $2.15 $8.75 $11.25 $11.25 $11.25 $11.75 $11.25 $2.15 $11.25 $2.15 $8.99 $8.99 $8.75 $9.25 $9.25 $11.25 $8.75 $4.45 $8.75 $1.25 $4.45 $11.25 $1.25 $8.75 $8.75 $11.25 $8.75 $1.25 $1.25 $1.25 $9.25 $11.75 $2.15 $8.75 $4.45 $8.75 $4.45 $11.25 $9.25 $8.75 $9.25 $4.45 $11.75 $4.45 $1.25 $4.45 $11.75 $9.25 $11.25 $2.15 $23.50 $23.50 $9.25 $2.15 $18.50 $18.50 $8.75 $5.90 $5.90 $11.89 $4.45 $8.75 $4.45 $9.25 $2.95 $11.25 $2.95 $11.25 $11.25 $11.25 $2.95 $11.75 $9.25 $9.25 $2.95 $11.25 $2.15 $9.25 $8.90 $8.90 $8.75 $11.25 $11.25 $11.25 $8.75 $2.15 $1.25 $11.25 $1.25 $8.75 $4.45 $1.25 $11.25 $11.25 $11.75 $1.25 $11.25 $11.25 $11.25 $8.75 $8.75 $18.50 $18.50 $11.75 $1.25 $4.45 $9.25 $6.49 $4.45 $8.75 $11.25 $6.49 $11.75 $8.75 $9.25 $11.25 $2.15 $8.75 $4.45 $11.25 $4.45 $8.75 $9.25 $4.45 $1.25 $1.25 $8.75 $11.25 $11.75 $2.15 $11.75 $4.45 $11.75 $1.25 $11.75 $11.75 $11.25 $4.30 $4.30 $9.39 $9.39 $8.75 $1.25 $9.25 $4.45 $11.25 $1.25 $8.75 $1.25 $2.95 $11.25 $4.45 $8.75 $1.50 $4.45 $4.45 $9.25 $8.75 $2.95 $1.25 $11.25 $2.95 $8.75 $8.75 $8.75 $8.75 $4.30 $4.30 $9.25 $9.39 $4.45 $9.25 $1.25 $22.50 $22.50 $4.45 $2.95 $2.15 $23.50 $23.50 $11.75 $2.15 $1.25 $9.25 $4.45 $11.25 $11.75 $17.50 $17.50 $8.75 $11.75 $11.25 $8.75 $4.45 $11.75 $1.50 $8.75 $8.75 $11.75 $9.25 $11.25 $4.45 $11.75 $9.25 $4.45 $11.25 $8.75 $8.75 $2.15 $1.50 $8.75 $4.45 $9.25 $8.75 $1.50 $1.25 $1.25 $1.25 $8.75 $2.95 $11.25 $11.25 $1.50 $11.75 $11.25 $2.15 $9.25 $8.75 $11.75 $2.95 $1.50 $8.75 $1.50 $1.25 $8.75 $11.75 $11.25 $11.25 $11.75 $11.25 $11.75 $8.75 $17.80 $17.80 $17.80 $17.80 $5.00 $5.00 $5.00 $5.00 $5.00 $5.00 $5.00 $5.00 $8.75 $2.95 $1.25 $11.25 $1.25 $2.15 $11.25 $2.50 $2.50 $9.25 $1.25 $11.25 $2.95 $11.75 $2.15 $11.25 $1.50 $8.99 $1.99 $11.49 $8.75 $4.45 $1.25 $8.75 $4.45 $1.25 $1.50 $11.75 $8.75 $8.75 $11.25 $6.49 $11.75 $8.75 $2.15 $1.25 $6.49 $8.75 $4.45 $8.75 $4.45 $8.75 $11.25 $4.45 $6.49 $9.25 $8.75 $1.25 $4.45 $11.25 $8.75 $1.50 $8.75 $1.50 $1.25 $9.25 $9.39 $4.45 $9.25 $8.75 $4.45 $1.25 $11.25 $11.75 $8.75 $11.25 $9.25 $8.75 $11.25 $2.50 $2.50 $17.50 $17.50 $9.25 $4.45 $11.25 $1.25 $8.75 $4.45 $1.50 $8.75 $1.50 $1.25 $9.39 $8.75 $8.75 $4.45 $11.25 $1.25 $9.25 $4.45 $11.25 $8.75 $3.00 $3.00 $8.75 $2.15 $1.25 $11.25 $11.25 $4.45 $11.25 $11.25 $8.75 $11.75 $11.75 $11.75 $8.75 $4.45 $1.25 $1.50 $8.75 $4.45 $1.25 $9.25 $9.25 $8.75 $4.45 $1.25 $11.75 $11.25 $1.25 $11.75 $11.25 $9.25 $2.15 $1.50 $8.75 $4.45 $11.75 $11.75 $11.25 $8.75 $8.75 ' to numeric\n\n\n\n\n\nStep 17. How many different items are sold?\n\nchipo.item_name.value_counts().count()\n\n50\n\n\n\nSource: Ex2 - Getting and Knowing your Data\n\n01Occupation-Exercises-with-solutions\n\n\nEx3 - Getting and Knowing your Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport numpy as np\n\n\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called users and use the ‘user_id’ as index\n\nusers = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user', \n                      sep='|', index_col='user_id')\n\n\n\nStep 4. See the first 25 entries\n\nusers.head(25)\n\n\n\n\n\n\n\n\nage\ngender\noccupation\nzip_code\n\n\nuser_id\n\n\n\n\n\n\n\n\n1\n24\nM\ntechnician\n85711\n\n\n2\n53\nF\nother\n94043\n\n\n3\n23\nM\nwriter\n32067\n\n\n4\n24\nM\ntechnician\n43537\n\n\n5\n33\nF\nother\n15213\n\n\n6\n42\nM\nexecutive\n98101\n\n\n7\n57\nM\nadministrator\n91344\n\n\n8\n36\nM\nadministrator\n05201\n\n\n9\n29\nM\nstudent\n01002\n\n\n10\n53\nM\nlawyer\n90703\n\n\n11\n39\nF\nother\n30329\n\n\n12\n28\nF\nother\n06405\n\n\n13\n47\nM\neducator\n29206\n\n\n14\n45\nM\nscientist\n55106\n\n\n15\n49\nF\neducator\n97301\n\n\n16\n21\nM\nentertainment\n10309\n\n\n17\n30\nM\nprogrammer\n06355\n\n\n18\n35\nF\nother\n37212\n\n\n19\n40\nM\nlibrarian\n02138\n\n\n20\n42\nF\nhomemaker\n95660\n\n\n21\n26\nM\nwriter\n30068\n\n\n22\n25\nM\nwriter\n40206\n\n\n23\n30\nF\nartist\n48197\n\n\n24\n21\nF\nartist\n94533\n\n\n25\n39\nM\nengineer\n55107\n\n\n\n\n\n\n\n\n\nStep 5. See the last 10 entries\n\nusers.tail(10)\n\n\n\n\n\n\n\n\nage\ngender\noccupation\nzip_code\n\n\nuser_id\n\n\n\n\n\n\n\n\n934\n61\nM\nengineer\n22902\n\n\n935\n42\nM\ndoctor\n66221\n\n\n936\n24\nM\nother\n32789\n\n\n937\n48\nM\neducator\n98072\n\n\n938\n38\nF\ntechnician\n55038\n\n\n939\n26\nF\nstudent\n33319\n\n\n940\n32\nM\nadministrator\n02215\n\n\n941\n20\nM\nstudent\n97229\n\n\n942\n48\nF\nlibrarian\n78209\n\n\n943\n22\nM\nstudent\n77841\n\n\n\n\n\n\n\n\n\nStep 6. What is the number of observations in the dataset?\n\nusers.shape[0]\n\n943\n\n\n\n\nStep 7. What is the number of columns in the dataset?\n\nusers.shape[1]\n\n4\n\n\n\n\nStep 8. Print the name of all the columns.\n\nusers.columns\n\nIndex(['age', 'gender', 'occupation', 'zip_code'], dtype='object')\n\n\n\n\nStep 9. How is the dataset indexed?\n\nusers.index\n\nIndex([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       934, 935, 936, 937, 938, 939, 940, 941, 942, 943],\n      dtype='int64', name='user_id', length=943)\n\n\n\n\nStep 10. What is the data type of each column?\n\nusers.dtypes\n\nage            int64\ngender        object\noccupation    object\nzip_code      object\ndtype: object\n\n\n\n\nStep 11. Print only the occupation column\n\nusers.occupation\n\n#or\n\nusers['occupation']\n\nuser_id\n1         technician\n2              other\n3             writer\n4         technician\n5              other\n           ...      \n939          student\n940    administrator\n941          student\n942        librarian\n943          student\nName: occupation, Length: 943, dtype: object\n\n\n\n\nStep 12. How many different occupations are in this dataset?\n\nusers.occupation.nunique()\n\n21\n\n\n\n\nStep 13. What is the most frequent occupation?\n\nusers.occupation.value_counts().head(1).index[0]\n\n'student'\n\n\n\n\nStep 14. Summarize the DataFrame.\n\nusers.describe() \n\n\n\n\n\n\n\n\nage\n\n\n\n\ncount\n943.000000\n\n\nmean\n34.051962\n\n\nstd\n12.192740\n\n\nmin\n7.000000\n\n\n25%\n25.000000\n\n\n50%\n31.000000\n\n\n75%\n43.000000\n\n\nmax\n73.000000\n\n\n\n\n\n\n\n\n\nStep 15. Summarize all the columns\n\nusers.describe(include = \"all\")\n\n\n\n\n\n\n\n\nage\ngender\noccupation\nzip_code\n\n\n\n\ncount\n943.000000\n943\n943\n943\n\n\nunique\nNaN\n2\n21\n795\n\n\ntop\nNaN\nM\nstudent\n55414\n\n\nfreq\nNaN\n670\n196\n9\n\n\nmean\n34.051962\nNaN\nNaN\nNaN\n\n\nstd\n12.192740\nNaN\nNaN\nNaN\n\n\nmin\n7.000000\nNaN\nNaN\nNaN\n\n\n25%\n25.000000\nNaN\nNaN\nNaN\n\n\n50%\n31.000000\nNaN\nNaN\nNaN\n\n\n75%\n43.000000\nNaN\nNaN\nNaN\n\n\nmax\n73.000000\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nStep 16. Summarize only the occupation column\n\nusers.occupation.describe()\n\ncount         943\nunique         21\ntop       student\nfreq          196\nName: occupation, dtype: object\n\n\n\n\nStep 17. What is the mean age of users?\n\nround(users.age.mean())\n\n34\n\n\n\n\nStep 18. What is the age with least occurrence?\n\nusers.age.value_counts().tail()\n\nage\n7     1\n66    1\n11    1\n10    1\n73    1\nName: count, dtype: int64\n\n\n\nSource: Ex3 - Getting and Knowing your Data\n\n01World-Food-Facts-Exercises-with-solutions\n\n\nExercise 1\n\nStep 1. Go to https://www.kaggle.com/openfoodfacts/world-food-facts/data\n\n\nStep 2. Download the dataset to your computer and unzip it.\n\nimport pandas as pd\nimport numpy as np\n\n\n\nStep 3. Use the tsv file and assign it to a dataframe called food\n\nfood = pd.read_csv('E:\\Yang Fan\\Lab 1\\en.openfoodfacts.org.products.tsv', sep='\\t')\n\n\n\nStep 4. See the first 5 entries\n\nfood.head()\n\n\n\n\n\n\n\n\ncode\nurl\ncreator\ncreated_t\ncreated_datetime\nlast_modified_t\nlast_modified_datetime\nproduct_name\ngeneric_name\nquantity\n...\nfruits-vegetables-nuts_100g\nfruits-vegetables-nuts-estimate_100g\ncollagen-meat-protein-ratio_100g\ncocoa_100g\nchlorophyl_100g\ncarbon-footprint_100g\nnutrition-score-fr_100g\nnutrition-score-uk_100g\nglycemic-index_100g\nwater-hardness_100g\n\n\n\n\n0\n3087\nhttp://world-en.openfoodfacts.org/product/0000...\nopenfoodfacts-contributors\n1474103866\n2016-09-17T09:17:46Z\n1474103893\n2016-09-17T09:18:13Z\nFarine de blé noir\nNaN\n1kg\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n4530\nhttp://world-en.openfoodfacts.org/product/0000...\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nBanana Chips Sweetened (Whole)\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n14.0\n14.0\nNaN\nNaN\n\n\n2\n4559\nhttp://world-en.openfoodfacts.org/product/0000...\nusda-ndb-import\n1489069957\n2017-03-09T14:32:37Z\n1489069957\n2017-03-09T14:32:37Z\nPeanuts\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.0\n0.0\nNaN\nNaN\n\n\n3\n16087\nhttp://world-en.openfoodfacts.org/product/0000...\nusda-ndb-import\n1489055731\n2017-03-09T10:35:31Z\n1489055731\n2017-03-09T10:35:31Z\nOrganic Salted Nut Mix\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n12.0\n12.0\nNaN\nNaN\n\n\n4\n16094\nhttp://world-en.openfoodfacts.org/product/0000...\nusda-ndb-import\n1489055653\n2017-03-09T10:34:13Z\n1489055653\n2017-03-09T10:34:13Z\nOrganic Polenta\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 163 columns\n\n\n\n\n\nStep 5. What is the number of observations in the dataset?\n\nfood.shape\n\n(356027, 163)\n\n\n\nfood.shape[0]\n\n356027\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\nprint(food.shape) \nprint(food.shape[1]) \n\n#OR\n\nfood.info() \n\n(356027, 163)\n163\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 356027 entries, 0 to 356026\nColumns: 163 entries, code to water-hardness_100g\ndtypes: float64(107), object(56)\nmemory usage: 442.8+ MB\n\n\n\n\nStep 7. Print the name of all the columns.\n\nfood.columns\n\nIndex(['code', 'url', 'creator', 'created_t', 'created_datetime',\n       'last_modified_t', 'last_modified_datetime', 'product_name',\n       'generic_name', 'quantity',\n       ...\n       'fruits-vegetables-nuts_100g', 'fruits-vegetables-nuts-estimate_100g',\n       'collagen-meat-protein-ratio_100g', 'cocoa_100g', 'chlorophyl_100g',\n       'carbon-footprint_100g', 'nutrition-score-fr_100g',\n       'nutrition-score-uk_100g', 'glycemic-index_100g',\n       'water-hardness_100g'],\n      dtype='object', length=163)\n\n\n\n\nStep 8. What is the name of 105th column?\n\nfood.columns[104]\n\n'-glucose_100g'\n\n\n\n\nStep 9. What is the type of the observations of the 105th column?\n\nfood.dtypes['-glucose_100g']\n\ndtype('float64')\n\n\n\n\nStep 10. How is the dataset indexed?\n\nfood.index\n\nRangeIndex(start=0, stop=356027, step=1)\n\n\n\n\nStep 11. What is the product name of the 19th observation?\n\nfood.values[18][7]\n\n'Lotus Organic Brown Jasmine Rice'\n\n\n\nSource: Exercise 1\n\n02Chipotle-Exercises-with-solutions\n\n\nEx1 - Filtering and Sorting Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called chipo.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n\nchipo = pd.read_csv(url, sep = '\\t')\n\n\n\nStep 4. How many products cost more than $10.00?\n\n\nprices = [float(value[1 : -1]) for value in chipo.item_price]\n\nchipo.item_price = prices\n\nchipo_filtered = chipo.drop_duplicates(['item_name','quantity','choice_description'])\n\nchipo_one_prod = chipo_filtered[chipo_filtered.quantity == 1]\nchipo_one_prod\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n0\n1\n1\nChips and Fresh Tomato Salsa\nNaN\n2.39\n\n\n1\n1\n1\nIzze\n[Clementine]\n3.39\n\n\n2\n1\n1\nNantucket Nectar\n[Apple]\n3.39\n\n\n3\n1\n1\nChips and Tomatillo-Green Chili Salsa\nNaN\n2.39\n\n\n5\n3\n1\nChicken Bowl\n[Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...\n10.98\n\n\n...\n...\n...\n...\n...\n...\n\n\n4602\n1827\n1\nBarbacoa Burrito\n[Tomatillo Green Chili Salsa]\n9.25\n\n\n4607\n1829\n1\nSteak Burrito\n[Tomatillo Green Chili Salsa, [Rice, Cheese, S...\n11.75\n\n\n4610\n1830\n1\nSteak Burrito\n[Fresh Tomato Salsa, [Rice, Sour Cream, Cheese...\n11.75\n\n\n4611\n1830\n1\nVeggie Burrito\n[Tomatillo Green Chili Salsa, [Rice, Fajita Ve...\n11.25\n\n\n4612\n1831\n1\nCarnitas Bowl\n[Fresh Tomato Salsa, [Fajita Vegetables, Rice,...\n9.25\n\n\n\n\n1806 rows × 5 columns\n\n\n\n\nchipo.query('item_price &gt; 10').item_name.nunique()\n\n31\n\n\n\n\nStep 5. What is the price of each item?\n\nprint a data frame with only two columns item_name and item_price\n\n\nchipo_filtered = chipo.drop_duplicates(['item_name','quantity'])\n\nchipo[(chipo['item_name'] == 'Chicken Bowl') & (chipo['quantity'] == 1)]\n\nchipo_one_prod = chipo_filtered[chipo_filtered.quantity == 1]\n\nprice_per_item = chipo_one_prod[['item_name', 'item_price']]\n\nprice_per_item.sort_values(by = \"item_price\", ascending = False).head(20)\n\n\n\n\n\n\n\n\nitem_name\nitem_price\n\n\n\n\n606\nSteak Salad Bowl\n11.89\n\n\n1229\nBarbacoa Salad Bowl\n11.89\n\n\n1132\nCarnitas Salad Bowl\n11.89\n\n\n7\nSteak Burrito\n11.75\n\n\n168\nBarbacoa Crispy Tacos\n11.75\n\n\n39\nBarbacoa Bowl\n11.75\n\n\n738\nVeggie Soft Tacos\n11.25\n\n\n186\nVeggie Salad Bowl\n11.25\n\n\n62\nVeggie Bowl\n11.25\n\n\n57\nVeggie Burrito\n11.25\n\n\n250\nChicken Salad\n10.98\n\n\n5\nChicken Bowl\n10.98\n\n\n8\nSteak Soft Tacos\n9.25\n\n\n554\nCarnitas Crispy Tacos\n9.25\n\n\n237\nCarnitas Soft Tacos\n9.25\n\n\n56\nBarbacoa Soft Tacos\n9.25\n\n\n92\nSteak Crispy Tacos\n9.25\n\n\n664\nSteak Salad\n8.99\n\n\n54\nSteak Bowl\n8.99\n\n\n3750\nCarnitas Salad\n8.99\n\n\n\n\n\n\n\n\n\n\nStep 6. Sort by the name of the item\n\nchipo.item_name.sort_values()\n\n# OR\n\nchipo.sort_values(by = \"item_name\")\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n3389\n1360\n2\n6 Pack Soft Drink\n[Diet Coke]\n12.98\n\n\n341\n148\n1\n6 Pack Soft Drink\n[Diet Coke]\n6.49\n\n\n1849\n749\n1\n6 Pack Soft Drink\n[Coke]\n6.49\n\n\n1860\n754\n1\n6 Pack Soft Drink\n[Diet Coke]\n6.49\n\n\n2713\n1076\n1\n6 Pack Soft Drink\n[Coke]\n6.49\n\n\n...\n...\n...\n...\n...\n...\n\n\n2384\n948\n1\nVeggie Soft Tacos\n[Roasted Chili Corn Salsa, [Fajita Vegetables,...\n8.75\n\n\n781\n322\n1\nVeggie Soft Tacos\n[Fresh Tomato Salsa, [Black Beans, Cheese, Sou...\n8.75\n\n\n2851\n1132\n1\nVeggie Soft Tacos\n[Roasted Chili Corn Salsa (Medium), [Black Bea...\n8.49\n\n\n1699\n688\n1\nVeggie Soft Tacos\n[Fresh Tomato Salsa, [Fajita Vegetables, Rice,...\n11.25\n\n\n1395\n567\n1\nVeggie Soft Tacos\n[Fresh Tomato Salsa (Mild), [Pinto Beans, Rice...\n8.49\n\n\n\n\n4622 rows × 5 columns\n\n\n\n\n\nStep 7. What was the quantity of the most expensive item ordered?\n\nchipo.sort_values(by = \"item_price\", ascending = False).head(1)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n3598\n1443\n15\nChips and Fresh Tomato Salsa\nNaN\n44.25\n\n\n\n\n\n\n\n\n\nStep 8. How many times was a Veggie Salad Bowl ordered?\n\nchipo_salad = chipo[chipo.item_name == \"Veggie Salad Bowl\"]\n# chipo_salad = chipo.query('item_name == \"Veggie Salad Bowl\"')\n\nlen(chipo_salad)\n\n18\n\n\n\n\nStep 9. How many times did someone order more than one Canned Soda?\n\nchipo_drink_steak_bowl = chipo[(chipo.item_name == \"Canned Soda\") & (chipo.quantity &gt; 1)]\n# chipo_drink_steak_bowl = chipo.query('item_name == \"Canned Soda\" & quantity &gt; 1')\n\nlen(chipo_drink_steak_bowl)\n\n20\n\n\n\nSource: Ex1 - Filtering and Sorting Data\n\n02Euro12-Exercises-with-solutions\n\n\nEx2 - Filtering and Sorting Data\nThis time we are going to pull data directly from the internet.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\n\n\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called euro12.\n\neuro12 = pd.read_csv('https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_%26_Sorting/Euro12/Euro_2012_stats_TEAM.csv', sep=',')\neuro12\n\n\n\n\n\n\n\n\nTeam\nGoals\nShots on target\nShots off target\nShooting Accuracy\n% Goals-to-shots\nTotal shots (inc. Blocked)\nHit Woodwork\nPenalty goals\nPenalties not scored\n...\nSaves made\nSaves-to-shots ratio\nFouls Won\nFouls Conceded\nOffsides\nYellow Cards\nRed Cards\nSubs on\nSubs off\nPlayers Used\n\n\n\n\n0\nCroatia\n4\n13\n12\n51.9%\n16.0%\n32\n0\n0\n0\n...\n13\n81.3%\n41\n62\n2\n9\n0\n9\n9\n16\n\n\n1\nCzech Republic\n4\n13\n18\n41.9%\n12.9%\n39\n0\n0\n0\n...\n9\n60.1%\n53\n73\n8\n7\n0\n11\n11\n19\n\n\n2\nDenmark\n4\n10\n10\n50.0%\n20.0%\n27\n1\n0\n0\n...\n10\n66.7%\n25\n38\n8\n4\n0\n7\n7\n15\n\n\n3\nEngland\n5\n11\n18\n50.0%\n17.2%\n40\n0\n0\n0\n...\n22\n88.1%\n43\n45\n6\n5\n0\n11\n11\n16\n\n\n4\nFrance\n3\n22\n24\n37.9%\n6.5%\n65\n1\n0\n0\n...\n6\n54.6%\n36\n51\n5\n6\n0\n11\n11\n19\n\n\n5\nGermany\n10\n32\n32\n47.8%\n15.6%\n80\n2\n1\n0\n...\n10\n62.6%\n63\n49\n12\n4\n0\n15\n15\n17\n\n\n6\nGreece\n5\n8\n18\n30.7%\n19.2%\n32\n1\n1\n1\n...\n13\n65.1%\n67\n48\n12\n9\n1\n12\n12\n20\n\n\n7\nItaly\n6\n34\n45\n43.0%\n7.5%\n110\n2\n0\n0\n...\n20\n74.1%\n101\n89\n16\n16\n0\n18\n18\n19\n\n\n8\nNetherlands\n2\n12\n36\n25.0%\n4.1%\n60\n2\n0\n0\n...\n12\n70.6%\n35\n30\n3\n5\n0\n7\n7\n15\n\n\n9\nPoland\n2\n15\n23\n39.4%\n5.2%\n48\n0\n0\n0\n...\n6\n66.7%\n48\n56\n3\n7\n1\n7\n7\n17\n\n\n10\nPortugal\n6\n22\n42\n34.3%\n9.3%\n82\n6\n0\n0\n...\n10\n71.5%\n73\n90\n10\n12\n0\n14\n14\n16\n\n\n11\nRepublic of Ireland\n1\n7\n12\n36.8%\n5.2%\n28\n0\n0\n0\n...\n17\n65.4%\n43\n51\n11\n6\n1\n10\n10\n17\n\n\n12\nRussia\n5\n9\n31\n22.5%\n12.5%\n59\n2\n0\n0\n...\n10\n77.0%\n34\n43\n4\n6\n0\n7\n7\n16\n\n\n13\nSpain\n12\n42\n33\n55.9%\n16.0%\n100\n0\n1\n0\n...\n15\n93.8%\n102\n83\n19\n11\n0\n17\n17\n18\n\n\n14\nSweden\n5\n17\n19\n47.2%\n13.8%\n39\n3\n0\n0\n...\n8\n61.6%\n35\n51\n7\n7\n0\n9\n9\n18\n\n\n15\nUkraine\n2\n7\n26\n21.2%\n6.0%\n38\n0\n0\n0\n...\n13\n76.5%\n48\n31\n4\n5\n0\n9\n9\n18\n\n\n\n\n16 rows × 35 columns\n\n\n\n\n\nStep 4. Select only the Goal column.\n\neuro12.Goals\n\n0      4\n1      4\n2      4\n3      5\n4      3\n5     10\n6      5\n7      6\n8      2\n9      2\n10     6\n11     1\n12     5\n13    12\n14     5\n15     2\nName: Goals, dtype: int64\n\n\n\n\nStep 5. How many team participated in the Euro2012?\n\neuro12.shape[0]\n\n16\n\n\n\n\nStep 6. What is the number of columns in the dataset?\n\neuro12.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 16 entries, 0 to 15\nData columns (total 35 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   Team                        16 non-null     object \n 1   Goals                       16 non-null     int64  \n 2   Shots on target             16 non-null     int64  \n 3   Shots off target            16 non-null     int64  \n 4   Shooting Accuracy           16 non-null     object \n 5   % Goals-to-shots            16 non-null     object \n 6   Total shots (inc. Blocked)  16 non-null     int64  \n 7   Hit Woodwork                16 non-null     int64  \n 8   Penalty goals               16 non-null     int64  \n 9   Penalties not scored        16 non-null     int64  \n 10  Headed goals                16 non-null     int64  \n 11  Passes                      16 non-null     int64  \n 12  Passes completed            16 non-null     int64  \n 13  Passing Accuracy            16 non-null     object \n 14  Touches                     16 non-null     int64  \n 15  Crosses                     16 non-null     int64  \n 16  Dribbles                    16 non-null     int64  \n 17  Corners Taken               16 non-null     int64  \n 18  Tackles                     16 non-null     int64  \n 19  Clearances                  16 non-null     int64  \n 20  Interceptions               16 non-null     int64  \n 21  Clearances off line         15 non-null     float64\n 22  Clean Sheets                16 non-null     int64  \n 23  Blocks                      16 non-null     int64  \n 24  Goals conceded              16 non-null     int64  \n 25  Saves made                  16 non-null     int64  \n 26  Saves-to-shots ratio        16 non-null     object \n 27  Fouls Won                   16 non-null     int64  \n 28  Fouls Conceded              16 non-null     int64  \n 29  Offsides                    16 non-null     int64  \n 30  Yellow Cards                16 non-null     int64  \n 31  Red Cards                   16 non-null     int64  \n 32  Subs on                     16 non-null     int64  \n 33  Subs off                    16 non-null     int64  \n 34  Players Used                16 non-null     int64  \ndtypes: float64(1), int64(29), object(5)\nmemory usage: 4.5+ KB\n\n\n\n\nStep 7. View only the columns Team, Yellow Cards and Red Cards and assign them to a dataframe called discipline\n\ndiscipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\ndiscipline\n\n\n\n\n\n\n\n\nTeam\nYellow Cards\nRed Cards\n\n\n\n\n0\nCroatia\n9\n0\n\n\n1\nCzech Republic\n7\n0\n\n\n2\nDenmark\n4\n0\n\n\n3\nEngland\n5\n0\n\n\n4\nFrance\n6\n0\n\n\n5\nGermany\n4\n0\n\n\n6\nGreece\n9\n1\n\n\n7\nItaly\n16\n0\n\n\n8\nNetherlands\n5\n0\n\n\n9\nPoland\n7\n1\n\n\n10\nPortugal\n12\n0\n\n\n11\nRepublic of Ireland\n6\n1\n\n\n12\nRussia\n6\n0\n\n\n13\nSpain\n11\n0\n\n\n14\nSweden\n7\n0\n\n\n15\nUkraine\n5\n0\n\n\n\n\n\n\n\n\n\nStep 8. Sort the teams by Red Cards, then to Yellow Cards\n\ndiscipline.sort_values(['Red Cards', 'Yellow Cards'], ascending = False)\n\n\n\n\n\n\n\n\nTeam\nYellow Cards\nRed Cards\n\n\n\n\n6\nGreece\n9\n1\n\n\n9\nPoland\n7\n1\n\n\n11\nRepublic of Ireland\n6\n1\n\n\n7\nItaly\n16\n0\n\n\n10\nPortugal\n12\n0\n\n\n13\nSpain\n11\n0\n\n\n0\nCroatia\n9\n0\n\n\n1\nCzech Republic\n7\n0\n\n\n14\nSweden\n7\n0\n\n\n4\nFrance\n6\n0\n\n\n12\nRussia\n6\n0\n\n\n3\nEngland\n5\n0\n\n\n8\nNetherlands\n5\n0\n\n\n15\nUkraine\n5\n0\n\n\n2\nDenmark\n4\n0\n\n\n5\nGermany\n4\n0\n\n\n\n\n\n\n\n\n\nStep 9. Calculate the mean Yellow Cards given per Team\n\n\nround(discipline['Yellow Cards'].mean())\n\n7\n\n\n\n\nStep 10. Filter teams that scored more than 6 goals\n\neuro12[euro12.Goals &gt; 6]\n\n\n\n\n\n\n\n\nTeam\nGoals\nShots on target\nShots off target\nShooting Accuracy\n% Goals-to-shots\nTotal shots (inc. Blocked)\nHit Woodwork\nPenalty goals\nPenalties not scored\n...\nSaves made\nSaves-to-shots ratio\nFouls Won\nFouls Conceded\nOffsides\nYellow Cards\nRed Cards\nSubs on\nSubs off\nPlayers Used\n\n\n\n\n5\nGermany\n10\n32\n32\n47.8%\n15.6%\n80\n2\n1\n0\n...\n10\n62.6%\n63\n49\n12\n4\n0\n15\n15\n17\n\n\n13\nSpain\n12\n42\n33\n55.9%\n16.0%\n100\n0\n1\n0\n...\n15\n93.8%\n102\n83\n19\n11\n0\n17\n17\n18\n\n\n\n\n2 rows × 35 columns\n\n\n\n\n\nStep 11. Select the teams that start with G\n\neuro12[euro12.Team.str.startswith('G')]\n\n\n\n\n\n\n\n\nTeam\nGoals\nShots on target\nShots off target\nShooting Accuracy\n% Goals-to-shots\nTotal shots (inc. Blocked)\nHit Woodwork\nPenalty goals\nPenalties not scored\n...\nSaves made\nSaves-to-shots ratio\nFouls Won\nFouls Conceded\nOffsides\nYellow Cards\nRed Cards\nSubs on\nSubs off\nPlayers Used\n\n\n\n\n5\nGermany\n10\n32\n32\n47.8%\n15.6%\n80\n2\n1\n0\n...\n10\n62.6%\n63\n49\n12\n4\n0\n15\n15\n17\n\n\n6\nGreece\n5\n8\n18\n30.7%\n19.2%\n32\n1\n1\n1\n...\n13\n65.1%\n67\n48\n12\n9\n1\n12\n12\n20\n\n\n\n\n2 rows × 35 columns\n\n\n\n\n\nStep 12. Select the first 7 columns\n\neuro12.iloc[: , 0:7]\n\n\n\n\n\n\n\n\nTeam\nGoals\nShots on target\nShots off target\nShooting Accuracy\n% Goals-to-shots\nTotal shots (inc. Blocked)\n\n\n\n\n0\nCroatia\n4\n13\n12\n51.9%\n16.0%\n32\n\n\n1\nCzech Republic\n4\n13\n18\n41.9%\n12.9%\n39\n\n\n2\nDenmark\n4\n10\n10\n50.0%\n20.0%\n27\n\n\n3\nEngland\n5\n11\n18\n50.0%\n17.2%\n40\n\n\n4\nFrance\n3\n22\n24\n37.9%\n6.5%\n65\n\n\n5\nGermany\n10\n32\n32\n47.8%\n15.6%\n80\n\n\n6\nGreece\n5\n8\n18\n30.7%\n19.2%\n32\n\n\n7\nItaly\n6\n34\n45\n43.0%\n7.5%\n110\n\n\n8\nNetherlands\n2\n12\n36\n25.0%\n4.1%\n60\n\n\n9\nPoland\n2\n15\n23\n39.4%\n5.2%\n48\n\n\n10\nPortugal\n6\n22\n42\n34.3%\n9.3%\n82\n\n\n11\nRepublic of Ireland\n1\n7\n12\n36.8%\n5.2%\n28\n\n\n12\nRussia\n5\n9\n31\n22.5%\n12.5%\n59\n\n\n13\nSpain\n12\n42\n33\n55.9%\n16.0%\n100\n\n\n14\nSweden\n5\n17\n19\n47.2%\n13.8%\n39\n\n\n15\nUkraine\n2\n7\n26\n21.2%\n6.0%\n38\n\n\n\n\n\n\n\n\n\nStep 13. Select all columns except the last 3.\n\neuro12.iloc[: , :-3]\n\n\n\n\n\n\n\n\nTeam\nGoals\nShots on target\nShots off target\nShooting Accuracy\n% Goals-to-shots\nTotal shots (inc. Blocked)\nHit Woodwork\nPenalty goals\nPenalties not scored\n...\nClean Sheets\nBlocks\nGoals conceded\nSaves made\nSaves-to-shots ratio\nFouls Won\nFouls Conceded\nOffsides\nYellow Cards\nRed Cards\n\n\n\n\n0\nCroatia\n4\n13\n12\n51.9%\n16.0%\n32\n0\n0\n0\n...\n0\n10\n3\n13\n81.3%\n41\n62\n2\n9\n0\n\n\n1\nCzech Republic\n4\n13\n18\n41.9%\n12.9%\n39\n0\n0\n0\n...\n1\n10\n6\n9\n60.1%\n53\n73\n8\n7\n0\n\n\n2\nDenmark\n4\n10\n10\n50.0%\n20.0%\n27\n1\n0\n0\n...\n1\n10\n5\n10\n66.7%\n25\n38\n8\n4\n0\n\n\n3\nEngland\n5\n11\n18\n50.0%\n17.2%\n40\n0\n0\n0\n...\n2\n29\n3\n22\n88.1%\n43\n45\n6\n5\n0\n\n\n4\nFrance\n3\n22\n24\n37.9%\n6.5%\n65\n1\n0\n0\n...\n1\n7\n5\n6\n54.6%\n36\n51\n5\n6\n0\n\n\n5\nGermany\n10\n32\n32\n47.8%\n15.6%\n80\n2\n1\n0\n...\n1\n11\n6\n10\n62.6%\n63\n49\n12\n4\n0\n\n\n6\nGreece\n5\n8\n18\n30.7%\n19.2%\n32\n1\n1\n1\n...\n1\n23\n7\n13\n65.1%\n67\n48\n12\n9\n1\n\n\n7\nItaly\n6\n34\n45\n43.0%\n7.5%\n110\n2\n0\n0\n...\n2\n18\n7\n20\n74.1%\n101\n89\n16\n16\n0\n\n\n8\nNetherlands\n2\n12\n36\n25.0%\n4.1%\n60\n2\n0\n0\n...\n0\n9\n5\n12\n70.6%\n35\n30\n3\n5\n0\n\n\n9\nPoland\n2\n15\n23\n39.4%\n5.2%\n48\n0\n0\n0\n...\n0\n8\n3\n6\n66.7%\n48\n56\n3\n7\n1\n\n\n10\nPortugal\n6\n22\n42\n34.3%\n9.3%\n82\n6\n0\n0\n...\n2\n11\n4\n10\n71.5%\n73\n90\n10\n12\n0\n\n\n11\nRepublic of Ireland\n1\n7\n12\n36.8%\n5.2%\n28\n0\n0\n0\n...\n0\n23\n9\n17\n65.4%\n43\n51\n11\n6\n1\n\n\n12\nRussia\n5\n9\n31\n22.5%\n12.5%\n59\n2\n0\n0\n...\n0\n8\n3\n10\n77.0%\n34\n43\n4\n6\n0\n\n\n13\nSpain\n12\n42\n33\n55.9%\n16.0%\n100\n0\n1\n0\n...\n5\n8\n1\n15\n93.8%\n102\n83\n19\n11\n0\n\n\n14\nSweden\n5\n17\n19\n47.2%\n13.8%\n39\n3\n0\n0\n...\n1\n12\n5\n8\n61.6%\n35\n51\n7\n7\n0\n\n\n15\nUkraine\n2\n7\n26\n21.2%\n6.0%\n38\n0\n0\n0\n...\n0\n4\n4\n13\n76.5%\n48\n31\n4\n5\n0\n\n\n\n\n16 rows × 32 columns\n\n\n\n\n\nStep 14. Present only the Shooting Accuracy from England, Italy and Russia\n\neuro12.loc[euro12.Team.isin(['England', 'Italy', 'Russia']), ['Team','Shooting Accuracy']]\n\n\n\n\n\n\n\n\nTeam\nShooting Accuracy\n\n\n\n\n3\nEngland\n50.0%\n\n\n7\nItaly\n43.0%\n\n\n12\nRussia\n22.5%\n\n\n\n\n\n\n\n\nSource: Ex2 - Filtering and Sorting Data\n\n03Chipotle-Exercises-with-solutions(1)\n\n\nVisualizing Chipotle’s Data\nThis time we are going to pull data directly from the internet. Special thanks to: https://github.com/justmarkham for sharing the dataset and materials.\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n# set this so the graphs open internally\n%matplotlib inline\n\n\n\nStep 2. Import the dataset from this address.\n\n\nStep 3. Assign it to a variable called chipo.\n\nurl = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n    \nchipo = pd.read_csv(url, sep = '\\t')\n\n\n\nStep 4. See the first 10 entries\n\nchipo.head(10)\n\n\n\n\n\n\n\n\norder_id\nquantity\nitem_name\nchoice_description\nitem_price\n\n\n\n\n0\n1\n1\nChips and Fresh Tomato Salsa\nNaN\n$2.39\n\n\n1\n1\n1\nIzze\n[Clementine]\n$3.39\n\n\n2\n1\n1\nNantucket Nectar\n[Apple]\n$3.39\n\n\n3\n1\n1\nChips and Tomatillo-Green Chili Salsa\nNaN\n$2.39\n\n\n4\n2\n2\nChicken Bowl\n[Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n$16.98\n\n\n5\n3\n1\nChicken Bowl\n[Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...\n$10.98\n\n\n6\n3\n1\nSide of Chips\nNaN\n$1.69\n\n\n7\n4\n1\nSteak Burrito\n[Tomatillo Red Chili Salsa, [Fajita Vegetables...\n$11.75\n\n\n8\n4\n1\nSteak Soft Tacos\n[Tomatillo Green Chili Salsa, [Pinto Beans, Ch...\n$9.25\n\n\n9\n5\n1\nSteak Burrito\n[Fresh Tomato Salsa, [Rice, Black Beans, Pinto...\n$9.25\n\n\n\n\n\n\n\n\n\nStep 5. Create a histogram of the top 5 items bought\n\n# get the Series of the names\nx = chipo.item_name\n\n# use the Counter class from collections to create a dictionary with keys(text) and frequency\nletter_counts = Counter(x)\n\n# convert the dictionary to a DataFrame\ndf = pd.DataFrame.from_dict(letter_counts, orient='index')\n\n# sort the values from the top to the least value and slice the first 5 items\ndf = df[0].sort_values(ascending = True)[45:50]\n\n# create the plot\ndf.plot(kind='bar')\n\n# Set the title and labels\nplt.xlabel('Items')\nplt.ylabel('Number of Times Ordered')\nplt.title('Most ordered Chipotle\\'s Items')\n\n# show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\nStep 6. Create a scatterplot with the number of items orderered per order price\n\nHint: Price should be in the X-axis and Items ordered in the Y-axis\n\n# create a list of prices\nchipo.item_price = [float(value[1:-1]) for value in chipo.item_price] # strip the dollar sign and trailing space\n\n# then groupby the orders and sum\norders = chipo.groupby('order_id').sum()\n\n# creates the scatterplot\n# plt.scatter(orders.quantity, orders.item_price, s = 50, c = 'green')\nplt.scatter(x = orders.item_price, y = orders.quantity, s = 50, c = 'green')\n\n# Set the title and labels\nplt.xlabel('Order Price')\nplt.ylabel('Items ordered')\nplt.title('Number of items ordered per order price')\nplt.ylim(0)\n\n(0.0, 36.7)\n\n\n\n\n\nStep 7. BONUS: Create a question and a graph to answer your own question.\n\nSource: Visualizing Chipotle's Data\n\n03Scores-Exercises-with-solutions\n\n\nScores\n\nIntroduction:\nThis time you will create the data.\nExercise based on Chris Albon work, the credits belong to him.\n\n\nStep 1. Import the necessary libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n%matplotlib inline\n\n\n\nStep 2. Create the DataFrame that should look like the one below.\n\nraw_data = {'first_name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n            'last_name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze'], \n            'female': [0, 1, 1, 0, 1],\n            'age': [42, 52, 36, 24, 73], \n            'preTestScore': [4, 24, 31, 2, 3],\n            'postTestScore': [25, 94, 57, 62, 70]}\n\ndf = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'female', 'preTestScore', 'postTestScore'])\n\ndf\n\n\n\n\n\n\n\n\nfirst_name\nlast_name\nage\nfemale\npreTestScore\npostTestScore\n\n\n\n\n0\nJason\nMiller\n42\n0\n4\n25\n\n\n1\nMolly\nJacobson\n52\n1\n24\n94\n\n\n2\nTina\nAli\n36\n1\n31\n57\n\n\n3\nJake\nMilner\n24\n0\n2\n62\n\n\n4\nAmy\nCooze\n73\n1\n3\n70\n\n\n\n\n\n\n\n\n\nStep 3. Create a Scatterplot of preTestScore and postTestScore, with the size of each point determined by age\n\nHint: Don’t forget to place the labels\n\nplt.scatter(df.preTestScore, df.postTestScore, s=df.age)\n\n#set labels and titles\nplt.title(\"preTestScore x postTestScore\")\nplt.xlabel('preTestScore')\nplt.ylabel('preTestScore')\n\nText(0, 0.5, 'preTestScore')\n\n\n\n\n\nStep 4. Create a Scatterplot of preTestScore and postTestScore.\n\n\nThis time the size should be 4.5 times the postTestScore and the color determined by sex\n\nplt.scatter(df.preTestScore, df.postTestScore, s= df.postTestScore * 4.5, c = df.female)\n\n#set labels and titles\nplt.title(\"preTestScore x postTestScore\")\nplt.xlabel('preTestScore')\nplt.ylabel('preTestScore')\n\nText(46.972222222222214, 0.5, 'preTestScore')\n\n\n\n\nBONUS: Create your own question and answer it.\n\nSource: Scores"
  }
]